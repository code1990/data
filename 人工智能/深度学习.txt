1	{"count":99,"start":0,"total":292,"books":[{"rating":{"max":10,"numRaters":809,"average":"8.4","min":0},"subtitle":"","author":["[美] 伊恩·古德费洛","[加] 约书亚·本吉奥","[加] 亚伦·库维尔"],"pubdate":"2017-7-1","tags":[{"count":1205,"name":"深度学习","title":"深度学习"},{"count":889,"name":"人工智能","title":"人工智能"},{"count":699,"name":"机器学习","title":"机器学习"},{"count":367,"name":"计算机","title":"计算机"},{"count":330,"name":"计算机科学","title":"计算机科学"},{"count":250,"name":"算法","title":"算法"},{"count":210,"name":"数学","title":"数学"},{"count":143,"name":"AI","title":"AI"}],"origin_title":"Deep Learning: Adaptive Computation and Machine Learning series","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29518349.jpg","binding":"平装","translator":["赵申剑","黎彧君","符天凡","李凯"],"catalog":"第 1 章 引言 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 本书面向的读者 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7\n1.2 深度学习的历史趋势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.1 神经网络的众多名称和命运变迁 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.2 与日俱增的数据量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n1.2.3 与日俱增的模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\n1.2.4 与日俱增的精度、复杂度和对现实世界的冲击 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n第 1 部分 应用数学与机器学习基础\n第 2 章 线性代数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.1 标量、向量、矩阵和张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.2 矩阵和向量相乘. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21\n2.3 单位矩阵和逆矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.4 线性相关和生成子空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5 范数. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24\n2.6 特殊类型的矩阵和向量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.7 特征分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.8 奇异值分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.9 Moore-Penrose 伪逆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.10 迹运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.11 行列式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n2.12 实例：主成分分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .30\n第 3 章 概率与信息论. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\n3.1 为什么要使用概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.2 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.3 概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.3.1 离散型变量和概率质量函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.3.2 连续型变量和概率密度函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.4 边缘概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.5 条件概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.6 条件概率的链式法则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.7 独立性和条件独立性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.8 期望、方差和协方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.9 常用概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n3.9.1 Bernoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.9.2 Multinoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.9.3 高斯分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.9.4 指数分布和 Laplace 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n3.9.5 Dirac 分布和经验分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n3.9.6 分布的混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n3.10 常用函数的有用性质. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .43\n3.11 贝叶斯规则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.12 连续型变量的技术细节 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3.13 信息论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n3.14 结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n第 4 章 数值计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.1 上溢和下溢 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n4.2 病态条件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3 基于梯度的优化方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3.1 梯度之上：Jacobian 和 Hessian 矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.4 约束优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n4.5 实例：线性最小二乘 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n第 5 章 机器学习基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63\n5.1 学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.1.1 任务 T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.1.2 性能度量 P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n5.1.3 经验 E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n5.1.4 示例：线性回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n5.2 容量、过拟合和欠拟合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n5.2.1 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.2.2 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n5.3 超参数和验证集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .76\n5.3.1 交叉验证 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5.4 估计、偏差和方差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\n5.4.1 点估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n5.4.2 偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n5.4.3 方差和标准差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n5.4.4 权衡偏差和方差以最小化均方误差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n5.4.5 一致性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n5.5 最大似然估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n5.5.1 条件对数似然和均方误差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84\n5.5.2 最大似然的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n5.6 贝叶斯统计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n5.6.1 最大后验 (MAP) 估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n5.7 监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n5.7.1 概率监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n5.7.2 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n5.7.3 其他简单的监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\n5.8 无监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91\n5.8.1 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n5.8.2 k-均值聚类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94\n5.9 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n5.10 构建机器学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n5.11 促使深度学习发展的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n5.11.1 维数灾难 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n5.11.2 局部不变性和平滑正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n5.11.3 流形学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n第 2 部分 深度网络：现代实践\n第 6 章 深度前馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n6.1 实例：学习 XOR. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n6.2 基于梯度的学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n6.2.1 代价函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n6.2.2 输出单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n6.3 隐藏单元. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .119\n6.3.1 整流线性单元及其扩展 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n6.3.2 logistic sigmoid 与双曲正切函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n6.3.3 其他隐藏单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n6.4 架构设计. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123\n6.4.1 万能近似性质和深度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123\n6.4.2 其他架构上的考虑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\n6.5 反向传播和其他的微分算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\n6.5.1 计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n6.5.2 微积分中的链式法则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128\n6.5.3 递归地使用链式法则来实现反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n6.5.4 全连接 MLP 中的反向传播计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n6.5.5 符号到符号的导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .131\n6.5.6 一般化的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133\n6.5.7 实例：用于 MLP 训练的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\n6.5.8 复杂化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n6.5.9 深度学习界以外的微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\n6.5.10 高阶微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\n6.6 历史小记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .139\n第 7 章 深度学习中的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n7.1 参数范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n7.1.1 L2 参数正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\n7.1.2 L1 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n7.2 作为约束的范数惩罚. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .146\n7.3 正则化和欠约束问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .147\n7.4 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n7.5 噪声鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n7.5.1 向输出目标注入噪声. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150\n7.6 半监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\n7.7 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\n7.8 提前终止. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151\n7.9 参数绑定和参数共享. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .156\n7.9.1 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\n7.10 稀疏表示. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .157\n7.11 Bagging 和其他集成方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158\n7.12 Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .159\n7.13 对抗训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165\n7.14 切面距离、正切传播和流形正切分类器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n第 8 章 深度模型中的优化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169\n8.1 学习和纯优化有什么不同 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n8.1.1 经验风险最小化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n8.1.2 代理损失函数和提前终止 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n8.1.3 批量算法和小批量算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n8.2 神经网络优化中的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\n8.2.1 病态 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\n8.2.2 局部极小值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n8.2.3 高原、鞍点和其他平坦区域 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175\n8.2.4 悬崖和梯度爆炸 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n8.2.5 长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n8.2.6 非精确梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n8.2.7 局部和全局结构间的弱对应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n8.2.8 优化的理论限制 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\n8.3 基本算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .180\n8.3.1 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\n8.3.2 动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\n8.3.3 Nesterov 动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .183\n8.4 参数初始化策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n8.5 自适应学习率算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\n8.5.1 AdaGrad . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\n8.5.2 RMSProp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\n8.5.3 Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n8.5.4 选择正确的优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .190\n8.6 二阶近似方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190\n8.6.1 牛顿法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190\n8.6.2 共轭梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n8.6.3 BFGS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n8.7 优化策略和元算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n8.7.1 批标准化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n8.7.2 坐标下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\n8.7.3 Polyak 平均 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\n8.7.4 监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\n8.7.5 设计有助于优化的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199\n8.7.6 延拓法和课程学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .199\n第 9 章 卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\n9.1 卷积运算. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\n9.2 动机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n9.3 池化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n9.4 卷积与池化作为一种无限强的先验 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\n9.5 基本卷积函数的变体. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211\n9.6 结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\n9.7 数据类型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\n9.8 高效的卷积算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\n9.9 随机或无监督的特征. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .220\n9.10 卷积网络的神经科学基础 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n9.11 卷积网络与深度学习的历史 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\n第 10 章 序列建模：循环和递归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\n10.1 展开计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n10.2 循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .230\n10.2.1 导师驱动过程和输出循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n10.2.2 计算循环神经网络的梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\n10.2.3 作为有向图模型的循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n10.2.4 基于上下文的 RNN 序列建模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\n10.3 双向 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239\n10.4 基于编码 - 解码的序列到序列架构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\n10.5 深度循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242\n10.6 递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\n10.7 长期依赖的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\n10.8 回声状态网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245\n10.9 渗漏单元和其他多时间尺度的策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\n10.9.1 时间维度的跳跃连接. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\n10.9.2 渗漏单元和一系列不同时间尺度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\n10.9.3 删除连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\n10.10 长短期记忆和其他门控 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\n10.10.1 LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\n10.10.2 其他门控 RNN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .250\n10.11 优化长期依赖. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\n10.11.1 截断梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n10.11.2 引导信息流的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\n10.12 外显记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\n第 11 章 实践方法论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\n11.1 性能度量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .256\n11.2 默认的基准模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\n11.3 决定是否收集更多数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n11.4 选择超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n11.4.1 手动调整超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .259\n11.4.2 自动超参数优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .262\n11.4.3 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n11.4.4 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\n11.4.5 基于模型的超参数优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\n11.5 调试策略. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .264\n11.6 示例：多位数字识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267\n第 12 章 应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .269\n12.1 大规模深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n12.1.1 快速的 CPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n12.1.2 GPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n12.1.3 大规模的分布式实现. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .271\n12.1.4 模型压缩 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\n12.1.5 动态结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n12.1.6 深度网络的专用硬件实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\n12.2 计算机视觉 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\n12.2.1 预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\n12.2.2 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\n12.3 语音识别. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .278\n12.4 自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .279\n12.4.1 n-gram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .280\n12.4.2 神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\n12.4.3 高维输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\n12.4.4 结合 n-gram 和神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\n12.4.5 神经机器翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\n12.4.6 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\n12.5 其他应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .290\n12.5.1 推荐系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\n12.5.2 知识表示、推理和回答 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292\n第 3 部分 深度学习研究\n第 13 章 线性因子模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\n13.1 概率 PCA 和因子分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\n13.2 独立成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .298\n13.3 慢特征分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\n13.4 稀疏编码. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .301\n13.5 PCA 的流形解释 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\n第 14 章 自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\n14.1 欠完备自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\n14.2 正则自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .307\n14.2.1 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n14.2.2 去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\n14.2.3 惩罚导数作为正则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .309\n14.3 表示能力、层的大小和深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\n14.4 随机编码器和解码器. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\n14.5 去噪自编码器详解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311\n14.5.1 得分估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\n14.5.2 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\n14.6 使用自编码器学习流形 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\n14.7 收缩自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .317\n14.8 预测稀疏分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .319\n14.9 自编码器的应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\n第 15 章 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\n15.1 贪心逐层无监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\n15.1.1 何时以及为何无监督预训练有效有效 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\n15.2 迁移学习和领域自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326\n15.3 半监督解释因果关系. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\n15.4 分布式表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\n15.5 得益于深度的指数增益 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\n15.6 提供发现潜在原因的线索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337\n第 16 章 深度学习中的结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339\n16.1 非结构化建模的挑战. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .339\n16.2 使用图描述模型结构. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .342\n16.2.1 有向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\n16.2.2 无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\n16.2.3 配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345\n16.2.4 基于能量的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346\n16.2.5 分离和 d-分离 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .347\n16.2.6 在有向模型和无向模型中转换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\n16.2.7 因子图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\n16.3 从图模型中采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\n16.4 结构化建模的优势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\n16.5 学习依赖关系 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\n16.6 推断和近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\n16.7 结构化概率模型的深度学习方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .355\n16.7.1 实例：受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356\n第 17 章 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359\n17.1 采样和蒙特卡罗方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359\n17.1.1 为什么需要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359\n17.1.2 蒙特卡罗采样的基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359\n17.2 重要采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .360\n17.3 马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362\n17.4 Gibbs 采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .365\n17.5 不同的峰值之间的混合挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\n17.5.1 不同峰值之间通过回火来混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367\n17.5.2 深度也许会有助于混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\n第 18 章 直面配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\n18.1 对数似然梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .369\n18.2 随机最大似然和对比散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\n18.3 伪似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375\n18.4 得分匹配和比率匹配. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .376\n18.5 去噪得分匹配 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .378\n18.6 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .378\n18.7 估计配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .380\n18.7.1 退火重要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382\n18.7.2 桥式采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\n第 19 章 近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\n19.1 把推断视作优化问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .385\n19.2 期望最大化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386\n19.3 最大后验推断和稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387\n19.4 变分推断和变分学习. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .389\n19.4.1 离散型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390\n19.4.2 变分法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394\n19.4.3 连续型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396\n19.4.4 学习和推断之间的相互作用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397\n19.5 学成近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .397\n19.5.1 醒眠算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398\n19.5.2 学成推断的其他形式. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .398\n第 20 章 深度生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399\n20.1 玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399\n20.2 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400\n20.2.1 条件分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401\n20.2.2 训练受限玻尔兹曼机. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402\n20.3 深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402\n20.4 深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404\n20.4.1 有趣的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406\n20.4.2 DBM 均匀场推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406\n20.4.3 DBM 的参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408\n20.4.4 逐层预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408\n20.4.5 联合训练深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410\n20.5 实值数据上的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413\n20.5.1 Gaussian-Bernoulli RBM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413\n20.5.2 条件协方差的无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414\n20.6 卷积玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417\n20.7 用于结构化或序列输出的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418\n20.8 其他玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419\n20.9 通过随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419\n20.9.1 通过离散随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420\n20.10 有向生成网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .422\n20.10.1 sigmoid 信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422\n20.10.2 可微生成器网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .423\n20.10.3 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .425\n20.10.4 生成式对抗网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .427\n20.10.5 生成矩匹配网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .429\n20.10.6 卷积生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .430\n20.10.7 自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430\n20.10.8 线性自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .430\n20.10.9 神经自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431\n20.10.10 NADE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432\n20.11 从自编码器采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433\n20.11.1 与任意去噪自编码器相关的马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434\n20.11.2 夹合与条件采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .434\n20.11.3 回退训练过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435\n20.12 生成随机网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435\n20.12.1 判别性 GSN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436\n20.13 其他生成方案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .436\n20.14 评估生成模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .437\n20.15 结论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438\n参考文献. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .439\n索引 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 486","pages":"500","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29518349.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29518349.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29518349.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27087503\/","id":"27087503","publisher":"人民邮电出版社","isbn10":"7115461473","isbn13":"9787115461476","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/27087503","alt_title":"Deep Learning: Adaptive Computation and Machine Learning series","author_intro":"作者简介\nIan Goodfellow，谷歌公司(Google) 的研究科学家，2014 年蒙特利尔大学机器学习博士。他的研究兴趣涵盖大多数深度学习主题，特别是生成模型以及机器学习的安全和隐私。Ian Goodfellow 在研究对抗样本方面是一位有影响力的早期研究者，他发明了生成式对抗网络，在深度学习领域贡献卓越。\nYoshua Bengio，蒙特利尔大学计算机科学与运筹学系(DIRO) 的教授，蒙特利尔学习算法研究所(MILA) 的负责人，CIFAR 项目的共同负责人，加拿大统计学习算法研究主席。Yoshua Bengio 的主要研究目标是了解产生智力的学习原则。他还教授“机器学习”研究生课程(IFT6266)，并培养了一大批研究生和博士后。\nAaron Courville，蒙特利尔大学计算机科学与运筹学系的助理教授，也是LISA 实验室的成员。目前他的研究兴趣集中在发展深度学习模型和方法，特别是开发概率模型和新颖的推断方法。Aaron Courville 主要专注于计算机视觉应用，在其他领域，如自然语言处理、音频信号处理、语音理解和其他AI 相关任务方面也有所研究。\n中文版审校者简介\n张志华，北京大学数学科学学院统计学教授，北京大学大数据研究中心和北京大数据研究院数据科学教授，主要从事机器学习和应用统计学的教学与研究工作。\n译者简介\n赵申剑，上海交通大学计算机系硕士研究生，研究方向为数值优化和自然语言处理。\n黎彧君，上海交通大学计算机系博士研究生，研究方向为数值优化和强化学习。\n符天凡，上海交通大学计算机系硕士研究生，研究方向为贝叶斯推断。\n李凯，上海交通大学计算机系博士研究生，研究方向为博弈论和强化学习。","summary":"《深度学习》由全球知名的三位专家Ian Goodfellow、Yoshua Bengio 和Aaron Courville撰写，是深度学习领域奠基性的经典教材。全书的内容包括3个部分：第1部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第2部分系统深入地讲解现今已成熟的深度学习方法和技术；第3部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。\n《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。","price":"168"},{"rating":{"max":10,"numRaters":445,"average":"9.6","min":0},"subtitle":"","author":["[美] 弗朗索瓦•肖莱"],"pubdate":"2018-8","tags":[{"count":978,"name":"深度学习","title":"深度学习"},{"count":766,"name":"Python","title":"Python"},{"count":578,"name":"人工智能","title":"人工智能"},{"count":551,"name":"机器学习","title":"机器学习"},{"count":453,"name":"python","title":"python"},{"count":305,"name":"计算机","title":"计算机"},{"count":300,"name":"神经网络","title":"神经网络"},{"count":293,"name":"Keras","title":"Keras"}],"origin_title":"Deep Learning with Python","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29839337.jpg","binding":"平装","translator":["张亮"],"catalog":"第一部分　深度学习基础\n第1章　什么是深度学习　　2\n1.1　人工智能、机器学习与深度学习　　2\n1.1.1　人工智能　　3\n1.1.2　机器学习　　3\n1.1.3　从数据中学习表示　　4\n1.1.4　深度学习之“深度”　　6\n1.1.5　用三张图理解深度学习的工作原理　　7\n1.1.6　深度学习已经取得的进展　　9\n1.1.7　不要相信短期炒作　　9\n1.1.8　人工智能的未来　　10\n1.2　深度学习之前：机器学习简史　　11\n1.2.1　概率建模　　11\n1.2.2　早期神经网络　　11\n1.2.3　核方法　　12\n1.2.4　决策树、随机森林与梯度提升机　　13\n1.2.5　回到神经网络　　14\n1.2.6　深度学习有何不同　　14\n1.2.7　机器学习现状　　15\n1.3　为什么是深度学习，为什么是现在　　15\n1.3.1　硬件　　16\n1.3.2　数据　　17\n1.3.3　算法　　17\n1.3.4　新的投资热潮　　17\n1.3.5　深度学习的大众化　　18\n1.3.6　这种趋势会持续吗　　18\n第2章　神经网络的数学基础　　20\n2.1　初识神经网络　　20\n2.2　神经网络的数据表示　　23\n2.2.1　标量（0D张量）　　23\n2.2.2　向量（1D张量）　　24\n2.2.3　矩阵（2D张量）　　24\n2.2.4　3D张量与更高维张量　　24\n2.2.5　关键属性　　25\n2.2.6　在Numpy中操作张量　　26\n2.2.7　数据批量的概念　　27\n2.2.8　现实世界中的数据张量　　27\n2.2.9　向量数据　　27\n2.2.10　时间序列数据或序列数据　　28\n2.2.11　图像数据　　28\n2.2.12　视频数据　　29\n2.3　神经网络的“齿轮”：张量运算　　29\n2.3.1　逐元素运算　　30\n2.3.2　广播　　31\n2.3.3　张量点积　　32\n2.3.4　张量变形　　34\n2.3.5　张量运算的几何解释　　34\n2.3.6　深度学习的几何解释　　35\n2.4　神经网络的“引擎”：基于梯度的优化　　36\n2.4.1　什么是导数　　37\n2.4.2　张量运算的导数：梯度　　38\n2.4.3　随机梯度下降　　38\n2.4.4　链式求导：反向传播算法　　41\n2.5　回顾第一个例子　　41\n本章小结　　42\n第3章　神经网络入门　　43\n3.1　神经网络剖析　　43\n3.1.1　层：深度学习的基础组件　　44\n3.1.2　模型：层构成的网络　　45\n3.1.3　损失函数与优化器：配置学习过程的关键　　45\n3.2　Keras简介　　46\n3.2.1　Keras、TensorFlow、Theano 和CNTK　　47\n3.2.2　使用Keras 开发：概述　　48\n3.3　建立深度学习工作站　　49\n3.3.1　Jupyter笔记本：运行深度学习实验的首选方法　　49\n3.3.2　运行Keras：两种选择　　50\n3.3.3　在云端运行深度学习任务：优点和缺点　　50\n3.3.4　深度学习的最佳GPU　　50\n3.4　电影评论分类：二分类问题　　51\n3.4.1　IMDB 数据集　　51\n3.4.2　准备数据　　52\n3.4.3　构建网络　　52\n3.4.4　验证你的方法　　56\n3.4.5　使用训练好的网络在新数据上生成预测结果　　59\n3.4.6　进一步的实验　　59\n3.4.7　小结　　59\n3.5　新闻分类：多分类问题　　59\n3.5.1　路透社数据集　　60\n3.5.2　准备数据　　61\n3.5.3　构建网络　　61\n3.5.4　验证你的方法　　62\n3.5.5　在新数据上生成预测结果　　65\n3.5.6　处理标签和损失的另一种方法　　65\n3.5.7　中间层维度足够大的重要性　　65\n3.5.8　进一步的实验　　66\n3.5.9　小结　　66\n3.6　预测房价：回归问题　　66\n3.6.1　波士顿房价数据集　　67\n3.6.2　准备数据　　67\n3.6.3　构建网络　　68\n3.6.4　利用K折验证来验证你的方法　　68\n3.6.5　小结　　72\n本章小结　　73\n第4章　机器学习基础　　74\n4.1　机器学习的四个分支　　74\n4.1.1　监督学习　　74\n4.1.2　无监督学习　　75\n4.1.3　自监督学习　　75\n4.1.4　强化学习　　75\n4.2　评估机器学习模型　　76\n4.2.1　训练集、验证集和测试集　　77\n4.2.2　评估模型的注意事项　　80\n4.3　数据预处理、特征工程和特征学习　　80\n4.3.1　神经网络的数据预处理　　80\n4.3.2　特征工程　　81\n4.4　过拟合与欠拟合　　83\n4.4.1　减小网络大小　　83\n4.4.2　添加权重正则化　　85\n4.4.3　添加dropout正则化　　87\n4.5　机器学习的通用工作流程　　89\n4.5.1　定义问题，收集数据集　　89\n4.5.2　选择衡量成功的指标　　89\n4.5.3　确定评估方法　　90\n4.5.4　准备数据　　90\n4.5.5　开发比基准更好的模型　　90\n4.5.6　扩大模型规模：开发过拟合的模型　　91\n4.5.7　模型正则化与调节超参数　　92\n本章小结　　92\n第二部分　深度学习实践\n第5章　深度学习用于计算机视觉　　94\n5.1　卷积神经网络简介　　94\n5.1.1　卷积运算　　96\n5.1.2　最大池化运算　　101\n5.2　在小型数据集上从头开始训练一个卷积神经网络　　102\n5.2.1　深度学习与小数据问题的相关性　　103\n5.2.2　下载数据　　103\n5.2.3　构建网络　　106\n5.2.4　数据预处理　　107\n5.2.5　使用数据增强　　111\n5.3　使用预训练的卷积神经网络　　115\n5.3.1　特征提取　　116\n5.3.2　微调模型　　124\n5.3.3　小结　　130\n5.4　卷积神经网络的可视化　　130\n5.4.1　可视化中间激活　　131\n5.4.2　可视化卷积神经网络的过滤器　　136\n5.4.3　可视化类激活的热力图　　142\n本章小结　　146\n第6章　深度学习用于文本和序列　　147\n6.1　处理文本数据　　147\n6.1.1　单词和字符的one-hot编码　　149\n6.1.2　使用词嵌入　　151\n6.1.3　整合在一起：从原始文本到词嵌入　　155\n6.1.4　小结　　162\n6.2　理解循环神经网络　　162\n6.2.1　Keras中的循环层　　164\n6.2.2　理解LSTM层和GRU层　　168\n6.2.3　Keras中一个LSTM的具体例子　　170\n6.2.4　小结　　172\n6.3　循环神经网络的高级用法　　172\n6.3.1　温度预测问题　　172\n6.3.2　准备数据　　175\n6.3.3　一种基于常识的、非机器学习的基准方法　　177\n6.3.4　一种基本的机器学习方法　　178\n6.3.5　第一个循环网络基准　　180\n6.3.6　使用循环dropout来降低过拟合　　181\n6.3.7　循环层堆叠　　182\n6.3.8　使用双向RNN　　184\n6.3.9　更多尝试　　187\n6.3.10　小结　　187\n6.4　用卷积神经网络处理序列　　188\n6.4.1　理解序列数据的一维卷积　　188\n6.4.2　序列数据的一维池化　　189\n6.4.3　实现一维卷积神经网络　　189\n6.4.4　结合CNN和RNN来处理长序列　　191\n6.4.5　小结　　195\n本章总结　　195\n第7章　高级的深度学习最佳实践　　196\n7.1　不用Sequential模型的解决方案：Keras 函数式API　　196\n7.1.1　函数式API简介　　199\n7.1.2　多输入模型　　200\n7.1.3　多输出模型　　202\n7.1.4　层组成的有向无环图　　204\n7.1.5　共享层权重　　208\n7.1.6　将模型作为层　　208\n7.1.7　小结　　209\n7.2　使用Keras回调函数和TensorBoard来检查并监控深度学习模型　　210\n7.2.1　训练过程中将回调函数作用于模型　　210\n7.2.2　TensorBoard简介：TensorFlow的可视化框架　　212\n7.2.3　小结　　219\n7.3　让模型性能发挥到极致　　219\n7.3.1　高级架构模式　　219\n7.3.2　超参数优化　　222\n7.3.3　模型集成　　223\n7.3.4　小结　　224\n本章总结　　225\n第8章　生成式深度学习　　226\n8.1　使用LSTM生成文本　　227\n8.1.1　生成式循环网络简史　　227\n8.1.2　如何生成序列数据　　228\n8.1.3　采样策略的重要性　　229\n8.1.4　实现字符级的LSTM文本生成　　230\n8.1.5　小结　　234\n8.2　DeepDream　　235\n8.2.1　用Keras实现DeepDream　　236\n8.2.2　小结　　241\n8.3　神经风格迁移　　241\n8.3.1　内容损失　　242\n8.3.2　风格损失　　243\n8.3.3　用Keras实现神经风格迁移　　243\n8.3.4　小结　　249\n8.4　用变分自编码器生成图像　　249\n8.4.1　从图像的潜在空间中采样　　249\n8.4.2　图像编辑的概念向量　　250\n8.4.3　变分自编码器　　251\n8.4.4　小结　　256\n8.5　生成式对抗网络简介　　257\n8.5.1　GAN 的简要实现流程　　258\n8.5.2　大量技巧　　259\n8.5.3　生成器　　260\n8.5.4　判别器　　261\n8.5.5　对抗网络　　261\n8.5.6　如何训练DCGAN　　262\n8.5.7　小结　　264\n本章总结　　264\n第9章　总结　　265\n9.1　重点内容回顾　　265\n9.1.1　人工智能的各种方法　　265\n9.1.2　深度学习在机器学习领域中的特殊之处　　266\n9.1.3　如何看待深度学习　　266\n9.1.4　关键的推动技术　　267\n9.1.5　机器学习的通用工作流程　　268\n9.1.6　关键网络架构　　268\n9.1.7　可能性空间　　272\n9.2　深度学习的局限性　　273\n9.2.1　将机器学习模型拟人化的风险　　273\n9.2.2　局部泛化与极端泛化　　275\n9.2.3　小结　　276\n9.3　深度学习的未来　　277\n9.3.1　模型即程序　　277\n9.3.2　超越反向传播和可微层　　278\n9.3.3　自动化机器学习　　279\n9.3.4　终身学习与模块化子程序复用　　279\n9.3.5　长期愿景　　281\n9.4　了解一个快速发展领域的最新进展　　281\n9.4.1　使用Kaggle练习解决现实世界的问题　　281\n9.4.2　在arXiv阅读最新进展　　282\n9.4.3　探索Keras生态系统　　282\n9.5　结束语　　282\n附录A　在Ubuntu上安装Keras及其依赖　　283\n附录B　在EC2 GPU实例上运行Jupyter笔记本　　287","pages":"292","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29839337.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29839337.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29839337.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30293801\/","id":"30293801","publisher":"人民邮电出版社","isbn10":"7115488762","isbn13":"9787115488763","title":"Python深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30293801","alt_title":"Deep Learning with Python","author_intro":"【作者简介】\n弗朗索瓦•肖莱（François Chollet）\nKeras之父，TensorFlow机器学习框架贡献者，Kaggle竞赛教练，个人Kaggle竞赛全球排名曾获得第17名。目前任职于Google，从事人工智能研究，尤其关注计算机视觉与机器学习在形式推理方面的应用。\n【译者简介】\n张亮（hysic）\n毕业于北京大学物理学院，爱好机器学习和数据分析的核安全工程师，译有《Python数据处理》《Python机器学习基础教程》等。","summary":"本书由Keras之父、现任Google人工智能研究员的弗朗索瓦•肖莱（François Chollet）执笔，详尽介绍了用Python和Keras进行深度学习的探索实践，涉及计算机视觉、自然语言处理、生成式模型等应用。书中包含30多个代码示例，步骤讲解详细透彻。由于本书立足于人工智能的可达性和大众化，读者无须具备机器学习相关背景知识即可展开阅读。在学习完本书后，读者将具备搭建自己的深度学习环境、建立图像识别模型、生成图像和文字等能力。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"119.00元"},{"rating":{"max":10,"numRaters":95,"average":"9.4","min":0},"subtitle":"","author":["阿斯顿·张（Aston Zhang）","李沐（Mu Li）","[美] 扎卡里·C. 立顿（Zachary C. Lipton）","[德] 亚历山大·J. 斯莫拉（Alexander J. Smola）"],"pubdate":"2019-6","tags":[{"count":178,"name":"深度学习","title":"深度学习"},{"count":104,"name":"机器学习","title":"机器学习"},{"count":100,"name":"人工智能","title":"人工智能"},{"count":56,"name":"计算机","title":"计算机"},{"count":54,"name":"Deep_Learning","title":"Deep_Learning"},{"count":31,"name":"李沐","title":"李沐"},{"count":21,"name":"编程","title":"编程"},{"count":21,"name":"数学","title":"数学"}],"origin_title":"Dive into deep learning","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32322795.jpg","binding":"平装","translator":[],"catalog":"对本书的赞誉\n前言\n如何使用本书\n资源与支持\n主要符号表\n第1 章　深度学习简介… ………………… 1\n1.1　起源…………………………………………… 2\n1.2　发展…………………………………………… 4\n1.3　成功案例……………………………………… 6\n1.4　特点………………………………………… 7\n小结…………………………………………… 8\n练习…………………………………………… 8\n第2 章　预备知识… ……………………… 9\n2.1　获取和运行本书的代码……………………… 9\n2.1.1　获取代码并安装运行环境 … ……… 9\n2.1.2　更新代码和运行环境 … …………… 11\n2.1.3　使用GPU版的MXNet … ………… 11\n小结……………………………………………12\n练习……………………………………………12\n2.2　数据操作… ……………………………… 12\n2.2.1　创建NDArray ………………………12\n2.2.2　运算 …………………………………14\n2.2.3　广播机制 ……………………………16\n2.2.4　索引 …………………………………17\n2.2.5　运算的内存开销 ……………………17\n2.2.6　NDArray和NumPy相互变换………18\n小结……………………………………………19\n练习……………………………………………19\n2.3　自动求梯度… …………………………… 19\n2.3.1　简单例子 … …………………………19\n2.3.2　训练模式和预测模式 …………… 20\n2.3.3　对Python控制流求梯度 … …… 20\n小结……………………………………………21\n练习……………………………………………21\n2.4　查阅文档… ……………………………… 21\n2.4.1　查找模块里的所有函数和类 … ……21\n2.4.2　查找特定函数和类的使用 ……… 22\n2.4.3　在MXNet网站上查阅 …………… 23\n小结………………………………………… 24\n练习………………………………………… 24\n第3 章　深度学习基础… ……………… 25\n3.1　线性回归…………………………………… 25\n3.1.1　线性回归的基本要素 … ………… 25\n3.1.2　线性回归的表示方法 … ………… 28\n小结………………………………………… 30\n练习………………………………………… 30\n3.2　线性回归的从零开始实现… …………… 30\n3.2.1　生成数据集 … …………………… 30\n3.2.2　读取数据集 ……………………… 32\n3.2.3　初始化模型参数 ………………… 32\n3.2.4　定义模型 ………………………… 33\n3.2.5　定义损失函数 …………………… 33\n3.2.6　定义优化算法 …………………… 33\n3.2.7　训练模型 ………………………… 33\n小结………………………………………… 34\n练习………………………………………… 34\n3.3　线性回归的简洁实现… ………………… 35\n3.3.1　生成数据集 … …………………… 35\n3.3.2　读取数据集 ……………………… 35\n3.3.3　定义模型 ………………………… 36\n3.3.4　初始化模型参数 ………………… 36\n3.3.5　定义损失函数 …………………… 37\n3.3.6　定义优化算法 …………………… 37\n3.3.7　训练模型 ………………………… 37\n小结………………………………………… 38\n练习………………………………………… 38\n3.4　softmax回归… ………………………… 38\n3.4.1　分类问题 … ……………………… 38\n3.4.2　softmax回归模型… …………… 39\n3.4.3　单样本分类的矢量计算表达式…… 40\n3.4.4　小批量样本分类的矢量计算表达式 …………………………… 40\n3.4.5　交叉熵损失函数 ……………………41\n3.4.6　模型预测及评价 ………………… 42\n小结………………………………………… 42\n练习………………………………………… 42\n3.5　图像分类数据集（Fashion-MNIST）… ……………… 42\n3.5.1　获取数据集 … …………………… 42\n3.5.2　读取小批量 ……………………… 44\n小结………………………………………… 45\n练习………………………………………… 45\n3.6　softmax回归的从零开始实现… ……… 45\n3.6.1　读取数据集 … …………………… 45\n3.6.2　初始化模型参数 ………………… 45\n3.6.3　实现softmax运算 … …………… 46\n3.6.4　定义模型 ………………………… 46\n3.6.5　定义损失函数 …………………… 47\n3.6.6　计算分类准确率 ………………… 47\n3.6.7　训练模型 ………………………… 48\n3.6.8　预测… …………………………… 48\n小结………………………………………… 49\n练习………………………………………… 49\n3.7　softmax回归的简洁实现… …………… 49\n3.7.1　读取数据集 … …………………… 49\n3.7.2　定义和初始化模型 ……………… 50\n3.7.3　softmax和交叉熵损失函数 … … 50\n3.7.4　定义优化算法 …………………… 50\n3.7.5　训练模型 ………………………… 50\n小结………………………………………… 50\n练习………………………………………… 50\n3.8　多层感知机… …………………………… 51\n3.8.1　隐藏层 … ……………………………51\n3.8.2　激活函数 ………………………… 52\n3.8.3　多层感知机 ……………………… 55\n小结………………………………………… 55\n练习………………………………………… 55\n3.9　多层感知机的从零开始实现… ………… 56\n3.9.1　读取数据集 … …………………… 56\n3.9.2　定义模型参数 …………………… 56\n3.9.3　定义激活函数 …………………… 56\n3.9.4　定义模型 ………………………… 56\n3.9.5　定义损失函数 …………………… 57\n3.9.6　训练模型 ………………………… 57\n小结………………………………………… 57\n练习………………………………………… 57\n3.10　多层感知机的简洁实现………………… 57\n3.10.1　定义模型 ………………………… 58\n3.10.2　训练模型 … …………………… 58\n小结………………………………………… 58\n练习………………………………………… 58\n3.11　模型选择、欠拟合和过拟合… ………… 58\n3.11.1　训练误差和泛化误差 …………… 59\n3.11.2　模型选择 ………………………… 59\n3.11.3　欠拟合和过拟合 ………………… 60\n3.11.4　多项式函数拟合实验 ……………61\n小结………………………………………… 65\n练习………………………………………… 65\n3.12　权重衰减………………………………… 65\n3.12.1　方法 ……………………………… 65\n3.12.2　高维线性回归实验 … ………… 66\n3.12.3　从零开始实现 … ……………… 66\n3.12.4　简洁实现 … …………………… 68\n小结………………………………………… 70\n练习………………………………………… 70\n3.13　丢弃法…………………………………… 70\n3.13.1　方法 ……………………………… 70\n3.13.2　从零开始实现 … …………………71\n3.13.3　简洁实现 … …………………… 73\n小结………………………………………… 74\n练习………………………………………… 74\n3.14　正向传播、反向传播和计算图………… 74\n3.14.1　正向传播 ……………………… 74\n3.14.2　正向传播的计算图 … ………… 75\n3.14.3　反向传播 … …………………… 75\n3.14.4　训练深度学习模型 … ………… 76\n小结………………………………………… 77\n练习………………………………………… 77\n3.15　数值稳定性和模型初始化……………… 77\n3.15.1　衰减和爆炸 ……………………… 77\n3.15.2　随机初始化模型参数 … ……… 78\n小结………………………………………… 78\n练习………………………………………… 79\n3.16　实战Kaggle比赛：房价预测… ……… 79\n3.16.1　Kaggle比赛 … ………………… 79\n3.16.2　读取数据集 … ………………… 80\n3.16.3　预处理数据集 … …………………81\n3.16.4　训练模型 … …………………… 82\n3.16.5　k 折交叉验证 …………………… 82\n3.16.6　模型选择 … …………………… 83\n3.16.7　预测并在Kaggle提交结果… … 84\n小结………………………………………… 85\n练习………………………………………… 85\n第4 章　深度学习计算… ……………… 86\n4.1　模型构造………………………………… 86\n4.1.1　继承Block类来构造模型 … …… 86\n4.1.2　Sequential类继承自Block类…………………………… 87\n4.1.3　构造复杂的模型… ……………… 88\n小结………………………………………… 89\n练习………………………………………… 90\n4.2　模型参数的访问、初始化和共享… …… 90\n4.2.1　访问模型参数 … ………………… 90\n4.2.2　初始化模型参数 ………………… 92\n4.2.3　自定义初始化方法 ……………… 93\n4.2.4　共享模型参数 …………………… 94\n小结………………………………………… 94\n练习………………………………………… 94\n4.3　模型参数的延后初始化… ……………… 95\n4.3.1　延后初始化 … …………………… 95\n4.3.2　避免延后初始化 ………………… 96\n小结………………………………………… 96\n练习………………………………………… 97\n4.4　自定义层… ……………………………… 97\n4.4.1　不含模型参数的自定义层 … …… 97\n4.4.2　含模型参数的自定义层 ………… 98\n小结………………………………………… 99\n练习………………………………………… 99\n4.5　读取和存储… …………………………… 99\n4.5.1　读写NDArray… ………………… 99\n4.5.2　读写Gluon模型的参数… ……… 100\n小结………………………………………… 101\n练习………………………………………… 101\n4.6　GPU计算………………………………… 101\n4.6.1　计算设备 … ……………………… 102\n4.6.2　NDArray的GPU计算…………… 102\n4.6.3　Gluon的GPU计算 ……………… 104\n小结………………………………………… 105\n练习………………………………………… 105\n第5 章　卷积神经网络… ……………… 106\n5.1　二维卷积层………………………………… 106\n5.1.1　二维互相关运算 … ……………… 106\n5.1.2　二维卷积层 … …………………… 107\n5.1.3　图像中物体边缘检测 … ………… 108\n5.1.4　通过数据学习核数组 … ………… 109\n5.1.5　互相关运算和卷积运算 … ……… 109\n5.1.6　特征图和感受野… ……………… 110\n小结………………………………………… 110\n练习………………………………………… 110\n5.2　填充和步幅… …………………………… 111\n5.2.1　填充 … …………………………… 111\n5.2.2　步幅 ……………………………… 112\n小结………………………………………… 113\n练习………………………………………… 113\n5.3　多输入通道和多输出通道… …………… 114\n5.3.1　多输入通道 … …………………… 114\n5.3.2　多输出通道… …………………… 115\n5.3.3　1×1卷积层 ……………………… 116\n小结………………………………………… 117\n练习………………………………………… 117\n5.4　池化层… ………………………………… 117\n5.4.1　二维最大池化层和平均池化层 … ………………………… 117\n5.4.2　填充和步幅 ……………………… 119\n5.4.3　多通道 …………………………… 120\n小结………………………………………… 120\n练习………………………………………… 121\n5.5　卷积神经网络（LeNet）… …………… 121\n5.5.1　LeNet模型 … …………………… 121\n5.5.2　训练模型… ……………………… 122\n小结………………………………………… 124\n练习………………………………………… 124\n5.6　深度卷积神经网络（AlexNet）… …… 124\n5.6.1　学习特征表示 … ………………… 125\n5.6.2　AlexNet… ……………………… 126\n5.6.3　读取数据集 ……………………… 127\n5.6.4　训练模型 ………………………… 128\n小结………………………………………… 128\n练习………………………………………… 129\n5.7　使用重复元素的网络（VGG）………… 129\n5.7.1　VGG块 …………………………… 129\n5.7.2　VGG网络 … …………………… 129\n5.7.3　训练模型… ……………………… 130\n小结………………………………………… 131\n练习………………………………………… 131\n5.8　网络中的网络（NiN）… ……………… 131\n5.8.1　NiN块 … ………………………… 131\n5.8.2　NiN模型 … ……………………… 132\n5.8.3　训练模型… ……………………… 133\n小结………………………………………… 134\n练习………………………………………… 134\n5.9　含并行连结的网络（GoogLeNet）…… 134\n5.9.1　Inception块 ……………………… 134\n5.9.2　GoogLeNet模型 … …………… 135\n5.9.3　训练模型 ………………………… 137\n小结………………………………………… 137\n练习………………………………………… 137\n5.10　批量归一化……………………………… 138\n5.10.1　批量归一化层 ………………… 138\n5.10.2　从零开始实现 … ……………… 139\n5.10.3　使用批量归一化层的LeNet … … 140\n5.10.4　简洁实现 … …………………… 141\n小结………………………………………… 142\n练习………………………………………… 142\n5.11　残差网络（ResNet） ……………… 143\n5.11.1　残差块 …………………………… 143\n5.11.2　ResNet模型… ………………… 145\n5.11.3　训练模型………………………… 146\n小结………………………………………… 146\n练习………………………………………… 146\n5.12　稠密连接网络（DenseNet）………… 147\n5.12.1　稠密块 …………………………… 147\n5.12.2　过渡层 … ……………………… 148\n5.12.3　DenseNet模型 ………………… 148\n5.12.4　训练模型 … …………………… 149\n小结………………………………………… 149\n练习………………………………………… 149\n第6 章　循环神经网络… ……………… 150\n6.1　语言模型………………………………… 150\n6.1.1　语言模型的计算 … ……………… 151\n6.1.2　n 元语法 … ……………………… 151\n小结………………………………………… 152\n练习………………………………………… 152\n6.2　循环神经网络… ………………………… 152\n6.2.1　不含隐藏状态的神经网络 … …… 152\n6.2.2　含隐藏状态的循环神经网络… … 152\n6.2.3　应用：基于字符级循环神经网络的语言模型 … ……………………… 154\n小结………………………………………… 155\n练习………………………………………… 155\n6.3　语言模型数据集（歌词）…… 155\n6.3.1　读取数据集 … …………………… 155\n6.3.2　建立字符索引 …………………… 156\n6.3.3　时序数据的采样 ………………… 156\n小结………………………………………… 158\n练习………………………………………… 159\n6.4　循环神经网络的从零开始实现… ……… 159\n6.4.1　one-hot向量 … ………………… 159\n6.4.2　初始化模型参数 ………………… 160\n6.4.3　定义模型 ………………………… 160\n6.4.4　定义预测函数 …………………… 161\n6.4.5　裁剪梯度 ………………………… 161\n6.4.6　困惑度 …………………………… 162\n6.4.7　定义模型训练函数 ……………… 162\n6.4.8　训练模型并创作歌词 …………… 163\n小结………………………………………… 164\n练习………………………………………… 164\n6.5　循环神经网络的简洁实现… …………… 165\n6.5.1　定义模型 … ……………………… 165\n6.5.2　训练模型 ………………………… 166\n小结………………………………………… 168\n练习………………………………………… 168\n6.6　通过时间反向传播… …………………… 168\n6.6.1　定义模型 … ……………………… 168\n6.6.2　模型计算图 ……………………… 169\n6.6.3　方法 ……………………………… 169\n小结………………………………………… 170\n练习………………………………………… 170\n6.7　门控循环单元（GRU）………………… 170\n6.7.1　门控循环单元 … ………………… 171\n6.7.2　读取数据集 ……………………… 173\n6.7.3　从零开始实现 …………………… 173\n6.7.4　简洁实现 ………………………… 175\n小结………………………………………… 176\n练习………………………………………… 176\n6.8　长短期记忆（LSTM）… ……………… 176\n6.8.1　长短期记忆 … …………………… 176\n6.8.2　读取数据集 ……………………… 179\n6.8.3　从零开始实现 …………………… 179\n6.8.4　简洁实现 ………………………… 181\n小结………………………………………… 181\n练习………………………………………… 182\n6.9　深度循环神经网络… …………………… 182\n小结………………………………………… 183\n练习………………………………………… 183\n6.10　双向循环神经网络……………………… 183\n小结………………………………………… 184\n练习………………………………………… 184\n第7 章　优化算法… …………………… 185\n7.1　优化与深度学习…………………………… 185\n7.1.1　优化与深度学习的关系 … ……… 185\n7.1.2　优化在深度学习中的挑战 … …… 186\n小结………………………………………… 188\n练习………………………………………… 189\n7.2　梯度下降和随机梯度下降… …………… 189\n7.2.1　一维梯度下降 … ………………… 189\n7.2.2　学习率 …………………………… 190\n7.2.3　多维梯度下降 …………………… 191\n7.2.4　随机梯度下降 …………………… 193\n小结………………………………………… 194\n练习………………………………………… 194\n7.3　小批量随机梯度下降… ………………… 194\n7.3.1　读取数据集 … …………………… 195\n7.3.2　从零开始实现 …………………… 196\n7.3.3　简洁实现 ………………………… 198\n小结………………………………………… 199\n练习………………………………………… 199\n7.4　动量法… …………………………………200\n7.4.1　梯度下降的问题 … ……………… 200\n7.4.2　动量法 …………………………… 201\n·6·　目　　录\n7.4.3　从零开始实现 …………………… 203\n7.4.4　简洁实现 ………………………… 205\n小结………………………………………… 205\n练习………………………………………… 205\n7.5　AdaGrad算法……………………………206\n7.5.1　算法 … …………………………… 206\n7.5.2　特点 ……………………………… 206\n7.5.3　从零开始实现 …………………… 208\n7.5.4　简洁实现 ………………………… 209\n小结………………………………………… 209\n练习………………………………………… 209\n7.6　RMSProp算法… ………………………209\n7.6.1　算法 … …………………………… 210\n7.6.2　从零开始实现 …………………… 211\n7.6.3　简洁实现 ………………………… 212\n小结………………………………………… 212\n练习………………………………………… 212\n7.7　AdaDelta算法… ……………………… 212\n7.7.1　算法… …………………………… 212\n7.7.2　从零开始实现 …………………… 213\n7.7.3　简洁实现 ………………………… 214\n小结………………………………………… 214\n练习………………………………………… 214\n7.8　Adam算法… …………………………… 215\n7.8.1　算法 … …………………………… 215\n7.8.2　从零开始实现 …………………… 216\n7.8.3　简洁实现 ………………………… 216\n小结………………………………………… 217\n练习………………………………………… 217\n第8 章　计算性能… …………………… 218\n8.1　命令式和符号式混合编程… …………… 218\n8.1.1　混合式编程取两者之长 … ……… 220\n8.1.2　使用HybridSequential类构造模型 … …………………………… 220\n8.1.3　使用HybridBlock类构造模型… …………………………… 222\n小结………………………………………… 224\n练习………………………………………… 224\n8.2　异步计算… ………………………………224\n8.2.1　MXNet中的异步计算 …………… 224\n8.2.2　用同步函数让前端等待计算结果 … …………………………… 226\n8.2.3　使用异步计算提升计算性能 …… 226\n8.2.4　异步计算对内存的影响 ………… 227\n小结………………………………………… 229\n练习………………………………………… 229\n8.3　自动并行计算… …………………………229\n8.3.1　CPU和GPU的并行计算 … …… 230\n8.3.2　计算和通信的并行计算 ………… 231\n小结………………………………………… 231\n练习………………………………………… 231\n8.4　多GPU计算……………………………… 232\n8.4.1　数据并行 … ……………………… 232\n8.4.2　定义模型 ………………………… 233\n8.4.3　多GPU之间同步数据 … ……… 234\n8.4.4　单个小批量上的多GPU训练 … …………………………… 236\n8.4.5　定义训练函数 …………………… 236\n8.4.6　多GPU训练实验 … …………… 237\n小结………………………………………… 237\n练习………………………………………… 237\n8.5　多GPU计算的简洁实现………………… 237\n8.5.1　多GPU上初始化模型参数……… 238\n8.5.2　多GPU训练模型 … …………… 239\n小结………………………………………… 241\n练习………………………………………… 241\n第9 章　计算机视觉… ………………… 242\n9.1　图像增广…………………………………242\n9.1.1　常用的图像增广方法 … ………… 243\n9.1.2　使用图像增广训练模型 … ……… 246\n小结………………………………………… 250\n练习………………………………………… 250\n9.2　微调… ……………………………………250\n热狗识别 … ……………………………… 251\n小结………………………………………… 255\n练习………………………………………… 255\n目　　录　·7·\n9.3　目标检测和边界框… ……………………255\n边界框 … ………………………………… 256\n小结………………………………………… 257\n练习………………………………………… 257\n9.4　锚框… …………………………………… 257\n9.4.1　生成多个锚框… ………………… 257\n9.4.2　交并比 …………………………… 259\n9.4.3　标注训练集的锚框 ……………… 260\n9.4.4　输出预测边界框… ……………… 263\n小结………………………………………… 265\n练习………………………………………… 265\n9.5　多尺度目标检测… ………………………265\n小结………………………………………… 268\n练习………………………………………… 268\n9.6　目标检测数据集（皮卡丘）… …………268\n9.6.1　获取数据集 … …………………… 269\n9.6.2　读取数据集… …………………… 269\n9.6.3　图示数据 ………………………… 270\n小结………………………………………… 270\n练习………………………………………… 271\n9.7　单发多框检测（SSD）… ……………… 271\n9.7.1　定义模型… ……………………… 271\n9.7.2　训练模型 ………………………… 275\n9.7.3　预测目标 ………………………… 277\n小结………………………………………… 278\n练习………………………………………… 278\n9.8　区域卷积神经网络（R-CNN）系列……280\n9.8.1　R-CNN … ……………………… 280\n9.8.2　Fast R-CNN …………………… 281\n9.8.3　Faster R-CNN ………………… 283\n9.8.4　Mask R-CNN … ……………… 284\n小结………………………………………… 285\n练习………………………………………… 285\n9.9　语义分割和数据集… ……………………285\n9.9.1　图像分割和实例分割 … ………… 285\n9.9.2　Pascal VOC2012语义分割数据集 … ………………………… 286\n小结………………………………………… 290\n练习………………………………………… 290\n9.10　全卷积网络（FCN）… ………………290\n9.10.1　转置卷积层 …………………… 291\n9.10.2　构造模型 … …………………… 292\n9.10.3　初始化转置卷积层……………… 294\n9.10.4　读取数据集 … ………………… 295\n9.10.5　训练模型………………………… 296\n9.10.6　预测像素类别…………………… 296\n小结………………………………………… 297\n练习………………………………………… 297\n9.11　样式迁移… ………………………………298\n9.11.1　方法 ……………………………… 298\n9.11.2　读取内容图像和样式图像……… 299\n9.11.3　预处理和后处理图像 ………… 300\n9.11.4　抽取特征 ……………………… 301\n9.11.5　定义损失函数 ………………… 302\n9.11.6　创建和初始化合成图像 ……… 303\n9.11.7　训练模型………………………… 304\n小结………………………………………… 306\n练习………………………………………… 306\n9.12　实战Kaggle比赛：图像\n分类（CIFAR-10）……………………306\n9.12.1　获取和整理数据集 ……………… 307\n9.12.2　图像增广 … …………………… 310\n9.12.3　读取数据集 … ………………… 310\n9.12.4　定义模型………………………… 311\n9.12.5　定义训练函数 … ……………… 312\n9.12.6　训练模型 … …………………… 312\n9.12.7　对测试集分类并在Kaggle\n提交结果 … …………………… 313\n小结………………………………………… 313\n练习………………………………………… 313\n9.13　实战Kaggle比赛：狗的品种\n识别（ImageNet Dogs）…………… 314\n9.13.1　获取和整理数据集 …………… 315\n9.13.2　图像增广 … …………………… 316\n9.13.3　读取数据集 … ………………… 317\n9.13.4　定义模型 … …………………… 318\n9.13.5　定义训练函数 … ……………… 318\n9.13.6　训练模型 … …………………… 319\n·8·　目　　录\n9.13.7　对测试集分类并在Kaggle提交结果 … …………………… 319\n小结………………………………………… 320\n练习………………………………………… 320\n第10 章　自然语言处理………………… 321\n10.1　词嵌入（word2vec）………………… 321\n10.1.1　为何不采用one-hot向量… …… 321\n10.1.2　跳字模型 ………………………… 322\n10.1.3　连续词袋模型 …………………… 323\n小结………………………………………… 325\n练习………………………………………… 325\n10.2　近似训练…………………………………325\n10.2.1　负采样 …………………………… 325\n10.2.2　层序softmax …………………… 326\n小结………………………………………… 327\n练习………………………………………… 328\n10.3　word2vec的实现………………………328\n10.3.1　预处理数据集 …………………… 328\n10.3.2　负采样 … ……………………… 331\n10.3.3　读取数据集 … ………………… 331\n10.3.4　跳字模型 … …………………… 332\n10.3.5　训练模型 … …………………… 333\n10.3.6　应用词嵌入模型 … …………… 335\n小结………………………………………… 336\n练习………………………………………… 336\n10.4　子词嵌入（fastText）… ……………336\n小结………………………………………… 337\n练习………………………………………… 337\n10.5　全局向量的词嵌入（GloVe）…………337\n10.5.1　GloVe模型 …………………… 338\n10.5.2　从条件概率比值理解GloVe模型……………………… 339\n小结………………………………………… 340\n练习………………………………………… 340\n10.6　求近义词和类比词………………………340\n10.6.1　使用预训练的词向量 ………… 340\n10.6.2　应用预训练词向量 … ………… 341\n小结………………………………………… 343\n练习………………………………………… 343\n10.7　文本情感分类：使用循环神经网络…… 343\n10.7.1　文本情感分类数据集 ………… 343\n10.7.2　使用循环神经网络的模型……… 345\n小结………………………………………… 347\n练习………………………………………… 347\n10.8　文本情感分类：使用卷积神经网络（textCNN）… …………………347\n10.8.1　一维卷积层 … ………………… 348\n10.8.2　时序最大池化层 … …………… 349\n10.8.3　读取和预处理IMDb数据集 … ……………………… 350\n10.8.4　textCNN模型 … ……………… 350\n小结………………………………………… 353\n练习………………………………………… 353\n10.9　编码器-解码器（seq2seq）…………353\n10.9.1　编码器 ………………………… 354\n10.9.2　解码器 … ……………………… 354\n10.9.3　训练模型………………………… 355\n小结………………………………………… 355\n练习………………………………………… 355\n10.10　 束搜索… ………………………………355\n10.10.1　贪婪搜索 … …………………… 356\n10.10.2　穷举搜索 ……………………… 357\n10.10.3　束搜索 ………………………… 357\n小结………………………………………… 358\n练习………………………………………… 358\n10.11　注意力机制… …………………………358\n10.11.1　计算背景变量 … ……………… 359\n10.11.2　更新隐藏状态 … ……………… 360\n10.11.3　发展… ………………………… 361\n小结………………………………………… 361\n练习………………………………………… 361\n10.12　机器翻译… …………………………… 361\n10.12.1　读取和预处理数据集… ……… 361\n10.12.2　含注意力机制的编码器-解码器 … …………… 363\n10.12.3　训练模型 ……………………… 365\n10.12.4　预测不定长的序列… ………… 367\n10.12.5　评价翻译结果 ………………… 367\n小结………………………………………… 369\n练习………………………………………… 369\n附录A　数学基础… …………………… 370\n附录B　使用 Jupyter 记事本… ……… 376\n附录C　使用 AWS 运行代码…………… 381\n附录D　GPU 购买指南………………… 388\n附录E　如何为本书做贡献… ………… 391\n附录F　d2lzh 包索引…………………… 395\n附录G　中英文术语对照表… ………… 397\n参考文献………………………………… 402\n索引……………………………………… 407","pages":"440","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32322795.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32322795.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32322795.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33450010\/","id":"33450010","publisher":"人民邮电出版社","isbn10":"7115490848","isbn13":"9787115490841","title":"动手学深度学习","url":"https:\/\/api.douban.com\/v2\/book\/33450010","alt_title":"Dive into deep learning","author_intro":"阿斯顿·张（Aston Zhang）\n亚马逊应用科学家，美国伊利诺伊大学香槟分校计算机科学博士，统计学和计算机科学双硕士。他专注于机器学习的研究，并在数个顶级学术会议发表过论文。他担任过NeurIPS、ICML、KDD、WWW、WSDM、SIGIR、AAAI 等学术会议的程序委员或审稿人以及Frontiers in Big Data 期刊的编委。\n李沐（Mu Li）\n亚马逊首席科学家（Principal Scientist），加州大学伯克利分校客座助理教授，美国卡内基梅隆大学计算机系博士。他专注于分布式系统和机器学习算法的研究。他是深度学习框架MXNet 的作者之一。他曾任机器学习创业公司Marianas Labs 的CTO 和百度深度学习研究院的主任研发架构师。他在理论、机器学习、应用和操作系统等多个领域的顶级学术会议（包括FOCS、ICML、NeurIPS、AISTATS、CVPR、KDD 、WSDM、OSDI）上发表过论文。\n扎卡里·C. 立顿（Zachary C. Lipton）\n亚马逊应用科学家，美国卡内基梅隆大学助理教授，美国加州大学圣迭戈分校博士。他专注于机器学习算法及其社会影响的研究，特别是在时序数据与序列决策上的深度学习。这类工作有着广泛的应用场景，包括医疗诊断、对话系统和产品推荐。他创立了博客“Approximately Correct”（approximatelycorrect.com）。\n亚历山大·J. 斯莫拉（Alexander J. Smola）\n亚马逊副总裁\/ 杰出科学家，德国柏林工业大学计算机科学博士。他曾在澳大利亚国立大学、美国加州大学伯克利分校和卡内基梅隆大学任教。他发表了超过200 篇学术论文，并著有5 本书，其论文及书被引用超过10 万次。他的研究兴趣包括深度学习、贝叶斯非参数、核方法、统计建模和可扩展算法。","summary":"本书旨在向读者交付有关深度学习的交互式学习体验。书中不仅阐述深度学习的算法原理，还演示它们的实现和运行。与传统图书不同，本书的每一节都是一个可以下载并运行的 Jupyter记事本，它将文字、公式、图像、代码和运行结果结合在了一起。此外，读者还可以访问并参与书中内容的讨论。\n全书的内容分为3个部分：第一部分介绍深度学习的背景，提供预备知识，并包括深度学习最基础的概念和技术；第二部分描述深度学习计算的重要组成部分，还解释近年来令深度学习在多个领域大获成功的卷积神经网络和循环神经网络；第三部分评价优化算法，检验影响深度学习计算性能的重要因素，并分别列举深度学习在计算机视觉和自然语言处理中的重要应用。\n本书同时覆盖深度学习的方法和实践，主要面向在校大学生、技术人员和研究人员。阅读本书需要读者了解基本的Python编程或附录中描述的线性代数、微分和概率基础。","price":"85.00元"},{"rating":{"max":10,"numRaters":377,"average":"7.6","min":0},"subtitle":"智能时代的核心驱动力量","author":["[美]特伦斯·谢诺夫斯基（Terrence Sejnowski）"],"pubdate":"2019-2","tags":[{"count":290,"name":"人工智能","title":"人工智能"},{"count":211,"name":"深度学习","title":"深度学习"},{"count":138,"name":"AI","title":"AI"},{"count":110,"name":"机器学习","title":"机器学习"},{"count":94,"name":"科普","title":"科普"},{"count":92,"name":"计算机","title":"计算机"},{"count":46,"name":"2019","title":"2019"},{"count":42,"name":"好书，值得一读","title":"好书，值得一读"}],"origin_title":"The Deep Learning Revolution","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29971614.jpg","binding":"精装","translator":["姜悦兵"],"catalog":"推 荐 序   面对科技拐点，我们的判断与选择\n中文版序   人工智能会放大认知能力\n前    言   深度学习与智能的本质\n第一部分 智能的新构想\n01 机器学习的崛起\n汽车新生态：无人驾驶将全面走入人们生活\n自然语言翻译：从语言到句子的飞跃\n语音识别：实时跨文化交流不再遥远\nAI医疗：医学诊断将更加准确\n金融科技：利用数据和算法获取最佳回报\n深度法律：效率的提高与费用的降低\n德州扑克：当机器智能学会了虚张声势\nAlphaGo奇迹：神经科学与人工智能的协同\n弗林效应：深度学习让人类更加智能\n新教育体系：每个人都需要终身学习\n正面影响：新兴技术不是生存威胁\n回到未来：当人类智能遇到人工智能\n02 人工智能的重生\n看似简单的视觉识别\n计算机视觉的进步\n早期人工智能发展缓慢\n从神经网络到人工智能\n03 神经网络的黎明\n深度学习的起点\n从样本中学习\n利用感知器区分性别\n被低估的神经网络\n04 大脑式的计算\n网络模型能够模仿智能行为\n神经网络先驱者\n乔治·布尔与机器学习\n利用神经科学理解大脑\n大脑如何处理问题\n计算神经科学的兴起\n05 洞察视觉系统\n人眼是如何看到东西的\n大脑皮层中的视觉\n突触的可塑性\n通过阴影脑补立体全貌\n视觉区域的层级结构\n认知神经科学的诞生\n第二部分 深度学习的演进\n06 语音识别的突破\n在嘈杂中找到你的声音\n将独立分量分析应用于大脑\n什么在操控我们的言行\n07 霍普菲尔德网络和玻尔兹曼机\n约翰·霍普菲尔德的伟大之处\n内容可寻址存储器\n局部最小值与全局最小值\n玻尔兹曼机\n赫布理论\n学习识别镜像对称\n学习识别手写数字\n无监督学习和皮层发育\n08 反向传播算法\n算法的优化\n语音合成的突破\n神经网络的重生\n理解真正的深度学习\n神经网络的局限性\n09 卷积学习\n机器学习的稳步发展\n卷积网络的渐进式改进\n当深度学习遇到视觉层级结构\n有工作记忆的神经网络\n生成式对抗网络\n应对现实社会的复杂性\n10 奖励学习\n机器如何学会下棋\n大脑的奖励机制\n用“感知-行动”框架提高绩效\n学习如何翱翔\n学习如何歌唱\n人工智能的可塑性\n更多需要被解决的问题\n11 火爆的NIPS\n为什么NIPS如此受欢迎\n谁拥有最多数据，谁就是赢家\n为未来做准备\n第三部分 人类，智能与未来\n12 智能时代\n21世纪的生活\n未来的身份认证\n社交机器人的崛起\n机器已经会识别人类面部表情\n新技术改变教育方式\n成为更好的学习者\n训练你的大脑\n智能商业\n13 算法驱动\n用算法把复杂问题简单化\n理解、分析复杂系统\n大脑的逻辑深度\n尝试所有可能的策略\n14 芯片崛起\n神经形态芯片\n视网膜芯片\n神经形态工程\n摩尔定律的终结\n15 信息科学\n用字节丈量世界\n用数学思维解决通信难题\n预测是如何产生的\n深度理解大脑\n大脑的操作系统\n生物学与计算科学\n人工智能能拥有媲美人类大脑的操作系统\n16 生命与意识\n视觉意识\n视觉感知的过程\n视觉感知的时机\n视觉感知的部位\n视觉搜索的机理\n创造意识比理解意识更容易\n17 进化的力量\n大自然比我们聪明\n认知科学的兴起\n不能把语言问题只留给语言学家\n难预测的行为规律\n神经网络的寒冬\n从深度学习到通用人工智能\n18 深度智能\n遗传密码\n每个物种都有智能\n进化的起源\n人类终将解决智能难题","ebook_url":"https:\/\/read.douban.com\/ebook\/107186317\/","pages":"400","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29971614.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29971614.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29971614.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30425822\/","id":"30425822","publisher":"中信出版集团","isbn10":"7508698355","isbn13":"9787508698359","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30425822","alt_title":"The Deep Learning Revolution","author_intro":"特伦斯·谢诺夫斯基  Terrence (Terry)  Sejnowski\n世界十大AI科学家之一，美国四大国家学院（国家科学院、国家医学院、国家工程院、国家艺术与科学学院）在世仅3位的“四院院士”之一，全球AI专业会议NIPS基金会主席。\n作为神经网络的先驱，早在1986年，特伦斯就与杰弗里·辛顿共同发明了玻尔兹曼机，把神经网络带入到研究与应用的热潮，将深度学习从边缘课题变成了互联网科技公司仰赖的核心技术，实现了人工智能井喷式的发展。\n特伦斯现任美国索尔克生物研究所(美国生命科学领域成果最多的研究机构) 计算神经生物学实验室主任，是美国政府注资50亿美元“脑计划”项目（BRAIN，the Brain Research through Advancing Innovative Neurotechnologies）领军人物。\n特伦斯同时是全球最大在线学习平台Coursera最受欢迎课程《学习如何学习》（Learning how to learn）主理人，通过系统讲解大脑认知的底层知识，让学习者可以改变思维模式，提高学习的能力和效率。目前该课程学习人数已经超过了300万。","summary":"全球科技巨头纷纷拥抱深度学习，自动驾驶、AI医疗、语音识别、图像识别、智能翻译以及震惊世界的AlphaGo，背后都是深度学习在发挥神奇的作用。深度学习是人工智能从概念到繁荣得以实现的主流技术。经过深度学习训练的计算机，不再被动按照指令运转，而是像自然进化的生命那样，开始自主地从经验中学习。\n本书作者特伦斯·谢诺夫斯基是全球人工智能十大科学家之一、深度学习先驱及奠基者，亲历了深度学习在20世纪70年代到90年代的寒冬。但他和一众开拓者，利用大数据和不断增强的计算能力，终于在神经网络算法上取得重大突破，实现了人工智能井喷式的发展。\n作为深度学习领域的通识作品，本书以恢弘的笔触，通过3个部分全景展现了深度学习的发展、演变与应用，首次以亲历者视角回溯了深度学习浪潮在过去60年间的发展脉络与人工智能的螺旋上升，并前瞻性地预测了智能时代的商业图景。","ebook_price":"52.80","price":"88"},{"rating":{"max":10,"numRaters":264,"average":"8.0","min":0},"subtitle":"","author":["郑泽宇","顾思宇"],"pubdate":"2017-2-10","tags":[{"count":228,"name":"深度学习","title":"深度学习"},{"count":138,"name":"tensorflow","title":"tensorflow"},{"count":135,"name":"机器学习","title":"机器学习"},{"count":117,"name":"TensorFlow","title":"TensorFlow"},{"count":115,"name":"人工智能","title":"人工智能"},{"count":77,"name":"机器学习深度学习","title":"机器学习深度学习"},{"count":50,"name":"计算机","title":"计算机"},{"count":43,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29349250.jpg","binding":"平装","translator":[],"catalog":"第1章 深度学习简介 1\n1.1 人工智能、机器学习与深度学习 2\n1.2 深度学习的发展历程 7\n1.3 深度学习的应用 10\n1.3.1 计算机视觉 10\n1.3.2 语音识别 14\n1.3.3 自然语言处理 15\n1.3.4 人机博弈 18\n1.4 深度学习工具介绍和对比 19\n小结 23\n第2章 TensorFlow环境搭建 25\n2.1 TensorFlow的主要依赖包 25\n2.1.1 Protocol Buffer 25\n2.1.2 Bazel 27\n2.2 TensorFlow安装 29\n2.2.1 使用Docker安装 30\n2.2.2 使用pip安装 32\n2.2.3 从源代码编译安装 33\n2.3 TensorFlow测试样例 37\n小结 38\n第3章 TensorFlow入门 40\n3.1 TensorFlow计算模型——计算图 40\n3.1.1 计算图的概念 40\n3.1.2 计算图的使用 41\n3.2 TensorFlow数据模型——张量 43\n3.2.1 张量的概念 43\n3.2.2 张量的使用 45\n3.3 TensorFlow运行模型——会话 46\n3.4 TensorFlow实现神经网络 48\n3.4.1 TensorFlow游乐场及神经网络简介 48\n3.4.2 前向传播算法简介 51\n3.4.3 神经网络参数与TensorFlow变量 54\n3.4.4 通过TensorFlow训练神经网络模型 58\n3.4.5 完整神经网络样例程序 62\n小结 65\n第4章 深层神经网络 66\n4.1 深度学习与深层神经网络 66\n4.1.1 线性模型的局限性 67\n4.1.2 激活函数实现去线性化 70\n4.1.3 多层网络解决异或运算 73\n4.2 损失函数定义 74\n4.2.1 经典损失函数 75\n4.2.2 自定义损失函数 79\n4.3 神经网络优化算法 81\n4.4 神经网络进一步优化 84\n4.4.1 学习率的设置 85\n4.4.2 过拟合问题 87\n4.4.3 滑动平均模型 90\n小结 92\n第5章 MNIST数字识别问题 94\n5.1 MNIST数据处理 94\n5.2 神经网络模型训练及不同模型结果对比 97\n5.2.1 TensorFlow训练神经网络 97\n5.2.2 使用验证数据集判断模型效果 102\n5.2.3 不同模型效果比较 103\n5.3 变量管理 107\n5.4 TensorFlow模型持久化 112\n5.4.1 持久化代码实现 112\n5.4.2 持久化原理及数据格式 117\n5.5 TensorFlow最佳实践样例程序 126\n小结 132\n第6章 图像识别与卷积神经网络 134\n6.1 图像识别问题简介及经典数据集 135\n6.2 卷积神经网络简介 139\n6.3 卷积神经网络常用结构 142\n6.3.1 卷积层 142\n6.3.2 池化层 147\n6.4 经典卷积网络模型 149\n6.4.1 LeNet-5模型 150\n6.4.2 Inception-v3模型 156\n6.5 卷积神经网络迁移学习 160\n6.5.1 迁移学习介绍 160\n6.5.2 TensorFlow实现迁移学习 161\n小结 169\n第7章 图像数据处理 170\n7.1 TFRecord输入数据格式 170\n7.1.1 TFRecord格式介绍 171\n7.1.2 TFRecord样例程序 171\n7.2 图像数据处理 173\n7.2.1 TensorFlow图像处理函数 174\n7.2.2 图像预处理完整样例 183\n7.3 多线程输入数据处理框架 185\n7.3.1 队列与多线程 186\n7.3.2 输入文件队列 190\n7.3.3 组合训练数据（batching） 193\n7.3.4 输入数据处理框架 196\n小结 198\n第8章 循环神经网络 200\n8.1 循环神经网络简介 200\n8.2 长短时记忆网络（LTSM）结构 206\n8.3 循环神经网络的变种 212\n8.3.1 双向循环神经网络和深层循环神经网络 212\n8.3.2 循环神经网络的dropout 214\n8.4 循环神经网络样例应用 215\n8.4.1 自然语言建模 216\n8.4.2 时间序列预测 225\n小结 230\n第9章 TensorBoard可视化 232\n9.1 TensorBoard简介 232\n9.2 TensorFlow计算图可视化 234\n9.2.1 命名空间与TensorBoard图上节点 234\n9.2.2 节点信息 241\n9.3 监控指标可视化 246\n小结 252\n第10章 TensorFlow计算加速 253\n10.1 TensorFlow使用GPU 253\n10.2 深度学习训练并行模式 258\n10.3 多GPU并行 261\n10.4 分布式TensorFlow 268\n10.4.1 分布式TensorFlow原理 269\n10.4.2 分布式TensorFlow模型训练 272\n10.4.3 使用Caicloud运行分布式TensorFlow 282\n小结 287","pages":"296","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29349250.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29349250.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29349250.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26976457\/","id":"26976457","publisher":"电子工业出版社","isbn10":"7121309599","isbn13":"9787121309595","title":"Tensorflow：实战Google深度学习框架","url":"https:\/\/api.douban.com\/v2\/book\/26976457","alt_title":"","author_intro":"郑泽宇，现为才云科技（Caicloud.io）联合创始人、首席大数据科学家。针对分布式TensorFlow上手难、管理难、监控难、上线难等问题，他带领团队成功开发了国内首个成熟的分布式TensorFlow深度学习平台（TensorFlow as a Service）。基于此平台，才云大数据团队为安防、电商、金融、物流等多个行业提供有针对性的人工智能解决方案。归国创业之前，郑泽宇曾任美国谷歌高级工程师。从2013 年加入谷歌，郑泽宇作为主要技术人员参与并领导了多个大数据项目。由他提出并主导的产品聚类项目用于衔接谷歌购物和谷歌知识图谱（knowledge graph）数据，使得知识卡片形式的广告逐步取代传统的产品列表广告，开启了谷歌购物广告在搜索页面投递的新纪元。郑泽宇于2011年5月获得北京大学计算机学士学位，并荣获北京大学信息科学技术学院十佳优秀毕业论文、北京大学优秀毕业生。2013年5月获得美国 Carnegie Mellon University（CMU）大学计算机硕士学位，并获得西贝尔奖学金 (Siebel Scholarship)。郑泽宇在机器学习、人工智能领域有多年研究经验，并在SIGIR、SIGKDD、ACL、ICDM、ICWSM等顶级国际会议上发表多篇学术论文。","summary":"TensorFlow是谷歌2015年开源的主流深度学习框架，目前已在谷歌、优步（Uber）、京东、小米等科技公司广泛应用。《Tensorflow实战》为使用TensorFlow深度学习框架的入门参考书，旨在帮助读者以最快、最有效的方式上手TensorFlow和深度学习。书中省略了深度学习繁琐的数学模型推导，从实际应用问题出发，通过具体的TensorFlow样例程序介绍如何使用深度学习解决这些问题。《Tensorflow实战》包含了深度学习的入门知识和大量实践经验，是走进这个最新、最火的人工智能领域的首选参考书。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":33,"average":"8.9","min":0},"subtitle":"","author":["魏溪含　涂铭　张修鹏　著"],"pubdate":"2019-7-10","tags":[{"count":29,"name":"深度学习","title":"深度学习"},{"count":26,"name":"图像识别","title":"图像识别"},{"count":19,"name":"计算机","title":"计算机"},{"count":10,"name":"科技","title":"科技"},{"count":9,"name":"机器学习","title":"机器学习"},{"count":9,"name":"好书，值得一读","title":"好书，值得一读"},{"count":6,"name":"Python","title":"Python"},{"count":4,"name":"提升","title":"提升"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33439354.jpg","binding":"平装","translator":[],"catalog":"前言\n第1章　机器视觉在行业中的应用1\n1.1　机器视觉的发展背景1\n1.1.1　人工智能1\n1.1.2　机器视觉2\n1.2　机器视觉的主要应用场景3\n1.2.1　人脸识别3\n1.2.2　视频监控分析4\n1.2.3　工业瑕疵检测5\n1.2.4　图片识别分析6\n1.2.5　自动驾驶\/驾驶辅助7\n1.2.6　三维图像视觉8\n1.2.7　医疗影像诊断8\n1.2.8　文字识别9\n1.2.9　图像\/视频的生成及设计9\n1.3　本章小结10\n第2章　图像识别前置技术11\n2.1　深度学习框架11\n2.1.1　Theano11\n2.1.2　Tensorflow12\n2.1.3　MXNet13\n2.1.4　Keras13\n2.1.5　PyTorch14\n2.1.6　Caffe14\n2.2　搭建图像识别开发环境15\n2.2.1　Anaconda15\n2.2.2　conda18\n2.2.3　Pytorch的下载与安装19\n2.3　Numpy使用详解20\n2.3.1　创建数组20\n2.3.2　创建Numpy数组22\n2.3.3　获取Numpy属性24\n2.3.4　Numpy数组索引25\n2.3.5　切片25\n2.3.6　Numpy中的矩阵运算26\n2.3.7　数据类型转换27\n2.3.8　Numpy的统计计算方法28\n2.3.9　Numpy中的arg运算29\n2.3.10　FancyIndexing29\n2.3.11　Numpy数组比较30\n2.4　本章小结31\n第3章　图像分类之KNN算法32\n3.1　KNN的理论基础与实现32\n3.1.1　理论知识32\n3.1.2　KNN的算法实现33\n3.2　图像分类识别预备知识35\n3.2.1　图像分类35\n3.2.2　图像预处理36\n3.3　KNN实战36\n3.3.1　KNN实现MNIST数据分类36\n3.3.2　KNN实现Cifar10数据分类41\n3.4　模型参数调优44\n3.5　本章小结48\n第4章　机器学习基础49\n4.1　线性回归模型49\n4.1.1　一元线性回归50\n4.1.2　多元线性回归56\n4.2　逻辑回归模型57\n4.2.1　Sigmoid函数58\n4.2.2　梯度下降法59\n4.2.3　学习率的分析61\n4.2.4　逻辑回归的损失函数63\n4.2.5　Python实现逻辑回归66\n4.3　本章小结68\n第5章　神经网络基础69\n5.1　神经网络69\n5.1.1　神经元70\n5.1.2　激活函数72\n5.1.3　前向传播76\n5.2　输出层80\n5.2.1　Softmax80\n5.2.2　one-hotencoding82\n5.2.3　输出层的神经元个数83\n5.2.4　MNIST数据集的前向传播83\n5.3　批处理85\n5.4　广播原则87\n5.5　损失函数88\n5.5.1　均方误差88\n5.5.2　交叉熵误差89\n5.5.3　Mini-batch90\n5.6　最优化91\n5.6.1　随机初始化91\n5.6.2　跟随梯度（数值微分）92\n5.7　基于数值微分的反向传播98\n5.8　基于测试集的评价101\n5.9　本章小结104\n第6章　误差反向传播105\n6.1　激活函数层的实现105\n6.1.1　ReLU反向传播实现106\n6.1.2　Sigmoid反向传播实现106\n6.2　Affine层的实现107\n6.3　Softmaxwithloss层的实现108\n6.4　基于数值微分和误差反向传播的比较109\n6.5　通过反向传播实现MNIST识别111\n6.6　正则化惩罚114\n6.7　本章小结115\n第7章　PyTorch实现神经网络图像分类116\n7.1　PyTorch的使用116\n7.1.1　Tensor116\n7.1.2　Variable117\n7.1.3　激活函数118\n7.1.4　损失函数120\n7.2　PyTorch实战122\n7.2.1　PyTorch实战之MNIST分类122\n7.2.2　PyTorch实战之Cifar10分类125\n7.3　本章小结128\n第8章　卷积神经网络129\n8.1　卷积神经网络基础129\n8.1.1　全连接层129\n8.1.2　卷积层130\n8.1.3　池化层134\n8.1.4　批规范化层135\n8.2　常见卷积神经网络结构135\n8.2.1　AlexNet136\n8.2.2　VGGNet138\n8.2.3　GoogLeNet140\n8.2.4　ResNet142\n8.2.5　其他网络结构144\n8.3　VGG16实现Cifar10分类145\n8.3.1　训练146\n8.3.2　预测及评估149\n8.4　本章小结152\n8.5　参考文献152\n第9章　目标检测153\n9.1　定位+分类153\n9.2　目标检测155\n9.2.1　R-CNN156\n9.2.2　Fast R-CNN160\n9.2.3　Faster R-CNN162\n9.2.4　YOLO165\n9.2.5　SSD166\n9.3　SSD实现VOC目标检测167\n9.3.1　PASCAL VOC数据集167\n9.3.2　数据准备170\n9.3.3　构建模型175\n9.3.4　定义Loss178\n9.3.5　SSD训练细节181\n9.3.6　训练186\n9.3.7　测试189\n9.4　本章小结190\n9.5　参考文献191\n第10章　分割192\n10.1　语义分割193\n10.1.1　FCN193\n10.1.2　UNet实现裂纹分割196\n10.1.3　SegNet209\n10.1.4　PSPNet210\n10.2　实例分割211\n10.2.1　层叠式212\n10.2.2　扁平式212\n10.3　本章小结213\n10.4　参考文献214\n第11章　产生式模型215\n11.1　自编码器215\n11.2　对抗生成网络215\n11.3　DCGAN及实战217\n11.3.1　数据集218\n11.3.2　网络设置220\n11.3.3　构建产生网络221\n11.3.4　构建判别网络223\n11.3.5　定义损失函数224\n11.3.6　训练过程224\n11.3.7　测试227\n11.4　其他GAN230\n11.5　本章小结235\n11.6　参考文献235\n第12章　神经网络可视化236\n12.1　卷积核236\n12.2　特征层237\n12.2.1　直接观测237\n12.2.2　通过重构观测239\n12.2.3　末端特征激活情况243\n12.2.4　特征层的作用244\n12.3　图片风格化245\n12.3.1　理论介绍245\n12.3.2　代码实现247\n12.4　本章小结255\n12.5　参考文献255\n第13章　图像识别算法的部署模式257\n13.1　图像算法部署模式介绍257\n13.2　实际应用场景和部署模式的匹配262\n13.3　案例介绍264\n13.4　本章小结265","pages":"265","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33439354.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33439354.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33439354.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34465535\/","id":"34465535","publisher":"机械工业出版社","isbn10":"7111630033","isbn13":"9787111630036","title":"深度学习与图像识别：原理与实践","url":"https:\/\/api.douban.com\/v2\/book\/34465535","alt_title":"","author_intro":"魏溪含\n爱丁堡大学人工智能硕士，阿里巴巴达摩院算法专家，在计算机视觉、大数据领域有8年以上的算法架构和研发经验。\n在大数据领域，曾带领团队对阿里巴巴个性化推荐系统进行升级；计算机视觉领域，主导并攻克了光伏EL全自动瑕疵识别的世界难题，并在行为识别领域带领团队参赛打破世界纪录等。\n涂铭\n阿里巴巴数据架构师，对大数据、自然语言处理、图像识别、Python、Java相关技术有深入的研究，积累了丰富的实践经验。在工业领域曾参与了燃煤优化、设备故障诊断项目，正泰光伏电池片和组件EL图像检测项目；在自然语言处理方面，担任导购机器人项目的架构师，主导开发机器人的语义理解、短文本相似度匹配、上下文理解，以及通过自然语言检索产品库，在项目中构建了NoSQL+文本检索等大数据架构，也同时负责问答对的整理和商品属性的提取，带领NLP团队构建语义解析层。\n张修鹏\n毕业于中南大学，阿里巴巴技术发展专家，长期从事云计算、大数据、人工智能与物联网技术的商业化应用，在阿里巴巴首次将图像识别技术引入工业，并推动图像识别产品化、平台化，擅于整合前沿技术解决产业问题，主导多个大数据和AI为核心的数字化转型项目成功实施，对技术和商业结合有着深刻的理解。","summary":"这是一部从技术原理、算法和工程实践3个维度系统讲解图像识别的著作，由阿里巴巴达摩院算法专家、阿里巴巴技术发展专家、阿里巴巴数据架构师联合撰写。\n在知识点的选择上，本书广度和深度兼顾，既能让完全没有基础的读者迅速入门，又能让有基础的读者深入掌握图像识别的核心技术；在写作方式上，本书避开了复杂的数学公式及其推导，从问题的前因后果 、创造者的思考过程，利用简单的数学计算来做模型分析和讲解，通俗易懂。更重要的是，本书不仅仅是聚焦于技术，而是将重点放在了如何用技术解决实际的业务问题。\n全书一共13章：\n第1-2章主要介绍了图像识别的应用场景、工具和工作环境的搭建；\n第3-6章详细讲解了图像分类算法、机器学习、神经网络、误差反向传播等图像识别的基础技术及其原理；\n第7章讲解了如何利用PyTorch来实现神经网络的图像分类，专注于实操，是从基础向高阶的过渡；\n第8-12章深入讲解了图像识别的核心技术及其原理，包括卷积神经网络、目标检测、分割、产生式模型、神经网络可视化等主题；\n第13章从工程实践的角度讲解了图像识别算法的部署模式。\n购买本书的读者请在http:\/\/www.hzcourse.com\/web\/refbook\/detail\/8376\/226\n下载源代码","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"129.00元"},{"rating":{"max":10,"numRaters":98,"average":"7.1","min":0},"subtitle":"","author":["唐亘"],"pubdate":"2018-5-8","tags":[{"count":81,"name":"数据科学","title":"数据科学"},{"count":67,"name":"机器学习","title":"机器学习"},{"count":33,"name":"统计分析","title":"统计分析"},{"count":32,"name":"Python","title":"Python"},{"count":31,"name":"数据分析","title":"数据分析"},{"count":27,"name":"人工智能","title":"人工智能"},{"count":25,"name":"算法","title":"算法"},{"count":13,"name":"AI","title":"AI"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32332172.jpg","binding":"平装","translator":[],"catalog":"第1章  数据科学概述 1\n1.1　挑战　2\n1.1.1　工程实现的挑战　2\n1.1.2　模型搭建的挑战　3\n1.2　机器学习　5\n1.2.1　机器学习与传统编程　5\n1.2.2　监督式学习和非监督式学习　8\n1.3　统计模型　8\n1.4　关于本书　10\n第2章 Python安装指南与简介：告别空谈　12\n2.1　Python简介　13\n2.1.1　什么是Python　15\n2.1.2　Python在数据科学中的地位　16\n2.1.3　不可能绕过的第三方库　17\n2.2　Python安装　17\n2.2.1　Windows下的安装　18\n2.2.2　Mac下的安装　21\n2.2.3　Linux下的安装　24\n2.3　Python上手实践　26\n2.3.1　Python shell　26\n2.3.2　第 一个Python程序：Word Count　28\n2.3.3　Python编程基础　30\n2.3.4　Python的工程结构　34\n2.4　本章小结　35\n第3章　数学基础：恼人但又不可或缺的知识　36\n3.1　矩阵和向量空间　37\n3.1.1　标量、向量与矩阵　37\n3.1.2　特殊矩阵　39\n3.1.3　矩阵运算　39\n3.1.4　代码实现　42\n3.1.5　向量空间　44\n3.2　概率：量化随机　46\n3.2.1　定义概率：事件和概率空间　47\n3.2.2　条件概率：信息的价值　48\n3.2.3　随机变量：两种不同的随机　50\n3.2.4　正态分布：殊途同归　52\n3.2.5　P-value：自信的猜测　53\n3.3　微积分　55\n3.3.1　导数和积分：位置、速度　55\n3.3.2　极限：变化的终点　57\n3.3.3　复合函数：链式法则　58\n3.3.4　多元函数：偏导数　59\n3.3.5　极值与最值：最优选择　59\n3.4　本章小结　61\n第4章　线性回归：模型之母　62\n4.1　一个简单的例子　64\n4.1.1　从机器学习的角度看这个问题　66\n4.1.2　从统计学的角度看这个问题　69\n4.2　上手实践：模型实现　73\n4.2.1　机器学习代码实现　74\n4.2.2　统计方法代码实现　77\n4.3　模型陷阱　82\n4.3.1　过度拟合：模型越复杂越好吗　84\n4.3.2　模型幻觉之统计学方案：假设检验　87\n4.3.3　模型幻觉之机器学习方案：惩罚项　89\n4.3.4　比较两种方案　92\n4.4　模型持久化　92\n4.4.1　模型的生命周期　93\n4.4.2　保存模型　93\n4.5　本章小结　96\n第5章　逻辑回归：隐藏因子　97\n5.1　二元分类问题：是与否　98\n5.1.1　线性回归：为何失效　98\n5.1.2　窗口效应：看不见的才是关键　100\n5.1.3　逻辑分布：胜者生存　102\n5.1.4　参数估计之似然函数：统计学角度　104\n5.1.5　参数估计之损失函数：机器学习角度　104\n5.1.6　参数估计之最终预测：从概率到选择　106\n5.1.7　空间变换：非线性到线性　106\n5.2　上手实践：模型实现　108\n5.2.1　初步分析数据：直观印象　108\n5.2.2　搭建模型　113\n5.2.3　理解模型结果　116\n5.3　评估模型效果：孰优孰劣　118\n5.3.1　查准率与查全率　119\n5.3.2　ROC曲线与AUC　123\n5.4　多元分类问题：超越是与否　127\n5.4.1　多元逻辑回归：逻辑分布的威力　128\n5.4.2　One-vs.-all：从二元到多元　129\n5.4.3　模型实现　130\n5.5　非均衡数据集　132\n5.5.1　准确度悖论　132\n5.5.2　一个例子　133\n5.5.3　解决方法　135\n5.6　本章小结　136\n第6章　工程实现：计算机是怎么算的　138\n6.1　算法思路：模拟滚动　139\n6.2　数值求解：梯度下降法　141\n6.3　上手实践：代码实现　142\n6.3.1　TensorFlow基础　143\n6.3.2　定义模型　148\n6.3.3　梯度下降　149\n6.3.4　分析运行细节　150\n6.4　更优化的算法：随机梯度下降法　153\n6.4.1　算法细节　153\n6.4.2　代码实现　154\n6.4.3　两种算法比较　156\n6.5　本章小结　158\n第7章　计量经济学的启示：他山之石　159\n7.1　定量与定性：变量的数学运算合理吗　161\n7.2　定性变量的处理　162\n7.2.1　虚拟变量　162\n7.2.2　上手实践：代码实现　164\n7.2.3　从定性变量到定量变量　168\n7.3　定量变量的处理　170\n7.3.1　定量变量转换为定性变量　171\n7.3.2　上手实践：代码实现　171\n7.3.3　基于卡方检验的方法　173\n7.4　显著性　175\n7.5　多重共线性：多变量的烦恼　176\n7.5.1　多重共线性效应　176\n7.5.2　检测多重共线性　180\n7.5.3　解决方法　185\n7.5.4　虚拟变量陷阱　188\n7.6　内生性：变化来自何处　191\n7.6.1　来源　192\n7.6.2　内生性效应　193\n7.6.3　工具变量　195\n7.6.4　逻辑回归的内生性　198\n7.6.5　模型的联结　200\n7.7　本章小结　201\n第8章　监督式学习： 目标明确　202\n8.1　支持向量学习机　203\n8.1.1　直观例子　204\n8.1.2　用数学理解直观　205\n8.1.3　从几何直观到最优化问题　207\n8.1.4　损失项　209\n8.1.5　损失函数与惩罚项　210\n8.1.6　Hard margin 与soft margin比较　211\n8.1.7　支持向量学习机与逻辑回归：隐藏的假设　213\n8.2　核函数　216\n8.2.1　空间变换：从非线性到线性　216\n8.2.2　拉格朗日对偶　218\n8.2.3　支持向量　220\n8.2.4　核函数的定义：优化运算　221\n8.2.5　常用的核函数　222\n8.2.6　Scale variant　225\n8.3　决策树　227\n8.3.1　决策规则　227\n8.3.2　评判标准　229\n8.3.3　代码实现　231\n8.3.4　决策树预测算法以及模型的联结　231\n8.3.5　剪枝　235\n8.4　树的集成　238\n8.4.1　随机森林　238\n8.4.2　Random forest embedding　239\n8.4.3　GBTs之梯度提升　241\n8.4.4　GBTs之算法细节　242\n8.5　本章小结　244\n第9章　生成式模型：量化信息的价值　246\n9.1　贝叶斯框架　248\n9.1.1　蒙提霍尔问题　248\n9.1.2　条件概率　249\n9.1.3　先验概率与后验概率　251\n9.1.4　参数估计与预测公式　251\n9.1.5　贝叶斯学派与频率学派　252\n9.2　朴素贝叶斯　254\n9.2.1　特征提取：文字到数字　254\n9.2.2　伯努利模型　256\n9.2.3　多项式模型　258\n9.2.4　TF-IDF　259\n9.2.5　文本分类的代码实现　260\n9.2.6　模型的联结　265\n9.3　判别分析　266\n9.3.1　线性判别分析　267\n9.3.2　线性判别分析与逻辑回归比较　269\n9.3.3　数据降维　270\n9.3.4　代码实现　273\n9.3.5　二次判别分析　275\n9.4　隐马尔可夫模型　276\n9.4.1　一个简单的例子　276\n9.4.2　马尔可夫链　278\n9.4.3　模型架构　279\n9.4.4　中文分词：监督式学习　280\n9.4.5　中文分词之代码实现　282\n9.4.6　股票市场：非监督式学习　284\n9.4.7　股票市场之代码实现　286\n9.5　本章小结　289\n第10章 非监督式学习：聚类与降维　290\n10.1　K-means　292\n10.1.1　模型原理　292\n10.1.2　收敛过程　293\n10.1.3　如何选择聚类个数　295\n10.1.4　应用示例　297\n10.2　其他聚类模型　298\n10.2.1　混合高斯之模型原理　299\n10.2.2　混合高斯之模型实现　300\n10.2.3　谱聚类之聚类结果　303\n10.2.4　谱聚类之模型原理　304\n10.2.5　谱聚类之图片分割　307\n10.3　Pipeline　308\n10.4　主成分分析　309\n10.4.1　模型原理　310\n10.4.2　模型实现　312\n10.4.3　核函数　313\n10.4.4　Kernel PCA的数学原理　315\n10.4.5　应用示例　316\n10.5　奇异值分解　317\n10.5.1　定义　317\n10.5.2　截断奇异值分解　317\n10.5.3　潜在语义分析　318\n10.5.4　大型推荐系统　320\n10.6　本章小结　323\n第11章 分布式机器学习：集体力量　325\n11.1　Spark简介　327\n11.1.1　Spark安装　328\n11.1.2　从MapReduce到Spark　333\n11.1.3　运行Spark　335\n11.1.4　Spark DataFrame　336\n11.1.5　Spark的运行架构　339\n11.2　最优化问题的分布式解法　341\n11.2.1　分布式机器学习的原理　341\n11.2.2　一个简单的例子　342\n11.3　大数据模型的两个维度　344\n11.3.1　数据量维度　344\n11.3.2　模型数量维度　346\n11.4　开源工具的另一面　348\n11.4.1　一个简单的例子　349\n11.4.2　开源工具的阿喀琉斯之踵　351\n11.5　本章小结　351\n第12章 神经网络：模拟人的大脑　353\n12.1　神经元　355\n12.1.1　神经元模型　355\n12.1.2　Sigmoid神经元与二元逻辑回归　356\n12.1.3　Softmax函数与多元逻辑回归　358\n12.2　神经网络　360\n12.2.1　图形表示　360\n12.2.2　数学基础　361\n12.2.3　分类例子　363\n12.2.4　代码实现　365\n12.2.5　模型的联结　369\n12.3　反向传播算法　370\n12.3.1　随机梯度下降法回顾　370\n12.3.2　数学推导　371\n12.3.3　算法步骤　373\n12.4　提高神经网络的学习效率　373\n12.4.1　学习的原理　373\n12.4.2　激活函数的改进　375\n12.4.3　参数初始化　378\n12.4.4　不稳定的梯度　380\n12.5　本章小结　381\n第13章 深度学习：继续探索　383\n13.1　利用神经网络识别数字　384\n13.1.1　搭建模型　384\n13.1.2　防止过拟合之惩罚项　386\n13.1.3　防止过拟合之dropout　387\n13.1.4　代码实现　389\n13.2　卷积神经网络　394\n13.2.1　模型结构之卷积层　395\n13.2.2　模型结构之池化层　397\n13.2.3　模型结构之完整结构　399\n13.2.4　代码实现　400\n13.2.5　结构真的那么重要吗　405\n13.3　其他深度学习模型　406\n13.3.1　递归神经网络　406\n13.3.2　长短期记忆　407\n13.3.3　非监督式学习　409\n13.4　本章小结　411","pages":"432","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32332172.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32332172.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32332172.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30217266\/","id":"30217266","publisher":"人民邮电出版社","isbn10":"7115479100","isbn13":"9787115479105","title":"精通数据科学：从线性回归到深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30217266","alt_title":"","author_intro":"唐亘，数据科学家，专注于机器学习和大数据，热爱并积极参与Apache Spark、scikit-learn等开源项目。作为讲师和技术顾问，为多家机构（包括惠普、华为、复旦大学等）提供百余场技术培训。\n此前的工作和研究集中于经济和量化金融，曾参与经济合作与发展组织（OECD）的研究项目并发表论文，并担任英国知名在线出版社Packt的技术审稿人。\n曾获得复旦大学的数学和计算机双学士学位；巴黎综合理工的金融硕士学位；法国国立统计与经济管理学校的数据科学硕士学位。","summary":"数据科学是一门内涵很广的学科，它涉及到统计分析、机器学习以及计算机科学三方面的知识和技能。本书深入浅出、全面系统地介绍了这门学科的内容。\n本书分为13章，最初的3章主要介绍数据科学想要解决的问题、常用的IT工具Python以及这门学科所涉及的数学基础。第4-7章主要讨论数据模型，主要包含三方面的内容：一是统计中最经典的线性回归和逻辑回归模型；二是计算机估算模型参数的随机梯度下降法，这是模型工程实现的基础；三是来自计量经济学的启示，主要涉及特征提取的方法以及模型的稳定性。接下来的8-10章主要讨论算法模型，也就是机器学习领域比较经典的模型。这三章依次讨论了监督式学习、生成式模型以及非监督式学习。目前数据科学最前沿的两个领域分别是大数据和人工智能。本书的第11章将介绍大数据中很重要的分布式机器学习，而本书的最后两章将讨论人工智能领域的神经网络和深度学习。\n本书通俗易懂，而且理论和实践相结合，可作为数据科学家和数据工程师的学习用书，也适合对数学科学有强烈兴趣的初学者使用。同时也可作为高等院校计算机、数学及相关专业的师生用书和培训学校的教材。","series":{"id":"43598","title":"深度学习系列"},"price":"99.00元"},{"rating":{"max":10,"numRaters":62,"average":"8.4","min":0},"subtitle":"算法原理、框架应用与代码实现","author":["叶韵"],"pubdate":"2017-7-25","tags":[{"count":72,"name":"深度学习","title":"深度学习"},{"count":65,"name":"计算机视觉","title":"计算机视觉"},{"count":22,"name":"计算机","title":"计算机"},{"count":22,"name":"数字图像处理\/计算机视觉","title":"数字图像处理\/计算机视觉"},{"count":15,"name":"机器学习\/深度学习\/TensorFlow\/Caffe","title":"机器学习\/深度学习\/TensorFlow\/Caffe"},{"count":15,"name":"人工智能","title":"人工智能"},{"count":12,"name":"计算机科学","title":"计算机科学"},{"count":10,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29528107.jpg","binding":"平装","translator":[],"catalog":"序言\n前言\n第1篇　基础知识\n第1章　引言\t2\n1.1　人工智能的新焦点——深度学习\t2\n1.1.1　人工智能——神话传说到影视漫画\t2\n1.1.2　人工智能的诞生\t3\n1.1.3　神经科学的研究\t4\n1.1.4　人工神经网络的兴起\t5\n1.1.5　神经网络的第一次寒冬\t6\n1.1.6　神经网络的第一次复兴\t8\n1.1.7　神经网络的第二次寒冬\t9\n1.1.8　2006年——深度学习的起点\t10\n1.1.9　生活中的深度学习\t11\n1.1.10　常见深度学习框架简介\t12\n1.2　给计算机一双眼睛——计算机视觉\t14\n1.2.1　计算机视觉简史\t14\n1.2.2　2012年——计算机视觉的新起点\t16\n1.2.3　计算机视觉的应用\t17\n1.2.4　常见计算机视觉工具包\t19\n1.3　基于深度学习的计算机视觉\t19\n1.3.1　从ImageNet竞赛到AlphaGo战胜李世石——计算机视觉超越人类\t19\n1.3.2　GPU和并行技术——深度学习和计算视觉发展的加速器\t21\n1.3.3　基于卷积神经网络的计算机视觉应用\t22\n第2章　深度学习和计算机视觉中的基础数学知识\t27\n2.1　线性变换和非线性变换\t27\n2.1.1　线性变换的定义\t27\n2.1.2　高中教科书中的小例子\t28\n2.1.3　点积和投影\t28\n2.1.4　矩阵乘法的几何意义（1）\t30\n2.1.5　本征向量和本征值\t34\n2.1.6　矩阵乘法的几何意义（2）\t37\n2.1.7　奇异值分解\t38\n2.1.8　线性可分性和维度\t39\n2.1.9　非线性变换\t42\n2.2　概率论及相关基础知识\t43\n2.2.1　条件概率和独立\t43\n2.2.2　期望值、方差和协方差\t44\n2.2.3　熵\t45\n2.2.4　最大似然估计（Maximum Likelihood Estimation，MLE）\t47\n2.2.5　KL散度（Kullback–Leibler divergence）\t49\n2.2.6　KL散度和MLE的联系\t49\n2.3　维度的诅咒\t50\n2.3.1　采样和维度\t50\n2.3.2　高维空间中的体积\t51\n2.3.3　高维空间中的距离\t53\n2.3.4　中心极限定理和高维样本距离分布的近似\t54\n2.3.5　数据实际的维度\t56\n2.3.6　局部泛化\t58\n2.3.7　函数对实际维度的影响\t59\n2.3.8　PCA——什么是主成分\t60\n2.3.9　PCA——通过本征向量和本征值求主成分\t60\n2.3.10　PCA——通过主成分分析降维\t61\n2.3.11　PCA——归一化和相关性系数\t63\n2.3.12　PCA——什么样的数据适合PCA\t64\n2.3.13　其他降维手段\t65\n2.4　卷积\t66\n2.4.1　点积和卷积\t66\n2.4.2　一维卷积\t67\n2.4.3　卷积和互相关\t68\n2.4.4　二维卷积和图像响应\t69\n2.4.5　卷积的计算\t70\n2.5　数学优化基础\t71\n2.5.1　最小值和梯度下降\t72\n2.5.2　冲量（Momentum）\t73\n2.5.3　牛顿法\t75\n2.5.4　学习率和自适应步长\t77\n2.5.5　学习率衰减（Learning Rate Decay）\t78\n2.5.6　AdaGrad：每个变量有自己的节奏\t78\n2.5.7　AdaDelta的进一步改进\t79\n2.5.8　其他自适应算法\t80\n2.5.9　损失函数\t81\n2.5.10　分类问题和负对数似然\t82\n2.5.11　逻辑回归\t83\n2.5.12　Softmax：将输出转换为概率\t84\n2.5.13　链式求导法则\t84\n第3章　神经网络和机器学习基础\t87\n3.1　感知机\t87\n3.1.1　基本概念\t87\n3.1.2　感知机和线性二分类\t87\n3.1.3　激活函数\t88\n3.2　神经网络基础\t89\n3.2.1　从感知机到神经网络\t89\n3.2.2　最简单的神经网络二分类例子\t90\n3.2.3　隐层神经元数量的作用\t93\n3.2.4　更加复杂的样本和更复杂的神经网络\t94\n3.3　后向传播算法\t95\n3.3.1　求神经网络参数的梯度\t95\n3.3.2　计算图（Computational Graph）\t95\n3.3.3　利用后向传播算法计算一个神经网络参数的梯度\t97\n3.3.4　梯度消失\t99\n3.3.5　修正线性单元（ReLU）\t100\n3.3.6　梯度爆炸\t101\n3.3.7　梯度检查（gradient check）\t102\n3.3.8　从信息传播的角度看后向传播算法\t103\n3.4　随机梯度下降和批量梯度下降\t104\n3.4.1　全量数据（full-batch）梯度下降\t104\n3.4.2　随机梯度下降（SGD）和小批量数据（mini-batch）\t104\n3.4.3　数据均衡和数据增加（data augmentation）\t106\n3.5　数据、训练策略和规范化\t108\n3.5.1　欠拟合和过拟合\t108\n3.5.2　训练误差和测试误差\t109\n3.5.3　奥卡姆剃刀没有免费午餐\t111\n3.5.4　数据集划分和提前停止\t112\n3.5.5　病态问题和约束\t113\n3.5.6　L2规范化（L2 Regularization）\t113\n3.5.7　L1规范化（L1 Regularization）\t114\n3.5.8　集成（Ensemble）和随机失活（Dropout）\t115\n3.6　监督学习、非监督学习、半监督学习和强化学习\t117\n3.6.1　监督学习、非监督学习和半监督学习\t117\n3.6.2　强化学习（reinforcement learning）\t118\n第4章　深度卷积神经网络\t120\n4.1　卷积神经网络\t120\n4.1.1　基本概念\t120\n4.1.2　卷积层和特征响应图\t121\n4.1.3　参数共享\t123\n4.1.4　稀疏连接\t124\n4.1.5　多通道卷积\t125\n4.1.6　激活函数\t125\n4.1.7　池化、不变性和感受野\t126\n4.1.8　分布式表征（Distributed Representation）\t128\n4.1.9　分布式表征和局部泛化\t130\n4.1.10　分层表达\t131\n4.1.11　卷积神经网络结构\t131\n4.2　LeNet——第一个卷积神经网络\t132\n4.3　新起点——AlexNet\t133\n4.3.1　网络结构\t133\n4.3.2　局部响应归一化（Local Response Normalization，LRN）\t136\n4.4　更深的网络——GoogLeNet\t136\n4.4.1　1×1卷积和Network In Network\t136\n4.4.2　Inception结构\t138\n4.4.3　网络结构\t138\n4.4.4　批规一化（Batch Normalization，BN）\t140\n4.5　更深的网络——ResNet\t142\n4.5.1　困难的深层网络训练：退化问题\t142\n4.5.2　残差单元\t142\n4.5.3　深度残差网络\t144\n4.5.4　从集成的角度看待ResNet\t144\n4.5.5　结构更复杂的网络\t146\n第2篇　实例精讲\n第5章　Python基础\t148\n5.1　Python简介\t148\n5.1.1　Python简史\t148\n5.1.2　安装和使用Python\t149\n5.2　Python基本语法\t150\n5.2.1　基本数据类型和运算\t150\n5.2.2　容器\t153\n5.2.3　分支和循环\t156\n5.2.4　函数、生成器和类\t159\n5.2.5　map、reduce和filter\t162\n5.2.6　列表生成（list comprehension）\t163\n5.2.7　字符串\t163\n5.2.8　文件操作和pickle\t164\n5.2.9　异常\t165\n5.2.10　多进程（multiprocessing）\t165\n5.2.11　os模块\t166\n5.3　Python的科学计算包——NumPy\t167\n5.3.1　基本类型（array）\t167\n5.3.2　线性代数模块（linalg）\t172\n5.3.3　随机模块（random）\t173\n5.4　Python的可视化包——matplotlib\t175\n5.4.1　2D图表\t175\n5.4.2　3D图表\t178\n5.4.3　图像显示\t180\n第6章　OpenCV基础\t182\n6.1　OpenCV简介\t182\n6.1.1　OpenCV的结构\t182\n6.1.2　安装和使用OpenCV\t183\n6.2　Python-OpenCV基础\t184\n6.2.1　图像的表示\t184\n6.2.2　基本图像处理\t185\n6.2.3　图像的仿射变换\t188\n6.2.4　基本绘图\t190\n6.2.5　视频功能\t192\n6.3　用OpenCV实现数据增加小工具\t193\n6.3.1　随机裁剪\t194\n6.3.2　随机旋转\t194\n6.3.3　随机颜色和明暗\t196\n6.3.4　多进程调用加速处理\t196\n6.3.5　代码：图片数据增加小工具\t196\n6.4　用OpenCV实现物体标注小工具\t203\n6.4.1　窗口循环\t203\n6.4.2　鼠标和键盘事件\t205\n6.4.3　代码：物体检测标注的小工具\t206\n第7章　Hello World! 212\n7.1　用MXNet实现一个神经网络\t212\n7.1.1　基础工具、NVIDIA驱动和CUDA安装\t212\n7.1.2　安装MXNet\t213\n7.1.3　MXNet基本使用\t214\n7.1.4　用MXNet实现一个两层神经网络\t215\n7.2　用Caffe实现一个神经网络\t219\n7.2.1　安装Caffe\t219\n7.2.2　Caffe的基本概念\t220\n7.2.3　用Caffe实现一个两层神经网络\t221\n第8章　最简单的图片分类——手写数字识别\t227\n8.1　准备数据——MNIST\t227\n8.1.1　下载MNIST\t227\n8.1.2　生成MNIST的图片\t227\n8.2　基于Caffe的实现\t228\n8.2.1　制作LMDB数据\t229\n8.2.2　训练LeNet-5\t230\n8.2.3　测试和评估\t235\n8.2.4　识别手写数字\t239\n8.2.5　增加平移和旋转扰动\t240\n8.3　基于MXNet的实现\t242\n8.3.1　制作Image Recordio数据\t242\n8.3.2　用Module模块训练LeNet-5\t243\n8.3.3　测试和评估\t245\n8.3.4　识别手写数字\t247\n第9章　利用Caffe做回归\t249\n9.1　回归的原理\t249\n9.1.1　预测值和标签值的欧式距离\t249\n9.1.2　EuclideanLoss层\t250\n9.2　预测随机噪声的频率\t250\n9.2.1　生成样本：随机噪声\t250\n9.2.2　制作多标签HDF5数据\t252\n9.2.3　网络结构和Solver定义\t253\n9.2.4　训练网络\t259\n9.2.5　批量装载图片并利用GPU预测\t260\n9.2.6　卷积核可视化\t262\n第10章　迁移学习和模型微调\t264\n10.1　吃货必备——通过Python采集美食图片\t264\n10.1.1　通过关键词和图片搜索引擎下载图片\t264\n10.1.2　数据预处理——去除无效和不相关图片\t267\n10.1.3　数据预处理——去除重复图片\t267\n10.1.4　生成训练数据\t269\n10.2　美食分类模型\t271\n10.2.1　迁移学习\t271\n10.2.2　模型微调法（Finetune）\t272\n10.2.3　混淆矩阵（Confusion Matrix）\t276\n10.2.4　P-R曲线和ROC曲线\t278\n10.2.5　全局平均池化和激活响应图\t284\n第11章　目标检测\t288\n11.1　目标检测算法简介\t288\n11.1.1　滑窗法\t288\n11.1.2　PASCAL VOC、mAP和IOU简介\t289\n11.1.3　Selective Search和R-CNN简介\t290\n11.1.4　SPP、ROI Pooling和Fast R-CNN简介\t291\n11.1.5　RPN和Faster R-CNN简介\t293\n11.1.6　YOLO和SSD简介\t294\n11.2　基于PASCAL VOC数据集训练SSD模型\t296\n11.2.1　MXNet的SSD实现\t296\n11.2.2　下载PASCAL VOC数据集\t297\n11.2.3　训练SSD模型\t298\n11.2.4　测试和评估模型效果\t299\n11.2.5　物体检测结果可视化\t299\n11.2.6　制作自己的标注数据\t302\n第12章　度量学习\t304\n12.1　距离和度量学习\t304\n12.1.1　欧氏距离和马氏距离\t304\n12.1.2　欧式距离和余弦距离\t305\n12.1.3　非线性度量学习和Siamese网络\t306\n12.1.4　Contrastive Loss：对比损失函数\t307\n12.2　用MNIST训练Siamese网络\t307\n12.2.1　数据准备\t307\n12.2.2　参数共享训练\t309\n12.2.3　结果和可视化\t314\n12.2.4　用τ-SNE可视化高维特征\t316\n第13章　图像风格迁移\t317\n13.1　风格迁移算法简介\t317\n13.1.1　通过梯度下降法进行图像重建\t317\n13.1.2　图像风格重建和Gram矩阵\t318\n13.1.3　图像风格迁移\t320\n13.2　MXNet中的图像风格迁移例子\t320\n13.2.1　MXNet的风格迁移实现\t321\n13.2.2　对图片进行风格迁移\t326","ebook_url":"https:\/\/read.douban.com\/ebook\/53052397\/","pages":"344","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29528107.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29528107.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29528107.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27125397\/","id":"27125397","publisher":"机械工业出版社","isbn10":"7111573676","isbn13":"9787111573678","title":"深度学习与计算机视觉","url":"https:\/\/api.douban.com\/v2\/book\/27125397","alt_title":"","author_intro":"叶韵博士，现在京东从事深度学习和计算机视觉算法研发。加入京东之前，曾在ProPlus Design Solutions硅谷和北京研发中心任职研发经理，负责统计建模算法研发，后加入Siemens Corporate Technology担任Research Scientist，专注计算影像和计算机视觉的研究。叶博士于2007年7月获得北京大学微电子学士学位，2011年4月获得Arizona State University的Electrical Engineering博士学位。","summary":"全书共13章，分为2篇。第1篇基础知识，介绍了人工智能发展里程、计算机视觉概要、深度学习和计算机视觉中的基础数学知识、神经网络及其相关的机器学习基础、卷积神经网络及其一些常见结构，最后对最前沿的趋势进行了简单探讨。第2篇实例精讲，介绍了Python基础、OpneCV基础、最简单的分类神经网络、图像识别、利用Caffe做回归、迁移学习和模型微调、目标检测、度量学习和图像风格迁移等常见的计算机视觉应用场景。从第5章开始包含了很多有趣和实用的代码示例。从第7章开始的所有实例都基于当前最流行的深度学习框架中的Caffe和MXNet，其中包含了作者原创的大量代码和搜集的数据，这些代码和作者训练好的部分模型已分享到本书github页面上供读者自行下载。\n代码库地址：\nhttps:\/\/github.com\/frombeijingwithlove\/dlcv_for_beginners","ebook_price":"40.00","price":"79"},{"rating":{"max":10,"numRaters":39,"average":"5.8","min":0},"subtitle":"基于TensorFlow的实践详解","author":["何之源"],"pubdate":"2018-3-1","tags":[{"count":27,"name":"TensorFlow","title":"TensorFlow"},{"count":22,"name":"人工智能","title":"人工智能"},{"count":17,"name":"深度学习","title":"深度学习"},{"count":6,"name":"机器学习","title":"机器学习"},{"count":6,"name":"Python","title":"Python"},{"count":4,"name":"编程","title":"编程"},{"count":4,"name":"人工神經網絡","title":"人工神經網絡"},{"count":2,"name":"中國","title":"中國"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29745965.jpg","binding":"平装","translator":[],"catalog":"第1章  MNIST机器学习入门  1\n1.1  MNIST数据集  2\n1.1.1  简介  2\n1.1.2  实验：将MNIST数据集保存为图片  5\n1.1.3  图像标签的独热(one-hot)表示  6\n1.2  利用TensorFlow识别MNIST  8\n1.2.1  Softmax回归  8\n1.2.2  两层卷积网络分类  14\n1.3  总结  18\n第2章  CIFAR-10与ImageNet图像识别  19\n2.1  CIFAR-10数据集  20\n2.1.1  CIFAR-10简介  20\n2.1.2  下载CIFAR-10数据  21\n2.1.3  TensorFlow的数据读取机制  23\n2.1.4  实验：将CIFAR-10数据集保存为图片形式  30\n2.2  利用TensorFlow训练CIFAR-10识别模型  34\n2.2.1  数据增强（Data Augmentation）  34\n2.2.2  CIFAR-10识别模型  36\n2.2.3  训练模型  39\n2.2.4  在TensorFlow中查看训练进度  39\n2.2.5  测试模型效果  42\n2.3  ImageNet图像识别模型  44\n2.3.1  ImageNet数据集简介  44\n2.3.2  历代ImageNet图像识别模型  45\n2.4  总结  49\n第3章  打造自己的图像识别模型  50\n3.1  微调（Fine-tune）的原理  51\n3.2  数据准备  52\n3.3  使用TensorFlow Slim微调模型  56\n3.3.1  下载TensorFlow Slim的源代码  56\n3.3.2  定义新的datasets文件  57\n3.3.3  准备训练文件夹  59\n3.3.4  开始训练  60\n3.3.5  训练程序行为  62\n3.3.6  验证模型正确率  63\n3.3.7  TensorBoard可视化与超参数选择  64\n3.3.8  导出模型并对单张图片进行识别  65\n3.4  总结  69\n第4章  Deep Dream模型  70\n4.1  Deep Dream的技术原理  71\n4.2  TensorFlow中的Deep Dream模型实践  73\n4.2.1  导入Inception模型  73\n4.2.2  生成原始的Deep Dream图像  76\n4.2.3  生成更大尺寸的Deep Dream图像  78\n4.2.4  生成更高质量的Deep Dream图像  82\n4.2.5  最终的Deep Dream模型  87\n4.3  总结  90\n第5章  深度学习中的目标检测  91\n5.1  深度学习中目标检测的原理  92\n5.1.1  R-CNN的原理  92\n5.1.2  SPPNet的原理  94\n5.1.3  Fast R-CNN的原理  97\n5.1.4  Faster R-CNN的原理  98\n5.2  TensorFlow Object Detection API  101\n5.2.1  安装TensorFlow Object Detection API  101\n5.2.2  执行已经训练好的模型  103\n5.2.3  训练新的模型  109\n5.2.4  导出模型并预测单张图片  113\n5.3  总结  114\n第6章  人脸检测和人脸识别  115\n6.1  MTCNN的原理  116\n6.2  使用深度卷积网络提取特征  121\n6.2.1  三元组损失（Triplet Loss）的定义  123\n6.2.2  中心损失（Center Loss）的定义  123\n6.3  使用特征设计应用  125\n6.4  在TensorFlow中实现人脸识别  126\n6.4.1  项目环境设置  126\n6.4.2  LFW人脸数据库  127\n6.4.3  LFW数据库上的人脸检测和对齐  128\n6.4.4  使用已有模型验证LFW数据库准确率  129\n6.4.5  在自己的数据上使用已有模型  130\n6.4.6  重新训练新模型  133\n6.4.7  三元组损失和中心损失的定义  138\n6.5  总结  140\n第7章  图像风格迁移  141\n7.1  图像风格迁移的原理  142\n7.1.1  原始图像风格迁移的原理  142\n7.1.2  快速图像风格迁移的原理  148\n7.2  在TensorFlow中实现快速风格迁移  149\n7.2.1  使用预训练模型  150\n7.2.2  训练自己的模型  153\n7.2.3  在TensorBoard中监控训练情况  154\n7.2.4  项目实现细节  157\n7.3  总结  162\n第8章  GAN和DCGAN入门  163\n8.1  GAN的原理  164\n8.2  DCGAN的原理  166\n8.3  在TensorFlow中用DCGAN生成图像  169\n8.3.1  生成MNIST图像  170\n8.3.2  使用自己的数据集训练  171\n8.3.3  程序结构分析：如何将图像读入模型  173\n8.3.4  程序结构分析：可视化方法  177\n8.4  总结  180\n第9章  pix2pix模型与自动上色技术  181\n9.1  cGAN的原理  182\n9.2  pix2pix模型的原理  184\n9.3  TensorFlow中的pix2pix模型  187\n9.3.1  执行已有的数据集  187\n9.3.2  创建自己的数据集  191\n9.4  使用TensorFlow为灰度图像自动上色  194\n9.4.1  为食物图片上色  194\n9.4.2  为动漫图片进行上色  196\n9.5  总结  198\n第10章  超分辨率：如何让图像变得更清晰  199\n10.1  数据预处理与训练  200\n10.1.1  去除错误图片  200\n10.1.2  将图像裁剪到统一大小  202\n10.1.3  为代码添加新的操作  202\n10.2  总结  209\n第11章  CycleGAN与非配对图像转换  210\n11.1  CycleGAN的原理  211\n11.2  在TensorFlow中用训练CycleGAN模型  213\n11.2.1  下载数据集并训练  213\n11.2.2  使用自己的数据进行训练  217\n11.3  程序结构分析  220\n11.4  总结  224\n第12章  RNN基本结构与Char RNN文本生成  225\n12.1  RNN的原理  226\n12.1.1  经典RNN的结构  226\n12.1.2  N VS 1 RNN的结构  229\n12.1.3  1 VS N RNN的结构  230\n12.2  LSTM的原理  231\n12.3  Char RNN的原理  235\n12.4  TensorFlow中的RNN实现方式  237\n12.4.1  实现RNN的基本单元：RNNCell  238\n12.4.2  对RNN进行堆叠：MultiRNNCell  239\n12.4.3  注意点：BasicRNNCell和BasicLSTMCell的output  240\n12.4.4  使用tf.nn.dynamic_rnn展开时间维度  241\n12.5  使用TensorFlow实现Char RNN  242\n12.5.1  定义输入数据  243\n12.5.2  定义多层LSTM模型  244\n12.5.3  定义损失  245\n12.5.4  训练模型与生成文字  246\n12.5.5  更多参数说明  250\n12.5.6  运行自己的数据  250\n12.6  总结  251\n第13章  序列分类问题详解  252\n13.1  N VS 1的RNN结构  253\n13.2  数列分类问题与数据生成  254\n13.3  在TensorFlow中定义RNN分类模型  258\n13.3.1  定义模型前的准备工作  258\n13.3.2  定义RNN分类模型  259\n13.3.3  定义损失并进行训练  261\n13.4  模型的推广  262\n13.5  总结  263\n第14章  词的向量表示：word2vec与词嵌入  264\n14.1  为什么需要做词嵌入  265\n14.2  词嵌入的原理  266\n14.2.1  CBOW实现词嵌入的原理  266\n14.2.2  Skip-Gram实现词嵌入的原理  269\n14.3  在TensorFlow中实现词嵌入  270\n14.3.1  下载数据集  270\n14.3.2  制作词表  272\n14.3.3  生成每步的训练样本  274\n14.3.4  定义模型  276\n14.3.5  执行训练  279\n14.3.6  可视化  281\n14.4  与第12章的对比  284\n14.5  总结  285\n第15章  在TensorFlow中进行时间序列预测  286\n15.1  时间序列问题的一般形式  287\n15.2  用TFTS读入时间序列数据  287\n15.2.1  从Numpy数组中读入时间序列数据  288\n15.2.2  从CSV文件中读入时间序列数据  291\n15.3  使用AR模型预测时间序列  293\n15.3.1  AR模型的训练  293\n15.3.2  AR模型的验证和预测  295\n15.4  使用LSTM模型预测时间序列  297\n15.4.1  LSTM模型中的单变量时间序列预测  297\n15.4.2  LSTM模型中的多变量时间序列预测  299\n15.5  总结  301\n第16章  神经网络机器翻译技术  302\n16.1  Encoder-Decoder模型的原理  303\n16.2  注意力机制（Attention）  305\n16.3  使用TensorFlow NMT搭建神经网络翻译引擎  309\n16.3.1  示例：将越南语翻译为英语  309\n16.3.2  构建中英翻译引擎  313\n16.4  TensorFlow NMT源码简介  317\n16.5  总结  319\n第17章  看图说话：将图像转换为文字  320\n17.1  Image Caption技术综述  321\n17.1.1  从Encoder-Decoder结构谈起  321\n17.1.2  将Encoder-Decoder应用到Image Caption任务上  322\n17.1.3  对Encoder-Decoder的改进1：加入Attention机制  323\n17.1.4  对Encoder-Decoder的改进2：加入高层语义  325\n17.2  在TensorFlow中实现Image Caption  327\n17.2.1  下载代码  327\n17.2.2  环境准备  328\n17.2.2  编译和数据准备  328\n17.2.3  训练和验证  330\n17.2.4  测试单张图片  331\n17.3  总结  332\n第18章  强化学习入门之Q  333\n18.1  强化学习中的几个重要概念  334\n18.2  Q Learning的原理与实验  336\n18.2.1  环境定义  336\n18.2.2  Q函数  338\n18.2.3  Q函数的学习策略  339\n18.2.4  ?-greedy策略  341\n18.2.5  简单的Q Learning示例  341\n18.2.6  更复杂的情况  342\n18.3  总结  343\n第19章  强化学习入门之SARSA算法  344\n19.1  SARSA 算法的原理  345\n19.1.1  通过与Q Learning对比学习SARSA算法  345\n19.1.2  off-policy与on-policy  346\n19.2  SARSA 算法的实现  347\n19.3  总结  348\n第20章  深度强化学习：Deep Q Learning  349\n20.1  DQN算法的原理  350\n20.1.1  问题简介  350\n20.1.2  Deep Q Network  351\n20.1.3  训练方法  352\n20.2  在TensorFlow中运行DQN算法  353\n20.2.1  安装依赖库  353\n20.2.2  训练  355\n20.2.3  测试  356\n20.3  在TensorFlow中DQN算法的实现分析  357\n20.4  总结  360\n第21章  策略梯度（Policy Gradient）算法  361\n21.1  策略梯度（Policy Gradient）算法的原理  362\n21.1.1  Cartpole游戏  362\n21.1.2  策略网络（Policy Network）  363\n21.1.3  训练策略网络  364\n21.2  在TensorFlow中实现策略梯度 算法  365\n21.2.1  初始化  365\n21.2.2  定义策略网络  366\n21.2.3  训练  367\n21.3  总结  371","ebook_url":"https:\/\/read.douban.com\/ebook\/59654305\/","pages":"372","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29745965.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29745965.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29745965.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30179607\/","id":"30179607","publisher":"电子工业出版社","isbn10":"7121335719","isbn13":"9787121335716","title":"21个项目玩转深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30179607","alt_title":"","author_intro":"何之源，现为复旦大学人工智能方向在读硕士生。针对Tensorflow早期学习案例不足的情况，在知乎等网站上发表了多篇实践文章，获得了广大读者的肯定。何之源于2012年通过信息学竞赛保送进入复旦大学学习，2016获得复旦大学理学学士学位，并荣获复旦大学优秀学生的称号。同年进入复旦大学计算机学院攻读硕士学位。在编程和机器学习领域有多年一线实践经验。","summary":"《21 个项目玩转深度学习——基于TensorFlow 的实践详解》以实践为导向，深入介绍了深度学习技术和TensorFlow 框架编程内容。\n通过本书，读者可以训练自己的图像识别模型、进行目标检测和人脸识别、完成一个风格迁移应用，还可以使用神经网络生成图像和文本，进行时间序列预测、搭建机器翻译引擎，训练机器玩游戏。全书共包含21 个项目，分为深度卷积网络、RNN网络、深度强化学习三部分。读者可以在自己动手实践的过程中找到学习的乐趣，了解算法和编程框架的细节，让学习深度学习算法和TensorFlow 的过程变得轻松和高效。本书代码基于TensorFlow 1.4 及以上版本，并介绍了TensorFlow 中的一些新特性。\n本书适合有一定机器学习基础的学生、研究者或从业者阅读，尤其是希望深入研究TensorFlow 和深度学习算法的数据工程师，也适合对人工智能、深度学习感兴趣的在校学生，以及希望进入大数据应用的研究者。","ebook_price":"47.40","series":{"id":"41172","title":"博文视点AI系列"},"price":"CNY 79.00"},{"rating":{"max":10,"numRaters":30,"average":"8.0","min":0},"subtitle":"","author":["俞栋","邓力"],"pubdate":"2016-6","tags":[{"count":48,"name":"深度学习","title":"深度学习"},{"count":45,"name":"语音识别","title":"语音识别"},{"count":19,"name":"人工智能","title":"人工智能"},{"count":14,"name":"计算机","title":"计算机"},{"count":11,"name":"机器学习","title":"机器学习"},{"count":5,"name":"2016","title":"2016"},{"count":4,"name":"machine_learning","title":"machine_learning"},{"count":2,"name":"数学-连续","title":"数学-连续"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29735805.jpg","binding":"平装","translator":["俞凯","钱彦旻"],"catalog":"译者序 iv\n序 vii\n前言 ix\n术语缩写 xxii\n符号 xxvii\n第 1 章 简介 1\n1.1 自动语音识别：更好的沟通之桥 . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1.1 人类之间的交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.2 人机交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.2 语音识别系统的基本结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 全书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.1 第一部分：传统声学模型 . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.2 第二部分：深度神经网络 . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.3 第三部分：语音识别中的 DNN-HMM 混合系统 . . . . . . . . . . 7\n1.3.4 第四部分：深度神经网络中的表征学习 . . . . . . . . . . . . . . 7\n1.3.5 第五部分：高级的深度模型 . . . . . . . . . . . . . . . . . . . . . 7\n第一部分 传统声学模型 9\n第 2 章 混合高斯模型 11\n2.1 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.2 高斯分布和混合高斯随机变量 . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.3 参数估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.4 采用混合高斯分布对语音特征建模 . . . . . . . . . . . . . . . . . . . . . 16\n第 3 章 隐马尔可夫模型及其变体 19\n3.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.2 马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.3 序列与模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3.3.1 隐马尔可夫模型的性质 . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.3.2 隐马尔可夫模型的仿真 . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3.3 隐马尔可夫模型似然度的计算 . . . . . . . . . . . . . . . . . . . . 24\n3.3.4 计算似然度的高效算法 . . . . . . . . . . . . . . . . . . . . . . . . 26\n3.3.5 前向与后向递归式的证明 . . . . . . . . . . . . . . . . . . . . . . 27\n3.4 期望最大化算法及其在学习 HMM 参数中的应用 . . . . . . . . . . . . . 28\n3.4.1 期望最大化算法介绍 . . . . . . . . . . . . . . . . . . . . . . . . . 28\n3.4.2 使用 EM 算法来学习 HMM 参数——Baum-Welch 算法 . . . . . . 30\n3.5 用于解码 HMM 状态序列的维特比算法 . . . . . . . . . . . . . . . . . . . 34\n3.5.1 动态规划和维特比算法 . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.5.2 用于解码 HMM 状态的动态规划算法 . . . . . . . . . . . . . . . . 35\n3.6 隐马尔可夫模型和生成语音识别模型的变体 . . . . . . . . . . . . . . . . 37\n3.6.1 用于语音识别的 GMM-HMM 模型 . . . . . . . . . . . . . . . . . 38\n3.6.2 基于轨迹和隐藏动态模型的语音建模和识别 . . . . . . . . . . . . 39\n3.6.3 使用生成模型 HMM 及其变体解决语音识别问题 . . . . . . . . . 40\n第二部分 深度神经网络 43\n第 4 章 深度神经网络 45\n4.1 深度神经网络框架 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.2 使用误差反向传播来进行参数训练 . . . . . . . . . . . . . . . . . . . . . 48\n4.2.1 训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n4.2.2 训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.3 实际应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.3.2 模型初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n4.3.3 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n4.3.4 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.3.5 批量块大小的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.3.6 取样随机化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.3.7 惯性系数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n4.3.8 学习率和停止准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4.3.9 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n4.3.10 可复现性与可重启性 . . . . . . . . . . . . . . . . . . . . . . . . . 62\n第 5 章 高级模型初始化技术 65\n5.1 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n5.1.1 受限玻尔兹曼机的属性 . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.1.2 受限玻尔兹曼机参数学习 . . . . . . . . . . . . . . . . . . . . . . 70\n5.2 深度置信网络预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.3 降噪自动编码器预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n5.4 鉴别性预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n5.5 混合预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n5.6 采用丢弃法的预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\n第三部分 语音识别中的深度神经网络–隐马尔可夫混合模型 81\n第 6 章 深度神经网络–隐马尔可夫模型混合系统 83\n6.1 DNN-HMM 混合系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n6.1.1 结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n6.1.2 用 CD-DNN-HMM 解码 . . . . . . . . . . . . . . . . . . . . . . . . 85\n6.1.3 CD-DNN-HMM 训练过程 . . . . . . . . . . . . . . . . . . . . . . . 86\n6.1.4 上下文窗口的影响 . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n6.2 CD-DNN-HMM 的关键模块及分析 . . . . . . . . . . . . . . . . . . . . . 90\n6.2.1 进行比较和分析的数据集和实验 . . . . . . . . . . . . . . . . . . 90\n6.2.2 对单音素或者三音素的状态进行建模 . . . . . . . . . . . . . . . . 92\n6.2.3 越深越好 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.2.4 利用相邻的语音帧 . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n6.2.5 预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n6.2.6 训练数据的标注质量的影响 . . . . . . . . . . . . . . . . . . . . . 95\n6.2.7 调整转移概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n6.3 基于 KL 距离的隐马尔可夫模型 . . . . . . . . . . . . . . . . . . . . . . . 96\n第 7 章 训练和解码的加速 99\n7.1 训练加速 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n7.1.1 使用多 GPU 流水线反向传播 . . . . . . . . . . . . . . . . . . . . 100\n7.1.2 异步随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n7.1.3 增广拉格朗日算法及乘子方向交替算法 . . . . . . . . . . . . . . 106\n7.1.4 减小模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n7.1.5 其他方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n7.2 加速解码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n7.2.1 并行计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n7.2.2 稀疏网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\n7.2.3 低秩近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n7.2.4 用大尺寸 DNN 训练小尺寸 DNN . . . . . . . . . . . . . . . . . . 114\n7.2.5 多帧 DNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\n第 8 章 深度神经网络序列鉴别性训练 117\n8.1 序列鉴别性训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n8.1.1 最大相互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\n8.1.2 增强型 MMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n8.1.3 最小音素错误\/状态级最小贝叶斯风险 . . . . . . . . . . . . . . . 120\n8.1.4 统一的公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n8.2 具体实现中的考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n8.2.1 词图产生 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n8.2.2 词图补偿 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n8.2.3 帧平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n8.2.4 学习率调整 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n8.2.5 训练准则选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n8.2.6 其他考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n8.3 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n8.3.1 将概率密度估计问题转换为二分类设计问题 . . . . . . . . . . . . 127\n8.3.2 拓展到未归一化的模型 . . . . . . . . . . . . . . . . . . . . . . . . 129\n8.3.3 在深度学习网络训练中应用噪声对比估计算法 . . . . . . . . . . 130\n第四部分 深度神经网络中的特征表示学习 133\n第 9 章 深度神经网络中的特征表示学习 135\n9.1 特征和分类器的联合学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n9.2 特征层级 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n9.3 使用随意输入特征的灵活性 . . . . . . . . . . . . . . . . . . . . . . . . . 140\n9.4 特征的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n9.4.1 对说话人变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . 141\n9.4.2 对环境变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 142\n9.5 对环境的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n9.5.1 对噪声的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\n9.5.2 对语速变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 147\n9.6 缺乏严重信号失真情况下的推广能力 . . . . . . . . . . . . . . . . . . . . 148\n第 10 章 深度神经网络和混合高斯模型的融合 151\n10.1 在 GMM-HMM 系统中使用由 DNN 衍生的特征 . . . . . . . . . . . . . . 151\n10.1.1 使用 Tandem 和瓶颈特征的 GMM-HMM 模型 . . . . . . . . . . . 151\n10.1.2 DNN-HMM 混合系统与采用深度特征的 GMM-HMM 系统的比较 154\n10.2 识别结果融合技术 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\n10.2.1 识别错误票选降低技术（ ROVER） . . . . . . . . . . . . . . . . . 157\n10.2.2 分段条件随机场（ SCARF） . . . . . . . . . . . . . . . . . . . . . 159\n10.2.3 最小贝叶斯风险词图融合 . . . . . . . . . . . . . . . . . . . . . . 160\n10.3 帧级别的声学分数融合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\n10.4 多流语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\n第 11 章 深度神经网络的自适应技术 165\n11.1 深度神经网络中的自适应问题 . . . . . . . . . . . . . . . . . . . . . . . . 165\n11.2 线性变换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n11.2.1 线性输入网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n11.2.2 线性输出网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n11.3 线性隐层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n11.4 保守训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n11.4.1 L 2 正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n11.4.2 KL 距离正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n11.4.3 减少每个说话人的模型开销 . . . . . . . . . . . . . . . . . . . . . 173\n11.5 子空间方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n11.5.1 通过主成分分析构建子空间 . . . . . . . . . . . . . . . . . . . . . 175\n11.5.2 噪声感知、说话人感知及设备感知训练 . . . . . . . . . . . . . . 176\n11.5.3 张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\n11.6 DNN 说话人自适应的效果 . . . . . . . . . . . . . . . . . . . . . . . . . . 181\n11.6.1 基于 KL 距离的正则化方法 . . . . . . . . . . . . . . . . . . . . . 181\n11.6.2 说话人感知训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\n第五部分 先进的深度学习模型 185\n第 12 章 深度神经网络中的表征共享和迁移 187\n12.1 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\n12.1.1 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\n12.1.2 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n12.2 多语言和跨语言语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n12.2.1 基于 Tandem 或瓶颈特征的跨语言语音识别 . . . . . . . . . . . . 190\n12.2.2 共享隐层的多语言深度神经网络 . . . . . . . . . . . . . . . . . . 191\n12.2.3 跨语言模型迁移 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n12.3 语音识别中深度神经网络的多目标学习 . . . . . . . . . . . . . . . . . . . 197\n12.3.1 使用多任务学习的鲁棒语音识别 . . . . . . . . . . . . . . . . . . 197\n12.3.2 使用多任务学习改善音素识别 . . . . . . . . . . . . . . . . . . . . 198\n12.3.3 同时识别音素和字素（ graphemes） . . . . . . . . . . . . . . . . . 199\n12.4 使用视听信息的鲁棒语音识别 . . . . . . . . . . . . . . . . . . . . . . . . 199\n第 13 章 循环神经网络及相关模型 201\n13.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\n13.2 基本循环神经网络中的状态-空间公式 . . . . . . . . . . . . . . . . . . . . 203\n13.3 沿时反向传播学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\n13.3.1 最小化目标函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\n13.3.2 误差项的递归计算 . . . . . . . . . . . . . . . . . . . . . . . . . . 205\n13.3.3 循环神经网络权重的更新 . . . . . . . . . . . . . . . . . . . . . . 206\n13.4 一种用于学习循环神经网络的原始对偶技术 . . . . . . . . . . . . . . . . 208\n13.4.1 循环神经网络学习的难点 . . . . . . . . . . . . . . . . . . . . . . 208\n13.4.2 回声状态（ Echo-State）性质及其充分条件 . . . . . . . . . . . . . 208\n13.4.3 将循环神经网络的学习转化为带约束的优化问题 . . . . . . . . . 209\n13.4.4 一种用于学习 RNN 的原始对偶方法 . . . . . . . . . . . . . . . . 210\n13.5 结合长短时记忆单元（ LSTM）的循环神经网络 . . . . . . . . . . . . . . 212\n13.5.1 动机与应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\n13.5.2 长短时记忆单元的神经元架构 . . . . . . . . . . . . . . . . . . . . 213\n13.5.3 LSTM-RNN 的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 214\n13.6 循环神经网络的对比分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\n13.6.1 信息流方向的对比：自上而下还是自下而上 . . . . . . . . . . . . 215\n13.6.2 信息表征的对比：集中式还是分布式 . . . . . . . . . . . . . . . . 217\n13.6.3 解释能力的对比：隐含层推断还是端到端学习 . . . . . . . . . . 218\n13.6.4 参数化方式的对比：吝啬参数集合还是大规模参数矩阵 . . . . . 218\n13.6.5 模型学习方法的对比：变分推理还是梯度下降 . . . . . . . . . . 219\n13.6.6 识别正确率的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 220\n13.7 讨论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n第 14 章 计算型网络 223\n14.1 计算型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\n14.2 前向计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\n14.3 模型训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\n14.4 典型的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n14.4.1 无操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . 232\n14.4.2 含一个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 232\n14.4.3 含两个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 237\n14.4.4 用来计算统计量的计算节点类型 . . . . . . . . . . . . . . . . . . 244\n14.5 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n14.6 循环连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\n14.6.1 只在循环中一个接一个地处理样本 . . . . . . . . . . . . . . . . . 249\n14.6.2 同时处理多个句子 . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n14.6.3 创建任意的循环神经网络 . . . . . . . . . . . . . . . . . . . . . . 252\n第 15 章 总结及未来研究方向 255\n15.1 路线图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\n15.1.1 语音识别中的深度神经网络启蒙 . . . . . . . . . . . . . . . . . . 255\n15.1.2 深度神经网络训练和解码加速 . . . . . . . . . . . . . . . . . . . . 258\n15.1.3 序列鉴别性训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\n15.1.4 特征处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n15.1.5 自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\n15.1.6 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 261\n15.1.7 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\n15.1.8 循环神经网络和长短时记忆神经网络 . . . . . . . . . . . . . . . . 261\n15.1.9 其他深度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n15.2 技术前沿和未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n15.2.1 技术前沿简析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n15.2.2 未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\n参考文献 267","ebook_url":"https:\/\/read.douban.com\/ebook\/58176156\/","pages":"336","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29735805.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29735805.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29735805.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26820808\/","id":"26820808","publisher":"电子工业出版社","isbn10":"712128796X","isbn13":"9787121287961","title":"解析深度学习：语音识别实践","url":"https:\/\/api.douban.com\/v2\/book\/26820808","alt_title":"","author_intro":"俞栋\n1998 年加入微软公司，现任微软研究院首席研究员、浙江大学兼职教授和中科大客座教授。他是语音识别和深度学习方向的资深专家，出版了两本专著，发表了150 多篇论文，是近60 项专利的发明人及有广泛影响力的深度学习开源软件CNTK 的发起人和主要作者之一。他在基于深度学习的语音识别技术上的工作带来了语音识别研究方向的转变，极大地推动了语音识别领域的发展，并获得2013 年IEEE 信号处理协会最佳论文奖。俞栋博士现担任IEEE 语音语言处理专业委员会委员，曾担任IEEE\/ACM音频、语音及语言处理汇刊、IEEE 信号处理杂志等期刊的编委。\n邓力\n世界著名人工智能、机器学习和语音语言信号处理专家，现任微软首席人工智能科学家和深度学习技术中心研究经理。他在美国威斯康星大学先后获硕士和博士学位，然后在加拿大滑铁卢大学任教获得终身正教授。其间，他还任麻省理工学院研究职位。1999 年加入微软研究院历任数职，并在2014 年初创办深度学习技术中心，主持微软公司和研究院的人工智能和深度学习领域的技术创新。 邓立博士的研究方向包括自动语音与说话者识别、口语识别与理解、语音-语音翻译、机器翻译、语言模式、统计方法与机器学习、听觉和其他生物信息处理、深层结构学习、类脑机器智能、图像语言多模态深度学习，商业大数据深度分析等。他在上述领域做出了重大贡献，是ASA（美国声学学会）会士、IEEE（美国电气和电子工程师协会）会士和理事、ISCA（国际语音通信协会）会士，并凭借在深度学习与自动语音识别方向做出的杰出贡献荣获2015年度IEEE 信号处理技术成就奖。同时，他也曾在顶级杂志和会议上发表过与上述领域相关的300 余篇学术论文，出版过5 部著作，发明及合作发明了超过70 多项专利。邓立博士还担任过IEEE 信号处理杂志和《音频、语音与语言处理学报》（IEEE\/ACMTransactions on Audio, Speech & anguage Processing）的主编。\n俞凯\nIEEE 高级会员，上海交通大学计算机科学与工程系特别研究员。清华大学本科、硕士，英国剑桥大学工程系博士。长期从事智能语音及语言处理、人机交互、模式识别及机器学习的研究和产业化工作。他是中组部\"千人计划\"（青年项目）获得者，国家自然科学基金委优秀青年科学基金获得者，上海市\"东方学者\"特聘教授；作为共同创始人和首席科学家创立\"苏州思必驰信息科技有限公司\"。现任中国声学学会语音语言、听觉及音乐分会执委会委员，中国计算机学会人机交互专委会委员，中国语音产业联盟技术工作组副组长。他的研究兴趣涉及语音识别、语音合成、口语理解、对话系统、认知型人机交互等智能语音语言处理技术的多个核心技术领域，在本领域的一流国际期刊和会议上发表论文80 余篇，申请专利10 余项，取得了一系列研究、工程和产业化成果。在InterSpeech 及IEEE Spoken Language Processing 等国际会议上获得3 篇国际会议优秀论文奖，获得国际语音通信联盟（ISCA）2013 年颁发的2008-2012 Computer Speech and Language 最优论文奖。受邀担任InterSpeech 2009 语音识别领域主席、EUSIPCO 2011\/EUSIPCO 2014 语音处理领域主席、InterSpeech 2014 口语对话系统领域主席等。他负责搭建或参与搭建的大规模连续语音识别系统，曾获得美国国家标准局（NIST）和美国国防部内部评测冠军；作为核心技术人员，负责设计并实现的认知型统计对话系统原型，在CMU 组织的2010 年对话系统国际挑战赛上获得了可控测试的冠军。作为项目负责人或Co-PI，他主持了欧盟第7 框架PARLANCE、国家自然科学基金委、上海市教委、经信委，以及美国通用公司、苏州思必驰信息科技有限公司的一系列科研及产业化项目。2014 年，因在智能语音技术产业化方面的贡献，获得中国人工智能学会颁发的\"吴文俊人工智能科学技术奖\"。\n钱彦旻\n上海交通大学计算机科学与工程系助理研究员，博士。分别在2007 年6 月和2013 年1 月于华中科技大学和清华大学获得工学学士和工学博士学位。2013 年4 月起，任上海交通大学计算机科与工程系理研究员。同时从2015 年1 月至2015 年12 月，在英国剑桥大学工程系机器智能实验室语音组进行访问，作为项目研究员与语音识别领域的著名科学家Phil Woodland 教授和Mark Gales 教授开展合作研究。现为IEEE、ISCA 会员，同时也是国际开源项目Kaldi 语音识别工具包开发的项目组创始成员之一。此外，担任IEEE Transactions on Audio, Speech, and Language Processing、SpeechCommunication、ICASSP、Interspeech、ASRU 等国际期刊和会议的审稿人。目前在国内外学术刊物和会议上发表学术论文50 余篇，Google Scholar 总引用数近1000 次。其中包括在语音识别领域权威国际会议ICASSP、InterSpeech 和ASRU 上发表论文30 余篇，申请国家专利共3 项，已授权1 项。2008 年获科技奥运先进集体奖，2014 年获中国人工智能学会颁发的\"吴文俊人工智能科学技术奖进步奖\"。曾作为负责人和主要参与者参加了包括英国EPSRC、国家自然科学基金、国家863 等多个项目。目前的研究领域包括：语音识别、说话人和语种识别、自然语言理解、深度学习建模、多媒体信号处理等。","summary":"AlphaGo与李世石的围棋大战激发了人们对人工智能是非的诸多争论。人工智能背后的工作原理深度学习跳入大众的视野。AlphaGo的大获全胜一定程度展示了深度学习在应用领域的成功，而语音识别正是深度学习取得显著成功的应用领域之一。\n本书是首次以深度学习为主线介绍语音识别应用的书籍，对读者了解语音识别技术及其发展历程有重要的参考价值。\n本书作者俞栋、邓力均是该领域的著名专家，他们是深度学习在应用领域取得突破性进展的推动者与实践者，他们在书中分享的研究成果一定程度上代表了本领域最新的研究进展；译者俞凯、钱彦旻也是本领域的资深专家，并有众多实践成果。对于从事此领域研究的读者来说，本书无疑有重要的参考价值。\n《解析深度学习：语音识别实践》是首部介绍语音识别中深度学习技术细节的专著。全书首先概要介绍了传统语音识别理论和经典的深度神经网络核心算法。接着全面而深入地介绍了深度学习在语音识别中的应用，包括\"深度神经网络-隐马尔可夫混合模型\"的训练和优化，特征表示学习、模型融合、自适应，以及以循环神经网络为代表的若干先进深度学习技术。\n《解析深度学习：语音识别实践》适合有一定机器学习或语音识别基础的学生、研究者或从业者阅读，所有的算法及技术细节都提供了详尽的参考文献，给出了深度学习在语音识别中应用的全景。","ebook_price":"35.55","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00元"},{"rating":{"max":10,"numRaters":72,"average":"6.4","min":0},"subtitle":"","author":["赵永科"],"pubdate":"","tags":[{"count":61,"name":"深度学习","title":"深度学习"},{"count":32,"name":"机器学习","title":"机器学习"},{"count":27,"name":"caffe","title":"caffe"},{"count":14,"name":"人工智能","title":"人工智能"},{"count":13,"name":"计算机","title":"计算机"},{"count":12,"name":"神经网络","title":"神经网络"},{"count":9,"name":"计算机科学","title":"计算机科学"},{"count":6,"name":"AI","title":"AI"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28865185.jpg","binding":"平装","translator":[],"catalog":"上篇 初见\n第1天 什么是深度学习 2\n1.1 星星之火，可以燎原 3\n1.2 师夷长技 4\n1.2.1 谷歌与微软 4\n1.2.2 Facebook、亚马逊与NVIDIA 5\n1.3 中国崛起 6\n1.3.1 BAT在路上 6\n1.3.2 星光闪耀 7\n1.3.3 企业热是风向标 8\n1.4 练习题 9\n第2天 深度学习的过往 10\n2.1 传统机器学习的局限性 10\n2.2 从表示学习到深度学习 11\n2.3 监督学习 12\n2.4 反向传播算法 13\n2.5 卷积神经网络 15\n2.6 深度学习反思 17\n2.7 练习题 18\n2.8 参考资料 18\n第3天 深度学习工具汇总 19\n3.1 Caffe 19\n3.2 Torch & OverFeat 20\n3.3 MxNet 22\n3.4 TensorFlow 22\n3.5 Theano 24\n3.6 CNTK 24\n3.7 练习题 25\n3.8 参考资料 26\n第4天 准备Caffe环境 27\n4.1 Mac OS环境准备 27\n4.2 Ubuntu环境准备 28\n4.3 RHEL\/Fedora\/CentOS环境准备 29\n4.4 Windows环境准备 29\n4.5 常见问题 32\n4.6 练习题 32\n4.7 参考资料 33\n第5天 Caffe依赖包解析 34\n5.1 ProtoBuffer 34\n5.2 Boost 38\n5.3 GFLAGS 38\n5.4 GLOG 39\n5.5 BLAS 40\n5.6 HDF5 41\n5.7 OpenCV 42\n5.8 LMDB和LEVELDB 42\n5.9 Snappy 43\n5.10 小结 43\n5.11 练习题 49\n5.12 参考资料 49\n第6天 运行手写体数字识别例程 50\n6.1 MNIST数据集 50\n6.1.1 下载MNIST数据集 50\n6.1.2 MNIST数据格式描述 51\n6.1.3 转换格式 53\n6.2 LeNet-5模型 60\n6.2.1 LeNet-5模型描述 60\n6.2.2 训练超参数 65\n6.2.3 训练日志 66\n6.2.4 用训练好的模型对数据进行预测 76\n6.2.5 Windows下训练模型 76\n6.3 回顾 78\n6.4 练习题 79\n6.5 参考资料 79\n篇尾语 80\n中篇 热恋\n第7天 Caffe代码梳理 82\n7.1 Caffe目录结构 82\n7.2 如何有效阅读Caffe源码 84\n7.3 Caffe支持哪些深度学习特性 86\n7.3.1 卷积层 86\n7.3.2 全连接层 89\n7.3.3 激活函数 91\n7.4 小结 99\n7.5 练习题 99\n7.6 参考资料 100\n第8天 Caffe数据结构 101\n8.1 Blob 101\n8.1.1 Blob基本用法 102\n8.1.2 数据结构描述 108\n8.1.3 Blob是怎样炼成的 109\n8.2 Layer 125\n8.2.1 数据结构描述 126\n8.2.2 Layer是怎样建成的 127\n8.3 Net 136\n8.3.1 Net基本用法 136\n8.3.2 数据结构描述 139\n8.3.3 Net是怎样绘成的 139\n8.4 机制和策略 146\n8.5 练习题 147\n8.6 参考资料 148\n第9天 Caffe I\/O模块 149\n9.1 数据读取层 149\n9.1.1 数据结构描述 149\n9.1.2 数据读取层实现 150\n9.2 数据变换器 155\n9.2.1 数据结构描述 155\n9.2.2 数据变换器的实现 156\n9.3 练习题 171\n第10天 Caffe模型 172\n10.1 prototxt表示 173\n10.2 内存中的表示 176\n10.3 磁盘上的表示 176\n10.4 Caffe Model Zoo 178\n10.5 练习题 180\n10.6 参考资料 180\n第11天 Caffe前向传播计算 181\n11.1 前向传播的特点 181\n11.2 前向传播的实现 182\n11.2.1 DAG构造过程 182\n11.2.2 Net Forward实现 190\n11.3 练习题 192\n第12天 Caffe反向传播计算 193\n12.1 反向传播的特点 193\n12.2 损失函数 193\n12.2.1 算法描述 194\n12.2.2 参数描述 195\n12.2.3 源码分析 195\n12.3 反向传播的实现 203\n12.4 练习题 205\n第13天 Caffe最优化求解过程 207\n13.1 求解器是什么 207\n13.2 求解器是如何实现的 208\n13.2.1 算法描述 208\n13.2.2 数据结构描述 210\n13.2.3 CNN训练过程 218\n13.2.4 CNN预测过程 225\n13.2.5 Solver的快照和恢复功能 227\n13.3 练习题 230\n第14天 Caffe实用工具 231\n14.1 训练和预测 231\n14.2 特征提取 241\n14.3 转换图像格式 247\n14.4 计算图像均值 254\n14.5 自己编写工具 257\n14.6 练习题 257\n篇尾语 258\n下篇 升华\n第15天 Caffe计算加速 260\n15.1 Caffe计时功能 260\n15.2 Caffe GPU加速模式 262\n15.2.1 GPU是什么 262\n15.2.2 CUDA是什么 263\n15.2.3 GPU、CUDA和深度学习 263\n15.2.4 Caffe GPU环境准备 264\n15.2.5 切换到Caffe GPU加速模式 268\n15.3 Caffe cuDNN加速模式 269\n15.3.1 获取cuDNN 270\n15.3.2 切换到Caffe cuDNN加速模式 270\n15.3.3 Caffe不同硬件配置性能 272\n15.4 练习题 273\n15.5 参考资料 273\n第16天 Caffe可视化方法 275\n16.1 数据可视化 275\n16.1.1 MNIST数据可视化 275\n16.1.2 CIFAR10数据可视化 277\n16.1.3 ImageNet数据可视化 278\n16.2 模型可视化 279\n16.2.1 网络结构可视化 279\n16.2.2 网络权值可视化 281\n16.3 特征图可视化 288\n16.4 学习曲线 295\n16.5 小结 298\n16.6 练习题 298\n16.7 参考资料 299\n第17天 Caffe迁移和部署 300\n17.1 从开发测试到生产部署 300\n17.2 使用Docker 302\n17.2.1 Docker基本概念 302\n17.2.2 Docker安装 303\n17.2.3 Docker入门 305\n17.2.4 Docker使用进阶 312\n17.3 练习题 317\n17.4 参考资料 317\n第18天 关于ILSVRC不得不说的一些事儿 318\n18.1 ImageNet数据集 318\n18.2 ILSVRC比赛项目 319\n18.2.1 图像分类（CLS） 320\n18.2.2 目标定位（LOC） 320\n18.2.3 目标检测（DET） 321\n18.2.4 视频目标检测（VID） 322\n18.2.5 场景分类 322\n18.3 Caffe ILSVRC实践 323\n18.4 练习题 326\n18.5 参考资料 326\n第19天 放之四海而皆准 327\n19.1 图像分类 327\n19.1.1 问题描述 327\n19.1.2 应用案例--商品分类 330\n19.2 图像中的字符识别 332\n19.2.1 问题描述 332\n19.2.2 应用案例--身份证实名认证 333\n19.3 目标检测 337\n19.3.1 问题描述 337\n19.3.2 最佳实践--运行R-CNN例程 337\n19.4 人脸识别 340\n19.4.1 问题描述 340\n19.4.2 最佳实践--使用Face++ SDK实现人脸检测 342\n19.5 自然语言处理 343\n19.5.1 问题描述 343\n19.5.2 最佳实践--NLP-Caffe 344\n19.6 艺术风格 350\n19.6.1 问题描述 350\n19.6.2 最佳实践--style-transfer 352\n19.7 小结 354\n19.8 练习题 354\n19.9 参考资料 355\n第20天 继往开来的领路人 356\n20.1 Caffe Traps and Pitfalls 356\n20.1.1 不支持任意数据类型 356\n20.1.2 不够灵活的高级接口 357\n20.1.3 繁杂的依赖包 357\n20.1.4 堪忧的卷积层实现 357\n20.1.5 架构之殇 358\n20.1.6 应用场景局限性 358\n20.2 最佳实践--Caffe2 359\n20.3 练习题 361\n20.4 参考资料 362\n第21天 新生 363\n21.1 三人行，必有我师 363\n21.2 路漫漫其修远兮，吾将上下而求索 364\n篇尾语 366\n结束语 367\n附录A 其他深度学习工具","ebook_url":"https:\/\/read.douban.com\/ebook\/58175557\/","pages":"392","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28865185.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28865185.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28865185.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26825082\/","id":"26825082","publisher":"电子工业出版社","isbn10":"7121291150","isbn13":"9787121291159","title":"深度学习：21天实战Caffe","url":"https:\/\/api.douban.com\/v2\/book\/26825082","alt_title":"","author_intro":"赵永科，CSDN 博主，博客地址：http:\/\/blog.csdn.net\/kkk584520，现就职于阿里云计算有限公司，从事计算机体系结构、高性能计算系统设计。对计算机视觉、深度学习具有浓厚兴趣。擅长 CPU\/GPU\/FPGA 的算法加速与性能优化。","summary":"《深度学习：21天实战Caffe》是一本深度学习入门读物。以目前已经大量用于线上系统的深度学习框架Caffe为例，由浅入深，从 Caffe 的配置、部署、使用开始学习，通过阅读 Caffe 源码理解其精髓，加强对深度学习理论的理解，最终达到熟练运用 Caffe 解决实际问题的目的。和国外机器学习、深度学习大部头著作相比，《深度学习：21天实战Caffe》偏重动手实践，将难以捉摸的枯燥理论用浅显易懂的形式表达，透过代码揭开其神秘面纱，更多地贴近实际应用。","ebook_price":"35.55","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":398,"average":"9.4","min":0},"subtitle":"基于Python的理论与实现","author":["[ 日］  斋藤康毅"],"pubdate":"2018-7","tags":[{"count":503,"name":"深度学习","title":"深度学习"},{"count":297,"name":"Python","title":"Python"},{"count":245,"name":"人工智能","title":"人工智能"},{"count":215,"name":"机器学习","title":"机器学习"},{"count":194,"name":"神经网络","title":"神经网络"},{"count":130,"name":"python","title":"python"},{"count":118,"name":"计算机","title":"计算机"},{"count":100,"name":"计算机科学","title":"计算机科学"}],"origin_title":"Deep Learning from Scratch","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29815955.jpg","binding":"平装","translator":["陆宇杰"],"catalog":"译者序　　xiii\n前言　　xv\n第1章　Python入门　　1\n1.1 Python是什么　　1\n1.2 Python的安装　　2\n1.2.1　Python版本　　2\n1.2.2　使用的外部库　　2\n1.2.3　Anaconda发行版　　3\n1.3 Python解释器　　4\n1.3.1　算术计算　　4\n1.3.2　数据类型　　5\n1.3.3　变量　　5\n1.3.4　列表　　6\n1.3.5　字典　　7\n1.3.6　布尔型　　7\n1.3.7　if 语句　　8\n1.3.8　for 语句　　8\n1.3.9　函数　　9\n1.4 Python脚本文件　　9\n1.4.1　保存为文件　　9\n1.4.2　类　　10\n1.5 NumPy　　11\n1.5.1　导入NumPy　　11\n1.5.2　生成NumPy数组　　12\n1.5.3　NumPy 的算术运算　　12\n1.5.4　NumPy的N维数组　　13\n1.5.5　广播　　14\n1.5.6　访问元素　　15\n1.6 Matplotlib　　16\n1.6.1　绘制简单图形　　16\n1.6.2　pyplot 的功能　　17\n1.6.3　显示图像　　18\n1.7 小结　　19\n第2章　感知机　　21\n2.1 感知机是什么　　21\n2.2 简单逻辑电路　　23\n2.2.1　与门　　23\n2.2.2　与非门和或门　　23\n2.3 感知机的实现　　25\n2.3.1　简单的实现　　25\n2.3.2　导入权重和偏置　　26\n2.3.3　使用权重和偏置的实现　　26\n2.4 感知机的局限性　　28\n2.4.1　异或门　　28\n2.4.2　线性和非线性　　30\n2.5 多层感知机　　31\n2.5.1　已有门电路的组合　　31\n2.5.2　异或门的实现　　33\n2.6 从与非门到计算机　　35\n2.7 小结　　36\n第3章　神经网络　　37\n3.1 从感知机到神经网络　　37\n3.1.1　神经网络的例子　　37\n3.1.2　复习感知机　　38\n3.1.3　激活函数登场　　40\n3.2 激活函数　　42\n3.2.1　sigmoid 函数　　42\n3.2.2　阶跃函数的实现　　43\n3.2.3　阶跃函数的图形　　44\n3.2.4　sigmoid 函数的实现　　45\n3.2.5　sigmoid 函数和阶跃函数的比较　　46\n3.2.6　非线性函数　　48\n3.2.7　ReLU函数　　49\n3.3 多维数组的运算　　50\n3.3.1　多维数组　　50\n3.3.2　矩阵乘法　　51\n3.3.3　神经网络的内积　　55\n3.4　　3 层神经网络的实现　　56\n3.4.1　符号确认　　57\n3.4.2　各层间信号传递的实现　　58\n3.4.3　代码实现小结　　62\n3.5 输出层的设计　　63\n3.5.1　恒等函数和softmax 函数　　64\n3.5.2　实现softmax 函数时的注意事项　　66\n3.5.3　softmax 函数的特征　　67\n3.5.4　输出层的神经元数量　　68\n3.6 手写数字识别　　69\n3.6.1　MNIST数据集　　70\n3.6.2　神经网络的推理处理　　73\n3.6.3　批处理　　75\n3.7 小结　　79\n第4章　神经网络的学习　　81\n4.1 从数据中学习　　81\n4.1.1　数据驱动　　82\n4.1.2　训练数据和测试数据　　84\n4.2 损失函数　　85\n4.2.1　均方误差　　85\n4.2.2　交叉熵误差　　87\n4.2.3　mini-batch 学习　　88\n4.2.4　mini-batch 版交叉熵误差的实现　　91\n4.2.5　为何要设定损失函数　　92\n4.3 数值微分　　94\n4.3.1　导数　　94\n4.3.2　数值微分的例子　　96\n4.3.3　偏导数　　98\n4.4 梯度　　100\n4.4.1　梯度法　　102\n4.4.2　神经网络的梯度　　106\n4.5 学习算法的实现　　109\n4.5.1　2 层神经网络的类　　110\n4.5.2　mini-batch 的实现　　114\n4.5.3　基于测试数据的评价　　116\n4.6 小结　　118\n第5章　误差反向传播法　　121\n5.1 计算图　　121\n5.1.1　用计算图求解　　122\n5.1.2　局部计算　　124\n5.1.3　为何用计算图解题　　125\n5.2 链式法则　　126\n5.2.1　计算图的反向传播　　127\n5.2.2　什么是链式法则　　127\n5.2.3　链式法则和计算图　　129\n5.3 反向传播　　130\n5.3.1　加法节点的反向传播　　130\n5.3.2　乘法节点的反向传播　　132\n5.3.3　苹果的例子　　133\n5.4 简单层的实现　　135\n5.4.1　乘法层的实现　　135\n5.4.2　加法层的实现　　137\n5.5 激活函数层的实现　　139\n5.5.1　ReLU层　　139\n5.5.2　Sigmoid 层　　141\n5.6 AffineSoftmax层的实现　　144\n5.6.1　Affine层　　144\n5.6.2　批版本的Affine层　　148\n5.6.3　Softmax-with-Loss 层　　150\n5.7 误差反向传播法的实现　　154\n5.7.1　神经网络学习的全貌图　　154\n5.7.2　对应误差反向传播法的神经网络的实现　　155\n5.7.3　误差反向传播法的梯度确认　　158\n5.7.4　使用误差反向传播法的学习　　159\n5.8 小结　　161\n第6章　与学习相关的技巧　　163\n6.1 参数的更新　　163\n6.1.1　探险家的故事　　164\n6.1.2　SGD　　164\n6.1.3　SGD的缺点　　166\n6.1.4　Momentum　　168\n6.1.5　AdaGrad　　170\n6.1.6　Adam　　172\n6.1.7　使用哪种更新方法呢　　174\n6.1.8　基于MNIST数据集的更新方法的比较　　175\n6.2 权重的初始值　　176\n6.2.1　可以将权重初始值设为0 吗　　176\n6.2.2　隐藏层的激活值的分布　　177\n6.2.3　ReLU的权重初始值　　181\n6.2.4　基于MNIST数据集的权重初始值的比较　　183\n6.3 Batch Normalization　　184\n6.3.1　Batch Normalization 的算法　　184\n6.3.2　Batch Normalization 的评估　　186\n6.4 正则化　　188\n6.4.1　过拟合　　189\n6.4.2　权值衰减　　191\n6.4.3　Dropout　　192\n6.5 超参数的验证　　195\n6.5.1　验证数据　　195\n6.5.2　超参数的最优化　　196\n6.5.3　超参数最优化的实现　　198\n6.6 小结　　200\n第7章　卷积神经网络　　201\n7.1 整体结构　　201\n7.2 卷积层　　202\n7.2.1　全连接层存在的问题　　203\n7.2.2　卷积运算　　203\n7.2.3　填充　　206\n7.2.4　步幅　　207\n7.2.5　3 维数据的卷积运算　　209\n7.2.6　结合方块思考　　211\n7.2.7　批处理　　213\n7.3 池化层　　214\n7.4 卷积层和池化层的实现　　216\n7.4.1　4 维数组　　216\n7.4.2　基于im2col 的展开　　217\n7.4.3　卷积层的实现　　219\n7.4.4　池化层的实现　　222\n7.5 CNN的实现　　224\n7.6 CNN的可视化　　228\n7.6.1　第1 层权重的可视化　　228\n7.6.2　基于分层结构的信息提取　　230\n7.7 具有代表性的CNN　　231\n7.7.1　LeNet　　231\n7.7.2　AlexNet　　232\n7.8 小结　　233\n第8章　深度学习　　235\n8.1 加深网络　　235\n8.1.1　向更深的网络出发　　235\n8.1.2　进一步提高识别精度　　238\n8.1.3　加深层的动机　　240\n8.2 深度学习的小历史　　242\n8.2.1　ImageNet　　243\n8.2.2　VGG　　244\n8.2.3　GoogLeNet　　245\n8.2.4　ResNet　　246\n8.3 深度学习的高速化　　248\n8.3.1　需要努力解决的问题　　248\n8.3.2　基于GPU的高速化　　249\n8.3.3　分布式学习　　250\n8.3.4　运算精度的位数缩减　　252\n8.4 深度学习的应用案例　　253\n8.4.1　物体检测　　253\n8.4.2　图像分割　　255\n8.4.3　图像标题的生成　　256\n8.5 深度学习的未来　　258\n8.5.1　图像风格变换　　258\n8.5.2　图像的生成　　259\n8.5.3　自动驾驶　　261\n8.5.4　Deep Q-Network（强化学习）　　262\n8.6 小结　　264\n附录A　Softmax-with-Loss 层的计算图　　267\nA.1 正向传播　　268\nA.2 反向传播　　270\nA.3 小结　　277\n参考文献　　279","pages":"285","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29815955.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29815955.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29815955.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30270959\/","id":"30270959","publisher":"人民邮电出版社","isbn10":"7115485585","isbn13":"9787115485588","title":"深度学习入门","url":"https:\/\/api.douban.com\/v2\/book\/30270959","alt_title":"Deep Learning from Scratch","author_intro":"作者简介：\n斋藤康毅\n东京工业大学毕业，并完成东京大学研究生院课程。现从事计算机视觉与机器学习相关的研究和开发工作。是Introducing Python、Python in Practice、The Elements of Computing Systems、Building Machine Learning Systems with Python的日文版译者。\n译者简介：\n陆宇杰\n众安科技NLP算法工程师。主要研究方向为自然语言处理及其应用，对图像识别、机器学习、深度学习等领域有密切关注。Python爱好者。","summary":"本书是深度学习真正意义上的入门书，深入浅出地剖析了深度学习的原理和相关技术。书中使用Python3，尽量不依赖外部库或工具，从基本的数学知识出发，带领读者从零创建一个经典的深度学习网络，使读者在此过程中逐步理解深度学习。书中不仅介绍了深度学习和神经网络的概念、特征等基础知识，对误差反向传播法、卷积神经网络等也有深入讲解，此外还介绍了深度学习相关的实用技巧，自动驾驶、图像生成、强化学习等方面的应用，以及为什么加深层可以提高识别精度等“为什么”的问题。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"59.00元"},{"rating":{"max":10,"numRaters":49,"average":"7.9","min":0},"subtitle":"入门、原理与进阶实战","author":["李金洪"],"pubdate":"2018-3-1","tags":[{"count":47,"name":"深度学习","title":"深度学习"},{"count":29,"name":"机器学习","title":"机器学习"},{"count":25,"name":"tensorflow","title":"tensorflow"},{"count":21,"name":"TensorFlow","title":"TensorFlow"},{"count":18,"name":"AI","title":"AI"},{"count":12,"name":"人工智能","title":"人工智能"},{"count":10,"name":"计算机","title":"计算机"},{"count":4,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29835968.jpg","binding":"平装","translator":[],"catalog":"配套学习资源\n前言\n第1篇 深度学习与TensorFlow基础\n第1章 快速了解人工智能与TensorFlow\t2\n1.1 什么是深度学习\t2\n1.2 TensorFlow是做什么的\t3\n1.3 TensorFlow的特点\t4\n1.4 其他深度学习框架特点及介绍\t5\n1.5 如何通过本书学好深度学习\t6\n1.5.1 深度学习怎么学\t6\n1.5.2 如何学习本书\t7\n第2章 搭建开发环境\t8\n2.1 下载及安装Anaconda开发工具\t8\n2.2 在Windows平台下载及安装TensorFlow\t11\n2.3 GPU版本的安装方法\t12\n2.3.1 安装CUDA软件包\t12\n2.3.2 安装cuDNN库\t13\n2.3.3 测试显卡\t14\n2.4 熟悉Anaconda 3开发工具\t15\n2.4.1 快速了解Spyder\t16\n2.4.2 快速了解Jupyter Notebook\t18\n第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例\t19\n3.1 实例1：从一组看似混乱的数据中找出y≈2x的规律\t19\n3.1.1 准备数据\t20\n3.1.2 搭建模型\t21\n3.1.3 迭代训练模型\t23\n3.1.4 使用模型\t25\n3.2 模型是如何训练出来的\t25\n3.2.1 模型里的内容及意义\t25\n3.2.2 模型内部的数据流向\t26\n3.3 了解TensorFlow开发的基本步骤\t27\n3.3.1 定义输入节点的方法\t27\n3.3.2 实例2：通过字典类型定义输入节点\t28\n3.3.3 实例3：直接定义输入节点\t28\n3.3.4 定义“学习参数”的变量\t29\n3.3.5 实例4：通过字典类型定义“学习参数”\t29\n3.3.6 定义“运算”\t29\n3.3.7 优化函数，优化目标\t30\n3.3.8 初始化所有变量\t30\n3.3.9 迭代更新参数到最优解\t31\n3.3.10 测试模型\t31\n3.3.11 使用模型\t31\n第4章 TensorFlow编程基础\t32\n4.1 编程模型\t32\n4.1.1 了解模型的运行机制\t33\n4.1.2 实例5：编写hello world程序演示session的使用\t34\n4.1.3 实例6：演示with session的使用\t35\n4.1.4 实例7：演示注入机制\t35\n4.1.5 建立session的其他方法\t36\n4.1.6 实例8：使用注入机制获取节点\t36\n4.1.7 指定GPU运算\t37\n4.1.8 设置GPU使用资源\t37\n4.1.9 保存和载入模型的方法介绍\t38\n4.1.10 实例9：保存\/载入线性回归模型\t38\n4.1.11 实例10：分析模型内容，演示模型的其他保存方法\t40\n4.1.12 检查点（Checkpoint）\t41\n4.1.13 实例11：为模型添加保存检查点\t41\n4.1.14 实例12：更简便地保存检查点\t44\n4.1.15 模型操作常用函数总结\t45\n4.1.16 TensorBoard可视化介绍\t45\n4.1.17 实例13：线性回归的TensorBoard可视化\t46\n4.2 TensorFlow基础类型定义及操作函数介绍\t48\n4.2.1 张量及操作\t49\n4.2.2 算术运算函数\t55\n4.2.3 矩阵相关的运算\t56\n4.2.4 复数操作函数\t58\n4.2.5 规约计算\t59\n4.2.6 分割\t60\n4.2.7 序列比较与索引提取\t61\n4.2.8 错误类\t62\n4.3 共享变量\t62\n4.3.1 共享变量用途\t62\n4.3.2 使用get-variable获取变量\t63\n4.3.3 实例14：演示get_variable和Variable的区别\t63\n4.3.4 实例15：在特定的作用域下获取变量\t65\n4.3.5 实例16：共享变量功能的实现\t66\n4.3.6 实例17：初始化共享变量的作用域\t67\n4.3.7 实例18：演示作用域与操作符的受限范围\t68\n4.4 实例19：图的基本操作\t70\n4.4.1 建立图\t70\n4.4.2 获取张量\t71\n4.4.3 获取节点操作\t72\n4.4.4 获取元素列表\t73\n4.4.5 获取对象\t73\n4.4.6 练习题\t74\n4.5 配置分布式TensorFlow\t74\n4.5.1 分布式TensorFlow的角色及原理\t74\n4.5.2 分布部署TensorFlow的具体方法\t75\n4.5.3 实例20：使用TensorFlow实现分布式部署训练\t75\n4.6 动态图（Eager）\t81\n4.7 数据集（tf.data）\t82\n第5章 识别图中模糊的手写数字（实例21）\t83\n5.1 导入图片数据集\t84\n5.1.1 MNIST数据集介绍\t84\n5.1.2 下载并安装MNIST数据集\t85\n5.2 分析图片的特点，定义变量\t87\n5.3 构建模型\t87\n5.3.1 定义学习参数\t87\n5.3.2 定义输出节点\t88\n5.3.3 定义反向传播的结构\t88\n5.4 训练模型并输出中间状态参数\t89\n5.5 测试模型\t90\n5.6 保存模型\t91\n5.7 读取模型\t92\n第2篇 深度学习基础——神经网络\n第6章 单个神经元\t96\n6.1 神经元的拟合原理\t96\n6.1.1 正向传播\t98\n6.1.2 反向传播\t98\n6.2 激活函数——加入非线性因素，解决线性模型缺陷\t99\n6.2.1 Sigmoid函数\t99\n6.2.2 Tanh函数\t100\n6.2.3 ReLU函数\t101\n6.2.4 Swish函数\t103\n6.2.5 激活函数总结\t103\n6.3 softmax算法——处理分类问题\t103\n6.3.1 什么是softmax\t104\n6.3.2 softmax原理\t104\n6.3.3 常用的分类函数\t105\n6.4 损失函数——用真实值与预测值的距离来指导模型的收敛方向\t105\n6.4.1 损失函数介绍\t105\n6.4.2 TensorFlow中常见的loss函数\t106\n6.5 softmax算法与损失函数的综合应用\t108\n6.5.1 实例22：交叉熵实验\t108\n6.5.2 实例23：one_hot实验\t109\n6.5.3 实例24：sparse交叉熵的使用\t110\n6.5.4 实例25：计算loss值\t110\n6.5.5 练习题\t111\n6.6 梯度下降——让模型逼近最小偏差\t111\n6.6.1 梯度下降的作用及分类\t111\n6.6.2 TensorFlow中的梯度下降函数\t112\n6.6.3 退化学习率——在训练的速度与精度之间找到平衡\t113\n6.6.4 实例26：退化学习率的用法举例\t114\n6.7 初始化学习参数\t115\n6.8 单个神经元的扩展——Maxout网络\t116\n6.8.1 Maxout介绍\t116\n6.8.2 实例27：用Maxout网络实现MNIST分类\t117\n6.9 练习题\t118\n第7章 多层神经网络——解决非线性问题\t119\n7.1 线性问题与非线性问题\t119\n7.1.1 实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的\t119\n7.1.2 实例29：用线性逻辑回归处理多分类问题\t123\n7.1.3 认识非线性问题\t129\n7.2 使用隐藏层解决非线性问题\t130\n7.2.1 实例30：使用带隐藏层的神经网络拟合异或操作\t130\n7.2.2 非线性网络的可视化及其意义\t133\n7.2.3 练习题\t135\n7.3 实例31：利用全连接网络将图片进行分类\t136\n7.4 全连接网络训练中的优化技巧\t137\n7.4.1 实例32：利用异或数据集演示过拟合问题\t138\n7.4.2 正则化\t143\n7.4.3 实例33：通过正则化改善过拟合情况\t144\n7.4.4 实例34：通过增大数据集改善过拟合\t145\n7.4.5 练习题\t146\n7.4.6 dropout——训练过程中，将部分神经单元暂时丢弃\t146\n7.4.7 实例35：为异或数据集模型添加dropout\t147\n7.4.8 实例36：基于退化学习率dropout技术来拟合异或数据集\t149\n7.4.9 全连接网络的深浅关系\t150\n7.5 练习题\t150\n第8章 卷积神经网络——解决参数太多问题\t151\n8.1 全连接网络的局限性\t151\n8.2 理解卷积神经网络\t152\n8.3 网络结构\t153\n8.3.1 网络结构描述\t153\n8.3.2 卷积操作\t155\n8.3.3 池化层\t157\n8.4 卷积神经网络的相关函数\t158\n8.4.1 卷积函数tf.nn.conv2d\t158\n8.4.2 padding规则介绍\t159\n8.4.3 实例37：卷积函数的使用\t160\n8.4.4 实例38：使用卷积提取图片的轮廓\t165\n8.4.5 池化函数tf.nn.max_pool（avg_pool）\t167\n8.4.6 实例39：池化函数的使用\t167\n8.5 使用卷积神经网络对图片分类\t170\n8.5.1 CIFAR介绍\t171\n8.5.2 下载CIFAR数据\t172\n8.5.3 实例40：导入并显示CIFAR数据集\t173\n8.5.4 实例41：显示CIFAR数据集的原始图片\t174\n8.5.5 cifar10_input的其他功能\t176\n8.5.6 在TensorFlow中使用queue\t176\n8.5.7 实例42：协调器的用法演示\t178\n8.5.8 实例43：为session中的队列加上协调器\t179\n8.5.9 实例44：建立一个带有全局平均池化层的卷积神经网络\t180\n8.5.10 练习题\t183\n8.6 反卷积神经网络\t183\n8.6.1 反卷积神经网络的应用场景\t184\n8.6.2 反卷积原理\t184\n8.6.3 实例45：演示反卷积的操作\t185\n8.6.4 反池化原理\t188\n8.6.5 实例46：演示反池化的操作\t189\n8.6.6 实例47：演示gradients基本用法\t192\n8.6.7 实例48：使用gradients对多个式子求多变量偏导\t192\n8.6.8 实例49：演示梯度停止的实现\t193\n8.7 实例50：用反卷积技术复原卷积网络各层图像\t195\n8.8 善用函数封装库\t198\n8.8.1 实例51：使用函数封装库重写CIFAR卷积网络\t198\n8.8.2 练习题\t201\n8.9 深度学习的模型训练技巧\t201\n8.9.1 实例52：优化卷积核技术的演示\t201\n8.9.2 实例53：多通道卷积技术的演示\t202\n8.9.3 批量归一化\t204\n8.9.4 实例54：为CIFAR图片分类模型添加BN\t207\n8.9.5 练习题\t209\n第9章 循环神经网络——具有记忆功能的网络\t210\n9.1 了解RNN的工作原理\t210\n9.1.1 了解人的记忆原理\t210\n9.1.2 RNN网络的应用领域\t212\n9.1.3 正向传播过程\t212\n9.1.4 随时间反向传播\t213\n9.2 简单RNN\t215\n9.2.1 实例55：简单循环神经网络实现——裸写一个退位减法器\t215\n9.2.2 实例56：使用RNN网络拟合回声信号序列\t220\n9.3 循环神经网络（RNN）的改进\t225\n9.3.1 LSTM网络介绍\t225\n9.3.2 窥视孔连接（Peephole）\t228\n9.3.3 带有映射输出的STMP\t230\n9.3.4 基于梯度剪辑的cell\t230\n9.3.5 GRU网络介绍\t230\n9.3.6 Bi-RNN网络介绍\t231\n9.3.7 基于神经网络的时序类分类CTC\t232\n9.4 TensorFlow实战RNN\t233\n9.4.1 TensorFlow中的cell类\t233\n9.4.2 通过cell类构建RNN\t234\n9.4.3 实例57：构建单层LSTM网络对MNIST数据集分类\t239\n9.4.4 实例58：构建单层GRU网络对MNIST数据集分类\t240\n9.4.5 实例59：创建动态单层RNN网络对MNIST数据集分类\t240\n9.4.6 实例60：静态多层LSTM对MNIST数据集分类\t241\n9.4.7 实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类\t242\n9.4.8 实例62：动态多层RNN对MNIST数据集分类\t242\n9.4.9 练习题\t243\n9.4.10 实例63：构建单层动态双向RNN对MNIST数据集分类\t243\n9.4.11 实例64：构建单层静态双向RNN对MNIST数据集分类\t244\n9.4.12 实例65：构建多层双向RNN对MNIST数据集分类\t246\n9.4.13 实例66：构建动态多层双向RNN对MNIST数据集分类\t247\n9.4.14 初始化RNN\t247\n9.4.15 优化RNN\t248\n9.4.16 实例67：在GRUCell中实现LN\t249\n9.4.17 CTC网络的loss——ctc_loss\t251\n9.4.18 CTCdecoder\t254\n9.5 实例68：利用BiRNN实现语音识别\t255\n9.5.1 语音识别背景\t255\n9.5.2 获取并整理样本\t256\n9.5.3 训练模型\t265\n9.5.4 练习题\t272\n9.6 实例69：利用RNN训练语言模型\t273\n9.6.1 准备样本\t273\n9.6.2 构建模型\t275\n9.7 语言模型的系统学习\t279\n9.7.1 统计语言模型\t279\n9.7.2 词向量\t279\n9.7.3 word2vec\t281\n9.7.4 实例70：用CBOW模型训练自己的word2vec\t283\n9.7.5 实例71：使用指定侯选采样本训练word2vec\t293\n9.7.6 练习题\t296\n9.8 处理Seq2Seq任务\t296\n9.8.1 Seq2Seq任务介绍\t296\n9.8.2 Encoder-Decoder框架\t297\n9.8.3 实例72：使用basic_rnn_seq2seq拟合曲线\t298\n9.8.4 实例73：预测当天的股票价格\t306\n9.8.5 基于注意力的Seq2Seq\t310\n9.8.6 实例74：基于Seq2Seq注意力模型实现中英文机器翻译\t313\n9.9 实例75：制作一个简单的聊天机器人\t339\n9.9.1 构建项目框架\t340\n9.9.2 准备聊天样本\t340\n9.9.3 预处理样本\t340\n9.9.4 训练样本\t341\n9.9.5 测试模型\t342\n9.10 时间序列的高级接口TFTS\t344\n第10章 自编码网络——能够自学习样本特征的网络\t346\n10.1 自编码网络介绍及应用\t346\n10.2 最简单的自编码网络\t347\n10.3 自编码网络的代码实现\t347\n10.3.1 实例76：提取图片的特征，并利用特征还原图片\t347\n10.3.2 线性解码器\t351\n10.3.3 实例77：提取图片的二维特征，并利用二维特征还原图片\t351\n10.3.4 实例78：实现卷积网络的自编码\t356\n10.3.5 练习题\t358\n10.4 去噪自编码\t359\n10.5 去噪自编码网络的代码实现\t359\n10.5.1 实例79：使用去噪自编码网络提取MNIST特征\t359\n10.5.2 练习题\t363\n10.6 栈式自编码\t364\n10.6.1 栈式自编码介绍\t364\n10.6.2 栈式自编码在深度学习中的意义\t365\n10.7 深度学习中自编码的常用方法\t366\n10.7.1 代替和级联\t366\n10.7.2 自编码的应用场景\t366\n10.8 去噪自编码与栈式自编码的综合实现\t366\n10.8.1 实例80：实现去噪自编码\t367\n10.8.2 实例81：添加模型存储支持分布训练\t375\n10.8.3 小心分布训练中的“坑”\t376\n10.8.4 练习题\t377\n10.9 变分自编码\t377\n10.9.1 什么是变分自编码\t377\n10.9.2 实例82：使用变分自编码模拟生成MNIST数据\t377\n10.9.3 练习题\t384\n10.10 条件变分自编码\t385\n10.10.1 什么是条件变分自编码\t385\n10.10.2 实例83：使用标签指导变分自编码网络生成MNIST数据\t385\n第3篇 深度学习进阶\n第11章 深度神经网络\t392\n11.1 深度神经网络介绍\t392\n11.1.1 深度神经网络起源\t392\n11.1.2 经典模型的特点介绍\t393\n11.2 GoogLeNet模型介绍\t394\n11.2.1 MLP卷积层\t394\n11.2.2 全局均值池化\t395\n11.2.3 Inception 原始模型\t396\n11.2.4 Inception v1模型\t396\n11.2.5 Inception v2模型\t397\n11.2.6 Inception v3模型\t397\n11.2.7 Inception v4模型\t399\n11.3 残差网络（ResNet）\t399\n11.3.1 残差网络结构\t399\n11.3.2 残差网络原理\t400\n11.4 Inception-ResNet-v2结构\t400\n11.5 TensorFlow中的图片分类模型库——slim\t400\n11.5.1 获取models中的slim模块代码\t401\n11.5.2 models中的Slim目录结构\t401\n11.5.3 slim中的数据集处理\t403\n11.5.4 实例84：利用slim读取TFRecord中的数据\t405\n11.5.5 在slim中训练模型\t407\n11.6 使用slim中的深度网络模型进行图像的识别与检测\t410\n11.6.1 实例85：调用Inception_ResNet_v2模型进行图像识别\t410\n11.6.2 实例86：调用VGG模型进行图像检测\t413\n11.7 实物检测模型库——Object Detection API\t417\n11.7.1 准备工作\t418\n11.7.2 实例87：调用Object Detection API进行实物检测\t421\n11.8 实物检测领域的相关模型\t425\n11.8.1 RCNN基于卷积神经网络特征的区域方法\t426\n11.8.2 SPP-Net：基于空间金字塔池化的优化RCNN方法\t426\n11.8.3 Fast-R-CNN快速的RCNN模型\t426\n11.8.4 YOLO：能够一次性预测多个位置和类别的模型\t427\n11.8.5 SSD：比YOLO更快更准的模型\t428\n11.8.6 YOLO2：YOLO的升级版模型\t428\n11.9 机器自己设计的模型（NASNet）\t428\n第12章 对抗神经网络（GAN）\t430\n12.1 GAN的理论知识\t430\n12.1.1 生成式模型的应用\t431\n12.1.2 GAN的训练方法\t431\n12.2 DCGAN——基于深度卷积的GAN\t432\n12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN\t432\n12.3.1 InfoGAN：带有隐含信息的GAN\t432\n12.3.2 AC-GAN：带有辅助分类信息的GAN\t433\n12.3.3 实例88：构建InfoGAN生成MNIST模拟数据\t434\n12.3.4 练习题\t440\n12.4 AEGAN：基于自编码器的GAN\t441\n12.4.1 AEGAN原理及用途介绍\t441\n12.4.2 实例89：使用AEGAN对MNIST数据集压缩特征及重建\t442\n12.5 WGAN-GP：更容易训练的GAN\t447\n12.5.1 WGAN：基于推土机距离原理的GAN\t448\n12.5.2 WGAN-GP：带梯度惩罚项的WGAN\t449\n12.5.3 实例90：构建WGAN-GP生成MNIST数据集\t451\n12.5.4 练习题\t455\n12.6 LSGAN（最小乘二GAN）：具有WGAN 同样效果的GAN\t455\n12.6.1 LSGAN介绍\t455\n12.6.2 实例91：构建LSGAN生成MNIST模拟数据\t456\n12.7 GAN-cls：具有匹配感知的判别器\t457\n12.7.1 GAN-cls的具体实现\t458\n12.7.2 实例92：使用GAN-cls技术实现生成标签匹配的模拟数据\t458\n12.8 SRGAN——适用于超分辨率重建的GAN\t461\n12.8.1 超分辨率技术\t461\n12.8.2 实例93：ESPCN实现MNIST数据集的超分辨率重建\t463\n12.8.3 实例94：ESPCN实现flowers数据集的超分辨率重建\t466\n12.8.4 实例95：使用残差网络的ESPCN\t472\n12.8.5 SRGAN的原理\t477\n12.8.6 实例96：使用SRGAN实现flowers数据集的超分辨率修复\t477\n12.9 GAN网络的高级接口TFGAN\t485\n12.10 总结\t486","ebook_url":"https:\/\/read.douban.com\/ebook\/53450634\/","pages":"487","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29835968.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29835968.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29835968.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30147782\/","id":"30147782","publisher":"机械工业出版社","isbn10":"7111590058","isbn13":"9787111590057","title":"深度学习之TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/30147782","alt_title":"","author_intro":"","summary":"本书通过96个案例，全面讲解了深度学习神经网络原理和TensorFlow的使用方法。全书共分为3篇，第1篇深度学习与TensorFlow基础，包括快速了解人工智能与TensorFlow、搭建开发环境、TensorFlow基本开发步骤、TensorFlow编程基础、识别图中模糊的手写数字等内容；第2篇深度学习基础——神经网络，介绍了神经网络的基础模型，包括单个神经元、多层神经网络、卷积神经网络、循环神经网络、自编码网络等内容；第3篇深度学习进阶，是对基础网络模型的灵活运用与自由组合，是对前面知识的综合及拔高，包括深度神经网络和对抗神经网络两章内容。本书特别适合TensorFlow深度学习的初学者和进阶读者阅读，也适合社会培训班和各大院校对深度学习有兴趣的学生阅读。","ebook_price":"49.00","price":"CNY 99.00"},{"rating":{"max":10,"numRaters":64,"average":"9.8","min":0},"subtitle":"","author":["邱锡鹏"],"pubdate":"2019-4-12","tags":[{"count":97,"name":"深度学习","title":"深度学习"},{"count":76,"name":"神经网络","title":"神经网络"},{"count":68,"name":"机器学习","title":"机器学习"},{"count":42,"name":"计算机","title":"计算机"},{"count":41,"name":"DeepLearning","title":"DeepLearning"},{"count":22,"name":"MachineLearning","title":"MachineLearning"},{"count":18,"name":"计算机科学","title":"计算机科学"},{"count":17,"name":"自然语言处理","title":"自然语言处理"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32292004.jpg","binding":"平装","translator":[],"catalog":"前言 1\n第一部分 入门篇 3\n第 1 章 绪论 5\n1.1 人工智能 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.1.1 人工智能的发展历史 . . . . . . . . . . . . . . . . . . . . 7\n1.1.2 人工智能的流派 . . . . . . . . . . . . . . . . . . . . . . 9\n1.2 神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.1 大脑神经网络 . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.2 人工神经网络 . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.2.3 神经网络的发展历史 . . . . . . . . . . . . . . . . . . . . 12\n1.3 机器学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n1.4 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n1.4.1 局部表示和分布式表示 . . . . . . . . . . . . . . . . . . . 15\n1.4.2 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n1.5 深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n1.5.1 端到端学习 . . . . . . . . . . . . . . . . . . . . . . . . . 18\n1.5.2 常用的深度学习框架 . . . . . . . . . . . . . . . . . . . . 19\n1.6 本书的组织结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n1.7 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n第 2 章 机器学习概述 25\n2.1 基本概念 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.2 机器学习的三个基本要素 . . . . . . . . . . . . . . . . . . . . . 28\n2.2.1 模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.2.2 学习准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n2.2.3 优化算法 . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n2.3 机器学习的简单示例：线性回归 . . . . . . . . . . . . . . . . . . 36\n2.3.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n2.4 偏差-方差分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n2.5 机器学习算法的类型 . . . . . . . . . . . . . . . . . . . . . . . . 44\n2.6 数据的特征表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n2.6.1 传统的特征学习 . . . . . . . . . . . . . . . . . . . . . . 47\n2.6.2 深度学习方法 . . . . . . . . . . . . . . . . . . . . . . . . 48\n2.7 评价指标 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n2.8 理论和定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n2.8.1 PAC学习理论 . . . . . . . . . . . . . . . . . . . . . . . . 51\n2.8.2 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . . . 52\n2.8.3 丑小鸭定理 . . . . . . . . . . . . . . . . . . . . . . . . . 53\n2.8.4 奥卡姆剃刀 . . . . . . . . . . . . . . . . . . . . . . . . . 53\n2.8.5 归纳偏置 . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n2.9 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n第 3 章 线性模型 57\n3.1 线性判别函数和决策边界 . . . . . . . . . . . . . . . . . . . . . 58\n3.1.1 两类分类 . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n3.1.2 多类分类 . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n3.2 Logistic回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n3.2.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n3.3 Softmax回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n3.3.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n3.4 感知器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.4.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.4.2 感知器的收敛性 . . . . . . . . . . . . . . . . . . . . . . 67\n3.4.3 参数平均感知器 . . . . . . . . . . . . . . . . . . . . . . 69\n3.4.4 扩展到多类分类 . . . . . . . . . . . . . . . . . . . . . . 70\n3.5 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n3.5.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n3.5.2 核函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n3.5.3 软间隔 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n3.6 损失函数对比 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n3.7 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n第二部分 基础模型 83\n第 4 章 前馈神经网络 85\n4.1 神经元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n4.1.1 Sigmoid型激活函数 . . . . . . . . . . . . . . . . . . . . 87\n4.1.2 修正线性单元 . . . . . . . . . . . . . . . . . . . . . . . . 90\n4.1.3 Swish函数 . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n4.1.4 Maxout单元 . . . . . . . . . . . . . . . . . . . . . . . . 93\n4.2 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n4.2.1 前馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n4.2.2 反馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n4.2.3 图网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n4.3 前馈神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n4.3.1 通用近似定理 . . . . . . . . . . . . . . . . . . . . . . . . 97\n4.3.2 应用到机器学习 . . . . . . . . . . . . . . . . . . . . . . 98\n4.3.3 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.4 反向传播算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.5 自动梯度计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n4.5.1 数值微分 . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n4.5.2 符号微分 . . . . . . . . . . . . . . . . . . . . . . . . . . 103\n4.5.3 自动微分 . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n4.6 优化问题 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n4.6.1 非凸优化问题 . . . . . . . . . . . . . . . . . . . . . . . . 107\n4.6.2 梯度消失问题 . . . . . . . . . . . . . . . . . . . . . . . . 107\n4.7 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\n第 5 章 卷积神经网络 113\n5.1 卷积 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n5.1.1 互相关 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\n5.1.2 卷积的变种 . . . . . . . . . . . . . . . . . . . . . . . . . 117\n5.1.3 卷积的数学性质 . . . . . . . . . . . . . . . . . . . . . . 118\n5.2 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n5.2.1 用卷积来代替全连接 . . . . . . . . . . . . . . . . . . . . 119\n5.2.2 卷积层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n5.2.3 汇聚层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n5.2.4 典型的卷积网络结构 . . . . . . . . . . . . . . . . . . . . 123\n5.3 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n5.3.1 误差项的计算 . . . . . . . . . . . . . . . . . . . . . . . . 125\n5.4 几种典型的卷积神经网络 . . . . . . . . . . . . . . . . . . . . . 126\n5.4.1 LeNet-5 . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n5.4.2 AlexNet . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n5.4.3 Inception网络 . . . . . . . . . . . . . . . . . . . . . . . 129\n5.4.4 残差网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n5.5 其它卷积方式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n5.5.1 转置卷积 . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n5.5.2 空洞卷积 . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n5.6 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n第 6 章 循环神经网络 139\n6.1 给网络增加记忆能力 . . . . . . . . . . . . . . . . . . . . . . . . 140\n6.1.1 延时神经网络 . . . . . . . . . . . . . . . . . . . . . . . . 140\n6.1.2 有外部输入的非线性自回归模型 . . . . . . . . . . . . . 140\n6.1.3 循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . 141\n6.2 简单循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n6.2.1 循环神经网络的计算能力 . . . . . . . . . . . . . . . . . 142\n6.3 应用到机器学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n6.3.1 序列到类别模式 . . . . . . . . . . . . . . . . . . . . . . 144\n6.3.2 同步的序列到序列模式 . . . . . . . . . . . . . . . . . . . 145\n6.3.3 异步的序列到序列模式 . . . . . . . . . . . . . . . . . . . 145\n6.4 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\n6.4.1 随时间反向传播算法 . . . . . . . . . . . . . . . . . . . . 147\n6.4.2 实时循环学习算法 . . . . . . . . . . . . . . . . . . . . . 148\n6.5 长期依赖问题 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n6.5.1 改进方案 . . . . . . . . . . . . . . . . . . . . . . . . . . 150\n6.6 基于门控的循环神经网络 . . . . . . . . . . . . . . . . . . . . . 151\n6.6.1 长短期记忆网络 . . . . . . . . . . . . . . . . . . . . . . 151\n6.6.2 LSTM网络的各种变体 . . . . . . . . . . . . . . . . . . . 154\n6.6.3 门控循环单元网络 . . . . . . . . . . . . . . . . . . . . . 154\n6.7 深层循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . 156\n6.7.1 堆叠循环神经网络 . . . . . . . . . . . . . . . . . . . . . 156\n6.7.2 双向循环神经网络 . . . . . . . . . . . . . . . . . . . . . 157\n6.8 扩展到图结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\n6.8.1 递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . 158\n6.8.2 图网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n6.9 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\n第 7 章 网络优化与正则化 165\n7.1 网络优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n7.1.1 网络优化的难点 . . . . . . . . . . . . . . . . . . . . . . 165\n7.2 优化算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\n7.2.1 小批量梯度下降 . . . . . . . . . . . . . . . . . . . . . . 167\n7.2.2 学习率衰减 . . . . . . . . . . . . . . . . . . . . . . . . . 169\n7.2.3 梯度方向优化 . . . . . . . . . . . . . . . . . . . . . . . . 171\n7.2.4 优化算法小结 . . . . . . . . . . . . . . . . . . . . . . . . 174\n7.3 参数初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n7.4 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n7.5 逐层归一化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\n7.5.1 批量归一化 . . . . . . . . . . . . . . . . . . . . . . . . . 180\n7.5.2 层归一化 . . . . . . . . . . . . . . . . . . . . . . . . . . 182\n7.5.3 其它归一化方法 . . . . . . . . . . . . . . . . . . . . . . 183\n7.6 超参数优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184\n7.6.1 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n7.6.2 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n7.6.3 贝叶斯优化 . . . . . . . . . . . . . . . . . . . . . . . . . 185\n7.6.4 动态资源分配 . . . . . . . . . . . . . . . . . . . . . . . . 186\n7.7 网络正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\n7.7.1 ℓ1 和ℓ2 正则化 . . . . . . . . . . . . . . . . . . . . . . . . 188\n7.7.2 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n7.7.3 提前停止 . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n7.7.4 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190\n7.7.5 数据增强 . . . . . . . . . . . . . . . . . . . . . . . . . . 192\n7.7.6 标签平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n7.8 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\n第 8 章 注意力机制与外部记忆 199\n8.1 注意力 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\n8.1.1 认知神经学中的注意力 . . . . . . . . . . . . . . . . . . . 200\n8.1.2 人工神经网络中的注意力机制 . . . . . . . . . . . . . . . 201\n8.1.3 注意力机制的变体 . . . . . . . . . . . . . . . . . . . . . 202\n8.2 注意力机制的应用 . . . . . . . . . . . . . . . . . . . . . . . . . 204\n8.2.1 指针网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 204\n8.2.2 自注意力模型 . . . . . . . . . . . . . . . . . . . . . . . . 205\n8.3 外部记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n8.3.1 人脑中的记忆 . . . . . . . . . . . . . . . . . . . . . . . . 207\n8.3.2 结构化的外部记忆 . . . . . . . . . . . . . . . . . . . . . 208\n8.3.3 典型的记忆网络 . . . . . . . . . . . . . . . . . . . . . . 210\n8.3.4 基于神经动力学的联想记忆 . . . . . . . . . . . . . . . . 213\n8.4 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\n第 9 章 无监督学习 219\n9.1 无监督特征学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\n9.1.1 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . 220\n9.1.2 稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . 222\n9.1.3 自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . 224\n9.1.4 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . . . 225\n9.1.5 堆叠自编码器 . . . . . . . . . . . . . . . . . . . . . . . . 226\n9.1.6 降噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . 226\n9.2 概率密度估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\n9.2.1 参数密度估计 . . . . . . . . . . . . . . . . . . . . . . . . 227\n9.2.2 非参数密度估计 . . . . . . . . . . . . . . . . . . . . . . 229\n9.3 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n第 10 章 模型独立的学习方式 235\n10.1 集成学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n10.1.1 AdaBoost算法 . . . . . . . . . . . . . . . . . . . . . . . 237\n10.2 自训练和协同训练 . . . . . . . . . . . . . . . . . . . . . . . . . 239\n10.2.1 自训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\n10.2.2 协同训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 240\n10.3 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\n10.4 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n10.5 终生学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249\n10.6 元学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\n10.6.1 基于优化器的元学习 . . . . . . . . . . . . . . . . . . . . 252\n10.6.2 模型无关的元学习 . . . . . . . . . . . . . . . . . . . . . 254\n10.7 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\n第三部分 进阶模型 259\n第 11 章 概率图模型 261\n11.1 模型表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\n11.1.1 有向图模型 . . . . . . . . . . . . . . . . . . . . . . . . . 263\n11.1.2 常见的有向图模型 . . . . . . . . . . . . . . . . . . . . . 265\n11.1.3 无向图模型 . . . . . . . . . . . . . . . . . . . . . . . . . 267\n11.1.4 无向图模型的概率分解 . . . . . . . . . . . . . . . . . . . 268\n11.1.5 常见的无向图模型 . . . . . . . . . . . . . . . . . . . . . 269\n11.1.6 有向图和无向图之间的转换 . . . . . . . . . . . . . . . . 270\n11.2 推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\n11.2.1 变量消除法 . . . . . . . . . . . . . . . . . . . . . . . . . 271\n11.2.2 信念传播算法 . . . . . . . . . . . . . . . . . . . . . . . . 272\n11.3 近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\n11.3.1 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . 275\n11.3.2 拒绝采样 . . . . . . . . . . . . . . . . . . . . . . . . . . 276\n11.3.3 重要性采样 . . . . . . . . . . . . . . . . . . . . . . . . . 277\n11.3.4 马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . 278\n11.4 学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\n11.4.1 不含隐变量的参数估计 . . . . . . . . . . . . . . . . . . . 282\n11.4.2 含隐变量的参数估计 . . . . . . . . . . . . . . . . . . . . 284\n11.5 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\n第 12 章 深度信念网络 293\n12.1 玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\n12.1.1 生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 295\n12.1.2 能量最小化与模拟退火 . . . . . . . . . . . . . . . . . . . 297\n12.1.3 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 298\n12.2 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\n12.2.1 生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 301\n12.2.2 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 304\n12.2.3 受限玻尔兹曼机的类型 . . . . . . . . . . . . . . . . . . . 305\n12.3 深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\n12.3.1 生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n12.3.2 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n12.4 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\n第 13 章 深度生成模型 315\n13.1 概率生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\n13.1.1 密度估计 . . . . . . . . . . . . . . . . . . . . . . . . . . 316\n13.1.2 生成样本 . . . . . . . . . . . . . . . . . . . . . . . . . . 316\n13.2 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\n13.2.1 含隐变量的生成模型 . . . . . . . . . . . . . . . . . . . . 317\n13.2.2 推断网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 319\n13.2.3 生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 320\n13.2.4 模型汇总 . . . . . . . . . . . . . . . . . . . . . . . . . . 321\n13.2.5 训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\n13.3 生成对抗网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\n13.3.1 显式密度模型和隐式密度模型 . . . . . . . . . . . . . . . 324\n13.3.2 网络分解 . . . . . . . . . . . . . . . . . . . . . . . . . . 325\n13.3.3 训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326\n13.3.4 一个生成对抗网络的具体实现：DCGAN . . . . . . . . . 326\n13.3.5 模型分析 . . . . . . . . . . . . . . . . . . . . . . . . . . 327\n13.3.6 改进模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 330\n13.4 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\n第 14 章 深度强化学习 335\n14.1 强化学习问题 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\n14.1.1 典型例子 . . . . . . . . . . . . . . . . . . . . . . . . . . 336\n14.1.2 强化学习定义 . . . . . . . . . . . . . . . . . . . . . . . . 336\n14.1.3 马尔可夫决策过程 . . . . . . . . . . . . . . . . . . . . . 337\n14.1.4 强化学习的目标函数 . . . . . . . . . . . . . . . . . . . . 339\n14.1.5 值函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340\n14.1.6 深度强化学习 . . . . . . . . . . . . . . . . . . . . . . . . 341\n14.2 基于值函数的学习方法 . . . . . . . . . . . . . . . . . . . . . . . 342\n14.2.1 动态规划算法 . . . . . . . . . . . . . . . . . . . . . . . . 342\n14.2.2 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . 345\n14.2.3 时序差分学习方法 . . . . . . . . . . . . . . . . . . . . . 346\n14.2.4 深度Q网络 . . . . . . . . . . . . . . . . . . . . . . . . . 349\n14.3 基于策略函数的学习方法 . . . . . . . . . . . . . . . . . . . . . 351\n14.3.1 REINFORCE算法 . . . . . . . . . . . . . . . . . . . . . 352\n14.3.2 带基准线的REINFORCE算法 . . . . . . . . . . . . . . 353\n14.4 Actor-Critic算法 . . . . . . . . . . . . . . . . . . . . . . . . . . 354\n14.5 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 356\n第 15 章 序列生成模型 361\n15.1 序列概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362\n15.1.1 序列生成 . . . . . . . . . . . . . . . . . . . . . . . . . . 362\n15.2 N元统计模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364\n15.3 深度序列模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\n15.3.1 参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 369\n15.4 评价方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\n15.4.1 困惑度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\n15.4.2 BLEU . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\n15.4.3 ROUGE . . . . . . . . . . . . . . . . . . . . . . . . . . . 371\n15.5 序列生成模型中的学习问题 . . . . . . . . . . . . . . . . . . . . 372\n15.5.1 曝光偏差问题 . . . . . . . . . . . . . . . . . . . . . . . . 372\n15.5.2 训练目标不一致问题 . . . . . . . . . . . . . . . . . . . . 373\n15.5.3 计算效率问题 . . . . . . . . . . . . . . . . . . . . . . . . 373\n15.6 序列到序列模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\n15.6.1 基于循环神经网络的序列到序列模型 . . . . . . . . . . . 382\n15.6.2 基于注意力的序列到序列模型 . . . . . . . . . . . . . . . 383\n15.6.3 基于自注意力的序列到序列模型 . . . . . . . . . . . . . 383\n15.7 总结和深入阅读 . . . . . . . . . . . . . . . . . . . . . . . . . . . 386\n附录 A 线性代数 389\nA.1 向量和向量空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . 389\nA.1.1 向量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389\nA.1.2 向量空间 . . . . . . . . . . . . . . . . . . . . . . . . . . 389\nA.1.3 范数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 391\nA.1.4 常见的向量 . . . . . . . . . . . . . . . . . . . . . . . . . 392\nA.2 矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392\nA.2.1 线性映射 . . . . . . . . . . . . . . . . . . . . . . . . . . 392\nA.2.2 矩阵操作 . . . . . . . . . . . . . . . . . . . . . . . . . . 393\nA.2.3 矩阵类型 . . . . . . . . . . . . . . . . . . . . . . . . . . 394\nA.2.4 特征值与特征矢量 . . . . . . . . . . . . . . . . . . . . . 396\nA.2.5 矩阵分解 . . . . . . . . . . . . . . . . . . . . . . . . . . 396\n附录 B 微积分 397\nB.1 导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397\nB.1.1 导数法则 . . . . . . . . . . . . . . . . . . . . . . . . . . 399\nB.2 常见函数的导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . 400\nB.2.1 向量函数及其导数 . . . . . . . . . . . . . . . . . . . . . 400\nB.2.2 按位计算的向量函数及其导数 . . . . . . . . . . . . . . . 400\nB.2.3 Logistic函数 . . . . . . . . . . . . . . . . . . . . . . . . 400\nB.2.4 softmax函数 . . . . . . . . . . . . . . . . . . . . . . . . 401\n附录 C 数学优化 403\nC.1 数学优化的类型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 403\nC.1.1 离散优化和连续优化 . . . . . . . . . . . . . . . . . . . . 403\nC.1.2 无约束优化和约束优化 . . . . . . . . . . . . . . . . . . . 404\nC.1.3 线性优化和非线性优化 . . . . . . . . . . . . . . . . . . . 404\nC.2 优化算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404\nC.3 拉格朗日乘数法与KKT条件 . . . . . . . . . . . . . . . . . . . 407\nC.3.1 等式约束优化问题 . . . . . . . . . . . . . . . . . . . . . 408\nC.3.2 不等式约束优化问题 . . . . . . . . . . . . . . . . . . . . 408\n附录 D 概率论 410\nD.1 样本空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410\nD.2 事件和概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410\nD.2.1 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . 411\nD.2.2 随机向量 . . . . . . . . . . . . . . . . . . . . . . . . . . 415\nD.2.3 边际分布 . . . . . . . . . . . . . . . . . . . . . . . . . . 416\nD.2.4 条件概率分布 . . . . . . . . . . . . . . . . . . . . . . . . 417\nD.2.5 独立与条件独立 . . . . . . . . . . . . . . . . . . . . . . 418\nD.2.6 期望和方差 . . . . . . . . . . . . . . . . . . . . . . . . . 418\nD.3 随机过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419\nD.3.1 马尔可夫过程 . . . . . . . . . . . . . . . . . . . . . . . . 420\nD.3.2 高斯过程 . . . . . . . . . . . . . . . . . . . . . . . . . . 421\n附录 E 信息论 423\nE.1 熵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423\nE.1.1 自信息和熵 . . . . . . . . . . . . . . . . . . . . . . . . . 423\nE.1.2 联合熵和条件熵 . . . . . . . . . . . . . . . . . . . . . . 424\nE.2 互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424\nE.3 交叉熵和散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425\nE.3.1 交叉熵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425\nE.3.2 KL散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . 425\nE.3.3 JS散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . 425\nE.3.4 Wasserstein距离 . . . . . . . . . . . . . . . . . . . . . . 426","pages":"444","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32292004.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32292004.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32292004.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33409947\/","id":"33409947","publisher":"","isbn10":"7631715858","isbn13":"9787631715855","title":"神经网络与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/33409947","alt_title":"","author_intro":"","summary":"复旦大学邱锡鹏老师在 Github 上开放的深度学习书籍\nhttps:\/\/nndl.github.io\/\nhttps:\/\/github.com\/nndl\/nndl.github.io","price":""},{"rating":{"max":10,"numRaters":65,"average":"9.0","min":0},"subtitle":"","author":["[日]涌井良幸","[日]涌井贞美"],"pubdate":"2019-4","tags":[{"count":114,"name":"深度学习","title":"深度学习"},{"count":105,"name":"数学","title":"数学"},{"count":53,"name":"机器学习","title":"机器学习"},{"count":36,"name":"计算机","title":"计算机"},{"count":34,"name":"神经网络","title":"神经网络"},{"count":20,"name":"数据分析","title":"数据分析"},{"count":17,"name":"计算科学","title":"计算科学"},{"count":16,"name":"很详尽的入门书","title":"很详尽的入门书"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32295077.jpg","binding":"平装","translator":["杨瑞龙"],"catalog":"第1章　神经网络的思想\n1 - 1　神经网络和深度学习　　2\n1 - 2　神经元工作的数学表示　　6\n1 - 3　激活函数：将神经元的工作一般化　　12\n1 - 4　什么是神经网络　　18\n1 - 5　用恶魔来讲解神经网络的结构　　23\n1 - 6　将恶魔的工作翻译为神经网络的语言　　31\n1 - 7　网络自学习的神经网络　　36\n第2章　神经网络的数学基础\n2 - 1　神经网络所需的函数　　40\n2 - 2　有助于理解神经网络的数列和递推关系式　　46\n2 - 3　神经网络中经常用到的Σ符号　　51\n2 - 4　有助于理解神经网络的向量基础　　53\n2 - 5　有助于理解神经网络的矩阵基础　　61\n2 - 6　神经网络的导数基础　　65\n2 - 7　神经网络的偏导数基础　　72\n2 - 8　误差反向传播法必需的链式法则　　76\n2 - 9　梯度下降法的基础：多变量函数的近似公式　　80\n2 - 10　梯度下降法的含义与公式　　83\n2 - 11　用Excel 体验梯度下降法　　91\n2 - 12　最优化问题和回归分析　　94\n第3章　神经网络的最优化\n3 - 1　神经网络的参数和变量　　102\n3 - 2　神经网络的变量的关系式　　111\n3 - 3　学习数据和正解　　114\n3 - 4　神经网络的代价函数　　119\n3 - 5　用Excel体验神经网络　　127\n第4章　神经网络和误差反向传播法\n4 - 1　梯度下降法的回顾　　134\n4 - 2　神经单元误差　　141\n4 - 3　神经网络和误差反向传播法　　146\n4 - 4　用Excel体验神经网络的误差反向传播法　　153\n第5章　深度学习和卷积神经网络\n5 - 1　小恶魔来讲解卷积神经网络的结构　　168\n5 - 2　将小恶魔的工作翻译为卷积神经网络的语言　　174\n5 - 3　卷积神经网络的变量关系式　　180\n5 - 4　用Excel体验卷积神经网络　　193\n5 - 5　卷积神经网络和误差反向传播法　　200\n5 - 6　用Excel体验卷积神经网络的误差反向传播法　　212\n附录\nA　训练数据（1）　　222\nB　训练数据（2）　　223\nC　用数学式表示模式的相似度　　225","pages":"236","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32295077.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32295077.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32295077.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33414479\/","id":"33414479","publisher":"人民邮电出版社","isbn10":"7115509344","isbn13":"9787115509345","title":"深度学习的数学","url":"https:\/\/api.douban.com\/v2\/book\/33414479","alt_title":"","author_intro":"作者简介：\n涌井良幸\n1950年生于东京，毕业于东京教育大学（现筑波大学）数学系，现为自由职业者。著有《用Excel学深度学习》（合著）、《统计学有什么用？》等。\n涌井贞美\n1952年生于东京，完成东京大学理学系研究科硕士课程，现为自由职业者。著有《用Excel学深度学习》（合著）、《图解贝叶斯统计入门》等。\n译者简介：\n杨瑞龙（\n1982年生，2008年北京大学数学科学学院硕士毕业，软件开发者，从事软件行业10年。2013年～2016年赴日工作3年，从2016年开始在哆嗒数学网公众号发表《数学上下三万年》等多篇翻译作品。","summary":"《深度学习的数学》基于丰富的图示和具体示例，通俗易懂地介绍了深度学习相关的数学知识。第1章介绍神经网络的概况；第2章介绍理解神经网络所需的数学基础知识；第3章介绍神经网络的最优化；第4章介绍神经网络和误差反向传播法；第5章介绍深度学习和卷积神经网络。书中使用Excel进行理论验证，帮助读者直观地体验深度学习的原理。","price":"69.00元"},{"rating":{"max":10,"numRaters":27,"average":"5.8","min":0},"subtitle":"","author":["王健宗","瞿晓阳"],"pubdate":"2019-8-20","tags":[{"count":16,"name":"AutoML和AutoDL","title":"AutoML和AutoDL"},{"count":13,"name":"人工智能","title":"人工智能"},{"count":12,"name":"深度学习","title":"深度学习"},{"count":12,"name":"机器学习","title":"机器学习"},{"count":3,"name":"ML","title":"ML"},{"count":2,"name":"系统的综述了三个ML前沿方向","title":"系统的综述了三个ML前沿方向"},{"count":2,"name":"科技","title":"科技"},{"count":2,"name":"机器学习利器","title":"机器学习利器"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33457888.jpg","binding":"平装","translator":[],"catalog":"目录\n赞誉\n前言\n第1章　人工智能概述1\n1.1　全面了解人工智能1\n1.1.1　人工智能定义1\n1.1.2　弱人工智能、强人工智能与超人工智能2\n1.1.3　人工智能三大主义3\n1.1.4　机器学习与深度学习4\n1.2　人工智能发展历程5\n1.3　深度学习的崛起之路7\n1.3.1　人脸识别的起源7\n1.3.2　自动驾驶的福音7\n1.3.3　超越人类的AI智能体8\n1.3.4　懂你的AI8\n1.3.5　奔跑、飞行以及玩游戏的AI8\n1.3.6　人人都可以创造属于自己的AI8\n1.4　深度学习的发展9\n1.4.1　计算机视觉9\n1.4.2　自然语言处理10\n1.4.3　语音识别11\n1.5　下一代人工智能11\n1.6　参考文献13\n第2章　自动化人工智能14\n2.1　AutoML概述14\n2.1.1　什么是自动化14\n2.1.2　AutoML的起源与发展15\n2.2　AutoML的研究意义17\n2.2.1　AutoML的研究动机17\n2.2.2　AutoML的意义和作用18\n2.3　现有AutoML平台产品21\n2.3.1　谷歌Cloud AutoML21\n2.3.2　百度EasyDL23\n2.3.3　阿里云PAI24\n2.3.4　探智立方DarwinML28\n2.3.5　第四范式AI ProphetAutoML29\n2.3.6　智易科技30\n2.4　参考文献31\n第3章　机器学习概述32\n3.1　机器学习的发展32\n3.1.1　“机器学习”名字的由来32\n3.1.2　“机器学习”的前世今生33\n3.1.3　“机器学习”的理论基础34\n3.2　机器学习的实现方法36\n3.2.1　分类问题36\n3.2.2　回归问题38\n3.2.3　聚类问题39\n3.3　自动化机器学习40\n3.3.1　机器学习面临的问题40\n3.3.2　为什么会产生AutoML41\n3.4　参考文献41\n第4章　自动化特征工程43\n4.1　特征工程43\n4.1.1　什么是特征43\n4.1.2　什么是特征工程44\n4.2　特征工程处理方法45\n4.2.1　特征选择45\n4.2.2　数据预处理47\n4.2.3　特征压缩48\n4.3　手工特征工程存在的问题49\n4.4　自动化特征工程50\n4.4.1　什么是自动化特征工程50\n4.4.2　机器学习和深度学习的特征工程51\n4.5　自动化特征工程生成方法52\n4.5.1　深度特征合成算法52\n4.5.2　Featuretools自动特征提取52\n4.5.3　基于时序数据的自动化特征工程56\n4.6　自动化特征工程工具67\n4.6.1　自动化特征工程系统67\n4.6.2　自动化特征工程平台71\n4.7　参考文献75\n第5章　自动化模型选择76\n5.1　模型选择76\n5.2　自动化模型选择77\n5.2.1　基于贝叶斯优化的自动化模型选择78\n5.2.2　基于进化算法的自动化模型选择84\n5.2.3　分布式自动化模型选择86\n5.2.4　自动化模型选择的相关平台92\n5.3　自动集成学习94\n5.3.1　集成学习基础94\n5.3.2　集成学习之结合策略97\n5.3.3　自动化模型集成98\n5.4　参考文献99\n第6章　自动化超参优化101\n6.1　概述101\n6.1.1　问题定义103\n6.1.2　搜索空间103\n6.1.3　搜索策略103\n6.1.4　评价预估104\n6.1.5　经验迁移加速105\n6.2　基本方法105\n6.2.1　网格搜索105\n6.2.2　随机搜索105\n6.3　基于模型的序列超参优化106\n6.3.1　代理模型的选择108\n6.3.2　代理模型的更新108\n6.3.3　新超参组的选择109\n6.3.4　基于高斯过程回归的序列超参优化111\n6.3.5　基于随机森林算法代理的序列超参优化112\n6.3.6　基于TPE算法的序列超参优化114\n6.3.7　SMBO的进阶技巧114\n6.4　基于进化算法的自动化超参优化115\n6.4.1　基于进化策略的自动化超参优化115\n6.4.2　基于粒子群算法的自动化超参优化116\n6.5　基于迁移学习的超参优化加速方法117\n6.5.1　经验迁移机制117\n6.5.2　经验迁移衰退机制117\n6.5.3　经验迁移权重机制117\n6.5.4　优化过程的试点机制118\n6.6　参考文献118\n第7章　深度学习基础120\n7.1　深度学习简介120\n7.1.1　什么是神经元120\n7.1.2　人工神经网络的发展历程121\n7.1.3　深度学习方法123\n7.2　卷积神经网络简介123\n7.2.1　卷积层123\n7.2.2　池化层125\n7.2.3　全连接层126\n7.3　CNN经典模型126\n7.3.1　LeNet126\n7.3.2　AlexNet127\n7.3.3　VGGNet128\n7.3.4　GoogLeNet129\n7.3.5　ResNet130\n7.3.6　DenseNet131\n7.4　循环神经网络132\n7.4.1　基本循环神经模型132\n7.4.2　LSTM模型133\n7.4.3　GRU模型134\n7.5　参考文献134\n第8章　自动化深度学习概述136\n8.1　深度学习vs自动化深度学习136\n8.2　什么是NAS136\n8.2.1　问题定义137\n8.2.2　搜索策略139\n8.2.3　加速方案140\n8.3　NAS方法分类140\n第9章　基于强化学习的AutoDL142\n9.1　强化学习基础142\n9.1.1　强化学习简介142\n9.1.2　基本要素及问题定义144\n9.1.3　发展历史144\n9.1.4　基本方法146\n9.2　两类基本模型147\n9.2.1　TD经典算法148\n9.2.2　DQN系列算法149\n9.2.3　策略梯度算法152\n9.3　强化学习之Actor-Critic系列154\n9.3.1　Actor-Critic算法154\n9.3.2　确定性策略梯度155\n9.3.3　深度确定性策略梯度157\n9.3.4　异步优势Actor-Critic算法158\n9.3.5　近端策略优化160\n9.3.6　分布式近端策略优化164\n9.4　基于强化学习的自动搜索166\n9.5　基本搜索方法166\n9.5.1　基于层的搜索166\n9.5.2　基于块的搜索169\n9.5.3　基于连接的搜索171\n9.6　进阶搜索方法173\n9.6.1　逆强化学习173\n9.6.2　图超网络174\n9.6.3　蒙特卡洛树搜索175\n9.6.4　知识提炼（教师网络）177\n9.7　参考文献179\n第10章　基于进化算法的AutoDL181\n10.1　启发式算法181\n10.1.1　随机搜索182\n10.1.2　近邻搜索183\n10.1.3　进化计算187\n10.1.4　启发式算法的局限性189\n10.2　初代进化算法190\n10.2.1　基本术语190\n10.2.2　基础算子191\n10.2.3　遗传算法196\n10.2.4　进化策略198\n10.2.5　进化规划199\n10.3　其他近代进化算法200\n10.3.1　遗传编程算法簇200\n10.3.2　群体算法—以PSO为例205\n10.3.3　文化基因算法207\n10.3.4　差分进化算法208\n10.3.5　分布估计算法208\n10.4　进化神经网络209\n10.4.1　简介209\n10.4.2　神经网络编码方式210\n10.4.3　竞争约定211\n10.4.4　网络结构的创新性212\n10.4.5　NAS之进化算法212\n10.5　细粒度的神经进化（NEAT算法）213\n10.5.1　基因编码214\n10.5.2　基因的可追溯性216\n10.5.3　通过物种形成保护创新结构216\n10.6　粗粒度的神经进化（CoDeep-NEAT算法）218\n10.6.1　DeepNEAT算法218\n10.6.2　CoDeepNEAT算法219\n10.7　block-level的进化220\n10.7.1　Genetic CNN算法220\n10.7.2　CGP-CNN方法222\n10.8　基于node-level的网络架构进化224\n10.8.1　思想简介224\n10.8.2　基本算法设计225\n10.8.3　信息复用与加速226\n10.9　基于NAS搜索空间的网络架构进化227\n10.9.1　思想简介227\n10.9.2　基本算法设计227\n10.9.3　信息复用与加速228\n10.10　基于层次拓扑表示的网络进化方法228\n10.10.1　思想简介228\n10.10.2　分级表示229\n10.10.3　随机的层次分级进化230\n10.11　参考文献230\n第11章　AutoDL高阶233\n11.1　搜索加速之权值共享法233\n11.1.1　ENAS233\n11.1.2　基于稀疏优化的NAS235\n11.2　基于one-shot模型的架构搜索236\n11.2.1　超网络的应用236\n11.2.2　基于one-shot的搜索237\n11.2.3　实例级架构搜索238\n11.2.4　单路径超网络240\n11.3　搜索加速之代理评估模型241\n11.3.1　代理模型241\n11.3.2　PNAS中的LSTM代理242\n11.4　基于网络态射法的神经架构搜索244\n11.4.1　网络态射的提出244\n11.4.2　什么是网络态射244\n11.4.3　网络态射+迂回爬山法246\n11.5　可微分神经架构搜索247\n11.5.1　可微分神经架构搜索的来源247\n11.5.2　可微分神经架构搜索的方法248\n11.6　参考文献250\n第12章　垂直领域的AutoDL252\n12.1　AutoCV252\n12.1.1　Auto-DeepLab（图像语义分割）252\n12.1.2　随机连线神经网络257\n12.2　AutoVoice261\n12.2.1　关键词定位问题定义261\n12.2.2　随机自适应架构搜索原理262\n12.2.3　SANAS模型262\n12.3　AutoNLP263\n12.3.1　什么是自注意力机制263\n12.3.2　初识Transformer模型265\n12.3.3　Evolved Transformer结构266\n12.4　参考文献270\n第13章　自动化模型压缩与加速271\n13.1　从生物角度看模型压缩的重要性271\n13.1.1　人脑神经元的修剪271\n13.1.2　大脑的冗余性272\n13.1.3　修剪的意义273\n13.2　模型压缩发展概述274\n13.3　入门级方法：量化技术275\n13.3.1　量化技术275\n13.3.2　二值化网络276\n13.3.3　TensorRT277\n13.4　初级方法：修剪法278\n13.4.1　修剪法278\n13.4.2　修剪与修复279\n13.5　中级方法：稀疏化技术281\n13.5.1　正则化281\n13.5.2　知识精炼281\n13.5.3　张量分解281\n13.6　高级方法：轻量级模型设计284\n13.6.1　简化卷积操作284\n13.6.2　深度可分离卷积285\n13.6.3　改进的Inception287\n13.7　自动化模型压缩技术289\n13.7.1　AMC算法289\n13.7.2　PocketFlow框架291\n13.8　基于AutoDL的轻量级模型292\n13.8.1　问题定义292\n13.8.2　帕累托最优问题293\n13.8.3　进化算法的应用294\n13.8.4　强化学习的应用296\n13.8.5　可微分架构搜索298\n13.9　参考文献300\n第14章　元学习302\n14.1　什么是元学习302\n14.1.1　基本介绍302\n14.1.2　经典案例303\n14.1.3　深入了解元学习304\n14.1.4　元学习应用的发展306\n14.2　元学习的通用流程306\n14.2.1　基本定义306\n14.2.2　流程框架306\n14.3　从模型评估中学习307\n14.3.1　任务无关推荐308\n14.3.2　参数空间设计308\n14.3.3　参数转换309\n14.3.4　学习曲线310\n14.4　从任务属性中学习310\n14.4.1　元特征310\n14.4.2　学习元特征311\n14.4.3　相似任务的热启动优化311\n14.4.4　元模型311\n14.4.5　管道合成312\n14.4.6　是否调整312\n14.5　从先前模型中学习312\n14.5.1　迁移学习313\n14.5.2　神经网络中的元学习313\n14.5.3　小样本学习314\n14.5.4　监督学习之外的方法315\n14.6　基于模型的方法316\n14.6.1　记忆增强神经网络316\n14.6.2　元网络317\n14.6.3　模型无关的元学习方法317\n14.6.4　利用注意力机制的方法319\n14.6.5　基于时间卷积的方法320\n14.6.6　基于损失预测的方法321\n14.6.7　元强化学习321\n14.7　基于度量的方法322\n14.7.1　Siamese网络322\n14.7.2　匹配网络324\n14.7.3　关系网络324\n14.7.4　原型网络325\n14.8　基于优化的方法326\n14.8.1　基于LSTM网络的元学习者326\n14.8.2　未知模型的元学习326\n14.8.3　Reptile：可扩展元学习方法327\n14.8.4　基于梯度预测的方法327\n14.9　参考文献329\n结束语332","pages":"348","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33457888.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33457888.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33457888.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34794803\/","id":"34794803","publisher":"机械工业出版社","isbn10":"7111634365","isbn13":"9787111634362","title":"深入理解AutoML和AutoDL：构建自动化机器学习与深度学习平台","url":"https:\/\/api.douban.com\/v2\/book\/34794803","alt_title":"","author_intro":"王健宗\n大型金融集团科技公司深度学习平台和AutoML平台负责人，中国人工智能开源软件发展联盟副理事长，美国佛罗里达大学人工智能博士后，曾任美国莱斯大学电子与计算机工程系研究员，专注于联邦学习和人工智能在金融、保险、投资、银行和医疗等领域的研发工作，发表联邦学习、深度学 习、云计算和大数据等领域国际论文30余篇，以及发明专利200余项。多届国内知名大数据、人工智能、金融科技和联邦学习会议\/论坛主席和出品人。\n瞿晓阳　华中科技大学计算机系统结构博士，美国中佛罗里达大学访问学者，大型金融集团科技公司资深算法工程师，一直从事机器学习、大数据、体系结构方面的研究工作，在AutoML平台、面向AI的云原生架构、高性能计算、高效能存储系统等方面经验丰富。近几年，在国际顶级会议和顶级期刊发表过多篇文章，担任过多个国际顶级期刊的评委。","summary":"这是一部从基础理论、核心原理、前沿算法等多个维度系统、全面讲解AutoML、AutoDL和元学习的著作。\n作者是资深的人工智能专家，大型金融集团科技公司深度学习平台和AutoML平台负责人。本书得到了IEEE Fellow\/ACM杰出科学家\/香港科技大学教授杨强、腾讯AI Lab副 主任俞 栋、美国佛罗里达大学教授李晓林等8位来自企业界、学术界和媒体界的资深专家的一致好评。它既能让新手理清AutoML的脉络，快速上手机器学习，又能让有经验的从业者全面掌握AutoML知识体系，工作变得更高效。\n全书共14章，逻辑上分为四部分：\n第一部分（第1~2章） 人工智能基础\n对人工智能、自动化人工智能的重要概念、发展历程及现状、适用场景、主要的工具和技术等做了全面的介绍，并引出了人工智能技术未来的发展方向——AutoML，这部分是阅读本书的基础。\n第二部分（第3~6章） AutoML\n主要讲解机器学习和自动化机器学习，核心是AutoML，包含自动化特征工程、自动化模型选择和自动化超参优化3个方面的内容。\n第三部分（第7~13章） AutoDL\n主要讲解深度学习和自动化深度学习，重点讲解了AutoDL的原理、基于强化学习的AutoDL、基于进化算法的AutoDL、AtuoDL的高阶知识、自动化模型压缩与加速，以及各种核心算法和前沿算法。\n第四部分（第14章） 元学习\n元学习是人工智能的理想目标，这部分对元学习的概念、流程和各种主流的学习方法都进行了详尽的介绍。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"99.00元"},{"rating":{"max":10,"numRaters":14,"average":"9.2","min":0},"subtitle":"","author":["[瑞士]　翁贝托•米凯卢奇（Umberto Michelucci）"],"pubdate":"2019-9-21","tags":[{"count":7,"name":"好书，值得一读","title":"好书，值得一读"},{"count":4,"name":"人工智能","title":"人工智能"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"学习系列","title":"学习系列"},{"count":2,"name":"好书","title":"好书"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"提升","title":"提升"}],"origin_title":"Applied Deep Learning: A Case-Based Approach to Understanding Deep Neural Networks","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33506322.jpg","binding":"平装","translator":["陶阳　邓红平"],"catalog":"译者序\n前言\n审校者简介\n致谢\n第1章　计算图和TensorFlow1\n1.1　如何构建Python环境1\n1.1.1　创建环境3\n1.1.2　安装TensorFlow7\n1.1.3　Jupyter记事本8\n1.2　TensorFlow基本介绍10\n1.2.1　计算图10\n1.2.2　张量12\n1.2.3　创建和运行计算图13\n1.2.4　包含tf.constant的计算图13\n1.2.5　包含tf.Variable的计算图14\n1.2.6　包含tf. placeholder的计算图15\n1.2.7　运行和计算的区别18\n1.2.8　节点之间的依赖关系18\n1.2.9　创建和关闭会话的技巧19\n第2章　单一神经元21\n2.1　神经元结构21\n2.1.1　矩阵表示法23\n2.1.2　Python实现技巧：循环和NumPy24\n2.1.3　激活函数25\n2.1.4　代价函数和梯度下降：学习率的特点32\n2.1.5　学习率的应用示例34\n2.1.6　TensorFlow中的线性回归示例38\n2.2　逻辑回归示例47\n2.2.1　代价函数47\n2.2.2　激活函数48\n2.2.3　数据集48\n2.2.4　TensorFlow实现51\n2.3　参考文献54\n第3章　前馈神经网络56\n3.1　网络架构57\n3.1.1　神经元的输出59\n3.1.2　矩阵维度小结59\n3.1.3　示例：三层网络的方程59\n3.1.4　全连接网络中的超参数60\n3.2　用于多元分类的softmax函数60\n3.3　过拟合简要介绍61\n3.3.1　过拟合示例61\n3.3.2　基本误差分析66\n3.4　Zalando数据集68\n3.5　使用TensorFlow构建模型71\n3.5.1　网络架构71\n3.5.2　softmax函数的标签转换：独热编码73\n3.5.3　TensorFlow模型74\n3.6　梯度下降变体77\n3.6.1　批量梯度下降77\n3.6.2　随机梯度下降78\n3.6.3　小批量梯度下降79\n3.6.4　各种变体比较80\n3.7　错误预测示例84\n3.8　权重初始化84\n3.9　有效添加多个层87\n3.10　增加隐藏层的优点89\n3.11　比较不同网络89\n3.12　选择正确网络的技巧92\n第4章　训练神经网络93\n4.1　动态学习率衰减93\n4.1.1　迭代还是周期94\n4.1.2　阶梯式衰减95\n4.1.3　步长衰减96\n4.1.4　逆时衰减98\n4.1.5　指数衰减100\n4.1.6　自然指数衰减101\n4.1.7　TensorFlow实现105\n4.1.8　将方法应用于Zalando数据集108\n4.2　常用优化器109\n4.2.1　指数加权平均109\n4.2.2　Momentum112\n4.2.3　RMSProp115\n4.2.4　Adam117\n4.2.5　应该使用哪种优化器117\n4.3　自己开发的优化器示例118\n第5章　正则化123\n5.1　复杂网络和过拟合123\n5.2　什么是正则化127\n5.3　?p范数128\n5.4　?2正则化128\n5.4.1　?2正则化原理128\n5.4.2　TensorFlow实现129\n5.5　?1正则化136\n5.5.1　?1正则化原理与TensorFlow实现137\n5.5.2　权重真的趋于零吗137\n5.6　Dropout140\n5.7　Early Stopping143\n5.8　其他方法144\n第6章　指标分析145\n6.1　人工水平表现和贝叶斯误差146\n6.2　关于人工水平表现的故事148\n6.3　MNIST中的人工水平表现149\n6.4　偏差150\n6.5　指标分析图151\n6.6　训练集过拟合151\n6.7　测试集152\n6.8　如何拆分数据集153\n6.9　不平衡类分布：会发生什么157\n6.10　精确率、召回率和F1指标161\n6.11　不同分布的数据集164\n6.12　k折交叉验证170\n6.13　手动指标分析示例177\n第7章　超参数调优183\n7.1　黑盒优化183\n7.2　黑盒函数注意事项184\n7.3　超参数调优问题185\n7.4　黑盒问题示例186\n7.5　网格搜索186\n7.6　随机搜索190\n7.7　粗到细优化192\n7.8　贝叶斯优化195\n7.8.1　Nadaraya-Watson回归195\n7.8.2　高斯过程195\n7.8.3　平稳过程196\n7.8.4　用高斯过程预测196\n7.8.5　采集函数200\n7.8.6　上置信界（UCB）201\n7.8.7　示例201\n7.9　对数尺度采样207\n7.10　使用Zalando数据集的超参数调优208\n7.11　径向基函数注意事项214\n第8章　卷积神经网络和循环神经网络216\n8.1　卷积核和过滤器216\n8.2　卷积217\n8.3　卷积运算示例223\n8.4　池化227\n8.5　构建CNN块230\n8.5.1　卷积层230\n8.5.2　池化层231\n8.5.3　各层的叠加231\n8.5.4　CNN示例232\n8.6　RNN介绍237\n8.6.1　符号237\n8.6.2　RNN的基本原理238\n8.6.3　循环神经网络名称的由来239\n8.6.4　学会统计239\n第9章　研究项目244\n9.1　问题描述244\n9.2　数学模型246\n9.3　回归问题246\n9.4　数据准备250\n9.5　模型训练258\n第10章　从零开始进行逻辑回归261\n10.1　逻辑回归的数学背景262\n10.2　Python实现264\n10.3　模型测试266\n10.3.1　数据集准备267\n10.3.2　运行测试268\n10.4　结论268","pages":"280","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33506322.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33506322.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33506322.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34867507\/","id":"34867507","publisher":"机械工业出版社","isbn10":"7111637100","isbn13":"9787111637103","title":"深度学习：基于案例理解深度神经网络","url":"https:\/\/api.douban.com\/v2\/book\/34867507","alt_title":"Applied Deep Learning: A Case-Based Approach to Understanding Deep Neural Networks","author_intro":"翁贝托•米凯卢奇（Umberto Michelucci）\n目前在瑞士领先的医疗保险公司从事创新和人工智能（AI）工作。他领导与人工智能、新技术、机器学习以及大学的研究合作相关的多项战略计划。此前，他曾担任多个大型医疗保健项目的数据科学家和首席建模师，并在编程和算法设计方面拥有丰富的实践经验。他管理过商务智能和数据仓库项目，使数据驱动的解决方案能够在复杂的生产环境中实施。最近，Umberto 对神经网络进行了广泛的研究，并应用深度学习来解决与保险、客户行为（如客户流失）和传感器科学相关的一些问题。他曾在意大利、美国和德国学习理论物理，并担任研究员，还在英国接受过高等教育。他经常在会议上发表科学成果，并在同行评审的期刊上发表研究论文。","summary":"本书探讨深度学习中的高级主题，例如优化算法、超参数调整、Dropout和误差分析，并讨论如何解决在训练深度神经网络时遇到的典型问题。书中首先介绍单一神经元网络的激活函数（ReLu、sigmoid和Swish），然后介绍如何使用TensorFlow进行线性和逻辑回归，以及如何选择正确的代价函数，之后讨论具有多个层和神经元的更复杂的神经网络结构，并探讨权重的随机初始化问题。本书用一整章对神经网络误差分析进行全面概述，给出如何解决来自不同分布的方差、偏差、过拟合和数据集问题的例子。\n本书还讨论在不使用任何Python库（NumPy除外）的情况下，如何从零开始完全实现逻辑回归，以便用诸如TensorFlow这样的库进行快速和有效的实验。本书包括每种方法的案例研究，以便将所有理论信息付诸实践。你还将学到Python代码的优化技巧（例如，使用NumPy对循环进行向量化）。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"89.00元"},{"rating":{"max":10,"numRaters":126,"average":"8.5","min":0},"subtitle":"","author":["顾思宇","梁博文","郑泽宇"],"pubdate":"2018-2-1","tags":[{"count":131,"name":"深度学习","title":"深度学习"},{"count":107,"name":"机器学习","title":"机器学习"},{"count":92,"name":"TensorFlow","title":"TensorFlow"},{"count":52,"name":"人工智能","title":"人工智能"},{"count":49,"name":"tensorflow","title":"tensorflow"},{"count":33,"name":"Python","title":"Python"},{"count":25,"name":"AI","title":"AI"},{"count":10,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29683030.jpg","binding":"平装","translator":[],"catalog":"第1章 深度学习简介\n1.1 人工智能、机器学习与深度学习\n1.2 深度学习的发展历程\n1.3 深度学习的应用\n1.3.1 计算机视觉\n1.3.2 语音识别\n1.3.3 自然语言处理\n1.3.4 人机博弈\n1.4 深度学习工具介绍和对比\n小结\n第2章 TensorFlow环境搭建\n2.1 TensorFlow的主要依赖包\n2.1.1 Protocol Buffer\n2.1.2 Bazel\n2.2 TensorFlow安装\n2.2.1 使用Docker安装\n2.2.2 使用pip安装\n2.2.3 从源代码编译安装\n2.3 TensorFlow测试样例\n小结\n第3章 TensorFlow入门\n3.1 TensorFlow计算模型——计算图\n3.1.1 计算图的概念\n3.1.2 计算图的使用\n3.2 TensorFlow数据模型——张量\n3.2.1 张量的概念\n3.2.2 张量的使用\n3.3 TensorFlow运行模型——会话\n3.4 TensorFlow实现神经网络\n3.4.1 TensorFlow游乐场及神经网络简介\n3.4.2 前向传播算法简介\n3.4.3 神经网络参数与TensorFlow变量\n3.4.4 通过TensorFlow训练神经网络模型\n3.4.5 完整神经网络样例程序\n小结\n第4章 深层神经网络\n4.1 深度学习与深层神经网络\n4.1.1 线性模型的局限性\n4.1.2 激活函数实现去线性化\n4.1.3 多层网络解决异或运算\n4.2 损失函数定义\n4.2.1 经典损失函数\n4.2.2 自定义损失函数\n4.3 神经网络优化算法\n4.4 神经网络进一步优化\n4.4.1 学习率的设置\n4.4.2 过拟合问题\n4.4.3 滑动平均模型\n小结\n第5章 MNIST数字识别问题\n5.1 MNIST数据处理\n5.2 神经网络模型训练及不同模型结果对比\n5.2.1 TensorFlow训练神经网络\n5.2.2 使用验证数据集判断模型效果\n5.2.3 不同模型效果比较\n5.3 变量管理\n5.4 TensorFlow模型持久化\n5.4.1 持久化代码实现\n5.4.2 持久化原理及数据格式\n5.5 TensorFlow最佳实践样例程序\n小结\n第6章 图像识别与卷积神经网络\n6.1 图像识别问题简介及经典数据集\n6.2 卷积神经网络简介\n6.3 卷积神经网络常用结构\n6.3.1 卷积层\n6.3.2 池化层\n6.4 经典卷积网络模型\n6.4.1 LeNet-5模型\n6.4.2 Inception-v3模型\n6.5 卷积神经网络迁移学习\n6.5.1 迁移学习介绍\n6.5.2 TensorFlow实现迁移学习\n小结\n第7章 图像数据处理\n7.1 TFRecord输入数据格式\n7.1.1 TFRecord格式介绍\n7.1.2 TFRecord样例程序\n7.2 图像数据处理\n7.2.1 TensorFlow图像处理函数\n7.2.2 图像预处理完整样例\n7.3 多线程输入数据处理框架\n7.3.1 队列与多线程\n7.3.2 输入文件队列\n7.3.3 组合训练数据（batching）\n7.3.4 输入数据处理框架\n7.4 数据集（Dataset）\n7.4.1 数据集的基本使用方法\n7.4.2 数据集的高层操作\n小结\n第8章 循环神经网络\n8.1 循环神经网络简介\n8.2 长短时记忆网络（LSTM）结构\n8.3 循环神经网络的变种\n8.3.1 双向循环神经网络和深层循环神经网络\n8.3.2 循环神经网络的dropout\n8.4 循环神经网络样例应用\n小结\n第9章 自然语言处理\n9.1 语言模型的背景知识\n9.1.1 语言模型简介\n9.1.2 语言模型的评价方法\n9.2 神经语言模型\n9.2.1 PTB数据集的预处理\n9.2.2 PTB数据的batching方法\n9.2.3 基于循环神经网络的神经语言模型\n9.3 神经网络机器翻译\n9.3.1 机器翻译背景与Seq2Seq模型介绍\n9.3.2 机器翻译文本数据的预处理\n9.3.3 Seq2Seq模型的代码实现\n9.3.4 注意力机制\n小结\n第10章 TensorFlow高层封装\n10.1 TensorFlow高层封装总览\n10.2 Keras介绍\n10.2.1 Keras基本用法\n10.2.2 Keras高级用法\n10.3 Estimator介绍\n10.3.1 Estimator基本用法\n10.3.2 Estimator自定义模型\n10.3.3 使用数据集（Dataset）作为Estimator输入\n小结\n第11章 TensorBoard可视化\n11.1 TensorBoard简介\n11.2 TensorFlow计算图可视化\n11.2.1 命名空间与TensorBoard图上节点\n11.2.2 节点信息\n11.3 监控指标可视化\n11.4 高维向量可视化\n小结\n第12章 TensorFlow计算加速\n12.1 TensorFlow使用GPU\n12.2 深度学习训练并行模式\n12.3 多GPU并行\n12.4 分布式TensorFlow\n12.4.1 分布式TensorFlow原理\n12.4.2 分布式TensorFlow模型训练\n小结","ebook_url":"https:\/\/read.douban.com\/ebook\/58733737\/","pages":"364","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29683030.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29683030.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29683030.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30137062\/","id":"30137062","publisher":"电子工业出版社","isbn10":"7121330660","isbn13":"9787121330667","title":"TensorFlow：实战Google深度学习框架（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/30137062","alt_title":"","author_intro":"郑泽宇，2011年获北京大学计算机学士学位，2013年获卡内基梅隆大学计算机硕士学位，前谷歌高级工程师，现为才云科技(Caicloud.io)联合创始人、首席大数据科学家。针对分布式TensorFlow上手难、管理难、监控难、上线难等问题，带领团队成功开发国内成熟的分布式TensorFlow深度学习平台，在机器学习、人工智能领域有着丰富的经验。\n梁博文，谷歌工程师。2011年获北京大学计算机学士学位，2013年获哥伦比亚大学计算机硕士学位，同年加入谷歌翻译组，参与并领导了多个项目，负责了3个语言的翻译模型的研发工作，在自然语言处理方面有丰富经验，在统计翻译模型、神经网络翻译模型、语料数据清洗等方面均有深入研究。","summary":"TensorFlow是谷歌2015年开源的主流深度学习框架，目前已得到广泛应用。《TensorFlow：实战Google深度学习框架（第2版）》为TensorFlow入门参考书，旨在帮助读者以快速、有效的方式上手TensorFlow和深度学习。书中省略了烦琐的数学模型推导，从实际应用问题出发，通过具体的TensorFlow示例介绍如何使用深度学习解决实际问题。书中包含深度学习的入门知识和大量实践经验，是走进这个前沿、热门的人工智能领域的优选参考书。\n第2版将书中所有示例代码从TensorFlow 0.9.0升级到了TensorFlow 1.4.0。在升级API的同时，第2版也补充了更多只有TensorFlow 1.4.0才支持的功能。另外，第2版还新增两章分别介绍TensorFlow高层封装和深度学习在自然语言领域应用的内容。\n《TensorFlow：实战Google深度学习框架（第2版）》适用于想要使用深度学习或TensorFlow的数据科学家、工程师，希望了解深度学习的大数据平台工程师，对人工智能、深度学习感兴趣的计算机相关从业人员及在校学生等。","ebook_price":"62.30","series":{"id":"41172","title":"博文视点AI系列"},"price":"89"},{"rating":{"max":10,"numRaters":63,"average":"6.9","min":0},"subtitle":"","author":["陈云"],"pubdate":"2018-1","tags":[{"count":45,"name":"深度学习","title":"深度学习"},{"count":21,"name":"机器学习","title":"机器学习"},{"count":18,"name":"Pytorch","title":"Pytorch"},{"count":13,"name":"Python","title":"Python"},{"count":10,"name":"人工智能","title":"人工智能"},{"count":10,"name":"PyTorch","title":"PyTorch"},{"count":9,"name":"计算机","title":"计算机"},{"count":5,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29660190.jpg","binding":"平装","translator":[],"catalog":"1  PyTorch简介\n1.1 PyTorch的诞生\n1.2 常见的深度学习框架简介\n1.2.1 Theano\n1.2.2 TensorFlow\n1.2.3 Keras\n1.2.4 Caffe\/Caffe2\n1.2.5 MXNet\n1.2.6 CNTK\n1.2.7 其他框架\n1.3 属于动态图的未来\n1.4 为什么选择PyTorch\n1.5 星火燎原\n1.6 fast.ai 放弃Keras+TensorFlow选择PyTorch\n2  快速入门\n2.1 安装与配置\n2.1.1 安装PyTorch\n2.1.2 学习环境配置\n2.2 PyTorch入门第一步\n2.2.1 Tensor\n2.2.2 Autograd：自动微分\n2.2.3 神经网络\n2.2.4 小试牛刀：CIFAR-10分类\n3  Tensor和autograd\n3.1 Tensor\n3.1.1 基础操作\n3.1.2 Tensor和Numpy\n3.1.3 内部结构\n3.1.4 其他有关Tensor的话题\n3.1.5 小试牛刀：线性回归\n3.2 autograd\n3.2.1 Variable\n3.2.2 计算图\n3.2.3 扩展autograd\n3.2.4 小试牛刀：用Variable实现线性回归\n4  神经网络工具箱nn\n4.1 nn.Module\n4.2 常用的神经网络层\n4.2.1 图像相关层\n4.2.2 激活函数\n4.2.3 循环神经网络层\n4.2.4 损失函数\n4.3 优化器\n4.4 nn.functional\n4.5 初始化策略\n4.6 nn.Module深入分析\n4.7 nn和autograd的关系\n4.8 小试牛刀：用50行代码搭建ResNet\n5  PyTorch中常用的工具\n5.1 数据处理\n5.2 计算机视觉工具包：torchvision\n5.3 可视化工具\n5.3.1 Tensorboard\n5.3.2 visdom\n5.4 使用GPU加速：cuda\n5.5 持久化\n6  PyTorch实战指南\n6.1 编程实战：猫和狗二分类\n6.1.1 比赛介绍\n6.1.2 文件组织架构\n6.1.3 关于__init__.py\n6.1.4 数据加载\n6.1.5 模型定义\n6.1.6 工具函数\n6.1.7 配置文件\n6.1.8 main.py\n6.1.9 使用\n6.1.10 争议\n6.2 PyTorch Debug 指南\n6.2.1 ipdb 介绍\n6.2.2 在PyTorch中Debug\n7  AI插画师：生成对抗网络\n7.1 GAN的原理简介\n7.2 用GAN生成动漫头像\n7.3 实验结果分析\n8  AI艺术家：神经网络风格迁移\n8.1 风格迁移原理介绍\n8.2 用PyTorch实现风格迁移\n8.3 实验结果分析\n9  AI诗人：用RNN写诗\n9.1 自然语言处理的基础知识\n9.1.1 词向量\n9.1.2 RNN\n9.2 CharRNN\n9.3 用PyTorch实现CharRNN\n9.4 实验结果分析\n10  Image Caption：让神经网络看图讲故事\n10.1 图像描述介绍\n10.2 数据\n10.2.1 数据介绍\n10.2.2 图像数据处理\n10.2.3 数据加载\n10.3 模型与训练\n10.4 实验结果分析\n11  展望与未来\n11.1 PyTorch的局限与发展\n11.2 使用建议","ebook_url":"https:\/\/read.douban.com\/ebook\/59649494\/","pages":"300","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29660190.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29660190.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29660190.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27624483\/","id":"27624483","publisher":"电子工业出版社","isbn10":"7121330776","isbn13":"9787121330773","title":"深度学习框架PyTorch：入门与实践","url":"https:\/\/api.douban.com\/v2\/book\/27624483","alt_title":"","author_intro":"陈云\nPython程序员、Linux爱好者和PyTorch源码贡献者。主要研究方向包括计算机视觉和机器学习。“2017知乎看山杯机器学习挑战赛”一等奖，“2017天池医疗AI大赛”第八名。 热衷于推广PyTorch，并有丰富的使用经验，活跃于PyTorch论坛和知乎相关板块。","summary":"《深度学习框架PyTorch：入门与实践》从多维数组Tensor开始，循序渐进地带领读者了解PyTorch各方面的基础知识。结合基础知识和前沿研究，带领读者从零开始完成几个经典有趣的深度学习小项目，包括GAN生成动漫头像、AI滤镜、AI写诗等。《深度学习框架PyTorch：入门与实践》没有简单机械地介绍各个函数接口的使用，而是尝试分门别类、循序渐进地向读者介绍PyTorch的知识，希望读者对PyTorch有一个完整的认识。\n《深度学习框架PyTorch：入门与实践》内容由浅入深，无论是深度学习的初学者，还是第一次接触PyTorch的研究人员，都能在学习本书的过程中快速掌握PyTorch。即使是有一定PyTorch使用经验的用户，也能够从本书中获得对PyTorch不一样的理解。","ebook_price":"39.00","series":{"id":"41172","title":"博文视点AI系列"},"price":"65"},{"rating":{"max":10,"numRaters":50,"average":"7.9","min":0},"subtitle":"","author":["Yoav Goldberg"],"pubdate":"2018-5-1","tags":[{"count":75,"name":"自然语言处理","title":"自然语言处理"},{"count":50,"name":"深度学习","title":"深度学习"},{"count":32,"name":"NLP","title":"NLP"},{"count":31,"name":"DL＋NLP","title":"DL＋NLP"},{"count":24,"name":"机器学习","title":"机器学习"},{"count":23,"name":"人工智能","title":"人工智能"},{"count":12,"name":"Python","title":"Python"},{"count":9,"name":"研究方法","title":"研究方法"}],"origin_title":"Neural Network Methods in Natural Language Processing","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29782015.jpg","binding":"平装","translator":["车万翔","郭江","张伟男","刘铭"],"catalog":"目录\n前言\n致谢\n第1章引言\n1.1自然语言处理的挑战\n1.2神经网络和深度学习\n1.3自然语言处理中的深度学习\n1.4本书的覆盖面和组织结构\n1.5本书未覆盖的内容\n1.6术语\n1.7数学符号\n注释\n部分有监督分类与前馈神经网络\n第2章学习基础与线性模型\n2.1有监督学习和参数化函数\n2.2训练集、测试集和验证集\n2.3线性模型\n2.3.1二分类\n2.3.2对数线性二分类\n2.3.3多分类\n2.4表示\n2.5独热和稠密向量表示\n2.6对数线性多分类\n2.7训练和优化\n2.7.1损失函数\n2.7.2正则化\n2.8基于梯度的优化\n2.8.1随机梯度下降\n2.8.2实例\n2.8.3其他训练方法\n第3章从线性模型到多层感知器\n3.1线性模型的局限性：异或问题\n3.2非线性输入转换\n3.3核方法\n3.4可训练的映射函数\n第4章前馈神经网络\n4.1一个关于大脑的比喻\n4.2数学表示\n4.3表达能力\n4.4常见的非线性函数\n4.5损失函数\n4.6正则化与丢弃法\n4.7相似和距离层\n4.8嵌入层\n第5章神经网络训练\n5.1计算图的抽象概念\n5.1.1前向计算\n5.1.2反向计算（导数、反向传播）\n5.1.3软件\n5.1.4实现流程\n5.1.5网络构成\n5.2实践经验\n5.2.1优化算法的选择\n5.2.2初始化\n5.2.3重启与集成\n5.2.4梯度消失与梯度爆炸\n5.2.5饱和神经元与死神经元\n5.2.6随机打乱\n5.2.7学习率\n5.2.8minibatch\n第二部分处理自然语言数据\n第6章文本特征构造\n6.1NLP分类问题中的拓扑结构\n6.2NLP问题中的特征\n6.2.1直接可观测特征\n6.2.2可推断的语言学特征\n6.2.3核心特征与组合特征\n6.2.4n元组特征\n6.2.5分布特征\n第7章NLP特征的案例分析\n7.1文本分类：语言识别\n7.2文本分类：主题分类\n7.3文本分类：作者归属\n7.4上下文中的单词：词性标注\n7.5上下文中的单词：命名实体识别\n7.6上下文中单词的语言特征：介词词义消歧\n7.7上下文中单词的关系：弧分解分析\n第8章从文本特征到输入\n8.1编码分类特征\n8.1.1独热编码\n8.1.2稠密编码（特征嵌入）\n8.1.3稠密向量与独热表示\n8.2组合稠密向量\n8.2.1基于窗口的特征\n8.2.2可变特征数目：连续词袋\n8.3独热和稠密向量间的关系\n8.4杂项\n8.4.1距离与位置特征\n8.4.2补齐、未登录词和词丢弃\n8.4.3特征组合\n8.4.4向量共享\n8.4.5维度\n8.4.6嵌入的词表\n8.4.7网络的输出\n8.5例子：词性标注\n8.6例子：弧分解分析\n第9章语言模型\n9.1语言模型任务\n9.2语言模型评估：困惑度\n9.3语言模型的传统方法\n9.3.1延伸阅读\n9.3.2传统语言模型的限制\n9.4神经语言模型\n9.5使用语言模型进行生成\n9.6副产品：词的表示\n第10章预训练的词表示\n10.1随机初始化\n10.2有监督的特定任务的预训练\n10.3无监督的预训练\n10.4词嵌入算法\n10.4.1分布式假设和词表示\n10.4.2从神经语言模型到分布式表示\n10.4.3词语联系\n10.4.4其他算法\n10.5上下文的选择\n10.5.1窗口方法\n10.5.2句子、段落或文档\n10.5.3句法窗口\n10.5.4多语种\n10.5.5基于字符级别和子词的表示\n10.6处理多字单元和字变形\n10.7分布式方法的限制\n第11章使用词嵌入\n11.1词向量的获取\n11.2词的相似度\n11.3词聚类\n11.4寻找相似词\n11.5同中选异\n11.6短文档相似度\n11.7词的类比\n11.8改装和映射\n11.9实用性和陷阱\n第12章案例分析:一种用于句子意义推理的前馈结构\n12.1自然语言推理与 SNLI数据集\n12.2文本相似网络\n第三部分特殊的结构\n第13章n元语法探测器：卷积神经网络\n13.1基础卷积池化\n13.1.1文本上的一维卷积\n13.1.2向量池化\n13.1.3变体\n13.2其他选择：特征哈希\n13.3层次化卷积\n第14章循环神经网络：序列和栈建模\n14.1RNN抽象描述\n14.2RNN的训练\n14.3RNN常见使用模式\n14.3.1接收器\n14.3.2编码器\n14.3.3传感器\n14.4双向RNN\n14.5堆叠RNN\n14.6用于表示栈的RNN\n14.7文献阅读的注意事项\n第15章实际的循环神经网络结构\n15.1作为RNN的CBOW\n15.2简单RNN\n15.3门结构\n15.3.1长短期记忆网络\n15.3.2门限循环单元\n15.4其他变体\n15.5应用到RNN的丢弃机制\n第16章通过循环网络建模\n16.1接收器\n16.1.1情感分类器\n16.1.2主谓一致语法检查\n16.2作为特征提取器的RNN\n16.2.1词性标注\n16.2.2RNNCNN文本分类\n16.2.3弧分解依存句法分析\n第17章条件生成\n17.1RNN生成器\n17.2条件生成（编码器）\n17.2.1序列到序列模型\n17.2.2应用\n17.2.3其他条件上下文\n17.3无监督的句子相似性\n17.4结合注意力机制的条件生成\n17.4.1计算复杂性\n17.4.2可解释性\n17.5自然语言处理中基于注意力机制的模型\n17.5.1机器翻译\n17.5.2形态屈折\n17.5.3句法分析\n第四部分其他主题\n第18章用递归神经网络对树建模\n18.1形式化定义\n18.2扩展和变体\n18.3递归神经网络的训练\n18.4一种简单的替代——线性化树\n18.5前景\n第19章结构化输出预测\n19.1基于搜索的结构化预测\n19.1.1基于线性模型的结构化预测\n19.1.2非线性结构化预测\n19.1.3概率目标函数（CRF）\n19.1.4近似搜索\n19.1.5重排序\n19.1.6参考阅读\n19.2贪心结构化预测\n19.3条件生成与结构化输出预测\n19.4实例\n19.4.1基于搜索的结构化预测：一阶依存句法分析\n19.4.2基于NeuralCRF的命名实体识别\n19.4.3基于柱搜索的NERCRF近似\n第20章级联、多任务与半监督学习\n20.1模型级联\n20.2多任务学习\n20.2.1多任务设置下的训练\n20.2.2选择性共享\n20.2.3作为多任务学习的词嵌入预训练\n20.2.4条件生成中的多任务学习\n20.2.5作为正则的多任务学习\n20.2.6注意事项\n20.3半监督学习\n20.4实例\n20.4.1眼动预测与句子压缩\n20.4.2弧标注与句法分析\n20.4.3介词词义消歧与介词翻译预测\n20.4.4条件生成：多语言机器翻译、句法分析以及图像描述生成\n20.5前景\n第21章结论\n21.1我们学到了什么\n21.2未来的挑战\n参考文献","pages":"255","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29782015.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29782015.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29782015.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30236842\/","id":"30236842","publisher":"机械工业出版社","isbn10":"7111593731","isbn13":"9787111593737","title":"基于深度学习的自然语言处理","url":"https:\/\/api.douban.com\/v2\/book\/30236842","alt_title":"Neural Network Methods in Natural Language Processing","author_intro":"Yoav Goldberg现就职于以色列巴伊兰大学，是自然语言处理领域一位非常活跃的青年学者。Goldberg博士期间的主要研究方向为依存句法分析，随着深度学习的兴起，他也将研究兴趣转移至此，并成功地将该技术应用于依存句法分析等任务。与此同时，他在理论上对词嵌入和传统矩阵分解方法的对比分析也具有广泛的影响力。另外，他还是DyNet深度学习库的主要开发者之一。","summary":"本书重点介绍了神经网络模型在自然语言处理中的应用。首先介绍有监督的机器学习和前馈神经网络的基本知识，如何将机器学习方法应用在自然语言处理中，以及词向量表示（而不是符号表示）的应用。然后介绍更多专门的神经网络结构，包括一维卷积神经网络、循环神经网络、条件生成模型和基于注意力的模型。后，讨论树形网络、结构化预测以及多任务学习的前景。","series":{"id":"42552","title":"智能科学与技术丛书"},"price":"69"},{"rating":{"max":10,"numRaters":38,"average":"8.0","min":0},"subtitle":"","author":["魏秀参"],"pubdate":"2018-11","tags":[{"count":25,"name":"深度学习","title":"深度学习"},{"count":20,"name":"机器学习","title":"机器学习"},{"count":19,"name":"卷积神经网络","title":"卷积神经网络"},{"count":16,"name":"计算机视觉","title":"计算机视觉"},{"count":13,"name":"人工智能","title":"人工智能"},{"count":4,"name":"计算机科学","title":"计算机科学"},{"count":4,"name":"AI","title":"AI"},{"count":3,"name":"Python","title":"Python"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29925585.jpg","binding":"平装","translator":[],"catalog":"第一部分绪论1\n0.1 引言  . 2\n0.2 什么是深度学习  3\n0.3 深度学习的前世今生  . 6\n第二部分基础理论篇9\n1 卷积神经网络基础知识10\n1.1 发展历程  11\n1.2 基本结构  13\n1.3 前馈运算  16\n1.4 反馈运算  16\n1.5 小结  . 19\n2 卷积神经网络基本部件21\n2.1 “端到端”思想  21\n2.2 网络符号定义  . 23\n2.3 卷积层  . 24\n2.3.1 什么是卷积  24\n2.3.2 卷积操作的作用  27\n2.4 汇合层  . 28\n2.4.1 什么是汇合  29\n2.4.2 汇合操作的作用  30\n2.5 激活函数  31\n2.6 全连接层  33\n2.7 目标函数  34\n2.8 小结  . 34\n3 卷积神经网络经典结构35\n3.1 CNN 网络结构中的重要概念  . 35\n3.1.1 感受野  . 35\n3.1.2 分布式表示  37\n3.1.3 深度特征的层次性  39\n3.2 经典网络案例分析  . 42\n3.2.1 Alex-Net 网络模型  . 42\n3.2.2 VGG-Nets 网络模型  46\n3.2.3 Network-In-Network  48\n3.2.4 残差网络模型  . 49\n3.3 小结  . 54\n4 卷积神经网络的压缩56\n4.1 低秩近似  58\n4.2 剪枝与稀疏约束  60\n4.3 参数量化  64\n4.4 二值网络  68\n4.5 知识蒸馏  71\n4.6 紧凑的网络结构  74\n4.7 小结  . 76\n第三部分实践应用篇77\n5 数据扩充78\n5.1 简单的数据扩充方式  . 78\n5.2 特殊的数据扩充方式  . 80\n5.2.1 Fancy PCA  . 80\n5.2.2 监督式数据扩充  80\n5.3 小结  . 82\n6 数据预处理83\n7 网络参数初始化85\n7.1 全零初始化  . 86\n7.2 随机初始化  . 86\n7.3 其他初始化方法  90\n7.4 小结  . 90\n8 激活函数91\n8.1 Sigmoid 型函数  . 92\n8.2 tanh(x) 型函数  . 93\n8.3 修正线性单元（ReLU）  93\n8.4 Leaky ReLU  . 94\n8.5 参数化ReLU  95\n8.6 随机化ReLU  97\n8.7 指数化线性单元（ELU）  . 98\n8.8 小结  . 99\n9 目标函数100\n9.1 分类任务的目标函数  . 100\n9.1.1 交叉熵损失函数  101\n9.1.2 合页损失函数  . 101\n9.1.3 坡道损失函数  . 101\n9.1.4 大间隔交叉熵损失函数  103\n9.1.5 中心损失函数  . 105\n9.2 回归任务的目标函数  . 107\n9.2.1 ℓ1 损失函数  108\n9.2.2 ℓ2 损失函数  108\n9.2.3 Tukey’s biweight 损失函数  109\n9.3 其他任务的目标函数  . 109\n9.4 小结  . 111\n10 网络正则化113\n10.1 ℓ2 正则化  114\n10.2 ℓ1 正则化  115\n10.3 最大范数约束  . 115\n10.4 随机失活  116\n10.5 验证集的使用  . 118\n10.6 小结  . 119\n11 超参数设定和网络训练120\n11.1 网络超参数设定  120\n11.1.1 输入数据像素大小  120\n11.1.2 卷积层参数的设定  121\n11.1.3 汇合层参数的设定  122\n11.2 训练技巧  123\n11.2.1 训练数据随机打乱  123\n11.2.2 学习率的设定  . 123\n11.2.3 批规范化操作  . 125\n11.2.4 网络模型优化算法选择  127\n11.2.5 微调神经网络  . 132\n11.3 小结  . 133\n12 不平衡样本的处理135\n12.1 数据层面处理方法  . 136\n12.1.1 数据重采样  136\n12.1.2 类别平衡采样  . 137\n12.2 算法层面处理方法  . 138\n12.2.1 代价敏感方法  . 139\n12.2.2 代价敏感法中权重的指定方式  140\n12.3 小结  . 142\n13 模型集成方法143\n13.1 数据层面的集成方法  . 143\n13.1.1 测试阶段数据扩充  143\n13.1.2 “简易集成”法  144\n13.2 模型层面的集成方法  . 144\n13.2.1 单模型集成  144\n13.2.2 多模型集成  146\n13.3 小结  . 149\n14 深度学习开源工具简介151\n14.1 常用框架对比  . 151\n14.2 常用框架的各自特点  . 153\n14.2.1 Caffe  153\n14.2.2 Deeplearning4j  . 153\n14.2.3 Keras  154\n14.2.4 MXNet  . 155\n14.2.5 MatConvNet  155\n14.2.6 TensorFlow  . 155\n14.2.7 Theano  . 156\n14.2.8 Torch  157\nA 向量、矩阵及其基本运算158\nB 随机梯度下降162\nC 链式法则165\n参考文献167\n索引181","pages":"200","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29925585.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29925585.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29925585.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30381203\/","id":"30381203","publisher":"电子工业出版社","isbn10":"7121345285","isbn13":"9787121345289","title":"解析深度学习：卷积神经网络原理与视觉实践","url":"https:\/\/api.douban.com\/v2\/book\/30381203","alt_title":"","author_intro":"魏秀参\n旷视科技（Face++）南京研究院负责人。南京大学LAMDA研究所博士，主要研究领域为计算机视觉和机器学习。在相关领域重要国际期刊和国际会议发表论文十余篇，并两次获得国际计算机视觉相关竞赛冠、亚军。曾获CVPR 2017最佳审稿人、南京大学博士生校长特别奖学金等荣誉，担任ICCV、CVPR、ECCV、NIPS、IJCAI、AAAI等国际会议PC member。（个人自媒体：知乎“魏秀参”，新浪微博“Wilson_NJUer”）","summary":"深度学习，特别是深度卷积神经网络是人工智能的重要分支领域，卷积神经网络技术也被广泛应用于各种现实场景，在许多问题上都取得了超越人类智能的结果。本书作为该领域的入门书籍，在内容上涵盖深度卷积神经网络的基础知识和实践应用两大方面。《解析深度学习：卷积神经网络原理与视觉实践》共14 章，分为三个部分：第一部分为绪论；第二部分 （第1～4 章）介绍卷积神经网络的基础知识、基本部件、经典结构和模型压缩等基础理论内容；第三部分（第5～14 章）介绍深度卷积神经网络自数据准备开始，到模型参数初始化、不同网络部件的选择、网络配置、网络模型训练、不平衡数据处理，最终到模型集成等实践应用技巧和经验。《解析深度学习：卷积神经网络原理与视觉实践》并不是一本编程类书籍，而是希望通过“基础知识”和“实践技巧”两方面使读者从更高维度了解、掌握并成功构建针对自身应用问题的深度卷积神经网络。\n《解析深度学习：卷积神经网络原理与视觉实践》可作为深度学习和卷积神经网络爱好者的入门书籍，也可供没有机器学习背景但希望能快速掌握该方面知识并将其应用于实际问题的各行从业者阅读参考。","price":"79"},{"rating":{"max":10,"numRaters":72,"average":"7.1","min":0},"subtitle":"","author":["高扬"],"pubdate":"2017-7-31","tags":[{"count":67,"name":"深度学习","title":"深度学习"},{"count":37,"name":"人工智能","title":"人工智能"},{"count":26,"name":"机器学习","title":"机器学习"},{"count":26,"name":"TensorFlow","title":"TensorFlow"},{"count":10,"name":"编程","title":"编程"},{"count":10,"name":"AI","title":"AI"},{"count":6,"name":"AI基础","title":"AI基础"},{"count":5,"name":"机器学习\/深度学习\/TensorFlow\/Caffe","title":"机器学习\/深度学习\/TensorFlow\/Caffe"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29510320.jpg","binding":"平装","translator":[],"catalog":"","pages":"304","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29510320.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29510320.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29510320.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27105581\/","id":"27105581","publisher":"机械工业出版社","isbn10":"7111574575","isbn13":"9787111574576","title":"白话深度学习与TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/27105581","alt_title":"","author_intro":"","summary":"本书基本独立成册，适用于零基础的初学者。\n基础篇（第1～3章），讲解了机器学习、深度学习与实践的上下文知识，如基本的机器学习与深度学习算法，TensorFlow框架的安全与配置，简单的深度学习实践。该篇是阅读和实践的基石。\n原理与实践篇（第4～8章），介绍“老牌”的深度学习网络的数学原理和工程实现原理，尤其是第4章，如果能基本读懂，后面的网络实现层面的问题基本都可以迎刃而解。涵盖BP网络、CNN、RNN的结构、思路、训练与使用，以及一些常见的综合性问题。该篇是学习深度学习的重点和难点，作者通过大量示例、推理与实现，帮读者*大化降低学习曲线。\n扩展篇（第9～13章），介绍一些网络的变种和一些较新的网络特性，涵盖深度残差网络、受限玻尔兹曼机、强化学习、对抗学习，这是读者进一步学习与实践思路的钥匙。最后给出了一些有趣的深度学习应用：人脸识别、作诗姬、大师风图像处理，有趣又有用。","price":"69.00元"},{"rating":{"max":10,"numRaters":116,"average":"5.8","min":0},"subtitle":"","author":["吴岸城"],"pubdate":"2016-6","tags":[{"count":45,"name":"深度学习","title":"深度学习"},{"count":44,"name":"神经网络","title":"神经网络"},{"count":30,"name":"机器学习","title":"机器学习"},{"count":19,"name":"人工智能","title":"人工智能"},{"count":12,"name":"科普","title":"科普"},{"count":10,"name":"入门和科普","title":"入门和科普"},{"count":9,"name":"计算机","title":"计算机"},{"count":5,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28827659.jpg","binding":"平装","translator":[],"catalog":"第0章　写在前面：神经网络的历史 1\n第1章　神经网络是个什么东西 13\n1.1　买橙子和机器学习 13\n1.1.1　规则列表 14\n1.1.2　机器学习 15\n1.2　怎么定义神经网络 16\n1.3　先来看看大脑如何学习 16\n1.3.1　信息输入 17\n1.3.2　模式加工 17\n1.3.3　动作输出 18\n1.4　生物意义上的神经元 19\n1.4.1　神经元是如何工作的 19\n1.4.2　组成神经网络 22\n1.5　大脑如何解决现实生活中的分类问题 24\n第2章　构造神经网络 26\n2.1　构造一个神经元 26\n2.2　感知机 30\n2.3　感知机的学习 32\n2.4　用代码实现一个感知机 34\n2.4.1　Neuroph：一个基于Java的神经网络框架 34\n2.4.2　代码实现感知机 37\n2.4.3　感知机学习一个简单逻辑运算 39\n2.4.4　XOR问题 42\n2.5　构造一个神经网络 44\n2.5.1　线性不可分 45\n2.5.2　解决XOR问题（解决线性不可分） 49\n2.5.3　XOR问题的代码实现 51\n2.6　解决一些实际问题 54\n2.6.1　识别动物 54\n2.6.2　我是预测大师 59\n第3章　深度学习是个什么东西 66\n3.1　机器学习 67\n3.2　特征 75\n3.2.1　特征粒度 75\n3.2.2　提取浅层特征 76\n3.2.3　结构性特征 78\n3.3　浅层学习和深度学习 81\n3.4　深度学习和神经网络 83\n3.5　如何训练神经网络 84\n3.5.1　BP算法：神经网络训练 84\n3.5.2　BP算法的问题 85\n3.6　总结深度学习及训练过程 86\n第4章　深度学习的常用方法 89\n4.1　模拟大脑的学习和重构 90\n4.1.1　灰度图像 91\n4.1.2　流行感冒 92\n4.1.3　看看如何编解码 93\n4.1.4　如何训练 95\n4.1.5　有监督微调 97\n4.2　快速感知：稀疏编码（Sparse Coding） 98\n4.3　栈式自编码器 100\n4.4　解决概率分布问题：限制波尔兹曼机 102\n4.4.1　生成模型和概率模型 102\n4.4.2　能量模型 107\n4.4.3　RBM的基本概念 109\n4.4.4　再看流行感冒的例子 111\n4.5　DBN 112\n4.6　卷积神经网络 114\n4.6.1　卷积神经网络的结构 116\n4.6.2　关于参数减少与权值共享 120\n4.6.3 举个典型的例子：图片内容识别 124\n4.7　不会忘记你：循环神经网络 131\n4.7.1　什么是RNN 131\n4.7.2　LSTM网络 136\n4.7.3　LSTM变体 141\n4.7.4　结论 143\n4.8　你是我的眼：利用稀疏编码器找图像的基本单位 143\n4.9　你是我的眼（续） 150\n4.10　使用深度信念网搞定花分类 160\n第5章　深度学习的胜利：AlphaGo 169\n5.1　AI如何玩棋类游戏 169\n5.2　围棋的复杂性 171\n5.3　AlphaGo的主要原理 173\n5.3.1　策略网络 174\n5.3.2　MCTS拯救了围棋算法 176\n5.3.3　强化学习：\"周伯通，左右互搏\" 179\n5.3.4　估值网络 181\n5.3.5　将所有组合到一起：树搜索 182\n5.3.6　AlphaGo有多好 185\n5.3.7　总结 187\n5.4　重要的技术进步 189\n5.5　一些可以改进的地方 190\n5.6　未来 192\n第6章　两个重要的概念 194\n6.1　迁移学习 194\n6.2　概率图模型 197\n6.2.1　贝叶斯的网络结构 201\n6.2.2　概率图分类 204\n6.2.3　如何应用PGM 208\n第7章　杂项 210\n7.1　如何为不同类型的问题选择模型 210\n7.2　我们如何学习\"深度学习\" 211\n7.3　如何理解机器学习和深度学习的差异 212\n7.4　大规模学习（Large Scale Learning）和并行计算 214\n7.5　如果喜欢应用领域，可以考虑以下几种应用 215\n7.6　类脑：人工智能的终极目标 216\n参考文献 218\n术语 220","pages":"232","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28827659.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28827659.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28827659.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26820803\/","id":"26820803","publisher":"电子工业出版社","isbn10":"7121288699","isbn13":"9787121288692","title":"神经网络与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/26820803","alt_title":"","author_intro":"","summary":"随着AlphaGo与李世石大战的落幕，人工智能成为话题焦点。AlphaGo背后的工作原理\"深度学习\"也跳入大众的视野。什么是深度学习，什么是神经网络，为何一段程序在精密的围棋大赛中可以大获全胜？人工智终将会取代人类智慧吗？\n本书结合日常生活中的寻常小事，生动形象地阐述了神经网络与深度学习的基本概念、原理和实践，案例丰富，深入浅出。对于正在进入人工智能时代的我们，这些内容无疑可以帮助我们更好地理解人工智能的原理，丰富我们对人类自身的认识，并启发我们对人机智能之争更深一层的思考与探索。\n《神经网络与深度学习》是一本介绍神经网络和深度学习算法基本原理及相关实例的书籍，它不是教科书，作者已尽量把公式减少到最少，以适应绝大部分人的阅读基础和知识储备。《神经网络与深度学习》涵盖了神经网络的研究历史、基础原理、深度学习中的自编码器、深度信念网络、卷积神经网络等，这些算法都已在很多行业发挥了价值。\n《神经网络与深度学习》适合有志于从事深度学习行业的，或想了解深度学习到底是什么的，或是有一定机器学习基础的朋友阅读。","series":{"id":"41172","title":"博文视点AI系列"},"price":"59"},{"rating":{"max":10,"numRaters":36,"average":"7.2","min":0},"subtitle":"","author":["[日] 山下隆义"],"pubdate":"2018-5","tags":[{"count":34,"name":"深度学习","title":"深度学习"},{"count":26,"name":"机器学习","title":"机器学习"},{"count":15,"name":"计算机","title":"计算机"},{"count":7,"name":"日本","title":"日本"},{"count":6,"name":"科普","title":"科普"},{"count":5,"name":"计算科学","title":"计算科学"},{"count":5,"name":"计算机科普","title":"计算机科普"},{"count":5,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29767846.jpg","binding":"平装","translator":["张弥"],"catalog":"第1章　绪论\n1.1　深度学习与机器学习　　2\n1.2　深度学习的发展历程　　3\n1.3　为什么是深度学习　　6\n1.4　什么是深度学习　　7\n1.5　本书结构　　9\n第2章　神经网络\n2.1　神经网络的历史　　12\n2.2　M-P模型　　14\n2.3　感知器　　16\n2.4　多层感知器　　18\n2.5　误差反向传播算法　　19\n2.6　误差函数和激活函数　　28\n2.7　似然函数　　30\n2.8　随机梯度下降法　　31\n2.9　学习率　　32\n2.10　小结　　33\n第3章　卷积神经网络\n3.1　卷积神经网络的结构　　36\n3.2　卷积层　　38\n3.3　池化层　　39\n3.4　全连接层　　40\n3.5　输出层　　41\n3.6　神经网络的训练方法　　41\n3.7　小结　　48\n第4章　受限玻尔兹曼机\n4.1　Hopfield 神经网络　　50\n4.2　玻尔兹曼机　　55\n4.3　受限玻尔兹曼机　　59\n4.4　对比散度算法　　61\n4.5　深度信念网络　　64\n4.6　小结　　66\n第5章　自编码器\n5.1　自编码器　　68\n5.2　降噪自编码器　　71\n5.3　稀疏自编码器　　73\n5.4　栈式自编码器　　76\n5.5　在预训练中的应用　　77\n5.6　小结　　78\n第6章　提高泛化能力的方法\n6.1　训练样本　　80\n6.2　预处理　　88\n6.3　激活函数　　92\n6.4　Dropout　　94\n6.5　DropConnect　　96\n6.6　小结　　98\n第7章　深度学习工具\n7.1　深度学习开发环境　　100\n7.2　Theano　　100\n7.3　Pylearn2　　108\n7.4　Caffe　　118\n7.5　训练系统——DIGITS137\n7.6　Chainer　　145\n7.7　TensorFlow　　160\n7.8　小结　　176\n第8章　深度学习的现在和未来\n8.1　深度学习的应用案例178\n8.2　深度学习的未来　　195\n8.3　小结　　197\n参考文献　　198\n作者介绍　　207","pages":"214","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29767846.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29767846.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29767846.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30221593\/","id":"30221593","publisher":"人民邮电出版社","isbn10":"7115480249","isbn13":"9787115480248","title":"图解深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30221593","alt_title":"","author_intro":"作者简介：\n山下隆义\n1978年出生于日本神户，2002年修完博士前期课程，并于当年入职欧姆龙股份有限公司，主要从事快速人脸图像检测相关的软件研究和开发。2011年在日本中部大学研究生院工学研究科修完博士后期课程，获得工学博士学位。2014年开始担任中部大学工学院信息工程系讲师。目前从事动画处理、模式识别和机器学习相关的研究。曾多次荣获日本深度学习研究相关奖项，并在多个相关研讨会上担任讲师。\n译者简介：\n张弥（译者）\n毕业于大连外国语大学日本语学院。现就职于某日本大型跨国公司，从事技术翻译工作，具有丰富的软件开发和医学翻译经验。喜欢挑战新事物，乐于学习新知识和接触新领域。","summary":"本书从深度学习的发展历程讲起，以丰富的图例从理论和实践两个层面介绍了深度学习的各种方法，以及深度学习在图像识别等领域的应用案例。内容涉及神经网络、卷积神经网络、受限玻尔兹曼机、自编码器、泛化能力的提高等。此外，还介绍了包括Theano、Pylearn2、Caffe、DIGITS、Chainer 和TensorFlow 在内的深度学习工具的安装和使用方法。\n本书图例丰富，清晰直观，适合所有对深度学习感兴趣的读者阅读。","series":{"id":"34135","title":"图解入门系列"},"price":"59.00元"},{"rating":{"max":10,"numRaters":27,"average":"4.3","min":0},"subtitle":"Caffe之经典模型详解与实战","author":["乐毅","王斌"],"pubdate":"2016-12","tags":[{"count":11,"name":"深度学习","title":"深度学习"},{"count":9,"name":"机器学习","title":"机器学习"},{"count":4,"name":"Caffe","title":"Caffe"},{"count":3,"name":"计算机视觉","title":"计算机视觉"},{"count":3,"name":"图像处理","title":"图像处理"},{"count":2,"name":"神经网络","title":"神经网络"},{"count":2,"name":"入门和科普","title":"入门和科普"},{"count":1,"name":"科学","title":"科学"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29144064.jpg","binding":"平装","translator":[],"catalog":"第1章　绪论   1\n1.1  引言   1\n1.2  人工智能的发展历程   2\n1.3  机器学习及相关技术   4\n1.3.1  学习形式分类   4\n1.3.2  学习方法分类   5\n1.3.3  机器学习的相关技术   7\n1.4  国内外研究现状   8\n1.4.1  国外研究现状   8\n1.4.2  国内研究现状   9\n第2章　深度学习   11\n2.1  神经网络模型   11\n2.1.1  人脑视觉机理   11\n2.1.2  生物神经元   13\n2.1.3  人工神经网络   15\n2.2  BP神经网络   18\n2.2.1  BP神经元   18\n2.2.2  BP神经网络构成   19\n2.2.3  正向传播   21\n2.2.4  反向传播   21\n2.3  卷积神经网络   24\n2.3.1  卷积神经网络的历史   25\n2.3.2  卷积神经网络的网络结构   26\n2.3.3  局部感知   27\n2.3.4  参数共享   28\n2.3.5  多卷积核   28\n2.3.6  池化（Pooling）   29\n2.4  深度学习框架   30\n2.4.1  Caffe   30\n2.4.2  Torch   31\n2.4.3  Keras   32\n2.4.4  MXNet   32\n2.4.5  TensorFlow   33\n2.4.6  CNTK   33\n2.4.7  Theano   34\n第3章　Caffe简介及其安装配置   36\n3.1  Caffe是什么   36\n3.1.1  Caffe的特点   38\n3.1.2  Caffe的架构   38\n3.2  Caffe的安装环境   39\n3.2.1  Caffe的硬件环境   39\n3.2.2  Caffe的软件环境   43\n3.2.3  Caffe的依赖库   44\n3.2.4  Caffe开发环境的安装   46\n3.3  Caffe接口   52\n3.3.1  Caffe Python接口   52\n3.3.2  Caffe MATLAB接口   55\n3.3.3  Caffe命令行接口   56\n第4章　Caffe网络定义   58\n4.1  Caffe模型要素   58\n4.1.1  网络模型   58\n4.1.2  参数配置   62\n4.2  Google Protobuf结构化数据   63\n4.3  Caffe数据库   65\n4.3.1  LevelDB   65\n4.3.2  LMDB   66\n4.3.3  HDF5   66\n4.4  Caffe Net   66\n4.5  Caffe Blob   68\n4.6  Caffe Layer   70\n4.6.1  Data Layers   71\n4.6.2  Convolution Layers   75\n4.6.3  Pooling Layers   76\n4.6.4  InnerProduct Layers   77\n4.6.5  ReLU Layers   78\n4.6.6  Sigmoid Layers   79\n4.6.7  LRN Layers   79\n4.6.8  Dropout Layers   80\n4.6.9  SoftmaxWithLoss Layers   80\n4.6.10  Softmax Layers   81\n4.6.11  Accuracy Layers   81\n4.7  Caffe Solver   82\nSolver方法   83\n第5章　LeNet模型   88\n5.1  LeNet模型简介   88\n5.2  LeNet模型解读   89\n5.3  Caffe环境LeNet模型   91\n5.3.1  mnist实例详解   91\n5.3.2  mnist手写测试   103\n5.3.3  mnist样本字库的图片转换   106\n第6章　AlexNet模型   107\n6.1  AlexNet模型介绍   107\n6.2  AlexNet模型解读   108\n6.3  AlexNet模型特点   111\n6.4  Caffe环境AlexNet模型训练   112\n6.4.1  数据准备   112\n6.4.2  其他支持文件   113\n6.4.3  图片预处理   113\n6.4.4  ImageNet数据集介绍   113\n6.4.5  ImageNet图片介绍   115\n6.4.6  ImageNet模型训练   115\n6.4.7  Caffe的AlexNet模型与论文的不同   124\n6.4.8  ImageNet模型测试   124\n第7章　GoogLeNet模型   126\n7.1  GoogLeNet模型简介   126\n7.1.1  背景和动机   127\n7.1.2  Inception结构   127\n7.2  GoogLeNet模型解读   129\n7.2.1  GoogLeNet模型结构   129\n7.2.2  GoogLeNet模型特点   134\n7.3  GoogLeNet模型的Caffe实现   135\n第8章　VGGNet模型   146\n8.1  VGGNet网络模型   146\n8.1.1  VGGNet模型介绍   146\n8.1.2  VGGNet模型特点   147\n8.1.3  VGGNet模型解读   147\n8.2  VGGNet网络训练   149\n8.2.1  VGGNet训练参数设置   149\n8.2.2  Multi-Scale训练   149\n8.2.3  测试   150\n8.2.4  部署   150\n8.3  VGGNet模型分类实验   150\n8.3.1  Single-scale对比   150\n8.3.2  Multi-scale对比   151\n8.3.3  模型融合   152\n8.4  VGGNet网络结构   153\n第9章　Siamese模型   158\n9.1  Siamese网络模型   159\n9.1.1  Siamese模型原理   159\n9.1.2  Siamese模型实现   160\n9.2  Siamese网络训练   165\n9.2.1  数据准备   165\n9.2.2  生成side   165\n9.2.3  对比损失函数   166\n9.2.4  定义solver   166\n9.2.5  网络训练   166\n第10章　SqueezeNet模型   168\n10.1  SqueezeNet网络模型   168\n10.1.1  SqueezeNet模型原理   168\n10.1.2  Fire Module   169\n10.1.3  SqueezeNet模型结构   170\n10.1.4  SqueezeNet模型特点   171\n10.2  SqueezeNet网络实现   172\n第11章　FCN模型   177\n11.1  FCN模型简介   177\n11.2  FCN的特点和使用场景   178\n11.3  Caffe FCN解读   179\n11.3.1  FCN模型训练准备   180\n11.3.1  FCN模型训练   183\n第12章　R-CNN模型   196\n12.1  R-CNN模型简介   196\n12.2  R-CNN的特点和使用场景   197\n12.3  Caffe R-CNN解读   198\n12.3.1  R-CNN模型训练准备   198\n12.3.2  R-CNN模型训练   201\n第13章　Fast-RCNN模型   217\n13.1  Fast-RCNN模型简介   217\n13.2  Fast-RCNN的特点和使用场景   218\n13.3  Caffe Fast-RCNN解读   220\n13.3.1  Fast-RCNN模型训练准备   220\n13.3.2  Fast-RCNN模型训练   222\n第14章　Faster-RCNN模型   239\n14.1  Faster-RCNN模型简介   239\n14.2  Faster-RCNN的特点和使用场景   241\n14.3  Caffe Faster-RCNN解读   242\n14.3.1  Faster-RCNN模型训练准备   242\n14.3.2  Faster-RCNN模型训练   244\n第15章　SSD模型   264\n15.1  SSD模型简介   264\n15.2  SSD的特点和使用场景   266\n15.3  Caffe SSD解读   267\n15.3.1  SSD模型训练准备   267\n15.3.2  SSD模型训练   268\n第16章　Kaggle项目实践：人脸特征检测   290\n16.1  项目简介   290\n16.2  赛题和数据   291\n16.3  Caffe训练和测试数据库   293\n16.3.1  数据库生成   293\n16.3.2  网络对比   295\n16.3.3  网络一   296\n16.3.4  网络二   300\n16.3.5  Python人脸特征预测程序   306\n第17章　Kaggle项目实践：猫狗分类检测   311\n17.1  项目简介   311\n17.2  赛题和数据   312\n17.3  Caffe训练和测试数据库   312\n17.3.1  数据库生成   312\n17.3.2  Caffe实现   316\n17.3.3  CatdogNet训练   328\n17.3.4  CatdogNet模型验证   332","pages":"344","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29144064.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29144064.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29144064.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26912214\/","id":"26912214","publisher":"电子工业出版社","isbn10":"7121301180","isbn13":"9787121301186","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/26912214","alt_title":"","author_intro":"乐毅：计算机专业硕士，现任职于某数据通信公司，高级系统工程师。负责公司深度学习技术领域的应用及相关项目，对深度学习及大数据深度挖掘具有浓厚的兴趣。擅长Caffe等深度学习框架及网络模型应用。王斌：通信与信息系统硕士，现任职于某数据通信公司，高级系统工程师。多年致力于深度学习技术的前沿研究与应用，对Caffe等深度学习框架在图像识别领域有深刻理解，承担公司多项与机器学习相关的研究工作。","summary":"《深度学习——Caffe之经典模型详解与实战》首先介绍了深度学习相关的理论和主流的深度学习框架，然后从Caffe深度学习框架为切入点，介绍了Caffe的安装、配置、编译和接口等运行环境，剖析Caffe网络模型的构成要素和常用的层类型和Solver方法。通过LeNet网络模型的Mnist手写实例介绍其样本训练和识别过程，进一步详细解读了AlexNet、VGGNet、GoogLeNet、Siamese和SqueezeNet网络模型，并给出了这些模型基于Caffe的训练实战方法。然后，《深度学习——Caffe之经典模型详解与实战》解读了利用深度学习进行目标定位的经典网络模型：FCN、R-CNN、Fast-RCNN、Faster-RCNN和SSD，并进行目标定位Caffe实战。《深度学习——Caffe之经典模型详解与实战》的最后，从著名的Kaggle网站引入了两个经典的实战项目，并进行了有针对性的原始数据分析、网络模型设计和Caffe训练策略实践，以求带给读者从问题提出到利用Caffe求解的完整工程经历，从而使读者能尽快掌握Caffe框架的使用技巧和实战经验。\n针对Caffe和深度学习领域的初学者，《深度学习——Caffe之经典模型详解与实战》是一本不可多得的参考资料。《深度学习——Caffe之经典模型详解与实战》的内容既有易懂的理论背景，又有丰富的应用实践，是深度学习初学者的指导手册，也可作为深度学习相关领域工程师和爱好者的参考用书。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":14,"average":"7.0","min":0},"subtitle":"","author":["（美）Eric Jensen"],"pubdate":"2010-5","tags":[{"count":27,"name":"学习方法","title":"学习方法"},{"count":15,"name":"学习","title":"学习"},{"count":12,"name":"心理学","title":"心理学"},{"count":10,"name":"教学方法","title":"教学方法"},{"count":9,"name":"教育","title":"教育"},{"count":8,"name":"深度学习","title":"深度学习"},{"count":6,"name":"学习法","title":"学习法"},{"count":5,"name":"學習","title":"學習"}],"origin_title":"Deeper Learning: 7 Powerful Strategies for In-Depth and Longer-Lasting Learning","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6161403.jpg","binding":"","translator":["温暖"],"catalog":"目录\n前言 \/ 1\n致谢 \/ 3\n作者简介 \/ 5\n引言 \/ 1\n1? 揭幕:探索深度学习路线 \/ 1\n终极学习目标 \/ 5\n学习的种类 \/ 7\n深度学习路线(DELC) \/ 11\n第一部分:准备学习 \/ 23\n2? 准备深度学习:DELC步骤1—3 \/ 25\nDELC步骤1:设计标准与课程 \/ 28\nDELC步骤2:预评估 \/ 33\nDELC步骤3:营造积极的学习文化 \/ 42\n结语 \/ 69\n3? 预备、激活先期知识与获取新知识:DELC步骤4与步骤5 \/ 80\nDELC步骤4:预备与激活先期知识 \/ 82\nDELC步骤5:获取新知识 \/ 91\n结语 \/ 102\n第二部分:加工内容 \/ 111\n4? 有目的地加工:DELC步骤6 \/ 113\nDELC步骤6:什么是加工? \/ 115\n精细和有效加工的领域(DEEP) \/ 119\n5? 丰富的加工策略:DELC步骤6——深入加工知识 \/ 133\n领域1:觉知的活动 \/ 135\n领域2:分析到综合的活动 \/ 154\n领域3:应用的活动 \/ 178\n领域4:同化的活动 \/ 198\n结语 \/ 227\n第三部分:总装 \/ 267\n6? DELC课程计划编制指南:DELC步骤7 \/ 269\nDELC步骤7:为加工您需要作的选择 \/ 271\n结语 \/ 300\n7? 加工必备的技巧 \/ 310\n组织和管理内容加工 \/ 311\n结语 \/ 317\n预评估期望指南:学习之后 \/ 320\n参考文献 \/ 323","pages":"330","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s6161403.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s6161403.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6161403.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4830786\/","id":"4830786","publisher":"华东师范大学出版社","isbn10":"7561773641","isbn13":"9787561773642","title":"深度学习的7种有力策略","url":"https:\/\/api.douban.com\/v2\/book\/4830786","alt_title":"Deeper Learning: 7 Powerful Strategies for In-Depth and Longer-Lasting Learning","author_intro":"Eric Jensen是一位非常热爱学习的教师培训人员。他曾是一名教师，执教过从小学到大学的各个层级，目前他正在攻读他的心理学博士学位。他与人共同创立了“超级阵营\/数量学习”，是全国第一家且规模最大的脑和谐学习课程，现已有超过50,000名毕业生。","summary":"《深度学习的7种有力策略》共分3个部分，主要对深度学习DELC课程的路线知识作了勾勒，具体内容包括预备、激活先期知识与获取新知识：DELC步骤4与步骤5；有目的地加工：DELC步骤6；丰富的加工策略：DELC步骤6——深入加工知识；DELC课程计划编制指南：DELC步骤7等。《深度学习的7种有力策略》可供各大专院校作为教材使用，也可供从事相关工作的人员作为参考用书使用。","series":{"id":"3612","title":"创智学习丛书"},"price":"44.00元"},{"rating":{"max":10,"numRaters":37,"average":"6.0","min":0},"subtitle":"","author":["邓力","俞栋"],"pubdate":"2016-3-1","tags":[{"count":28,"name":"深度学习","title":"深度学习"},{"count":16,"name":"机器学习","title":"机器学习"},{"count":7,"name":"人工智能","title":"人工智能"},{"count":6,"name":"神经网络","title":"神经网络"},{"count":5,"name":"计算机","title":"计算机"},{"count":3,"name":"数学","title":"数学"},{"count":2,"name":"语音识别","title":"语音识别"},{"count":1,"name":"计算科学","title":"计算科学"}],"origin_title":"Deep Learning:Methods and Applications","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28806669.jpg","binding":"平装","translator":["谢磊"],"catalog":"目录\n译者序\n原书序\n1引言\n1.1深度学习的定义与背景\n1.2本书的结构安排\n2深度学习的历史\n3三类深度学习网络\n3.1三元分类方式\n3.2无监督和生成式学习深度网络\n3.3监督学习深度网络\n3.4混合深度网络\n4深度自编码器——一种无监督学习方法\n4.1引言\n4.2利用深度自编码器来提取语音特征\n4.3堆叠式去噪自编码器\n4.4转换自编码器\n5预训练的深度神经网络——一种混合方法\n5.1受限玻尔兹曼机\n5.2无监督逐层预训练\n5.3DNN和HMM结合\n6深度堆叠网络及其变形——有监督学习\n6.1简介\n6.2深度堆叠网络的基本结构\n6.3一种学习DSN权值的方法\n6.4张量深度堆叠网络\n6.5核化深度堆叠网络\n7语音和音频处理中的应用\n7.1语音识别中声学模型的建立\n7.2语音合成\n7.3音频和音乐处理\n8在语言模型和自然语言处理中的相关应用\n8.1语言模型\n8.2自然语言处理\n9信息检索领域中的应用\n9.1信息检索简介\n9.2用基于深度自编码器的语义哈希方法对文档进行索引和检索\n9.3文档检索中的深度结构语义模型\n9.4信息检索中深度堆叠网络的应用\n10在目标识别和计算机视觉中的应用\n10.1无监督或生成特征学习\n10.2有监督特征学习和分类\n11多模态和多任务学习中的典型应用\n11.1多模态：文本和图像\n11.2多模态：语音和图像\n11.3在语音、自然语言处理或者图像领域的多任务学习\n12结论\n附录\n参考文献","pages":"165","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28806669.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28806669.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28806669.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26815801\/","id":"26815801","publisher":"机械工业出版社","isbn10":"7111529065","isbn13":"9787111529064","title":"深度学习:方法及应用","url":"https:\/\/api.douban.com\/v2\/book\/26815801","alt_title":"Deep Learning:Methods and Applications","author_intro":"","summary":"序言\n译者序\n深度学习是目前人工智能、机器学习领域异常火热的研究方向，受到了学术界和工业界的高度关注，被《麻省理工学院技术评论》（MIT Technology Review）评为2013年十大突破性技术之首。深度学习已经在语音识别、图像识别、自然语言处理等诸多领域取得了突破性进展，对学术界和工业界产生了深远的影响。本书原著的作者——微软研究院的邓力博士和俞栋博士是最早将深度学习技术付诸于语音识别工业级实践的专家，他们和深度学习专家多伦多大学Geoffrey Hinton教授合作，最早将深度神经网络应用于大词汇量连续语音识别领域中，使相对识别错误率降低了20%以上。\n作为多年的导师和好朋友，两位专家将这本书的中文翻译任务交付给我，我倍感荣幸。此次中译本是在忠于原著的基础上进行翻译的，既涉及深度学习的背景和基本概念，又涉及常用的模型与方法，同时包含深度学习在不同领域中的应用。本书共有12章，具体内容包括：引言、深度学习的历史、三类深度学习网络、深度自编码器、预训练的深度神经网络、深度堆叠网络及其变种、语音和音频处理中的应用、在语言模型和自然语言处理中的相关应用、信息检索领域中的应用、在目标识别和计算机视觉中的应用、多模态和多任务学习中的典型应用、结论。\n本书的翻译除了受到原著作者的指导，也受到了张蓬副教授、陈小敏、吕航、丁闯、孙思宁、何长青、樊博、张弼弘、张彬彬、周祥增的帮助，在此表示感谢。同时感谢机械工业出版社的大力支持与推动。没有他们的帮助，本书的翻译是无法促成的。\n由于深度学习技术是一个快速发展的方向，新的模型和应用层出不穷，加之本人学识有限以及中英文语言表达、术语翻译上的差异，书中难免存在错误，还请广大读者指正与原谅。建议读者在学习过程中和英文原著一起阅读，并参考本书引用的参考文献，以便提高学习和理解效果。\n谢磊\n原书序\n“这本书对最前沿的深度学习方法及应用进行了全面的阐述，不仅包括自动语音识别(ASR)，还包括计算机视觉、语言建模、文本处理、多模态学习以及信息检索。在深度学习这一领域，这是第一本，也是最有价值的一本书，能使读者对这一领域进行广泛而深入的学习。深度学习对信息处理的很多方面（尤其对语音识别）都具有重大的影响，甚至对整个科技领域的影响也不容忽视。因此，对于有意了解这一领域的学者，这本书是绝对不容错过的。”\n——Sadaoki Furui，芝加哥丰田技术研究院院长，日本东京工业大学教授\n如前所述，深度学习指的是一类广泛的机器学习技术和架构，其特点是采用多层的非线性信息处理方法，这种方法在本质上是分层的。根据这些结构和技术不同的应用领域，如合成／生成或识别／分类，我们可以大致把这些结构分为三类：\n（1）无监督或生成式学习的深度网络针对模式分析和合成任务，用于在没有目标类标签信息的情况下捕捉观测到的或可见数据的高阶相关性。各种文献中的无监督特征或表达学习指的就是这一类深度网络。当用于生成模式时，它也可以用来描述可见数据和其相关分类的联合概率分布，此时它具有可利用的类别标签，而且这些类别标签被看作是可见数据的一部分。在后一种情况中，利用贝叶斯准则可以把生成式学习网络转换为判别式学习网络。\n（2）有监督学习的深度网络 直接提供用于模式分类目的的判别能力，它的特点是描述了可见数据条件下的类别后验分布。对于这种有监督的学习，目标类别标签总是以直接或间接形式给出，所以它们也被称作判别式深度网络。\n（3）混合深度网络 目标是判别式模型，往往以生成式或无监督深度网络的结果作为重要辅助，可以通过更好地优化和正则化类别（2）中的深度网络来实现，也可以通过在对类别（1）中所述的深度生成式或无监督深度网络的参数进行估计时，使用判别式准则来实现。","series":{"id":"45476","title":"大数据丛书"},"price":"25.40元"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["李金洪"],"pubdate":"2019-5","tags":[{"count":4,"name":"深度学习","title":"深度学习"},{"count":4,"name":"实践书籍","title":"实践书籍"},{"count":3,"name":"案例多","title":"案例多"},{"count":3,"name":"代码讲解详细","title":"代码讲解详细"},{"count":2,"name":"TensorFlow丰富","title":"TensorFlow丰富"},{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32344075.jpg","binding":"平装","translator":[],"catalog":"第1篇  准备\n第1章  学习准备\t2\n1.1  TensorFlow能做什么\t2\n1.2  学习TensorFlow的必备知识\t3\n1.3  学习技巧：跟读代码\t4\n1.4  如何学习本书\t4\n第2章  搭建开发环境\t5\n2.1  准备硬件环境\t5\n2.2  下载及安装Anaconda\t6\n2.3  安装TensorFlow\t9\n2.4  GPU版本的安装方法\t10\n2.4.1  在Windows中安装CUDA\t10\n2.4.2  在Linux中安装CUDA\t13\n2.4.3  在Windows中安装cuDNN\t13\n2.4.4  在Linux中安装cuDNN\t14\n2.4.5  常见错误及解决方案\t16\n2.5  测试显卡的常用命令\t16\n2.6  TensorFlow 1.x版本与2.x版本共存的解决方案\t18\n第3章  实例1：用AI模型识别图像是桌子、猫、狗，还是其他\t21\n3.1  准备代码环境并预训练模型\t21\n3.2  代码实现：初始化环境变量，并载入ImgNet标签\t24\n3.3  代码实现：定义网络结构\t25\n3.4  代码实现：载入模型进行识别\t26\n3.5  扩展：用更多预训练模型完成图片分类任务\t28\n第2篇  基础\n第4章  用TensorFlow制作自己的数据集\t30\n4.1  快速导读\t30\n4.1.1  什么是数据集\t30\n4.1.2  TensorFlow的框架\t31\n4.1.3  什么是TFDS\t31\n4.2  实例2：将模拟数据制作成内存对象数据集\t32\n4.2.1  代码实现：生成模拟数据\t32\n4.2.2  代码实现：定义占位符\t33\n4.2.3  代码实现：建立会话，并获取数据\t34\n4.2.4  代码实现：将模拟数据可视化\t34\n4.2.5  运行程序\t34\n4.2.6  代码实现：创建带有迭代值并支持乱序功能的模拟数据集\t35\n4.3  实例3：将图片制作成内存对象数据集\t37\n4.3.1  样本介绍\t38\n4.3.2  代码实现：载入文件名称与标签\t39\n4.3.3  代码实现：生成队列中的批次样本数据\t40\n4.3.4  代码实现：在会话中使用数据集\t41\n4.3.5  运行程序\t42\n4.4  实例4：将Excel文件制作成内存对象数据集\t42\n4.4.1  样本介绍\t43\n4.4.2  代码实现：逐行读取数据并分离标签\t43\n4.4.3  代码实现：生成队列中的批次样本数据\t44\n4.4.4  代码实现：在会话中使用数据集\t45\n4.4.5  运行程序\t46\n4.5  实例5：将图片文件制作成TFRecord数据集\t46\n4.5.1  样本介绍\t47\n4.5.2  代码实现：读取样本文件的目录及标签\t47\n4.5.3  代码实现：定义函数生成TFRecord数据集\t48\n4.5.4  代码实现：读取TFRecord数据集，并将其转化为队列\t49\n4.5.5  代码实现：建立会话，将数据保存到文件\t50\n4.5.6  运行程序\t51\n4.6  实例6：将内存对象制作成Dataset数据集\t52\n4.6.1  如何生成Dataset数据集\t52\n4.6.2  如何使用Dataset接口\t53\n4.6.3  tf.data.Dataset接口所支持的数据集变换操作\t54\n4.6.4  代码实现：以元组和字典的方式生成Dataset对象\t58\n4.6.5  代码实现：对Dataset对象中的样本进行变换操作\t59\n4.6.6  代码实现：创建Dataset迭代器\t60\n4.6.7  代码实现：在会话中取出数据\t60\n4.6.8  运行程序\t61\n4.6.9  使用tf.data.Dataset.from_tensor_slices接口的注意事项\t62\n4.7  实例7：将图片文件制作成Dataset数据集\t63\n4.7.1  代码实现：读取样本文件的目录及标签\t64\n4.7.2  代码实现：定义函数，实现图片转换操作\t64\n4.7.3  代码实现：用自定义函数实现图片归一化\t65\n4.7.4  代码实现：用第三方函数将图片旋转30°\t65\n4.7.5  代码实现：定义函数，生成Dataset对象\t66\n4.7.6  代码实现：建立会话，输出数据\t67\n4.7.7  运行程序\t68\n4.8  实例8：将TFRecord文件制作成Dataset数据集\t69\n4.8.1  样本介绍\t69\n4.8.2  代码实现：定义函数，生成Dataset对象\t70\n4.8.3  代码实现：建立会话输出数据\t71\n4.8.4  运行程序\t72\n4.9  实例9：在动态图中读取Dataset数据集\t72\n4.9.1  代码实现：添加动态图调用\t72\n4.9.2  制作数据集\t73\n4.9.3  代码实现：在动态图中显示数据\t73\n4.9.4  实例10：在TensorFlow 2.x中操作数据集\t74\n4.10  实例11：在不同场景中使用数据集\t77\n4.10.1  代码实现：在训练场景中使用数据集\t78\n4.10.2  代码实现：在应用模型场景中使用数据集\t79\n4.10.3  代码实现：在训练与测试混合场景中使用数据集\t80\n4.11  tf.data.Dataset接口的更多应用\t81\n第5章  10分钟快速训练自己的图片分类模型\t82\n5.1  快速导读\t82\n5.1.1  认识模型和模型检查点文件\t82\n5.1.2  了解“预训练模型”与微调（Fine-Tune）\t82\n5.1.3  学习TensorFlow中的预训练模型库——TF-Hub库\t83\n5.2  实例12：通过微调模型分辨男女\t83\n5.2.1  准备工作\t84\n5.2.2  代码实现：处理样本数据并生成Dataset对象\t85\n5.2.3  代码实现：定义微调模型的类MyNASNetModel\t88\n5.2.4  代码实现：构建MyNASNetModel类中的基本模型\t88\n5.2.5  代码实现：实现MyNASNetModel类中的微调操作\t89\n5.2.6  代码实现：实现与训练相关的其他方法\t90\n5.2.7  代码实现：构建模型，用于训练、测试、使用\t92\n5.2.8  代码实现：通过二次迭代来训练微调模型\t94\n5.2.9  代码实现：测试模型\t96\n5.3  扩展：通过摄像头实时分辨男女\t100\n5.4  TF-slim接口中的更多成熟模型\t100\n5.5  实例13：用TF-Hub库微调模型以评估人物的年龄\t100\n5.5.1  准备样本\t101\n5.5.2  下载TF-Hub库中的模型\t102\n5.5.3  代码实现：测试TF-Hub库中的MobileNet_V2模型\t104\n5.5.4  用TF-Hub库微调MobileNet_V2模型\t107\n5.5.5  代码实现：用模型评估人物的年龄\t109\n5.5.6  扩展：用TF-Hub库中的其他模型处理不同领域的分类任务\t113\n5.6  总结\t113\n5.7  练习题\t114\n5.7.1  基于TF-slim接口的练习\t115\n5.7.2  基于TF-Hub库的练习\t115\n第6章  用TensorFlow编写训练模型的程序\t117\n6.1  快速导读\t117\n6.1.1  训练模型是怎么一回事\t117\n6.1.2  用“静态图”方式训练模型\t117\n6.1.3  用“动态图”方式训练模型\t118\n6.1.4  什么是估算器框架接口（Estimators API）\t119\n6.1.5  什么是tf.layers接口\t120\n6.1.6  什么是tf.keras接口\t121\n6.1.7  什么是tf.js接口\t122\n6.1.8  什么是TFLearn框架\t123\n6.1.9  该选择哪种框架\t123\n6.1.10  分配运算资源与使用分布策略\t124\n6.1.11  用tfdbg调试TensorFlow模型\t127\n6.1.12  用钩子函数（Training_Hooks）跟踪训练状态\t127\n6.1.13  用分布式运行方式训练模型\t128\n6.1.14  用T2T框架系统更方便地训练模型\t128\n6.1.15  将TensorFlow 1.x中的代码移植到2.x版本\t129\n6.1.16  TensorFlow 2.x中的新特性——自动图\t130\n6.2  实例14：用静态图训练一个具有保存检查点功能的回归模型\t131\n6.2.1  准备开发步骤\t131\n6.2.2  生成检查点文件\t131\n6.2.3  载入检查点文件\t132\n6.2.4  代码实现：在线性回归模型中加入保存检查点功能\t132\n6.2.5  修改迭代次数，二次训练\t135\n6.3  实例15：用动态图（eager）训练一个具有保存检查点功能的回归模型\t136\n6.3.1  代码实现：启动动态图，生成模拟数据\t136\n6.3.2  代码实现：定义动态图的网络结构\t137\n6.3.3  代码实现：在动态图中加入保存检查点功能\t138\n6.3.4  代码实现：按指定迭代次数进行训练，并可视化结果\t139\n6.3.5  运行程序，显示结果\t140\n6.3.6  代码实现：用另一种方法计算动态图梯度\t141\n6.3.7  实例16：在动态图中获取参数变量\t142\n6.3.8  小心动态图中的参数陷阱\t144\n6.3.9  实例17：在静态图中使用动态图\t145\n6.4  实例18：用估算器框架训练一个回归模型\t147\n6.4.1  代码实现：生成样本数据集\t147\n6.4.2  代码实现：设置日志级别\t148\n6.4.3  代码实现：实现估算器的输入函数\t148\n6.4.4  代码实现：定义估算器的模型函数\t149\n6.4.5  代码实现：通过创建config文件指定硬件的运算资源\t151\n6.4.6  代码实现：定义估算器\t152\n6.4.7  用tf.estimator.RunConfig控制更多的训练细节\t153\n6.4.8  代码实现：用估算器训练模型\t153\n6.4.9  代码实现：通过热启动实现模型微调\t155\n6.4.10  代码实现：测试估算器模型\t158\n6.4.11  代码实现：使用估算器模型\t158\n6.4.12  实例19：为估算器添加日志钩子函数\t159\n6.5  实例20：将估算器代码改写成静态图代码\t161\n6.5.1  代码实现：复制网络结构\t161\n6.5.2  代码实现：重用输入函数\t163\n6.5.3  代码实现：创建会话恢复模型\t163\n6.5.4  代码实现：继续训练\t163\n6.6  实例21：用tf.layers API在动态图上识别手写数字\t165\n6.6.1  代码实现：启动动态图并加载手写图片数据集\t165\n6.6.2  代码实现：定义模型的类\t166\n6.6.3  代码实现：定义网络的反向传播\t167\n6.6.4  代码实现：训练模型\t167\n6.7  实例22：用tf.keras API训练一个回归模型\t168\n6.7.1  代码实现：用model类搭建模型\t168\n6.7.2  代码实现：用sequential类搭建模型\t169\n6.7.3  代码实现：搭建反向传播的模型\t171\n6.7.4  代码实现：用两种方法训练模型\t172\n6.7.5  代码实现：获取模型参数\t172\n6.7.6  代码实现：测试模型与用模型进行预测\t173\n6.7.7  代码实现：保存模型与加载模型\t173\n6.7.8  代码实现：将模型导出成JSON文件，再将JSON文件导入模型\t175\n6.7.9  实例23：在tf.keras接口中使用预训练模型ResNet\t176\n6.7.10  扩展：在动态图中使用tf.keras接口\t178\n6.7.11  实例24：在静态图中使用tf.keras接口\t178\n6.8  实例25：用tf.js接口后方训练一个回归模型\t180\n6.8.1  代码实现：在HTTP的头标签中添加tfjs模块\t180\n6.8.2  代码实现：用JavaScript脚本实现回归模型\t181\n6.8.3  运行程序：在浏览器中查看效果\t181\n6.8.4  扩展：tf.js 接口的应用场景\t182\n6.9  实例26：用估算器框架实现分布式部署训练\t182\n6.9.1  运行程序：修改估算器模型，使其支持分布式\t182\n6.9.2  通过TF_CONFIG进行分布式配置\t183\n6.9.3  运行程序\t185\n6.9.4  扩展：用分布策略或KubeFlow框架进行分布式部署\t186\n6.10  实例27：在分布式估算器框架中用tf.keras接口训练ResNet模型，识别图片中是橘子还是苹果\t186\n6.10.1  样本准备\t186\n6.10.2  代码实现：准备训练与测试数据集\t187\n6.10.3  代码实现：制作模型输入函数\t187\n6.10.4  代码实现：搭建ResNet模型\t188\n6.10.5  代码实现：训练分类器模型\t189\n6.10.6  运行程序：评估模型\t190\n6.10.7  扩展：全连接网络的优化\t190\n6.11  实例28：在T2T框架中用tf.layers接口实现MNIST数据集分类\t191\n6.11.1  代码实现：查看T2T框架中的数据集（problems）\t191\n6.11.2  代码实现：构建T2T框架的工作路径及下载数据集\t192\n6.11.3  代码实现：在T2T框架中搭建自定义卷积网络模型\t193\n6.11.4  代码实现：用动态图方式训练自定义模型\t194\n6.11.5  代码实现：在动态图中用metrics模块评估模型\t195\n6.12  实例29：在T2T框架中，用自定义数据集训练中英文翻译模型\t196\n6.12.1  代码实现：声明自己的problems数据集\t196\n6.12.2  代码实现：定义自己的problems数据集\t197\n6.12.3  在命令行下生成TFrecoder格式的数据\t198\n6.12.4  查找T2T框架中的模型及超参，并用指定的模型及超参进行训练\t199\n6.12.5  用训练好的T2T框架模型进行预测\t201\n6.12.6  扩展：在T2T框架中，如何选取合适的模型及超参\t202\n6.13  实例30：将TensorFlow 1.x中的代码升级为可用于2.x版本的代码\t203\n6.13.1  准备工作：创建Python虚环境\t203\n6.13.2  使用工具转换源码\t204\n6.13.3  修改转换后的代码文件\t204\n6.13.4  将代码升级到TensorFlow 2.x版本的经验总结\t205\n第3篇  进阶\n第7章  特征工程——会说话的数据\t208\n7.1  快速导读\t208\n7.1.1  特征工程的基础知识\t208\n7.1.2  离散数据特征与连续数据特征\t209\n7.1.3  了解特征列接口\t210\n7.1.4  了解序列特征列接口\t210\n7.1.5  了解弱学习器接口——梯度提升树（TFBT接口）\t210\n7.1.6  了解特征预处理模块（tf.Transform）\t211\n7.1.7  了解因子分解模块\t212\n7.1.8  了解加权矩阵分解算法\t212\n7.1.9  了解Lattice模块——点阵模型\t213\n7.1.10  联合训练与集成学习\t214\n7.2  实例31：用wide_deep模型预测人口收入\t214\n7.2.1  了解人口收入数据集\t214\n7.2.2  代码实现：探索性数据分析\t217\n7.2.3  认识wide_deep模型\t218\n7.2.4  部署代码文件\t219\n7.2.5  代码实现：初始化样本常量\t220\n7.2.6  代码实现：生成特征列\t220\n7.2.7  代码实现：生成估算器模型\t222\n7.2.8  代码实现：定义输入函数\t223\n7.2.9  代码实现：定义用于导出冻结图文件的函数\t224\n7.2.10  代码实现：定义类，解析启动参数\t225\n7.2.11  代码实现：训练和测试模型\t226\n7.2.12  代码实现：使用模型\t227\n7.2.13  运行程序\t228\n7.3  实例32：用弱学习器中的梯度提升树算法预测人口收入\t229\n7.3.1  代码实现：为梯度提升树模型准备特征列\t230\n7.3.2  代码实现：构建梯度提升树模型\t230\n7.3.3  代码实现：训练并导出梯度提升树模型\t231\n7.3.4  代码实现：设置启动参数，运行程序\t232\n7.3.5  扩展：更灵活的TFBT接口\t233\n7.4  实例33：用feature_column模块转换特征列\t233\n7.4.1  代码实现：用feature_column模块处理连续值特征列\t234\n7.4.2  代码实现：将连续值特征列转化成离散值特征列\t237\n7.4.3  代码实现：将离散文本特征列转化为one-hot与词向量\t239\n7.4.4  代码实现：根据特征列生成交叉列\t246\n7.5  实例34：用sequence_feature_column接口完成自然语言处理任务的数据预处理工作\t248\n7.5.1  代码实现：构建模拟数据\t248\n7.5.2  代码实现：构建词嵌入初始值\t249\n7.5.3  代码实现：构建词嵌入特征列与共享特征列\t249\n7.5.4  代码实现：构建序列特征列的输入层\t250\n7.5.5  代码实现：建立会话输出结果\t251\n7.6  实例35：用factorization模块的kmeans接口聚类COCO数据集中的标注框\t253\n7.6.1  代码实现：设置要使用的数据集\t253\n7.6.2  代码实现：准备带聚类的数据样本\t253\n7.6.3  代码实现：定义聚类模型\t255\n7.6.4  代码实现：训练模型\t256\n7.6.5  代码实现：输出图示化结果\t256\n7.6.6  代码实现：提取并排序聚类结果\t258\n7.6.7  扩展：聚类与神经网络混合训练\t258\n7.7  实例36：用加权矩阵分解模型实现基于电影评分的推荐系统\t259\n7.7.1  下载并加载数据集\t259\n7.7.2  代码实现：根据用户和电影特征列生成稀疏矩阵\t260\n7.7.3  代码实现：建立WALS模型，并对其进行训练\t261\n7.7.4  代码实现：评估WALS模型\t263\n7.7.5  代码实现：用WALS模型为用户推荐电影\t264\n7.7.6  扩展：使用WALS的估算器接口\t265\n7.8  实例37：用Lattice模块预测人口收入\t265\n7.8.1  代码实现：读取样本，并创建输入函数\t266\n7.8.2  代码实现：创建特征列，并保存校准关键点\t267\n7.8.3  代码实现：创建校准线性模型\t270\n7.8.4  代码实现：创建校准点阵模型\t270\n7.8.5  代码实现：创建随机微点阵模型\t271\n7.8.6  代码实现：创建集合的微点阵模型\t271\n7.8.7  代码实现：定义评估与训练函数\t272\n7.8.8  代码实现：训练并评估模型\t273\n7.8.9  扩展：将点阵模型嵌入神经网络中\t274\n7.9  实例38：结合知识图谱实现基于电影的推荐系统\t278\n7.9.1  准备数据集\t278\n7.9.2  预处理数据\t279\n7.9.3  搭建MKR模型\t279\n7.9.4  训练模型并输出结果\t286\n7.10  可解释性算法的意义\t286\n第8章  卷积神经网络（CNN）——在图像处理中应用最广泛的模型\t287\n8.1  快速导读\t287\n8.1.1  认识卷积神经网络\t287\n8.1.2  什么是空洞卷积\t288\n8.1.3  什么是深度卷积\t290\n8.1.4  什么是深度可分离卷积\t290\n8.1.5  了解卷积网络的缺陷及补救方法\t291\n8.1.6  了解胶囊神经网络与动态路由\t292\n8.1.7  了解矩阵胶囊网络与EM路由算法\t297\n8.1.8  什么是NLP任务\t298\n8.1.9  了解多头注意力机制与内部注意力机制\t298\n8.1.10  什么是带有位置向量的词嵌入\t300\n8.1.11  什么是目标检测任务\t300\n8.1.12  什么是目标检测中的上采样与下采样\t301\n8.1.13  什么是图片分割任务\t301\n8.2  实例39：用胶囊网络识别黑白图中服装的图案\t302\n8.2.1  熟悉样本：了解Fashion-MNIST数据集\t302\n8.2.2  下载Fashion-MNIST数据集\t303\n8.2.3  代码实现：读取及显示Fashion-MNIST数据集中的数据\t304\n8.2.4  代码实现：定义胶囊网络模型类CapsuleNetModel\t305\n8.2.5  代码实现：实现胶囊网络的基本结构\t306\n8.2.6  代码实现：构建胶囊网络模型\t309\n8.2.7  代码实现：载入数据集，并训练胶囊网络模型\t310\n8.2.8  代码实现：建立会话训练模型\t311\n8.2.9  运行程序\t313\n8.2.10  实例40：实现带有EM路由的胶囊网络\t314\n8.3  实例41：用TextCNN模型分析评论者是否满意\t322\n8.3.1  熟悉样本：了解电影评论数据集\t322\n8.3.2  熟悉模型：了解TextCNN模型\t322\n8.3.3  数据预处理：用preprocessing接口制作字典\t323\n8.3.4  代码实现：生成NLP文本数据集\t326\n8.3.5  代码实现：定义TextCNN模型\t327\n8.3.6  代码实现：训练TextCNN模型\t330\n8.3.7  运行程序\t332\n8.3.8  扩展：提升模型精度的其他方法\t333\n8.4  实例42：用带注意力机制的模型分析评论者是否满意\t333\n8.4.1  熟悉样本：了解tf.keras接口中的电影评论数据集\t333\n8.4.2  代码实现：将tf.keras接口中的IMDB数据集还原成句子\t334\n8.4.3  代码实现：用tf.keras接口开发带有位置向量的词嵌入层\t336\n8.4.4  代码实现：用tf.keras接口开发注意力层\t338\n8.4.5  代码实现：用tf.keras接口训练模型\t340\n8.4.6  运行程序\t341\n8.4.7  扩展：用Targeted Dropout技术进一步提升模型的性能\t342\n8.5  实例43：搭建YOLO V3模型，识别图片中的酒杯、水果等物体\t343\n8.5.1  YOLO V3模型的样本与结构\t343\n8.5.2  代码实现：Darknet-53 模型的darknet块\t344\n8.5.3  代码实现：Darknet-53 模型的下采样卷积\t345\n8.5.4  代码实现：搭建Darknet-53模型，并返回3种尺度特征值\t345\n8.5.5  代码实现：定义YOLO检测模块的参数及候选框\t346\n8.5.6  代码实现：定义YOLO检测块，进行多尺度特征融合\t347\n8.5.7  代码实现：将YOLO检测块的特征转化为bbox attrs单元\t347\n8.5.8  代码实现：实现YOLO V3的检测部分\t349\n8.5.9  代码实现：用非极大值抑制算法对检测结果去重\t352\n8.5.10  代码实现：载入预训练权重\t355\n8.5.11  代码实现：载入图片，进行目标实物的识别\t356\n8.5.12  运行程序\t358\n8.6  实例44：用YOLO V3模型识别门牌号\t359\n8.6.1  工程部署：准备样本\t359\n8.6.2  代码实现：读取样本数据，并制作标签\t359\n8.6.3  代码实现：用tf.keras接口构建YOLO V3模型，并计算损失\t364\n8.6.4  代码实现：在动态图中训练模型\t368\n8.6.5  代码实现：用模型识别门牌号\t372\n8.6.6  扩展：标注自己的样本\t374\n8.7  实例45：用Mask R-CNN模型定位物体的像素点\t375\n8.7.1  下载COCO数据集及安装pycocotools\t376\n8.7.2  代码实现：验证pycocotools及读取COCO数据集\t377\n8.7.3  拆分Mask R-CNN模型的处理步骤\t383\n8.7.4  工程部署：准备代码文件及模型\t385\n8.7.5  代码实现：加载数据构建模型，并输出模型权重\t385\n8.7.6  代码实现：搭建残差网络ResNet\t387\n8.7.7  代码实现：搭建Mask R-CNN模型的骨干网络ResNet\t393\n8.7.8  代码实现：可视化Mask R-CNN模型骨干网络的特征输出\t396\n8.7.9  代码实现：用特征金字塔网络处理骨干网络特征\t400\n8.7.10  计算RPN中的锚点\t402\n8.7.11  代码实现：构建RPN\t403\n8.7.12  代码实现：用非极大值抑制算法处理RPN的结果\t405\n8.7.13  代码实现：提取RPN的检测结果\t410\n8.7.14  代码实现：可视化RPN的检测结果\t412\n8.7.15  代码实现：在MaskRCNN类中对ROI区域进行分类\t415\n8.7.16  代码实现：金字塔网络的区域对齐层（ROIAlign）中的区域框与特征的匹配算法\t416\n8.7.17  代码实现：在金字塔网络的ROIAlign层中按区域边框提取内容\t418\n8.7.18  代码实现：调试并输出ROIAlign层的内部运算值\t421\n8.7.19  代码实现：对ROI内容进行分类\t422\n8.7.20  代码实现：用检测器DetectionLayer检测ROI内容，得到最终的实物矩形\t426\n8.7.21  代码实现：根据ROI内容进行实物像素分割\t432\n8.7.22  代码实现：用Mask R-CNN模型分析图片\t436\n8.8  实例46：训练Mask R-CNN模型，进行形状的识别\t439\n8.8.1  工程部署：准备代码文件及模型\t440\n8.8.2  样本准备：生成随机形状图片\t440\n8.8.3  代码实现：为Mask R-CNN模型添加损失函数\t442\n8.8.4  代码实现：为Mask R-CNN模型添加训练函数，使其支持微调与全网训练\t444\n8.8.5  代码实现：训练并使用模型\t446\n8.8.6  扩展：替换特征提取网络\t449\n第9章  循环神经网络（RNN）——处理序列样本的神经网络\t450\n9.1  快速导读\t450\n9.1.1  什么是循环神经网络\t450\n9.1.2  了解RNN模型的基础单元LSTM与GRU\t451\n9.1.3  认识QRNN单元\t451\n9.1.4  认识SRU单元\t451\n9.1.5  认识IndRNN单元\t452\n9.1.6  认识JANET单元\t453\n9.1.7  优化RNN模型的技巧\t453\n9.1.8  了解RNN模型中多项式分布的应用\t453\n9.1.9  了解注意力机制的Seq2Seq框架\t454\n9.1.10  了解BahdanauAttention与LuongAttention\t456\n9.1.11  了解单调注意力机制\t457\n9.1.12  了解混合注意力机制\t458\n9.1.13  了解Seq2Seq接口中的采样接口（Helper）\t460\n9.1.14  了解RNN模型的Wrapper接口\t460\n9.1.15  什么是时间序列（TFTS）框架\t461\n9.1.16  什么是梅尔标度\t461\n9.1.17  什么是短时傅立叶变换\t462\n9.2  实例47：搭建RNN模型，为女孩生成英文名字\t463\n9.2.1  代码实现：读取及处理样本\t463\n9.2.2  代码实现：构建Dataset数据集\t466\n9.2.3  代码实现：用tf.keras接口构建生成式RNN模型\t467\n9.2.4  代码实现：在动态图中训练模型\t468\n9.2.5  代码实现：载入检查点文件并用模型生成名字\t469\n9.2.6  扩展：用RNN模型编写文章\t471\n9.3  实例48：用带注意力机制的Seq2Seq模型为图片添加内容描述\t471\n9.3.1  设计基于图片的Seq2Seq\t471\n9.3.2  代码实现：图片预处理——用ResNet提取图片特征并保存\t472\n9.3.3  代码实现：文本预处理——过滤处理、字典建立、对齐与向量化处理\t475\n9.3.4  代码实现：创建数据集\t477\n9.3.5  代码实现：用tf.keras接口构建Seq2Seq模型中的编码器\t477\n9.3.6  代码实现：用tf.keras接口构建Bahdanau类型的注意力机制\t478\n9.3.7  代码实现：搭建Seq2Seq模型中的解码器Decoder\t478\n9.3.8  代码实现：在动态图中计算Seq2Seq模型的梯度\t480\n9.3.9  代码实现：在动态图中为Seq2Seq模型添加保存检查点功能\t480\n9.3.10  代码实现：在动态图中训练Seq2Seq模型\t481\n9.3.11  代码实现：用多项式分布采样获取图片的内容描述\t482\n9.4  实例49：用IndRNN与IndyLSTM单元制作聊天机器人\t485\n9.4.1  下载及处理样本\t486\n9.4.2  代码实现：读取样本，分词并创建字典\t487\n9.4.3  代码实现：对样本进行向量化、对齐、填充预处理\t489\n9.4.4  代码实现：在Seq2Seq模型中加工样本\t489\n9.4.5  代码实现：在Seq2Seq模型中，实现基于IndRNN与IndyLSTM的\n动态多层RNN编码器\t491\n9.4.6  代码实现：为Seq2Seq模型中的解码器创建Helper\t491\n9.4.7  代码实现：实现带有Bahdanau注意力、dropout、OutputProjectionWrapper的解码器\t492\n9.4.8  代码实现：在Seq2Seq模型中实现反向优化\t493\n9.4.9  代码实现：创建带有钩子函数的估算器，并进行训练\t494\n9.4.10  代码实现：用估算器框架评估模型\t496\n9.4.11  扩展：用注意力机制的Seq2Seq模型实现中英翻译\t498\n9.5  实例50：预测飞机发动机的剩余使用寿命\t498\n9.5.1  准备样本\t499\n9.5.2  代码实现：预处理数据——制作数据集的输入样本与标签\t500\n9.5.3  代码实现：构建带有JANET单元的多层动态RNN模型\t504\n9.5.4  代码实现：训练并测试模型\t505\n9.5.5  运行程序\t507\n9.5.6  扩展：为含有JANET单元的RNN模型添加注意力机制\t508\n9.6  实例51：将动态路由用于RNN模型，对路透社新闻进行分类\t509\n9.6.1  准备样本\t509\n9.6.2  代码实现：预处理数据——对齐序列数据并计算长度\t510\n9.6.3  代码实现：定义数据集\t510\n9.6.4  代码实现：用动态路由算法聚合信息\t511\n9.6.5  代码实现：用IndyLSTM单元搭建RNN模型\t513\n9.6.6  代码实现：建立会话，训练网络\t514\n9.6.7  扩展：用分级网络将文章（长文本数据）分类\t515\n9.7  实例52：用TFTS框架预测某地区每天的出生人数\t515\n9.7.1  准备样本\t515\n9.7.2  代码实现：数据预处理——制作TFTS框架中的读取器\t515\n9.7.3  代码实现：用TFTS框架定义模型，并进行训练\t516\n9.7.4  代码实现：用TFTS框架评估模型\t517\n9.7.5  代码实现：用模型进行预测，并将结果可视化\t517\n9.7.6  运行程序\t518\n9.7.7  扩展：用TFTS框架进行异常值检测\t519\n9.8  实例53：用Tacotron模型合成中文语音（TTS）\t520\n9.8.1  准备安装包及样本数据\t520\n9.8.2  代码实现：将音频数据分帧并转为梅尔频谱\t521\n9.8.3  代码实现：用多进程预处理样本并保存结果\t523\n9.8.4  拆分Tacotron网络模型的结构\t525\n9.8.5  代码实现：搭建CBHG网络\t527\n9.8.6  代码实现：构建带有混合注意力机制的模块\t529\n9.8.7  代码实现：构建自定义wrapper\t531\n9.8.8  代码实现：构建自定义采样器\t534\n9.8.9  代码实现：构建自定义解码器\t537\n9.8.10  代码实现：构建输入数据集\t539\n9.8.11  代码实现：构建Tacotron网络\t542\n9.8.12  代码实现：构建Tacotron网络模型的训练部分\t545\n9.8.13  代码实现：训练模型并合成音频文件\t546\n9.8.14  扩展：用pypinyin模块实现文字到声音的转换\t551\n第4篇  高级\n第10章  生成式模型——能够输出内容的模型\t554\n10.1  快速导读\t554\n10.1.1  什么是自编码网络模型\t554\n10.1.2  什么是对抗神经网络模型\t554\n10.1.3  自编码网络模型与对抗神经网络模型的关系\t555\n10.1.4  什么是批量归一化中的自适应模式\t555\n10.1.5  什么是实例归一化\t556\n10.1.6  了解SwitchableNorm及更多的归一化方法\t556\n10.1.7  什么是图像风格转换任务\t557\n10.1.8  什么是人脸属性编辑任务\t558\n10.1.9  什么是TFgan框架\t558\n10.2  实例54：构建DeblurGAN模型，将模糊相片变清晰\t559\n10.2.1  获取样本\t559\n10.2.2  准备SwitchableNorm算法模块\t560\n10.2.3  代码实现：构建DeblurGAN中的生成器模型\t560\n10.2.4  代码实现：构建DeblurGAN中的判别器模型\t562\n10.2.5  代码实现：搭建DeblurGAN的完整结构\t563\n10.2.6  代码实现：引入库文件，定义模型参数\t563\n10.2.7  代码实现：定义数据集，构建正反向模型\t564\n10.2.8  代码实现：计算特征空间损失，并将其编译到生成器模型的训练模型中\t566\n10.2.9  代码实现：按指定次数训练模型\t568\n10.2.10  代码实现：用模型将模糊相片变清晰\t569\n10.2.11  练习题\t572\n10.2.12  扩展：DeblurGAN模型的更多妙用\t572\n10.3  实例55：构建AttGAN模型，对照片进行加胡子、加头帘、加眼镜、变年轻等修改\t573\n10.3.1  获取样本\t573\n10.3.2  了解AttGAN模型的结构\t574\n10.3.3  代码实现：实现支持动态图和静态图的数据集工具类\t575\n10.3.4  代码实现：将CelebA做成数据集\t577\n10.3.5  代码实现：构建AttGAN模型的编码器\t581\n10.3.6  代码实现：构建含有转置卷积的解码器模型\t582\n10.3.7  代码实现：构建AttGAN模型的判别器模型部分\t584\n10.3.8  代码实现：定义模型参数，并构建AttGAN模型\t585\n10.3.9  代码实现：定义训练参数，搭建正反向模型\t587\n10.3.10  代码实现：训练模型\t592\n10.3.11  实例56：为人脸添加不同的眼镜\t595\n10.3.12  扩展：AttGAN模型的局限性\t597\n10.4  实例57：用RNN.WGAN模型模拟生成恶意请求\t597\n10.4.1  获取样本：通过Panabit设备获取恶意请求样本\t597\n10.4.2  了解RNN.WGAN模型\t600\n10.4.3  代码实现：构建RNN.WGAN模型\t601\n10.4.4  代码实现：训练指定长度的RNN.WGAN模型\t607\n10.4.5  代码实现：用长度依次递增的方式训练模型\t612\n10.4.6  运行代码\t613\n10.4.7  扩展：模型的使用及优化\t614\n第11章  模型的攻与防——看似智能的AI也有脆弱的一面\t616\n11.1  快速导读\t616\n11.1.1  什么是FGSM方法\t616\n11.1.2  什么是cleverhans模块\t616\n11.1.3  什么是黑箱攻击\t617\n11.1.4  什么是基于雅可比矩阵的数据增强方法\t618\n11.1.5  什么是数据中毒攻击\t620\n11.2  实例58：用FGSM方法生成样本，并攻击PNASNet模型，让其将“狗”识别成“盘子”\t621\n11.2.1  代码实现：创建PNASNet模型\t621\n11.2.2  代码实现：搭建输入层并载入图片，复现PNASNet模型的预测效果\t623\n11.2.3  代码实现：调整参数，定义图片的变化范围\t624\n11.2.4  代码实现：用梯度下降方式生成对抗样本\t625\n11.2.5  代码实现：用生成的样本攻击模型\t626\n11.2.6  扩展：如何防范攻击模型的行为\t627\n11.2.7  代码实现：将数据增强方式用在使用场景，以加固PNASNet模型，防范攻击\t627\n11.3  实例59：击破数据增强防护，制作抗旋转对抗样本\t629\n11.3.1  代码实现：对输入的数据进行多次旋转\t629\n11.3.2  代码实现：生成并保存鲁棒性更好的对抗样本\t630\n11.3.3  代码实现：在PNASNet模型中比较对抗样本的效果\t631\n11.4  实例60：以黑箱方式攻击未知模型\t633\n11.4.1  准备工程代码\t633\n11.4.2  代码实现：搭建通用模型框架\t634\n11.4.3  代码实现：搭建被攻击模型\t637\n11.4.4  代码实现：训练被攻击模型\t638\n11.4.5  代码实现：搭建替代模型\t639\n11.4.6  代码实现：训练替代模型\t639\n11.4.7  代码实现：黑箱攻击目标模型\t641\n11.4.8  扩展：利用黑箱攻击中的对抗样本加固模型\t645\n第5篇  实战——深度学习实际应用\n第12章  TensorFlow模型制作——一种功能，多种身份\t648\n12.1  快速导读\t648\n12.1.1  详细分析检查点文件\t648\n12.1.2  什么是模型中的冻结图\t649\n12.1.3  什么是TF Serving模块与saved_model模块\t649\n12.1.4  用编译子图（defun）提升动态图的执行效率\t649\n12.1.5  什么是TF_Lite模块\t652\n12.1.6  什么是TFjs-converter模块\t653\n12.2  实例61：在源码与检查点文件分离的情况下，对模型进行二次训练\t653\n12.2.1  代码实现：在线性回归模型中，向检查点文件中添加指定节点\t654\n12.2.2  代码实现：在脱离源码的情况下，用检查点文件进行二次训练\t657\n12.2.3  扩展：更通用的二次训练方法\t659\n12.3  实例62：导出\/导入冻结图文件\t661\n12.3.1  熟悉TensorFlow中的freeze_graph工具脚本\t661\n12.3.2  代码实现：从线性回归模型中导出冻结图文件\t662\n12.3.3  代码实现：导入冻结图文件，并用模型进行预测\t664\n12.4  实例63：逆向分析冻结图文件\t665\n12.4.1  使用import_to_tensorboard工具\t666\n12.4.2  用TensorBoard工具查看模型结构\t666\n12.5  实例64：用saved_model模块导出与导入模型文件\t668\n12.5.1  代码实现：用saved_model模块导出模型文件\t668\n12.5.2  代码实现：用saved_model模块导入模型文件\t669\n12.5.3  扩展：用saved_model模块导出带有签名的模型文件\t670\n12.6  实例65：用saved_model_cli工具查看及使用saved_model模型\t672\n12.6.1  用show参数查看模型\t672\n12.6.2  用run参数运行模型\t673\n12.6.3  扩展：了解scan参数的黑名单机制\t674\n12.7  实例66：用TF-Hub库导入、导出词嵌入模型文件\t674\n12.7.1  代码实现：模拟生成通用词嵌入模型\t674\n12.7.2  代码实现：用TF-Hub库导出词嵌入模型\t675\n12.7.3  代码实现：导出TF-Hub模型\t678\n12.7.4  代码实现：用TF-Hub库导入并使用词嵌入模型\t680\n第13章  部署TensorFlow模型——模型与项目的深度结合\t681\n13.1  快速导读\t681\n13.1.1  什么是gRPC服务与HTTP\/REST API\t681\n13.1.2  了解TensorFlow对移动终端的支持\t682\n13.1.3  了解树莓派上的人工智能\t683\n13.2  实例67：用TF_Serving部署模型并进行远程使用\t684\n13.2.1  在Linux系统中安装TF_Serving\t684\n13.2.2  在多平台中用Docker安装TF_Serving\t685\n13.2.3  编写代码：固定模型的签名信息\t686\n13.2.4  在Linux中开启TF_Serving服务\t688\n13.2.5  编写代码：用gRPC访问远程TF_Serving服务\t689\n13.2.6  用HTTP\/REST API访问远程TF_Serving服务\t691\n13.2.7  扩展：关于TF_Serving的更多例子\t694\n13.3  实例68：在安卓手机上识别男女\t694\n13.3.1  准备工程代码\t694\n13.3.2  微调预训练模型\t695\n13.3.3  搭建安卓开发环境\t698\n13.3.4  制作lite模型文件\t701\n13.3.5  修改分类器代码，并运行App\t702\n13.4  实例69：在iPhone手机上识别男女并进行活体检测\t703\n13.4.1  搭建iOS开发环境\t703\n13.4.2  部署工程代码并编译\t704\n13.4.3  载入Lite模型，实现识别男女功能\t706\n13.4.4  代码实现：调用摄像头并采集视频流\t707\n13.4.5  代码实现：提取人脸特征\t710\n13.4.6  活体检测算法介绍\t712\n13.4.7  代码实现：实现活体检测算法\t713\n13.4.8  代码实现：完成整体功能并运行程序\t714\n13.5  实例70：在树莓派上搭建一个目标检测器\t717\n13.5.1  安装树莓派系统\t718\n13.5.2  在树莓派上安装TensorFlow\t721\n13.5.3  编译并安装Protobuf\t725\n13.5.4  安装OpenCV\t726\n13.5.5  下载目标检测模型SSDLite\t726\n13.5.6  代码实现：用SSDLite 模型进行目标检测\t727\n第14章  商业实例——科技源于生活，用于生活\t730\n14.1  实例71：将特征匹配技术应用在商标识别领域\t730\n14.1.1  项目背景\t730\n14.1.2  技术方案\t730\n14.1.3  预处理图片——统一尺寸\t731\n14.1.4  用自编码网络加夹角余弦实现商标识别\t731\n14.1.5  用卷积网络加triplet-loss提升特征提取效果\t731\n14.1.6  进一步的优化空间\t732\n14.2  实例72：用RNN抓取蠕虫病毒\t732\n14.2.1  项目背景\t733\n14.2.2  判断是否恶意域名不能只靠域名\t733\n14.2.3  如何识别恶意域名\t733\n14.3  实例73：迎宾机器人的技术关注点——体验优先\t734\n14.3.1  迎宾机器人的产品背景\t734\n14.3.2  迎宾机器人的实现方案\t734\n14.3.3  迎宾机器人的同类产品\t736\n14.4  实例74：基于摄像头的路边停车场项目\t737\n14.4.1  项目背景\t737\n14.4.2  技术方案\t738\n14.4.3  方案缺陷\t738\n14.4.4  工程化补救方案\t738\n14.5  实例75：智能冰箱产品——硬件成本之痛\t739\n14.5.1  智能冰箱系列的产品背景\t739\n14.5.2  智能冰箱的技术基础\t740\n14.5.3  真实的非功能性需求——低成本\t740\n14.5.4  未来的技术趋势及应对策略\t741","pages":"768","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32344075.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32344075.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32344075.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33477126\/","id":"33477126","publisher":"电子工业出版社","isbn10":"7121363925","isbn13":"9787121363924","title":"深度学习之TensorFlow工程化项目实战","url":"https:\/\/api.douban.com\/v2\/book\/33477126","alt_title":"","author_intro":"本书由李金洪主笔编写，参与本书编写的还有以下作者。\n石昌帅\n代码医生工作室成员，具有丰富的嵌入式及算法开发经验，参与多款机器人、图像识别等项目开发，擅长机器人定位、导航技术、计算机视觉技术，熟悉NVIDIA jetson系列、Raspberry PI系列等平台软硬件开发、算法优化。从事的技术方向包括机器人导航、图像处理、自动驾驶等。\n甘月\n代码医生工作室成员，资深iOS高级工程师，有丰富的iOS研发经验，先后担任iOS主管、项目经理、iOS技术总监等职务，精通Objective-C、Swift、C等编程语言，参与过银行金融、娱乐机器人、婚庆、医疗等领域的多个项目。擅长Mac系统下的AI技术开发。\n江枭宇\n代码医生工作室成员，是大蛇智能社区成长最快的AI学者。半年时间，由普通读者升级为社区的资深辅导员。在校期间曾参加过电子设计大赛（获省级一等奖）、Google校企合作的AI创新项目、省级创新训练AI项目。熟悉Python、C和Java等编程语言。擅长图像处理方向、特征工程方向及语义压缩方向的AI任务。","summary":"《深度学习之TensorFlow工程化项目实战》是一本非常全面的、专注于实战的AI图书，兼容TensorFlow 1.x和2.x版本，共75个实例。\n《深度学习之TensorFlow工程化项目实战》共分为5篇：第1篇，介绍了学习准备、搭建开发环境、使用AI模型来识别图像；第2篇，介绍了用TensorFlow开发实际工程的一些基础操作，包括使用TensorFlow制作自己的数据集、快速训练自己的图片分类模型、编写训练模型的程序；第3篇，介绍了机器学习算法相关内容，包括特征工程、卷积神经网络（CNN）、循环神经网络（RNN）；第4篇，介绍了多模型的组合训练技术，包括生成式模型、模型的攻与防；第5篇，介绍了深度学习在工程上的应用，侧重于提升读者的工程能力，包括TensorFlow模型制作、布署TensorFlow模型、商业实例。\n本书结构清晰、案例丰富、通俗易懂、实用性强。适合对人工智能、TensorFlow感兴趣的读者作为自学教程。另外，本书也适合社会培训学校作为培训教材，还适合大中专院校的相关专业作为教学参考书。","price":"159.00元"},{"rating":{"max":10,"numRaters":10,"average":"4.9","min":0},"subtitle":"原理与应用实践","author":["张重生"],"pubdate":"2016-12-1","tags":[{"count":7,"name":"机器学习","title":"机器学习"},{"count":4,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29308703.jpg","binding":"平装","translator":[],"catalog":"","pages":"220","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29308703.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29308703.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29308703.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26963178\/","id":"26963178","publisher":"电子工业出版社","isbn10":"7121304139","isbn13":"9787121304132","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/26963178","alt_title":"","author_intro":"","summary":"","price":"CNY 48.00"},{"rating":{"max":10,"numRaters":11,"average":"7.3","min":0},"subtitle":"一起玩转TensorLayer","author":["董豪 等"],"pubdate":"2018-1-1","tags":[{"count":5,"name":"计算机","title":"计算机"},{"count":5,"name":"深度学习","title":"深度学习"},{"count":4,"name":"tensorflow","title":"tensorflow"},{"count":4,"name":"ML","title":"ML"},{"count":2,"name":"神经网络","title":"神经网络"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":1,"name":"算法","title":"算法"},{"count":1,"name":"实用","title":"实用"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29663708.jpg","binding":"平装","translator":[],"catalog":"1 深度学习简介1\n1.1 人工智能、机器学习和深度学习  1\n1.1.1 引言  1\n1.1.2 人工智能、机器学习和深度学习三者的关系  2\n1.2 神经网络  3\n1.2.1 感知器  3\n1.2.2 激活函数  5\n1.2.3 损失函数  8\n1.2.4 梯度下降和随机梯度下降  8\n1.2.5 反向传播算法简述  11\n1.2.6 其他神经网络  12\n1.3 学习方法建议  13\n1.3.1 网络资源  13\n1.3.2 TensorFlow 官方深度学习教程  14\n1.3.3 开源社区  15\n1.4 TensorLayer  15\n1.4.1 深度学习框架概况  15\n1.4.2 TensorLayer 概括  16\n1.4.3 实验环境配置  17\n2 多层感知器19\n2.1 McCulloch-Pitts 神经元模型  19\n2.1.1 人工神经网络到底能干什么？到底在干什么  21\n2.1.2 什么是激活函数？什么是偏值  22\n2.2 感知器  23\n2.2.1 什么是线性分类器  24\n2.2.2 线性分类器有什么优缺点  26\n2.2.3 感知器实例和异或问题（XOR 问题）  26\n2.3 多层感知器  30\n2.4 实现手写数字分类  32\n2.5 过拟合  40\n2.5.1 什么是过拟合  40\n2.5.2 Dropout  41\n2.5.3 批规范化  42\n2.5.4 L1、L2 和其他正则化方法  42\n2.5.5 Lp 正则化的图形化解释  44\n2.6 再实现手写数字分类  46\n2.6.1 数据迭代器  46\n2.6.2 通过all_drop 启动与关闭Dropout  47\n2.6.3 通过参数共享实现训练测试切换  50\n3 自编码器54\n3.1 稀疏性  54\n3.2 稀疏自编码器  56\n3.3 实现手写数字特征提取  59\n3.4 降噪自编码器  65\n3.5 再实现手写数字特征提取  68\n3.6 堆栈式自编码器及其实现  72\n4 卷积神经网络80\n4.1 卷积原理  80\n4.1.1 卷积操作  81\n4.1.2 张量  84\n4.1.3 卷积层  85\n4.1.4 池化层  87\n4.1.5 全连接层  89\n4.2 经典任务  90\n4.2.1 图像分类  90\n4.2.2 目标检测  91\n4.2.3 语义分割  94\n4.2.4 实例分割  94\n4.3 经典卷积网络  95\n4.3.1 LeNet  95\n4.3.2 AlexNet  96\n4.3.3 VGGNet  96\n4.3.4 GoogLeNet  98\n4.3.5 ResNet  99\n4.4 实现手写数字分类  100\n4.5 数据增强与规范化  104\n4.5.1 数据增强  104\n4.5.2 批规范化  106\n4.5.3 局部响应归一化  107\n4.6 实现CIFAR10 分类  108\n4.6.1 方法1：tl.prepro 做数据增强  108\n4.6.2 方法2：TFRecord 做数据增强  114\n4.7 反卷积神经网络  120\n5 词的向量表达121\n5.1 目的与原理  121\n5.2 Word2Vec  124\n5.2.1 简介  124\n5.2.2 Continuous Bag-Of-Words（CBOW）模型  124\n5.2.3 Skip Gram（SG）模型  129\n5.2.4 Hierarchical Softmax  132\n5.2.5 Negative Sampling  135\n5.3 实现Word2Vec  136\n5.3.1 简介  136\n5.3.2 实现  136\n5.4 重载预训练矩阵  144\n6 递归神经网络148\n6.1 为什么需要它  148\n6.2 不同的RNNs  151\n6.2.1 简单递归网络  151\n6.2.2 回音网络  152\n6.3 长短期记忆  153\n6.3.1 LSTM 概括  153\n6.3.2 LSTM 详解  157\n6.3.3 LSTM 变种  159\n6.4 实现生成句子  160\n6.4.1 模型简介  160\n6.4.2 数据迭代  163\n6.4.3 损失函数和更新公式  164\n6.4.4 生成句子及Top K 采样  167\n6.4.5 接下来还可以做什么  169\n7 深度增强学习171\n7.1 增强学习  172\n7.1.1 概述  172\n7.1.2 基于价值的增强学习  173\n7.1.3 基于策略的增强学习  176\n7.1.4 基于模型的增强学习  177\n7.2 深度增强学习  179\n7.2.1 深度Q 学习  179\n7.2.2 深度策略网络  181\n7.3 更多参考资料  187\n7.3.1 书籍  187\n7.3.2 在线课程  187\n8 生成对抗网络188\n8.1 何为生成对抗网络  189\n8.2 深度卷积对抗生成网络  190\n8.3 实现人脸生成  191\n8.4 还能做什么  198\n9 高级实现技巧202\n9.1 与其他框架对接  202\n9.1.1 无参数层  203\n9.1.2 有参数层  203\n9.2 自定义层  204\n9.2.1 无参数层  204\n9.2.2 有参数层  205\n9.3 建立词汇表  207\n9.4 补零与序列长度  209\n9.5 动态递归神经网络  210\n9.6 实用小技巧  211\n9.6.1 屏蔽显示  211\n9.6.2 参数名字前缀  212\n9.6.3 获取特定参数  213\n9.6.4 获取特定层输出  213\n10 实例一：使用预训练卷积网络214\n10.1 高维特征表达  214\n10.2 VGG 网络  215\n10.3 连接TF-Slim  221\n11 实例二：图像语义分割及其医学图像应用225\n11.1 图像语义分割概述  225\n11.1.1 传统图像分割算法简介  227\n11.1.2 损失函数与评估指标  229\n11.2 医学图像分割概述  230\n11.3 全卷积神经网络和U-Net 网络结构  232\n11.4 医学图像应用：实现脑部肿瘤分割  234\n11.4.1 数据与数据增强  235\n11.4.2 U-Net 网络  238\n11.4.3 损失函数  239\n11.4.4 开始训练  241\n12 实例三：由文本生成图像244\n12.1 条件生成对抗网络之GAN-CLS  245\n12.2 实现句子生成花朵图片  246\n13 实例四：超高分辨率复原260\n13.1 什么是超高分辨率复原  260\n13.2 网络结构  261\n13.3 联合损失函数  264\n13.4 训练网络  269\n13.5 使用测试  277\n14 实例五：文本反垃圾280\n14.1 任务场景  280\n14.2 网络结构  281\n14.3 词的向量表示  282\n14.4 Dynamic RNN 分类器  283\n14.5 训练网络  284\n14.5.1 训练词向量  284\n14.5.2 文本的表示  290\n14.5.3 训练分类器  291\n14.5.4 模型导出  296\n14.6 TensorFlow Serving 部署  299\n14.7 客户端调用  301\n14.8 其他常用方法  306\n中英对照表及其缩写309\n参考文献316","ebook_url":"https:\/\/read.douban.com\/ebook\/53966516\/","pages":"340","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29663708.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29663708.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29663708.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27663327\/","id":"27663327","publisher":"电子工业出版社","isbn10":"7121326221","isbn13":"9787121326226","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/27663327","alt_title":"","author_intro":"董豪：目前就读于帝国理工学院，从事计算机视觉、医疗数据分析和深度学习理论研究，在ICCV、TNSRE、TIFS、ACM MM等顶级会议和期刊发表过论文，Neurocomputing、TIP等会议和期刊的审稿人。有创业经验，擅长把深度学习算法与实际问题结合，获得多项国家发明专利和实用新型专利，TensorLayer创始人。\n郭毅可：帝国理工学院计算机系终身教授，Data Science Institute主任，Discovery Science Group主任，主持多项欧盟和英国大型项目，研究重点为机器学习、云计算、大数据和生物信息学。伦敦E-Science研究中心首席科学家，英国InforSense有限公司董事会主席兼首席执行官，上海生物信息技术研究中心客座教授、首席科学家，TensorLayer项目领导。\n杨光：帝国理工医学院高级研究员，皇家布朗普顿医院医学图像分析师，伦敦大学圣乔治医学院荣誉讲师，伦敦大学学院（UCL）硕士、博士、IEEE会员、SPIE会员、ISMRM会员、BMVA会员，专注于医疗大数据以及医学图像的成像和分析，在各类期刊会议上发表论文近40篇，国际专利两项，Medical Physics杂志临时副主编，MIUA会议委员会委员，长期为专业杂志会议义务审稿50余篇。其研究方向获得英国EPSRC、CRUK、NIHR和British Heart Foundation （BHF）资助。近期致力于Medical AI方向的创新创业。\n吴超：帝国理工数字科学研究所研究员，主要从事医疗和城市领域数据分析和建模的研究工作，研究工作获得EPSRC、Royal Society等多项研究基金资助。\n王剑虹：帝国理工硕士及利物浦大学本科毕业，主要研究语音识别分类问题；目前在UCL攻读研究型硕士，主要研究增强学习在游戏中的运用。\n幺忠玮：帝国理工硕士，本科毕业于北京邮电大学，主要研究方向为计算机视觉，对生成模型和目标识别领域感兴趣。目前致力于将目标检测算法植入嵌入式系统实现即时检测。\n张敬卿：帝国理工博士在读，研究型硕士，主要研究兴趣包括深度学习、数据挖掘、时间序列与文本挖掘、多模态问题与生成模型。本科毕业于清华大学计算机科学与技术系，曾获得中国国家奖学金。\n陈竑：北京大学光华管理学院在读，哈尔滨工业大学电子与信息工程学院毕业，深度学习爱好者。\n林一鸣：帝国理工博士在读，主要研究深度学习在人脸分析方向的应用。\n于思淼：帝国理工博士在读，浙江大学本科毕业，主要研究方向为深度学习、生成模型及其在计算机视觉方面的应用。\n莫元汉：帝国理工博士在读，北京航空航天大学本科毕业，主要研究方向为深度学习、动力学及其在医疗图像分析方面的应用。\n袁航：瑞士洛桑联邦理工（EPFL）硕士在读，本科就读于德国雅各布大学（Jacobs）计算机系，及在美国卡内基梅隆大学（CMU）计算机科学学院交换学习，主要从事计算神经科学与电脑人机接口研究。之前分别在帝国理工及马克斯普朗克智能系统研究院（Max Planck Institute for Intelligent Systems）进行研习，现在主要在EPFL G-lab研究脊髓修复对运动功能康复及血压控制等课题。","summary":"《深度学习：一起玩转TensorLayer》由TensorLayer创始人领衔写作，TensorLayer社区众包完成，作者全部来自一线人工智能研究员和工程师，内容不仅覆盖了传统书籍都有的多层感知器、卷积网络、递归网络及增强学习等，还着重讲解了生成对抗网络、学习方法和实践经验，配有若干产品级别的实例。读者将会从零开始学会目前最新的深度学习技术，以及使用TL实现各种应用。\n《深度学习：一起玩转TensorLayer》以通俗易懂的方式讲解深度学习技术，同时配有实现方法教学，面向深度学习初学者、进阶者，以及希望长期从事深度学习研究和产品开发的深度学习工程师和TensorFlow用户。","ebook_price":"59.40","series":{"id":"41172","title":"博文视点AI系列"},"price":"CNY 99.00"},{"rating":{"max":10,"numRaters":17,"average":"6.9","min":0},"subtitle":"","author":["猿辅导研究团队"],"pubdate":"2018-2","tags":[{"count":23,"name":"深度学习","title":"深度学习"},{"count":14,"name":"机器学习","title":"机器学习"},{"count":11,"name":"人工智能","title":"人工智能"},{"count":11,"name":"AI","title":"AI"},{"count":9,"name":"计算机","title":"计算机"},{"count":3,"name":"算法","title":"算法"},{"count":1,"name":"科学","title":"科学"},{"count":1,"name":"神经网络","title":"神经网络"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29705589.jpg","binding":"平装","translator":[],"catalog":"第1 部分深度学习基础篇1\n1 概述2\n1.1 人工智能  3\n1.1.1 人工智能的分类  3\n1.1.2 人工智能发展史  3\n1.2 机器学习  7\n1.2.1 机器学习的由来  7\n1.2.2 机器学习发展史  9\n1.2.3 机器学习方法分类  10\n1.2.4 机器学习中的基本概念  11\n1.3 神经网络  12\n1.3.1 神经网络发展史  13\n参考文献  16\n2 神经网络17\n2.1 在神经科学中对生物神经元的研究  17\n2.1.1 神经元激活机制  17\n2.1.2 神经元的特点  18\n2.2 神经元模型  19\n2.2.1 线性神经元  19\n2.2.2 线性阈值神经元  19\n2.2.3 Sigmoid 神经元  21\n2.2.4 Tanh 神经元  22\n2.2.5 ReLU  22\n2.2.6 Maxout  24\n2.2.7 Softmax  24\n2.2.8 小结  25\n2.3 感知机  27\n2.3.1 感知机的提出  27\n2.3.2 感知机的困境  28\n2.4 DNN  29\n2.4.1 输入层、输出层及隐层  30\n2.4.2 目标函数的选取  30\n2.4.3 前向传播  32\n2.4.4 后向传播  33\n2.4.5 参数更新  35\n2.4.6 神经网络的训练步骤  36\n参考文献  36\n3 初始化模型38\n3.1 受限玻尔兹曼机  38\n3.1.1 能量模型  39\n3.1.2 带隐藏单元的能量模型  40\n3.1.3 受限玻尔兹曼机基本原理  41\n3.1.4 二值RBM  43\n3.1.5 对比散度  45\n3.2 自动编码器  47\n3.2.1 稀疏自动编码器  48\n3.2.2 降噪自动编码器  48\n3.2.3 栈式自动编码器  49\n3.3 深度信念网络  50\n参考文献  52\n4 卷积神经网络53\n4.1 卷积算子  53\n4.2 卷积的特征  56\n4.3 卷积网络典型结构  59\n4.3.1 基本网络结构  59\n4.3.2 构成卷积神经网络的层  59\n4.3.3 网络结构模式  60\n4.4 卷积网络的层  61\n4.4.1 卷积层  61\n4.4.2 池化层  66\n参考文献  67\n5 循环神经网络68\n5.1 循环神经网络简介  68\n5.2 RNN、LSTM 和GRU  69\n5.3 双向RNN  76\n5.4 RNN 语言模型的简单实现  77\n参考文献  80\n6 深度学习优化算法81\n6.1 SGD  81\n6.2 Momentum  82\n6.3 NAG  83\n6.4 Adagrad  85\n6.5 RMSProp  86\n6.6 Adadelta  87\n6.7 Adam  88\n6.8 AdaMax  90\n6.9 Nadam  90\n6.10 关于优化算法的使用  92\n参考文献  92\n7 深度学习训练技巧94\n7.1 数据预处理  94\n7.2 权重初始化  95\n7.3 正则化  96\n7.3.1 提前终止  96\n7.3.2 数据增强  96\n7.3.3 L2\/L1 参数正则化  98\n7.3.4 集成  100\n7.3.5 Dropout  101\n参考文献  102\n8 深度学习框架103\n8.1 Theano  103\n8.1.1 Theano  103\n8.1.2 安装  104\n8.1.3 计算图  104\n8.2 Torch  105\n8.2.1 概述  105\n8.2.2 安装  106\n8.2.3 核心结构  107\n8.2.4 小试牛刀  110\n8.3 PyTorch  113\n8.3.1 概述  113\n8.3.2 安装  113\n8.3.3 核心结构  114\n8.3.4 小试牛刀  114\n8.4 Caffe  117\n8.4.1 概述  117\n8.4.2 安装  118\n8.4.3 核心组件  119\n8.4.4 小试牛刀  125\n8.5 TensorFlow  125\n8.5.1 概述  125\n8.5.2 安装  126\n8.5.3 核心结构  126\n8.5.4 小试牛刀  127\n8.6 MXNet  131\n8.6.1 概述  131\n8.6.2 安装  131\n8.6.3 核心结构  132\n8.6.4 小试牛刀  133\n8.7 Keras  135\n8.7.1 概述  135\n8.7.2 安装  136\n8.7.3 模块介绍  136\n8.7.4 小试牛刀  136\n参考文献  139\n第2 部分计算机视觉篇140\n9 计算机视觉背景141\n9.1 传统计算机视觉  141\n9.2 基于深度学习的计算机视觉  145\n9.3 参考文献  146\n10 图像分类模型147\n10.1 LeNet-5  147\n10.2 AlexNet  149\n10.3 VGGNet  154\n10.3.1 网络结构  155\n10.3.2 配置  157\n10.3.3 讨论  157\n10.3.4 几组实验  158\n10.4 GoogLeNet  159\n10.4.1 NIN  161\n10.4.2 GoogLeNet 的动机  161\n10.4.3 网络结构细节  162\n10.4.4 训练方法  164\n10.4.5 后续改进版本  165\n10.5 ResNet  165\n10.5.1 基本思想  165\n10.5.2 网络结构  167\n10.6 DenseNet  169\n10.7 DPN  170\n参考文献  170\n11 目标检测173\n11.1 相关研究  175\n11.1.1 选择性搜索  175\n11.1.2 OverFeat  177\n11.2 基于区域提名的方法  179\n11.2.1 R-CNN  179\n11.2.2 SPP-net  181\n11.2.3 Fast R-CNN  182\n11.2.4 Faster R-CNN  184\n11.2.5 R-FCN  185\n11.3 端到端的方法  186\n11.3.1 YOLO  186\n11.3.2 SSD  187\n11.4 小结  188\n参考文献  190\n12 语义分割192\n12.1 全卷积网络  193\n12.1.1 FCN  193\n12.1.2 DeconvNet  195\n12.1.3 SegNet  197\n12.1.4 DilatedConvNet  198\n12.2 CRF\/MRF 的使用  199\n12.2.1 DeepLab  199\n12.2.2 CRFasRNN  201\n12.2.3 DPN  203\n12.3 实例分割  205\n12.3.1 Mask R-CNN  205\n参考文献  206\n13 图像检索的深度哈希编码208\n13.1 传统哈希编码方法  208\n13.2 CNNH  209\n13.3 DSH  210\n13.4 小结  212\n参考文献  212\n第3 部分语音识别篇214\n14 传统语音识别基础215\n14.1 语音识别简介  215\n14.2 HMM 简介  216\n14.2.1 HMM 是特殊的混合模型  218\n14.2.2 转移概率矩阵  219\n14.2.3 发射概率  220\n14.2.4 Baum-Welch 算法  220\n14.2.5 后验概率  224\n14.2.6 前向-后向算法  224\n14.3 HMM 梯度求解  227\n14.3.1 梯度算法1  228\n14.3.2 梯度算法2  230\n14.3.3 梯度求解的重要性  234\n14.4 孤立词识别  234\n14.4.1 特征提取  234\n14.4.2 孤立词建模  235\n14.4.3 GMM-HMM  237\n14.5 连续语音识别  240\n14.6 Viterbi 解码  243\n14.7 三音素状态聚类  245\n14.8 判别式训练  248\n参考文献  254\n15 基于WFST 的语音解码256\n15.1 有限状态机  257\n15.2 WFST 及半环定义  257\n15.2.1 WFST  257\n15.2.2 半环（Semiring）  258\n15.3 自动机操作  260\n15.3.1 自动机基本操作  261\n15.3.2 转换器基本操作  262\n15.3.3 优化操作  265\n15.4 基于WFST 的语音识别系统  277\n15.4.1 声学模型WFST  279\n15.4.2 三音素WFST  281\n15.4.3 发音字典WFST  281\n15.4.4 语言模型WFST  282\n15.4.5 WFST 组合和优化  284\n15.4.6 组合和优化实验  285\n15.4.7 WFST 解码  286\n参考文献  287\n16 深度语音识别288\n16.1 CD-DNN-HMM  288\n16.2 TDNN  292\n16.3 CTC  295\n16.4 EESEN  299\n16.5 Deep Speech  301\n16.6 Chain  310\n参考文献  313\n17 CTC 解码315\n17.1 序列标注  315\n17.2 序列标注任务的解决办法  316\n17.2.1 序列分类  316\n17.2.2 分割分类  317\n17.2.3 时序分类  318\n17.3 隐马模型  318\n17.4 CTC 基本定义  319\n17.5 CTC 前向算法  321\n17.6 CTC 后向算法  324\n17.7 CTC 目标函数  325\n17.8 CTC 解码基本原理  327\n17.8.1 最大概率路径解码  327\n17.8.2 前缀搜索解码  328\n17.8.3 约束解码  329\n参考文献  333\n第4 部分自然语言处理篇334\n18 自然语言处理简介335\n18.1 NLP 的难点  335\n18.2 NLP 的研究范围  336\n19 词性标注338\n19.1 传统词性标注模型  338\n19.2 基于神经网络的词性标注模型  340\n19.3 基于Bi-LSTM 的神经网络词性标注模型  342\n参考文献  344\n20 依存句法分析345\n20.1 背景  346\n20.2 SyntaxNet 技术要点  348\n20.2.1 Transition-based 系统  349\n20.2.2 “模板化” 技术  353\n20.2.3 Beam Search  355\n参考文献  357\n21 word2vec 358\n21.1 背景  359\n21.1.1 词向量  359\n21.1.2 统计语言模型  359\n21.1.3 神经网络语言模型  362\n21.1.4 Log-linear 模型  364\n21.1.5 Log-bilinear 模型  365\n21.1.6 层次化Log-bilinear 模型  365\n21.2 CBOW 模型  366\n21.3 Skip-gram 模型  369\n21.4 Hierarchical Softmax 与Negative Sampling  371\n21.5 fastText  372\n21.6 GloVe  373\n21.7 小结  374\n参考文献  374\n22 神经网络机器翻译376\n22.1 机器翻译简介  376\n22.2 神经网络机器翻译基本模型  377\n22.3 基于Attention 的神经网络机器翻译  379\n22.4 谷歌机器翻译系统GNMT  381\n22.5 基于卷积的机器翻译  382\n22.6 小结  383\n参考文献  384\n第5 部分深度学习研究篇385\n23 Batch Normalization 386\n23.1 前向与后向传播  387\n23.1.1 前向传播  387\n23.1.2 后向传播  390\n23.2 有效性分析  393\n23.2.1 内部协移  393\n23.2.2 梯度流  393\n23.3 使用与优化方法  395\n23.4 小结  396\n参考文献  396\n24 Attention 397\n24.1 从简单RNN 到RNN + Attention  398\n24.2 Soft Attention 与Hard Attention  398\n24.3 Attention 的应用  399\n24.4 小结  401\n参考文献  402\n25 多任务学习403\n25.1 背景  403\n25.2 什么是多任务学习  404\n25.3 多任务分类与其他分类概念的关系  406\n25.3.1 二分类  406\n25.3.2 多分类  407\n25.3.3 多标签分类  407\n25.3.4 相关关系  408\n25.4 多任务学习如何发挥作用  409\n25.4.1 提高泛化能力的潜在原因  410\n25.4.2 多任务学习机制  410\n25.4.3 后向传播多任务学习如何发现任务是相关的  412\n25.5 多任务学习被广泛应用  413\n25.5.1 使用未来预测现在  413\n25.5.2 多种表示和度量  413\n25.5.3 时间序列预测  413\n25.5.4 使用不可操作特征  414\n25.5.5 使用额外任务来聚焦  414\n25.5.6 有序迁移  414\n25.5.7 多个任务自然地出现  414\n25.5.8 将输入变成输出  414\n25.6 多任务深度学习应用  416\n25.6.1 脸部特征点检测  416\n25.6.2 DeepID2  418\n25.6.3 Fast R-CNN  419\n25.6.4 旋转人脸网络  420\n25.6.5 实例感知语义分割的MNC  422\n25.7 小结  423\n参考文献  425\n26 模型压缩426\n26.1 模型压缩的必要性  426\n26.2 较浅的网络  428\n26.3 剪枝  428\n26.4 参数共享  434\n26.5 紧凑网络  437\n26.6 二值网络  438\n26.7 小结  442\n参考文献  442\n27 增强学习445\n27.1 什么是增强学习  445\n27.2 增强学习的数学表达形式  448\n27.2.1 MDP  449\n27.2.2 策略函数  450\n27.2.3 奖励与回报  450\n27.2.4 价值函数  452\n27.2.5 贝尔曼方程  453\n27.2.6 最优策略性质  453\n27.3 用动态规划法求解增强学习问题  454\n27.3.1 Agent 的目标  454\n27.3.2 策略评估  455\n27.3.3 策略改进  456\n27.3.4 策略迭代  457\n27.3.5 策略迭代的例子  458\n27.3.6 价值迭代  459\n27.3.7 价值迭代的例子  461\n27.3.8 策略函数和价值函数的关系  462\n27.4 无模型算法  462\n27.4.1 蒙特卡罗法  463\n27.4.2 时序差分法  465\n27.4.3 Q-Learning  466\n27.5 Q-Learning 的例子  467\n27.6 AlphaGo 原理剖析  469\n27.6.1 围棋与机器博弈  469\n27.6.2 Alpha-Beta 树  472\n27.6.3 MCTS  473\n27.6.4 UCT  476\n27.6.5 AlphaGo 的训练策略  478\n27.6.6 AlphaGo 的招式搜索算法  482\n27.6.7 围棋的对称性  484\n27.7 AlphaGo Zero  484\n参考文献  484\n28 GAN 486\n28.1 生成模型  486\n28.2 生成对抗模型的概念  488\n28.3 GAN 实战  492\n28.4 InfoGAN——探寻隐变量的内涵  493\n28.5 Image-Image Translation  496\n28.6 WGAN（Wasserstein GAN）  499\n28.6.1 GAN 目标函数的弱点  500\n28.6.2 Wasserstein 度量的优势  501\n28.6.3 WGAN 的目标函数  504\n参考文献  505\nA 本书涉及的开源资源列表 506","ebook_url":"https:\/\/read.douban.com\/ebook\/58561679\/","pages":"528","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29705589.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29705589.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29705589.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30159603\/","id":"30159603","publisher":"电子工业出版社","isbn10":"7121329050","isbn13":"9787121329050","title":"深度学习核心技术与实践","url":"https:\/\/api.douban.com\/v2\/book\/30159603","alt_title":"","author_intro":"猿辅导应用研究团队成立于2014年年中，一直从事深度学习在教育领域的应用和研究工作。团队成员均毕业于北京大学、清华大学、上海交大、中科院、香港大学等知名高校，大多数拥有硕士或博士学位。研究方向涵盖了图像识别、语音识别、自然语言理解、数据挖掘、深度学习等领域。团队成功运用深度学习技术，从零开始打造出活跃用户过亿的拍照搜题APP——小猿搜题，开源了分布式机器学习系统ytk-learn和分布式通信系统ytk-mp4j。此外，团队自主研发的一系列成果均成功应用到猿辅导公司的产品中。包括：速算应用中的在线手写识别、古诗词背诵中的语音识别、英语口语智能批改、英文手写拍照识别和英语作文智能批改等技术。","summary":"《深度学习核心技术与实践》主要介绍深度学习的核心算法，以及在计算机视觉、语音识别、自然语言处理中的相关应用。《深度学习核心技术与实践》的作者们都是业界一线的深度学习从业者，所以书中所写内容和业界联系紧密，所涵盖的深度学习相关知识点比较全面。《深度学习核心技术与实践》主要讲解原理，较少贴代码。\n《深度学习核心技术与实践》适合深度学习从业人士或者相关研究生作为参考资料，也可以作为入门教程来大致了解深度学习的相关前沿技术。","ebook_price":"83.30","series":{"id":"41172","title":"博文视点AI系列"},"price":"119.00元"},{"rating":{"max":10,"numRaters":23,"average":"6.9","min":0},"subtitle":"","author":["喻俨","莫瑜","王琛","胡振邦","高杰"],"pubdate":"2017-6","tags":[{"count":16,"name":"深度学习","title":"深度学习"},{"count":16,"name":"TensorFlow","title":"TensorFlow"},{"count":6,"name":"机器学习","title":"机器学习"},{"count":4,"name":"人工智能","title":"人工智能"},{"count":3,"name":"python","title":"python"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29444395.jpg","binding":"平装","translator":[],"catalog":"1    深度学习简介  1\n1.1  深度学习介绍  1\n1.2  深度学习的趋势  7\n1.3  参考资料  10\n2    TensorFlow系统介绍  12\n2.1  TensorFlow诞生的动机  12\n2.2  TensorFlow系统简介  14\n2.3  TensorFlow基础概念  16\n2.3.1  计算图  16\n2.3.2  Session会话  18\n2.4  系统架构  19\n2.5  源码结构  21\n2.5.1  后端执行引擎  22\n2.5.2  前端语言接口  24\n2.6  小结  24\n2.7  参考资料  25\n3    Hello TensorFlow  26\n3.1  环境准备  26\n3.1.1  Mac OS安装  27\n3.1.2  Linux GPU服务器安装  28\n3.1.3  常用Python库  32\n3.2  Titanic题目实战  34\n3.2.1  Kaggle平台介绍  34\n3.2.2  Titanic题目介绍  35\n3.2.3  数据读入及预处理  38\n3.2.4  构建计算图  40\n3.2.5  构建训练迭代过程  44\n3.2.6  执行训练  46\n3.2.7  存储和加载模型参数  47\n3.2.8  预测测试数据结果  50\n3.3  数据挖掘的技巧  51\n3.3.1  数据可视化  52\n3.3.2  特征工程  54\n3.3.3  多种算法模型  57\n3.4  TensorBoard可视化  58\n3.4.1  记录事件数据  58\n3.4.2  启动TensorBorad服务  60\n3.5  数据读取  62\n3.5.1  数据文件格式  63\n3.5.2  TFRecord  63\n3.6  SkFlow、TFLearn与TF-Slim  67\n3.7  小结  69\n3.8  参考资料  69\n4    CNN“看懂”世界  71\n4.1  图像识别的难题  72\n4.2  CNNs的基本原理  74\n4.2.1  卷积的数学意义  75\n4.2.2  卷积滤波  77\n4.2.3  CNNs中的卷积层  81\n4.2.4  池化（Pooling）  83\n4.2.5  ReLU  84\n4.2.6  多层卷积  86\n4.2.7  Dropout  86\n4.3  经典CNN模型  87\n4.3.1  AlexNet  88\n4.3.2  VGGNets  95\n4.3.3  GoogLeNet & Inception  98\n4.3.4  ResNets  106\n4.4  图像风格转换  109\n4.4.1  量化的风格  109\n4.4.2  风格的滤镜  116\n4.5  小结  120\n4.6  参考资料  121\n5    RNN“能说会道”  123\n5.1  文本理解和文本生成问题  124\n5.2  标准RNN模型  128\n5.2.1  RNN模型介绍  128\n5.2.2  BPTT算法  130\n5.2.3  灵活的RNN结构  132\n5.2.4  TensorFlow实现正弦序列预测  135\n5.3  LSTM模型  138\n5.3.1  长期依赖的难题  138\n5.3.2  LSTM基本原理  139\n5.3.3  TensorFlow构建LSTM模型  142\n5.4  更多RNN的变体  144\n5.5  语言模型  146\n5.5.1  NGram语言模型  146\n5.5.2  神经网络语言模型  148\n5.5.3  循环神经网络语言模型  150\n5.5.4  语言模型也能写代码  152\n5.5.5  改进方向  163\n5.6  对话机器人  164\n5.6.1  对话机器人的发展  165\n5.6.2  基于seq2seq的对话机器人  169\n5.7  小结  181\n5.8  参考资料  182\n6    CNN+LSTM看图说话  183\n6.1  CNN+LSTM网络模型与图像检测问题  184\n6.1.1  OverFeat和Faster R-CNN图像检测算法介绍  185\n6.1.2  遮挡目标图像检测方法  187\n6.1.3  ReInspect算法实现及模块说明  188\n6.1.4  ReInspect算法的实验数据与结论  204\n6.2  CNN+LSTM网络模型与图像摘要问题  207\n6.2.1  图像摘要问题  208\n6.2.2  NIC图像摘要生成算法  209\n6.2.3  NIC图像摘要生成算法实现说明  214\n6.2.4  NIC算法的实验数据与结论  243\n6.3  小结  249\n6.4  参考资料  250\n7    损失函数与优化算法  253\n7.1  目标函数优化策略  254\n7.1.1  梯度下降算法  254\n7.1.2  RMSProp优化算法  256\n7.1.3  Adam优化算法  257\n7.1.4  目标函数优化算法小结  258\n7.2  类别采样（Candidate Sampling）损失函数  259\n7.2.1  softmax类别采样损失函数  261\n7.2.2  噪声对比估计类别采样损失函数  281\n7.2.3  负样本估计类别采样损失函数  286\n7.2.4  类别采样logistic损失函数  286\n7.3  小结  287\n7.4  参考资料  288\n结语  289","pages":"304","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29444395.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29444395.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29444395.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27038400\/","id":"27038400","publisher":"电子工业出版社","isbn10":"7121312980","isbn13":"9787121312984","title":"深度学习原理与TensorFlow实践","url":"https:\/\/api.douban.com\/v2\/book\/27038400","alt_title":"","author_intro":"喻俨，百纳信息（海豚浏览器）研发副总裁。2007年加入微软亚洲工程院，2011年加入百纳信息负责海外业务线，从0到1做过多个项目，现致力于AI和大数据产品的研究与应用。\n莫瑜，先后任职于微软和海豚浏览器，从事搜索引擎、音乐检索\/哼唱搜索、内容分发推荐算法和对话机器人技术研发。长期以来持续关注和实践大规模数据算法性能优化、搜索引擎、推荐系统和人工智能技术。\n王琛，英国爱丁堡大学人工智能专业硕士，现为百纳信息技术有限公司人工智能方向负责人。早年参加过信息学奥林匹克竞赛获得河北省第一名、全国三等奖，并保送进入中山大学。大学期间，在ACM竞赛上也屡获佳绩。硕士毕业后就职于百度基础架构部，参与大数据平台研发工作，对大数据分析处理、分布式系统架构等方面都有比较深刻的理解。2014年加入百纳，负责多个项目的研发，自2016年起负责人工智能方向的探索。\n胡振邦，拥有博士学位，百纳信息技术有限公司高级算法研究员，毕业于中国地质大学计算机学院地学信息工程专业。读博期间，参与了关于遥感卫星图像识别分析的863项目，并且是主要的研发人员。毕业以来，一直从事图像识别方面的算法研发工作，主要方向包括目标检测、图文检索、图像分类与验证等，在图像处理、计算机视觉等方面都有深厚的积累和经验。\n高杰，是一位1980年出生于苏北的“爱学习、能折腾、有情怀”的大叔。毕业于扬州中学特招班，1998年入学华中科技大学机械系，兼修管理、会计，自学计算机，2003年考入南京大学软件学院，曾任德国西门子内部SAP咨询师，还在中银国际TMT投行、金山软件集团投资部任过职，2015年与合伙人联合创立了图灵科技集团，与华尔街顶尖交易团队一起致力于量化交易、算法模型和人工智能在金融领域的应用，目前这家公司管理着超过20亿元的资产，是细分市场的领先公司。","summary":"《深度学习原理与TensorFlow实践》主要介绍了深度学习的基础原理和TensorFlow系统基本使用方法。TensorFlow是目前机器学习、深度学习领域最优秀的计算系统之一，《深度学习原理与TensorFlow实践》结合实例介绍了使用TensorFlow开发机器学习应用的详细方法和步骤。同时，《深度学习原理与TensorFlow实践》着重讲解了用于图像识别的卷积神经网络和用于自然语言处理的循环神经网络的理论知识及其TensorFlow实现方法，并结合实际场景和例子描述了深度学习技术的应用范围与效果。\n《深度学习原理与TensorFlow实践》非常适合对机器学习、深度学习感兴趣的读者，或是对深度学习理论有所了解，希望尝试更多工程实践的读者，抑或是对工程产品有较多经验，希望学习深度学习理论的读者。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":11,"average":"6.6","min":0},"subtitle":"","author":["黄安埠"],"pubdate":"2017-6","tags":[{"count":17,"name":"深度学习","title":"深度学习"},{"count":8,"name":"Python","title":"Python"},{"count":6,"name":"机器学习","title":"机器学习"},{"count":4,"name":"python","title":"python"},{"count":4,"name":"AI","title":"AI"},{"count":3,"name":"计算科学","title":"计算科学"},{"count":2,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"理论性","title":"理论性"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29450393.jpg","binding":"平装","translator":[],"catalog":"第1 部分 概要  1\n1 绪论  2\n1.1 人工智能、机器学习与深度学习的关系  3\n1.1.1 人工智能——机器推理  4\n1.1.2 机器学习——数据驱动的科学  5\n1.1.3 深度学习——大脑的仿真  8\n1.2 深度学习的发展历程  8\n1.3 深度学习技术概述  10\n1.3.1 从低层到高层的特征抽象  11\n1.3.2 让网络变得更深 13\n1.3.3 自动特征提取 14\n1.4 深度学习框架  15\n2 Theano 基础  19\n2.1 符号变量  20\n2.2 符号计算的抽象——符号计算图模型  23\n2.3 函数  26\n2.3.1 函数的定义 26\n2.3.2 Logistic回归  27\n2.3.3 函数的复制 29\n2.4 条件表达式  31\n2.5 循环  32\n2.6 共享变量  39\n2.7 配置  39\n2.7.1 通过THEANO_FLAGS配置 40\n2.7.2 通过. theanorc文件配置  41\n2.8 常用的Debug技巧  42\n2.9 小结  43\n第2 部分 数学与机器学习基础篇  45\n3 线性代数基础  46\n3.1 标量、向量、矩阵和张量  46\n3.2 矩阵初等变换  47\n3.3 线性相关与向量空间  48\n3.4 范数  49\n3.4.1 向量范数 49\n3.4.2 矩阵范数 53\n3.5 特殊的矩阵与向量  56\n3.6 特征值分解  57\n3.7 奇异值分解  58\n3.8 迹运算 60\n3.9 样例：主成分分析  61\n4 概率统计基础  64\n4.1 样本空间与随机变量  65\n4.2 概率分布与分布函数  65\n4.3 一维随机变量  66\n4.3.1 离散型随机变量和分布律 66\n4.3.2 连续型随机变量和概率密度函数 67\n4.4 多维随机变量  68\n4.4.1 离散型二维随机变量和联合分布律 69\n4.4.2 连续型二维随机变量和联合密度函数 69\n4.5 边缘分布  70\n4.6 条件分布与链式法则  71\n4.6.1 条件概率  71\n4.6.2 链式法则  73\n4.7 多维随机变量的独立性分析 73\n4.7.1 边缘独立 74\n4.7.2 条件独立 74\n4.8 数学期望、方差、协方差  75\n4.8.1 数学期望 75\n4.8.2 方差 76\n4.8.3 协方差 76\n4.8.4 协方差矩阵 78\n4.9 信息论基础  81\n4.9.1 信息熵 81\n4.9.2 条件熵 83\n4.9.3 互信息 84\n4.9.4 相对熵与交叉熵 84\n5 概率图模型 87\n5.1 生成模型与判别模型  89\n5.2 图论基础  90\n5.2.1 图的结构 90\n5.2.2 子图 91\n5.2.3 路径、迹、环与拓扑排序 92\n5.3 贝叶斯网络  95\n5.3.1 因子分解 96\n5.3.2 局部马尔科夫独立性断言 99\n5.3.3 I-Map与因子分解  100\n5.3.4 有效迹  103\n5.3.5 D-分离与全局马尔科夫独立性  108\n5.4 马尔科夫网络  108\n5.4.1 势函数因子与参数化表示  109\n5.4.2 马尔科夫独立性  111\n5.5 变量消除 114\n5.6 信念传播 116\n5.6.1 聚类图  116\n5.6.2 团树  120\n5.6.3 由变量消除构建团树  123\n5.7 MCMC采样原理  126\n5.7.1 随机采样  127\n5.7.2 随机过程与马尔科夫链  128\n5.7.3 MCMC采样  132\n5.7.4 Gibbs采样 134\n5.8 参数学习 137\n5.8.1 最大似然估计  137\n5.8.2 期望最大化算法  138\n5.9 小结  140\n6 机器学习基础  142\n6.1 线性模型 143\n6.1.1 线性回归  143\n6.1.2 Logistic回归 148\n6.1.3 广义的线性模型  150\n6.2 支持向量机  151\n6.2.1 最优间隔分类器  152\n6.2.2 对偶问题  155\n6.2.3 核函数  156\n6.3 朴素贝叶斯  160\n6.4 树模型  162\n6.4.1 特征选择  163\n6.4.2 剪枝策略  165\n6.5 聚类  166\n6.5.1 距离度量  167\n6.5.2 层次聚类  168\n6.5.3 K-means聚类  171\n6.5.4 谱聚类  172\n7 数值计算与最优化 177\n7.1 无约束极小值的最优化条件  177\n7.2 梯度下降 179\n7.2.1 传统更新策略  181\n7.2.2 动量更新策略  183\n7.2.3 改进的动量更新策略  184\n7.2.4 自适应梯度策略  187\n7.3 共轭梯度 188\n7.4 牛顿法  192\n7.5 拟牛顿法 194\n7.5.1 拟牛顿条件  194\n7.5.2 DFP算法  195\n7.5.3 BFGS算法  196\n7.5.4 L-BFGS算法  197\n7.6 约束最优化条件  200\n第3 部分 理论与应用篇  205\n8 前馈神经网络  206\n8.1 生物神经元结构  207\n8.2 人工神经元结构  208\n8.3 单层感知机  209\n8.4 多层感知机  212\n8.5 激活函数 217\n8.5.1 激活函数的作用  217\n8.5.2 常用的激活函数  219\n9 反向传播与梯度消失 225\n9.1 经验风险最小化  227\n9.2 梯度计算 228\n9.2.1 输出层梯度  228\n9.2.2 隐藏层梯度  230\n9.2.3 参数梯度  234\n9.3 反向传播 235\n9.4 深度学习训练的难点 237\n9.4.1 欠拟合——梯度消失  237\n9.4.2 过拟合  240\n10 自编码器及其相关模型  243\n10.1 自编码器  243\n10.2 降噪自编码器  245\n10.3 栈式自编码器  247\n10.4 稀疏编码器 250\n10.5 应用：cifar10图像分类 254\n11 玻尔兹曼机及其相关模型  258\n11.1 玻尔兹曼机 258\n11.2 能量模型  261\n11.2.1 能量函数 261\n11.2.2 从能量函数到势函数 262\n11.2.3 从势函数到概率分布 263\n11.3 推断  264\n11.3.1 边缘分布 265\n11.3.2 条件分布 267\n11.4 学习  270\n11.4.1 最大似然估计 271\n11.4.2 对比散度 274\n11.5 应用：个性化推荐  276\n11.5.1 个性化推荐概述 276\n11.5.2 个性化推荐架构与算法 279\n11.5.3 RBM与协同过滤  285\n12 递归神经网络  291\n12.1 Elman递归神经网络  292\n12.2 时间反向传播  295\n12.3 长短时记忆网络  299\n12.4 结构递归神经网络  302\n12.5 应用：语言模型  308\n12.5.1 N元统计模型 308\n12.5.2 基于LSTM 构建语言模型  312\n13 卷积神经网络  318\n13.1 卷积运算  319\n13.2 网络结构  320\n13.3 卷积层  324\n13.4 池化层  329\n13.5 应用：文本分类  333","pages":"344","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29450393.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29450393.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29450393.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27044428\/","id":"27044428","publisher":"电子工业出版社","isbn10":"7121312700","isbn13":"9787121312700","title":"深入浅出深度学习：原理剖析与Python实践","url":"https:\/\/api.douban.com\/v2\/book\/27044428","alt_title":"","author_intro":"黄安埠，2012年毕业于清华大学，获硕士学位，在校期间活跃于TopCoder等编程竞赛社区。现为腾讯基础研究高级工程师，研究领域包括个性化推荐、自然语言处理和大规模的相似度优化计算，特别是对于深度学习在推荐系统的应用有深入的研究，并申请了国内十余项相关专利。\n本书的配套代码，读者也可以在作者的Github主页中下载查看：\nhttps:\/\/github.com\/innovation-cat\/DeepLearningBook)","summary":"《深入浅出深度学习：原理剖析与Python实践》介绍了深度学习相关的原理与应用，全书共分为三大部分，第一部分主要回顾了深度学习的发展历史，以及Theano的使用；第二部分详细讲解了与深度学习相关的基础知识，包括线性代数、概率论、概率图模型、机器学习和最优化算法；在第三部分中，针对若干核心的深度学习模型，如自编码器、受限玻尔兹曼机、递归神经网络和卷积神经网络等进行详细的原理分析与讲解，并针对不同的模型给出相应的具体应用。\n《深入浅出深度学习：原理剖析与Python实践》适合有一定高等数学、机器学习和Python编程基础的在校学生、高校研究者或在企业中从事深度学习的工程师使用，书中对模型的原理与难点进行了深入分析，在每一章的最后都提供了详细的参考文献，读者可以对相关的细节进行更深入的研究。最后，理论与实践相结合，《深入浅出深度学习：原理剖析与Python实践》针对常用的模型分别给出了相应的应用，读者也可以在Github中下载和查看《深入浅出深度学习：原理剖析与Python实践》的代码（https:\/\/github.com\/innovation-cat\/DeepLearningBook）。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":126,"average":"3.7","min":0},"subtitle":"","author":["焦李成"],"pubdate":"2017-6","tags":[{"count":51,"name":"计算机","title":"计算机"},{"count":36,"name":"科学","title":"科学"},{"count":30,"name":"软件开发","title":"软件开发"},{"count":23,"name":"技术","title":"技术"},{"count":18,"name":"已购买","title":"已购买"},{"count":16,"name":"机器学习","title":"机器学习"},{"count":15,"name":"自然","title":"自然"},{"count":14,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475492.jpg","binding":"","translator":[],"catalog":"第1章 深度学习基础 1\n1.1 数学基础 2\n1.1.1 矩阵论 2\n1.1.2 概率论 3\n1.1.3 优化分析 5\n1.1.4 框架分析 6\n1.2 稀疏表示 8\n1.2.1 稀疏表示初步 8\n1.2.2 稀疏模型 20\n1.2.3 稀疏认知学习、计算与识别的范式 24\n1.3 机器学习与神经网络 31\n1.3.1 机器学习 31\n1.3.2 神经网络 36\n参考文献 38\n第2章 深度前馈神经网络 41\n2.1 神经元的生物机理 42\n2.1.1 生物机理 42\n2.1.2 单隐层前馈神经网络 43\n2.2 多隐层前馈神经网络 45\n2.3 反向传播算法 47\n2.4 深度前馈神经网络的学习范式 48\n参考文献 51\n第3章 深度卷积神经网络 54\n3.1 卷积神经网络的生物机理及数学刻画 55\n3.1.1 生物机理 55\n3.1.2 卷积流的数学刻画 56\n3.2 深度卷积神经网络 61\n3.2.1 典型网络模型与框架 61\n3.2.2 学习算法及训练策略 69\n3.2.3 模型的优缺点分析 71\n3.3 深度反卷积神经网络 73\n3.3.1 卷积稀疏编码 74\n3.3.2 深度反卷积神经网络 75\n3.3.3 网络模型的性能分析与应用举例 77\n3.4 全卷积神经网络 77\n3.4.1 网络模型的数学刻画 77\n3.4.2 网络模型的性能分析及应用举例 79\n参考文献 80\n第4章 深度堆栈自编码网络 83\n4.1 自编码网络 84\n4.1.1 逐层学习策略 84\n4.1.2 自编码网络 84\n4.1.3 自编码网络的常见范式 87\n4.2 深度堆栈网络 90\n4.3 深度置信网络\/深度玻尔兹曼机网络 93\n4.3.1 玻尔兹曼机\/受限玻尔兹曼机 93\n4.3.2 深度玻尔兹曼机\/深度置信网络 94\n参考文献 96\n第5章 稀疏深度神经网络 99\n5.1 稀疏性的生物机理 100\n5.1.1 生物视觉机理 100\n5.1.2 稀疏性响应与数学物理描述 102\n5.2 稀疏深度网络模型及基本性质 102\n5.2.1 数据的稀疏性 103\n5.2.2 稀疏正则 103\n5.2.3 稀疏连接 104\n5.2.4 稀疏分类器设计 106\n5.2.5 深度学习中关于稀疏的技巧与策略 108\n5.3 网络模型的性能分析 110\n5.3.1 稀疏性对深度学习的影响 110\n5.3.2 对比实验及结果分析 110\n参考文献 111\n第6章 深度融合网络 113\n6.1 深度SVM网络 114\n6.1.1 从神经网络到SVM 114\n6.1.2 网络模型的结构 115\n6.1.3 训练技巧 117\n6.2 深度PCA网络 117\n6.3 深度ADMM网络 119\n6.4 深度极限学习机 121\n6.4.1 极限学习机 121\n6.4.2 深度极限学习机 123\n6.5 深度多尺度几何网络 125\n6.5.1 深度脊波网络 125\n6.5.2 深度轮廓波网络 127\n6.6 深度森林 130\n6.6.1 多分辨特性融合 131\n6.6.2 级联特征深度处理 131\n参考文献 133\n第7章 深度生成网络 136\n7.1 生成式对抗网络的基本原理 137\n7.1.1 网络模型的动机 137\n7.1.2 网络模型的数学物理描述 139\n7.2 深度卷积对抗生成网络 141\n7.2.1 网络模型的基本结构 141\n7.2.2 网络模型的性能分析 144\n7.2.3 网络模型的典型应用 146\n7.3 深度生成网络模型的新范式 151\n7.3.1 生成式对抗网络的新范式 151\n7.3.2 网络框架的性能分析与改进 154\n7.4 应用驱动下的两种新生成式对抗网络 155\n7.4.1 堆栈生成式对抗网络 155\n7.4.2 对偶学习范式下的生成式对抗网络 158\n7.5 变分自编码器 160\n参考文献 162\n第8章 深度复卷积神经网络与深度二值神经网络 167\n8.1 深度复卷积神经网络 168\n8.1.1 网络模型构造的动机 168\n8.1.2 网络模型的数学物理描述 168\n8.2 深度二值神经网络 172\n8.2.1 网络基本结构 172\n8.2.2 网络的数学物理描述 173\n8.2.3 讨论 176\n参考文献 177\n第9章 深度循环和递归神经网络 180\n9.1 深度循环神经网络 181\n9.1.1 循环神经网络的生物机理 181\n9.1.2 简单的循环神经网络 181\n9.1.3 深度循环神经网络的数学物理描述 183\n9.2 深度递归神经网络 188\n9.2.1 简单的递归神经网络 188\n9.2.2 深度递归神经网络的优势 189\n9.3 长短时记忆神经网络 190\n9.3.1 改进动机分析 190\n9.3.2 长短时记忆神经网络的数学分析 191\n9.4 典型应用 192\n9.4.1 深度循环神经网络的应用举例 193\n9.4.2 深度递归神经网络的应用举例 194\n参考文献 194\n第10章 深度强化学习 197\n10.1 深度强化学习基础 198\n10.1.1 深度强化学习的基本思路 198\n10.1.2 发展历程 198\n10.1.3 应用的新方向 200\n10.2 深度Q网络 201\n10.2.1 网络基本模型与框架 201\n10.2.2 深度Q网络的数学分析 202\n10.3 应用举例—AlphaGo 204\n10.3.1 AlphaGo原理分析 205\n10.3.2 深度强化学习性能分析 206\n参考文献 207\n第11章 深度学习软件仿真平台及开发环境 209\n11.1 Caffe平台 210\n11.1.1 Caffe平台开发环境 210\n11.1.2 AlexNet神经网络学习 210\n11.1.3 AlexNet神经网络应用于图像分类 212\n11.2 TensorFlow平台 215\n11.2.1 TensorFlow平台开发环境 215\n11.2.2 深度卷积生成式对抗网DCGAN 216\n11.2.3 DAN应用于样本扩充 217\n11.3 MXNet平台 220\n11.3.1 MXNet平台开发环境 220\n11.3.2 VGG-NET深度神经网络学习 222\n11.3.3 图像分类应用任务 225\n11.4 Torch 7平台 226\n11.4.1 Torch 7平台开发环境 226\n11.4.2 二值神经网络 227\n11.4.3 二值神经网络应用于图像分类 239\n11.5 Theano平台 233\n11.5.1 Theano平台开发环境 233\n11.5.2 递归神经网络 234\n11.5.3 LSTM应用于情感分类任务 237\n参考文献 238\n第12章 基于深度神经网络的SAR\/PolSAR影像地物分类 240\n12.1 数据集及研究目的 241\n12.1.1 数据集特性分析 241\n12.1.2 基本数据集 244\n12.1.3 研究目的 247\n12.2 基于深度神经网络的SAR影像地物分类 251\n12.2.1 基于自适应自编码和超像素的SAR图像分类 251\n12.2.2 基于卷积中层特征学习的SAR图像分类 257\n12.3 基于第一代深度神经网络的PolSAR影像地物分类 263\n12.3.1 基于稀疏极化DBN的极化SAR地物分类 263\n12.3.2 基于深度PCA网络的极化SAR影像地物分类 267\n12.4 基于第二代深度神经网络的PolSAR影像地物分类 271\n12.4.1 基于深度复卷积网络的极化PolSAR影像地物分类 271\n12.4.2基于生成式对抗网的极化PolSAR影像地物分类 274\n12.4.3基于深度残差网络的极化PolSAR影像地物分类 278\n参考文献 280\n第13章 基于深度神经网络的SAR影像变化检测 284\n13.1 数据集特点及研究目的 285\n13.1.1 研究目的 285\n13.1.2 数据基本特性 288\n13.1.3 典型数据集 291\n13.2 基于深度学习和SIFT特征的SAR图像变化检测 293\n13.2.1 基本方法与实现策略 284\n13.2.2 对比实验结果分析 295\n13.3基于SAE的SAR图像变化检测 299\n13.3.1 基本方法与实现策略 299\n13.3.2 对比实验结果分析 303\n13.4基于CNN的SAR图像变化检测 305\n13.4.1基本方法与实现策略 305\n13.4.2对比实验结果分析 307\n参考文献 309\n第14章 基于深度神经网络的高光谱图像分类与压缩 311\n14.1 数据集及研究目的 312\n14.1.1 高光谱遥感技术 312\n14.1.2 高光谱遥感的研究目的 313\n14.1.3 常用的高光谱数据集 314\n14.2 基于深度神经网络的高光谱影像的分类 318\n14.2.1 基于堆栈自编码的高光谱影像的分类 319\n14.2.2 基于卷积神经网络的高光谱影像的分类 325\n14.3基于深度神经网络的高光谱影像的压缩 333\n14.3.1 基于深度自编码网络的高光谱图像压缩方法 334\n14.3.2 实验设计及分类结果 336\n参考文献 338\n第15章 基于深度神经网络的目标检测与识别 340\n15.1 数据特性及研究目的 341\n15.1.1 研究目的 341\n15.1.2 常用数据集 343\n15.2 基于快速CNN的目标检测与识别 345\n15.2.1 R-CNN 346\n15.2.2 Fast R-CNN 348\n15.2.3 Faster R-CNN 349\n15.2.4 对比实验结果与分析 352\n15.3 基于回归学习的目标检测与识别 353\n15.3.1 YOLO 353\n15.3.2 SSD 356\n15.3.3 对比实验结果分析 359\n15.4 基于学习搜索的目标检测与识别 360\n15.4.1 基于深度学习的主动目标定位 360\n15.4.2 AttentionNet 363\n15.4.3 对比实验结果分析 365\n参考文献 366\n第16章 总结与展望 368\n16.1 深度学习发展历史图 369\n16.1.1 从机器学习、稀疏表示学习到深度学习 370\n16.1.2 深度学习、计算与认知的范式演进 371\n16.1.3 深度学习形成脉络 375\n16.2 深度学习的典型应用 375\n16.2.1 目标检测与识别 375\n16.2.2 超分辨 376\n16.2.3 自然语言处理 376\n16.3 深度神经网络的可塑性 377\n16.3.1 旋转不变性 377\n16.3.2 平移不变性 378\n16.3.3 多尺度、多分辨和多通路特性 378\n16.3.4 稀疏性 379\n16.4 基于脑启发式的深度学习前沿方向 380\n16.4.1 生物神经领域关于认知、识别、注意等的最新研究进展 380\n16.4.2 深度神经网络的进一步研究方向 382\n16.4.3 深度学习的可拓展性 383\n参考文献 383\n附录A 基于深度学习的常见任务处理介绍 386\n附录B 代码介绍 393","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29475492.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29475492.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475492.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27064768\/","id":"27064768","publisher":"清华大学出版社","isbn10":"7302473676","isbn13":"9787302473671","title":"深度学习、优化与识别","url":"https:\/\/api.douban.com\/v2\/book\/27064768","alt_title":"","author_intro":"","summary":"《深度学习、优化与识别》的特色\n深度学习是计算机科学与人工智能的重要组成部分。全书16章，分为理论与实践应用两部分，同时介绍5种深度学习主流平台的特性与应用，最后给出了深度学习的前沿进展介绍，另附带47种相关网络模型的实现代码。本书具有以下的特点：\n一、内容系统全面\n全书16章，覆盖了深度学习当前出现的诸多经典框架或模型，分为两个部分。第一部分系统地从数据、模型、优化目标函数和求解等四个方面论述了深度学习的理论及算法，如卷积神经网络、深度生成模型等；第二部分基于5种主流的深度学习平台给出了深度网络在自然图像、卫星遥感影像等领域的应用，如分类、变化检测、目标检测与识别等任务。另外给出了深度学习发展的脉络图及最新研究进展，提供可基于5种平台实现的47中深度网络代码，以便有兴趣的读者进一步钻研探索。\n二、叙述立场客观\n作为深度学习的入门教材，尽可能不带偏见地对材料进行分析、加工以及客观介绍。本书理论部分均从模型产生的本源来介绍，并给出各个经典模型之间内在的相互联系。本书实践应用部分对相关任务做了详尽的分析，并给出深度学习应用实践的经验总结。\n三、设计装帧精美\n该书设计人性化，文字、公式、数学符号混排格式美观精致，特别是，全书采用全彩印制，软精装装帧。封面设计清新却不脱俗、学术化，足可以看出出版社和作者的用心。\n内容简介\n书籍\n计算机书籍\n深度神经网络是近年来受到广泛关注的研究方向，它已成为人工智能2.0的主要组成部分。本书系统地论述了深度神经网络基本理论、算法及应用。全书共16章，分为两个部分；第一部分（第1章～10章）系统论述了理论及算法，包括深度前馈神经网络、深度卷积神经网络、深度堆栈神经网络、深度递归神经网络、深度生成网络、深度融合网络等；第二部分（第11～15章）论述了常用的深度学习平台，以及在高光谱图像、自然图像、SAR与极化SAR影像等领域的应用；第16章为总结与展望，给出了深度学习发展的历史图、前沿方向及最新进展。每章都附有相关阅读材料及仿真代码，以便有兴趣的读者进一步钻研探索。\n本书可为高等院校计算机科学、电子科学与技术、信息科学、控制科学与工程、人工智能等领域的研究人员提供参考，以及作为相关专业本科生及研究生教学参考书，同时可供深度学习及其应用感兴趣的研究人员和工程技术人员参考。","price":""},{"rating":{"max":10,"numRaters":41,"average":"2.0","min":0},"subtitle":"","author":["乐毅","严超"],"pubdate":"2017-8","tags":[{"count":14,"name":"抄袭","title":"抄袭"},{"count":9,"name":"抄袭opensource文档","title":"抄袭opensource文档"},{"count":7,"name":"深度学习","title":"深度学习"},{"count":3,"name":"keras","title":"keras"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"抄袭狗","title":"抄袭狗"},{"count":1,"name":"反面典型","title":"反面典型"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29486957.jpg","binding":"平装","translator":[],"catalog":"第1章　Keras概述\t1\n1.1  Keras简介\t1\n1.1.1  Keras 2\t1\n1.1.2  Keras功能构成\t4\n1.2  Keras特点\t6\n1.3  主要深度学习框架\t8\n1.3.1  Caffe\t8\n1.3.2  Torch\t10\n1.3.3  Keras\t12\n1.3.4  MXNet\t12\n1.3.5  TensorFlow\t13\n1.3.5  CNTK\t14\n1.3.6  Theano\t14\n第2章　Keras的安装与配置\t16\n2.1  Windows环境下安装Keras\t16\n2.1.1  硬件配置\t16\n2.1.2  Windows版本\t18\n2.1.3  Microsoft Visual Studio版本\t18\n2.1.4  Python环境\t18\n2.1.5  CUDA\t18\n2.1.6  加速库CuDNN\t19\n2.1.7  Keras框架的安装\t19\n2.2  Linux环境下的安装\t20\n2.2.1  硬件配置\t20\n2.2.2  Linux版本\t21\n2.2.3  Ubuntu环境的设置\t22\n2.2.4  CUDA开发环境\t22\n2.2.5  加速库cuDNN\t23\n2.2.6  Keras框架安装\t24\n第3章　Keras快速上手\t25\n3.1  基本概念\t25\n3.2  初识Sequential模型\t29\n3.3  一个MNIST手写数字实例\t30\n3.3.1  MNIST数据准备\t30\n3.3.2  建立模型\t31\n3.3.3  训练模型\t32\n第4章　Keras模型的定义\t36\n4.1  Keras模型\t36\n4.2  Sequential模型\t38\n4.2.1  Sequential模型接口\t38\n4.2.2  Sequential模型的数据输入\t48\n4.2.3  模型编译\t49\n4.2.4  模型训练\t50\n4.3  函数式模型\t51\n4.3.1  全连接网络\t52\n4.3.2  函数模型接口\t53\n4.3.3  多输入和多输出模型\t63\n4.3.4  共享层模型\t67\n第5章　Keras网络结构\t71\n5.1  Keras层对象方法\t71\n5.2  常用层\t72\n5.2.1  Dense层\t72\n5.2.2  Activation层\t74\n5.2.3  Dropout层\t75\n5.2.4  Flatten层\t75\n5.2.5  Reshape层\t76\n5.2.6  Permute层\t77\n5.2.7  RepeatVector层\t78\n5.2.8  Lambda层\t79\n5.2.9  ActivityRegularizer层\t80\n5.2.10  Masking层\t81\n5.3  卷积层\t82\n5.3.1  Conv1D层\t82\n5.3.2  Conv2D层\t84\n5.3.3  SeparableConv2D层\t87\n5.3.4  Conv2DTranspose层\t91\n5.3.5  Conv3D层\t94\n5.3.6  Cropping1D层\t97\n5.3.6  Cropping2D层\t97\n5.3.7  Cropping3D层\t98\n5.3.8  UpSampling1D层\t99\n5.3.9  UpSampling2D层\t100\n5.3.10  UpSampling3D层\t101\n5.3.11  ZeroPadding1D层\t102\n5.3.12  ZeroPadding2D层\t103\n5.3.13  ZeroPadding3D层\t104\n5.4  池化层\t105\n5.4.1  MaxPooling1D层\t105\n5.4.2  MaxPooling2D层\t106\n5.4.3  MaxPooling3D层\t108\n5.4.4  AveragePooling1D层\t109\n5.4.5  AveragePooling2D层\t110\n5.4.6  AveragePooling3D层\t111\n5.4.7  GlobalMaxPooling1D层\t112\n5.4.8  GlobalAveragePooling1D层\t113\n5.4.9  GlobalMaxPooling2D层\t113\n5.4.10  GlobalAveragePooling2D层\t114\n5.5  局部连接层\t115\n5.5.1  LocallyConnected1D层\t115\n5.5.2  LocallyConnected2D层\t117\n5.6  循环层\t120\n5.6.1  Recurrent层\t120\n5.6.2  SimpleRNN层\t124\n5.6.3  GRU层\t126\n5.6.4  LSTM层\t127\n5.7  嵌入层\t129\n5.8  融合层\t131\n5.9  激活层\t134\n5.9.1  LeakyReLU层\t134\n5.9.2  PReLU层\t134\n5.9.3  ELU层\t135\n5.9.4  ThresholdedReLU层\t136\n5.10  规范层\t137\n5.11  噪声层\t139\n5.11.1  GaussianNoise层\t139\n5.11.2  GaussianDropout层\t139\n5.12  包装器Wrapper\t140\n5.12.1  TimeDistributed层\t140\n5.12.2  Bidirectional层\t141\n5.13  自定义层\t142\n第6章　Keras数据预处理\t144\n6.1  序列数据预处理\t145\n6.1.1  序列数据填充\t145\n6.1.2  提取序列跳字样本\t148\n6.1.3  生成序列抽样概率表\t151\n6.2  文本预处理\t153\n6.2.1  分割句子获得单词序列\t153\n6.2.2  OneHot序列编码器\t154\n6.2.3  单词向量化\t155\n6.3  图像预处理\t159\n第7章　Keras内置网络配置\t167\n7.1  模型性能评估模块\t168\n7.1.1  Keras内置性能评估方法\t168\n7.1.2  使用Keras内置性能评估\t170\n7.1.3  自定义性能评估函数\t171\n7.2  损失函数\t171\n7.3  优化器函数\t174\n7.3.1  Keras优化器使用\t174\n7.3.2  Keras内置优化器\t176\n7.4  激活函数\t180\n7.4.1  添加激活函数方法\t180\n7.4.2  Keras内置激活函数\t181\n7.4.3  Keras高级激活函数\t185\n7.5  初始化参数\t189\n7.5.1  使用初始化方法\t189\n7.5.2  Keras内置初始化方法\t190\n7.5.3  自定义Keras初始化方法\t196\n7.6  正则项\t196\n7.6.1  使用正则项\t197\n7.6.2  Keras内置正则项\t198\n7.6.3  自定义Keras正则项\t198\n7.7  参数约束项\t199\n7.7.1  使用参数约束项\t199\n7.7.2  Keras内置参数约束项\t200\n第8章　Keras实用技巧和可视化\t202\n8.1  Keras调试与排错\t202\n8.1.1  Keras Callback回调函数与调试技巧\t202\n8.1.2  备份和还原Keras模型\t215\n8.2  Keras内置Scikit-Learn接口包装器\t217\n8.3  Keras内置可视化工具\t224\n第9章　Keras实战\t227\n9.1  训练一个准确率高于90%的Cifar-10预测模型\t227\n9.1.1  数据预处理\t232\n9.1.2  训练\t233\n9.2  在Keras模型中使用预训练词向量判定文本类别\t239\n9.2.1  数据下载和实验方法\t240\n9.2.2  数据预处理\t241\n9.2.3  训练\t245\n9.3  用Keras实现DCGAN生成对抗网络还原MNIST样本\t247\n9.3.1  DCGAN网络拓扑结构\t250\n9.3.2  训练\t254","pages":"276","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29486957.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29486957.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29486957.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27081208\/","id":"27081208","publisher":"电子工业出版社","isbn10":"7121318687","isbn13":"9787121318689","title":"深度学习：Keras快速开发入门","url":"https:\/\/api.douban.com\/v2\/book\/27081208","alt_title":"","author_intro":"","summary":"《深度学习：Keras快速开发入门》首先介绍了深度学习相关的理论和主流的深度学习框架，对比了不同深度学习框架的优缺点，以Keras这一具有高度模块化，极简式的高层深度学习框架为切入点，从Keras的安装、配置和编译等基本环境入手，详细介绍了Keras的模型、网络结构、数据预处理方法、参数配置以及调试技巧和可视化工具。帮助读者快速掌握一款深度学习框架，从而解决工作和学习当中神经网络模型的使用问题。同时，《深度学习：Keras快速开发入门》还介绍了如何用Keras快速构建深度学习原型并着手实战。最后通过Kaggle的知识竞赛实例向读者展示Keras作为深度学习开发工具的强大之处，从而帮助读者迅速获得深度学习开发经验。\n《深度学习：Keras快速开发入门》是一本实践性很强的深度学习工具书，适合希望快速学习和使用Keras深度学习框架的工程师、学者和从业者。特别适合立志从事深度学习和AI相关的行业，并且对于希望用Keras开发实际项目的工程技术人员，是非常实用的参考手册和工具书。","series":{"id":"41172","title":"博文视点AI系列"},"price":"69.00"},{"rating":{"max":10,"numRaters":17,"average":"6.9","min":0},"subtitle":"核心算法与视觉实践","author":["冯超"],"pubdate":"2017-7","tags":[{"count":30,"name":"深度学习","title":"深度学习"},{"count":18,"name":"机器学习","title":"机器学习"},{"count":10,"name":"算法","title":"算法"},{"count":8,"name":"计算机","title":"计算机"},{"count":7,"name":"Caffe","title":"Caffe"},{"count":3,"name":"计算机视觉","title":"计算机视觉"},{"count":3,"name":"科学","title":"科学"},{"count":3,"name":"知乎","title":"知乎"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29480805.jpg","binding":"平装","translator":[],"catalog":"1 机器学习与深度学习的概念1\n1.1 什么是机器学习 1\n1.1.1 机器学习的形式. 2\n1.1.2 机器学习的几个组成部分. 8\n1.2 深度学习的逆袭 9\n1.3 深层模型在视觉领域的应用. 13\n1.4 本书的主要内容 15\n1.5 总结. 17\n2 数学与机器学习基础18\n2.1 线性代数基础. 18\n2.2 对称矩阵的性质 22\n2.2.1 特征值与特征向量 22\n2.2.2 对称矩阵的特征值和特征向量 23\n2.2.3 对称矩阵的对角化 24\n2.3 概率论. 25\n2.3.1 概率与分布. 25\n2.3.2 最大似然估计 28\n2.4 信息论基础 31\n2.5 KL 散度. 33\n2.6 凸函数及其性质 37\n2.7 机器学习基本概念. 39\n2.8 机器学习的目标函数 42\n2.9 总结. 44\n3 CNN 的基石：全连接层45\n3.1 线性部分. 45\n3.2 非线性部分 48\n3.3 神经网络的模样 50\n3.4 反向传播法 55\n3.4.1 反向传播法的计算方法. 55\n3.4.2 反向传播法在计算上的抽象. 58\n3.4.3 反向传播法在批量数据上的推广. 59\n3.4.4 具体的例子. 63\n3.5 参数初始化 65\n3.6 总结. 68\n4 CNN 的基石：卷积层69\n4.1 卷积操作. 69\n4.1.1 卷积是什么. 69\n4.1.2 卷积层效果展示. 73\n4.1.3 卷积层汇总了什么 76\n4.1.4 卷积的另一种解释 77\n4.2 卷积层的反向传播. 79\n4.2.1 实力派解法. 80\n4.2.2 “偶像派”解法. 84\n4.3 ReLU 88\n4.3.1 梯度消失问题 89\n4.3.2 ReLU 的理论支撑. 92\n4.3.3 ReLU 的线性性质. 93\n4.3.4 ReLU 的不足. 93\n4.4 总结. 94\n4.5 参考文献. 94\n5 Caffe 入门95\n5.1 使用Caffe 进行深度学习训练. 96\n5.1.1 数据预处理. 96\n5.1.2 网络结构与模型训练的配置. 100\n5.1.3 训练与再训练 108\n5.1.4 训练日志分析 110\n5.1.5 预测检验与分析. 112\n5.1.6 性能测试 115\n5.2 模型配置文件介绍. 117\n5.3 Caffe 的整体结构. 122\n5.3.1 SyncedMemory 124\n5.3.2 Blob 125\n5.3.3 Layer 125\n5.3.4 Net 126\n5.3.5 Solver 126\n5.3.6 多GPU 训练. 127\n5.3.7 IO 127\n5.4 Caffe 的Layer 128\n5.4.1 Layer 的创建——LayerRegistry 128\n5.4.2 Layer 的初始化. 130\n5.4.3 Layer 的前向计算. 132\n5.5 Caffe 的Net 组装流程 133\n5.6 Caffe 的Solver 计算流程. 139\n5.6.1 优化流程 140\n5.6.2 多卡优化算法 142\n5.7 Caffe 的Data Layer 145\n5.7.1 Datum 结构. 145\n5.7.2 DataReader Thread 147\n5.7.3 BasePrefetchingDataLayer Thread 148\n5.7.4 Data Layer 149\n5.8 Caffe 的Data Transformer 150\n5.8.1 C++ 中的Data Transformer 150\n5.8.2 Python 中的Data Transformer 153\n5.9 模型层扩展实践——Center Loss Layer 156\n5.9.1 Center Loss 的原理 156\n5.9.2 Center Loss 实现. 160\n5.9.3 实验分析与总结. 164\n5.10 总结. 165\n5.11 参考文献. 165\n6 深层网络的数值问题166\n6.1 ReLU 和参数初始化. 166\n6.1.1 第一个ReLU 数值实验. 167\n6.1.2 第二个ReLU 数值实验. 169\n6.1.3 第三个实验——Sigmoid 171\n6.2 Xavier 初始化. 172\n6.3 MSRA 初始化. 178\n6.3.1 前向推导 178\n6.3.2 后向推导 181\n6.4 ZCA 182\n6.5 与数值溢出的战斗. 186\n6.5.1 Softmax Layer 186\n6.5.2 Sigmoid Cross Entropy Loss 189\n6.6 总结. 192\n6.7 参考文献. 192\n7 网络结构193\n7.1 关于网络结构，我们更关心什么 193\n7.2 网络结构的演化 195\n7.2.1 VGG：模型哲学. 195\n7.2.2 GoogLeNet：丰富模型层的内部结构. 196\n7.2.3 ResNet：从乘法模型到加法模型. 197\n7.2.4 全连接层的没落. 198\n7.3 Batch Normalization 199\n7.3.1 Normalization 199\n7.3.2 使用BN 层的实验. 200\n7.3.3 BN 的实现. 201\n7.4 对Dropout 的思考. 204\n7.5 从迁移学习的角度观察网络功能 206\n7.6 ResNet 的深入分析. 210\n7.6.1 DSN 解决梯度消失问题 211\n7.6.2 ResNet 网络的展开结构. 212\n7.6.3 FractalNet 214\n7.6.4 DenseNet 215\n7.7 总结. 217\n7.8 参考文献. 217\n8 优化与训练219\n8.1 梯度下降是一门手艺活儿. 219\n8.1.1 什么是梯度下降法 219\n8.1.2 优雅的步长. 220\n8.2 路遥知马力：动量. 225\n8.3 SGD 的变种算法 232\n8.3.1 非凸函数 232\n8.3.2 经典算法的弯道表现. 233\n8.3.3 Adagrad 234\n8.3.4 Rmsprop 235\n8.3.5 AdaDelta 236\n8.3.6 Adam 237\n8.3.7 爬坡赛. 240\n8.3.8 总结. 242\n8.4 L1 正则的效果. 243\n8.4.1 MNIST 的L1 正则实验. 244\n8.4.2 次梯度下降法 246\n8.5 寻找模型的弱点 251\n8.5.1 泛化性实验. 252\n8.5.2 精确性实验. 255\n8.6 模型优化路径的可视化. 255\n8.7 模型的过拟合. 260\n8.7.1 过拟合方案. 261\n8.7.2 SGD 与过拟合 263\n8.7.3 对于深层模型泛化的猜想. 264\n8.8 总结. 265\n8.9 参考文献. 265\n9 应用：图像的语意分割267\n9.1 FCN 268\n9.2 CRF 通俗非严谨的入门. 272\n9.2.1 有向图与无向图模型. 272\n9.2.2 Log-Linear Model 278\n9.2.3 条件随机场. 280\n9.3 Dense CRF 281\n9.3.1 Dense CRF 是如何被演化出来的. 281\n9.3.2 Dense CRF 的公式形式. 284\n9.4 Mean Field 对Dense CRF 模型的化简 285\n9.5 Dense CRF 的推断计算公式 288\n9.5.1 Variational Inference 推导 289\n9.5.2 进一步化简. 291\n9.6 完整的模型：CRF as RNN 292\n9.7 总结. 294\n9.8 参考文献. 294\n10 应用：图像生成295\n10.1 VAE 295\n10.1.1 生成式模型. 295\n10.1.2 Variational Lower bound 296\n10.1.3 Reparameterization Trick 298\n10.1.4 Encoder 和Decoder 的计算公式. 299\n10.1.5 实现. 300\n10.1.6 MNIST 生成模型可视化 301\n10.2 GAN 303\n10.2.1 GAN 的概念. 303\n10.2.2 GAN 的训练分析. 305\n10.2.3 GAN 实战. 309\n10.3 Info-GAN 314\n10.3.1 互信息. 315\n10.3.2 InfoGAN 模型 317\n10.4 Wasserstein GAN 320\n10.4.1 分布的重叠度 321\n10.4.2 两种目标函数存在的问题. 323\n10.4.3 Wasserstein 距离. 325\n10.4.4 Wasserstein 距离的优势. 329\n10.4.5 Wasserstein GAN 的实现 331\n10.5 总结. 333\n10.6 参考文献. 334","pages":"360","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29480805.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29480805.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29480805.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27074813\/","id":"27074813","publisher":"电子工业出版社","isbn10":"7121317133","isbn13":"9787121317132","title":"深度学习轻松学","url":"https:\/\/api.douban.com\/v2\/book\/27074813","alt_title":"","author_intro":"","summary":"《深度学习轻松学：核心算法与视觉实践》介绍了深度学习基本算法和视觉领域的应用实例。书中以轻松直白的语言，生动详细地介绍了深层模型相关的基础知识，并深入剖析了算法的原理与本质。同时，书中还配有大量案例与源码，帮助读者切实体会深度学习的核心思想和精妙之处。除此之外，书中还介绍了深度学习在视觉领域的应用，从原理层面揭示其思路思想，帮助读者在此领域中夯实技术基础。\n《深度学习轻松学：核心算法与视觉实践》十分适合对深度学习感兴趣，希望对深层模型有较深入了解的读者阅读。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["刘月霞","郭华"],"pubdate":"","tags":[{"count":2,"name":"教育","title":"教育"},{"count":2,"name":"学校教育","title":"学校教育"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"核心素养","title":"核心素养"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29962780.jpg","binding":"平装","translator":[],"catalog":"","pages":"240","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29962780.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29962780.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29962780.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30417014\/","id":"30417014","publisher":"教育科学出版社","isbn10":"7519117510","isbn13":"9787519117511","title":"深度学习:走向核心素养","url":"https:\/\/api.douban.com\/v2\/book\/30417014","alt_title":"","author_intro":"","summary":"为全面深化课程改革，落实立德树人根本任务，从2014年9月起，教育部基础教育课程教材发展中心组织专家团队，在借鉴国外相关研究成果和总结我国课程教学改革经验的基础上，着手研究开发“深度学习”教学改进项目，探索落实学生发展核心素养和各学科课程标准的重要途径和有力抓手。经过4年的研究实验，项目取得了阶段性研究成果,受到了区域、学校和教师的广泛好评，教师的教育教学理念、能力和水平都得到了提高，有力地推动了实验区教研质量的提升和教学改革。为此，将陆续出版“深度学习教学改进丛书”，包括理论普及读本、学科教学指南和教学案例选。本书是理论普及读本，着重阐明以下几个主要问题：1.为什么要推进深度学习；2.什么是深度学习；3.怎样实现深度学习；4.怎样推进深度学习。","price":"35.00"},{"rating":{"max":10,"numRaters":38,"average":"4.6","min":0},"subtitle":"","author":["谢梁","鲁颖","劳虹岚"],"pubdate":"2017-8","tags":[{"count":24,"name":"机器学习","title":"机器学习"},{"count":21,"name":"Python","title":"Python"},{"count":12,"name":"人工智能","title":"人工智能"},{"count":7,"name":"深度学习","title":"深度学习"},{"count":6,"name":"数据挖掘","title":"数据挖掘"},{"count":6,"name":"Keras","title":"Keras"},{"count":5,"name":"keras","title":"keras"},{"count":4,"name":"骗钱","title":"骗钱"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29499730.jpg","binding":"平装","translator":[],"catalog":"1 准备深度学习的环境 1\n1.1 硬件环境的搭建和配置选择  1\n1.1.1 通用图形处理单元  3\n1.1.2 你需要什么样的 GPU 加速卡  6\n1.1.3 你的 GPU 需要多少内存  6\n1.1.4 是否应该用多个 GPU  10\n1.2 安装软件环境  12\n1.2.1 所需软件列表  12\n1.2.2 CUDA 的安装  13\n1.2.3 Python 计算环境的安装  13\n1.2.4 深度学习建模环境介绍  15\n1.2.5 安装 CNTK 及对应的 Keras  17\n1.2.6 安装 Theano 计算环境  23\n1.2.7 安装 TensorFlow 计算环境  25\n1.2.8 安装 cuDNN 和 CNMeM  27\n2 数据收集与处理 28\n2.1 网络爬虫  28\n2.1.1 网络爬虫技术  29\n2.1.2 构造自己的 Scrapy 爬虫  30\n2.1.3 构造可接受参数的 Scrapy 爬虫  35\n2.1.4 运行 Scrapy 爬虫  36\n2.1.5 运行 Scrapy 爬虫的一些要点  38\n2.2 大规模非结构化数据的存储和分析  40\n2.2.1 ElasticSearch 介绍  42\n2.2.2 ElasticSearch 应用实例  44\n3 深度学习简介 57\n3.1 概述  57\n3.2 深度学习的统计学入门  58\n3.3 一些基本概念的解释  61\n3.3.1 深度学习中的函数类型  62\n3.3.2 深度学习中的其他常见概念  65\n3.4 梯度递减算法  67\n3.5 后向传播算法  70\n4 Keras 入门 72\n4.1 Keras 简介  72\n4.2 Keras 中的数据处理  73\n4.2.1 文字预处理  74\n4.2.2 序列数据预处理  82\n4.2.3 图片数据输入  83\n4.3 Keras 中的模型  83\n4.4 Keras 中的重要对象  86\n4.5 Keras 中的网络层构造  90\n4.6 使用 Keras 进行奇异值矩阵分解  102\n5 推荐系统 105\n5.1 推荐系统简介  105\n5.2 矩阵分解模型  108\n5.3 深度神经网络模型  114\n5.4 其他常用算法  117\n5.5 评判模型指标  119\n6 图像识别 121\n6.1 图像识别入门  121\n6.2 卷积神经网络的介绍  122\n6.3 端到端的 MNIST 训练数字识别  127\n6.4 利用 VGG16 网络进行字体识别  131\n6.5 总结  135\n7 自然语言情感分析 136\n7.1 自然语言情感分析简介  136\n7.2 文字情感分析建模  139\n7.2.1 词嵌入技术  139\n7.2.2 多层全连接神经网络训练情感分析  140\n7.2.3 卷积神经网络训练情感分析  143\n7.2.4 循环神经网络训练情感分析  144\n7.3 总结  146\n8 文字生成 147\n8.1 文字生成和聊天机器人  147\n8.2 基于检索的对话系统  148\n8.3 基于深度学习的检索式对话系统  159\n8.3.1 对话数据的构造  159\n8.3.2 构造深度学习索引模型  162\n8.4 基于文字生成的对话系统  166\n8.5 总结  172\n9 时间序列 173\n9.1 时间序列简介  173\n9.2 基本概念  174\n9.3 时间序列模型预测准确度的衡量  178\n9.4 时间序列数据示例  179\n9.5 简要回顾 ARIMA 时间序列模型  181\n9.6 循环神经网络与时间序列模型  186\n9.7 应用案例  188\n9.7.1 长江汉口月度流量时间序列模型  190\n9.7.2 国际航空月度乘客数时间序列模型  203\n9.8 总结  209\n10 智能物联网 210\n10.1 Azure 和 IoT  210\n10.2 Azure IoT Hub 服务  213\n10.3 使用 IoT Hub 管理设备概述  215\n10.4 使用.NET 将模拟设备连接到 IoT 中心  218\n10.5 机器学习应用实例  237","ebook_url":"https:\/\/read.douban.com\/ebook\/45972695\/","pages":"272","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29499730.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29499730.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29499730.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27093647\/","id":"27093647","publisher":"电子工业出版社","isbn10":"7121318725","isbn13":"9787121318726","title":"Keras快速上手：基于Python的深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/27093647","alt_title":"","author_intro":"","summary":"《Keras快速上手：基于Python的深度学习实战》系统地讲解了深度学习的基本知识、建模过程和应用，并以深度学习在推荐系统、图像识别、自然语言处理、文字生成和时间序列中的具体应用为案例，详细介绍了从工具准备、数据获取和处理到针对问题进行建模的整个过程和实践经验，是一本非常好的深度学习入门书。\n不同于许多讲解深度学习的书籍，《Keras快速上手：基于Python的深度学习实战》以实用为导向，选择了 Keras 作为编程框架，强调简单、快速地设计模型，而不去纠缠底层代码，使得内容相当易于理解，读者可以在 CNTK、 TensorFlow 和 Theano 的后台之间随意切换，非常灵活。并且本书能帮助读者从高度抽象的角度去审视业务问题，达到事半功倍的效果。","ebook_price":"38.71","price":"79.00"},{"rating":{"max":10,"numRaters":15,"average":"9.0","min":0},"subtitle":"","author":["吴茂贵","郁明敏","杨本法","李涛","张粤磊"],"pubdate":"2019-11-1","tags":[{"count":6,"name":"好书！","title":"好书！"},{"count":4,"name":"好书，值得一读","title":"好书，值得一读"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"pytorch","title":"pytorch"},{"count":2,"name":"Pytorch","title":"Pytorch"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"pythone","title":"pythone"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33511165.jpg","binding":"平装","translator":[],"catalog":"Contents  目　　录\n前言\n第一部分　PyTorch基础\n第1章　Numpy基础2\n1.1　生成Numpy数组3\n1.1.1　从已有数据中创建数组3\n1.1.2　利用random模块生成数组4\n1.1.3　创建特定形状的多维数组5\n1.1.4　利用arange、linspace函数生成数组6\n1.2　获取元素7\n1.3　Numpy的算术运算9\n1.3.1　对应元素相乘9\n1.3.2　点积运算10\n1.4　数组变形11\n1.4.1　更改数组的形状11\n1.4.2　合并数组14\n1.5　批量处理16\n1.6　通用函数17\n1.7　广播机制19\n1.8　小结20\n第2章　PyTorch基础21\n2.1　为何选择PyTorch？21\n2.2　安装配置22\n2.2.1　安装CPU版PyTorch22\n2.2.2　安装GPU版PyTorch24\n2.3　Jupyter Notebook环境配置26\n2.4　Numpy与Tensor28\n2.4.1　Tensor概述28\n2.4.2　创建Tensor28\n2.4.3　修改Tensor形状30\n2.4.4　索引操作31\n2.4.5　广播机制32\n2.4.6　逐元素操作32\n2.4.7　归并操作33\n2.4.8　比较操作34\n2.4.9　矩阵操作35\n2.4.10　PyTorch与Numpy比较35\n2.5　Tensor与Autograd36\n2.5.1　自动求导要点36\n2.5.2　计算图37\n2.5.3　标量反向传播38\n2.5.4　非标量反向传播39\n2.6　使用Numpy实现机器学习41\n2.7　使用Tensor及Antograd实现机器学习44\n2.8　使用TensorFlow架构46\n2.9　小结48\n第3章　PyTorch神经网络工具箱49\n3.1　神经网络核心组件49\n3.2　实现神经网络实例50\n3.2.1　背景说明51\n3.2.2　准备数据52\n3.2.3　可视化源数据53\n3.2.4　构建模型53\n3.2.5　训练模型54\n3.3　如何构建神经网络？56\n3.3.1　构建网络层56\n3.3.2　前向传播57\n3.3.3　反向传播57\n3.3.4　训练模型58\n3.4　神经网络工具箱nn58\n3.4.1　nn.Module58\n3.4.2　nn.functional58\n3.5　优化器59\n3.6　动态修改学习率参数60\n3.7　优化器比较60\n3.8　小结62\n第4章　PyTorch数据处理工具箱63\n4.1　数据处理工具箱概述63\n4.2　utils.data简介64\n4.3　torchvision简介66\n4.3.1　transforms67\n4.3.2　ImageFolder67\n4.4　可视化工具69\n4.4.1　tensorboardX简介69\n4.4.2　用tensorboardX可视化神经网络71\n4.4.3　用tensorboardX可视化损失值72\n4.4.4　用tensorboardX可视化特征图73\n4.5　本章小结74\n第二部分　深度学习基础\n第5章　机器学习基础76\n5.1　机器学习的基本任务76\n5.1.1　监督学习77\n5.1.2　无监督学习77\n5.1.3　半监督学习78\n5.1.4　强化学习78\n5.2　机器学习一般流程78\n5.2.1　明确目标79\n5.2.2　收集数据79\n5.2.3　数据探索与预处理79\n5.2.4　选择模型及损失函数80\n5.2.5　评估及优化模型81\n5.3　过拟合与欠拟合81\n5.3.1　权重正则化82\n5.3.2　Dropout正则化83\n5.3.3　批量正则化86\n5.3.4　权重初始化88\n5.4　选择合适激活函数89\n5.5　选择合适的损失函数90\n5.6　选择合适优化器92\n5.6.1　传统梯度优化的不足93\n5.6.2　动量算法94\n5.6.3　AdaGrad算法96\n5.6.4　RMSProp算法97\n5.6.5　Adam算法98\n5.7　GPU加速99\n5.7.1　单GPU加速100\n5.7.2　多GPU加速101\n5.7.3　使用GPU注意事项104\n5.8　本章小结104\n第6章　视觉处理基础105\n6.1　卷积神经网络简介105\n6.2　卷积层107\n6.2.1　卷积核108\n6.2.2　步幅109\n6.2.3　填充111\n6.2.4　多通道上的卷积111\n6.2.5　激活函数113\n6.2.6　卷积函数113\n6.2.7　转置卷积114\n6.3　池化层115\n6.3.1　局部池化116\n6.3.2　全局池化117\n6.4　现代经典网络119\n6.4.1　LeNet-5模型119\n6.4.2　AlexNet模型120\n6.4.3　VGG模型121\n6.4.4　GoogleNet模型122\n6.4.5　ResNet模型123\n6.4.6　胶囊网络简介124\n6.5　PyTorch实现CIFAR-10多分类125\n6.5.1　数据集说明125\n6.5.2　加载数据125\n6.5.3　构建网络127\n6.5.4　训练模型128\n6.5.5　测试模型129\n6.5.6　采用全局平均池化130\n6.5.7　像Keras一样显示各层参数131\n6.6　模型集成提升性能133\n6.6.1　使用模型134\n6.6.2　集成方法134\n6.6.3　集成效果135\n6.7　使用现代经典模型提升性能136\n6.8　本章小结137\n第7章　自然语言处理基础138\n7.1　循环神经网络基本结构138\n7.2　前向传播与随时间反向传播140\n7.3　循环神经网络变种143\n7.3.1　LSTM144\n7.3.2　GRU145\n7.3.3　Bi-RNN146\n7.4　循环神经网络的PyTorch实现146\n7.4.1　RNN实现147\n7.4.2　LSTM实现149\n7.4.3　GRU实现151\n7.5　文本数据处理152\n7.6　词嵌入153\n7.6.1　Word2Vec原理154\n7.6.2　CBOW模型155\n7.6.3　Skip-Gram模型155\n7.7　PyTorch实现词性判别156\n7.7.1　词性判别主要步骤156\n7.7.2　数据预处理157\n7.7.3　构建网络157\n7.7.4　训练网络158\n7.7.5　测试模型160\n7.8　用LSTM预测股票行情160\n7.8.1　 导入数据160\n7.8.2　数据概览161\n7.8.3　预处理数据162\n7.8.4　定义模型163\n7.8.5　训练模型163\n7.8.6　测试模型164\n7.9　循环神经网络应用场景165\n7.10　小结166\n第8章　生成式深度学习167\n8.1　用变分自编码器生成图像167\n8.1.1　自编码器168\n8.1.2　变分自编码器168\n8.1.3　用变分自编码器生成图像169\n8.2　GAN简介173\n8.2.1　GAN架构173\n8.2.2　GAN的损失函数174\n8.3　用GAN生成图像175\n8.3.1　判别器175\n8.3.2　生成器175\n8.3.3　训练模型175\n8.3.4　可视化结果177\n8.4　VAE与GAN的优缺点178\n8.5　ConditionGAN179\n8.5.1　CGAN的架构179\n8.5.2　CGAN生成器180\n8.5.3　CGAN判别器180\n8.5.4　CGAN损失函数181\n8.5.5　CGAN可视化181\n8.5.6　查看指定标签的数据182\n8.5.7　可视化损失值182\n8.6　DCGAN183\n8.7　提升GAN训练效果的一些技巧184\n8.8　小结185\n第三部分　深度学习实践\n第9章　人脸检测与识别188\n9.1　人脸识别一般流程188\n9.2　人脸检测189\n9.2.1　目标检测189\n9.2.2　人脸定位191\n9.2.3　人脸对齐191\n9.2.4　MTCNN算法192\n9.3　特征提取193\n9.4　人脸识别198\n9.4.1　人脸识别主要原理198\n9.4.2　人脸识别发展198\n9.5　PyTorch实现人脸检测与识别199\n9.5.1　验证检测代码199\n9.5.2　检测图像200\n9.5.3　检测后进行预处理200\n9.5.4　查看经检测后的图像201\n9.5.5　人脸识别202\n9.6　小结202\n第10章　迁移学习实例203\n10.1　迁移学习简介203\n10.2　特征提取204\n10.2.1　PyTorch提供的预处理模块205\n10.2.2　特征提取实例206\n10.3　数据增强209\n10.3.1　按比例缩放209\n10.3.2　裁剪210\n10.3.3　翻转210\n10.3.4　改变颜色211\n10.3.5　组合多种增强方法211\n10.4　微调实例212\n10.4.1　数据预处理212\n10.4.2　加载预训练模型213\n10.4.3　修改分类器213\n10.4.4　选择损失函数及优化器213\n10.4.5　训练及验证模型214\n10.5　清除图像中的雾霾214\n10.6　小结217\n第11章　神经网络机器翻译实例218\n11.1　Encoder-Decoder模型原理218\n11.2　注意力框架220\n11.3　PyTorch实现注意力Decoder224\n11.3.1　构建Encoder224\n11.3.2　构建简单Decoder225\n11.3.3　构建注意力Decoder226\n11.4　用注意力机制实现中英文互译227\n11.4.1　导入需要的模块228\n11.4.2　数据预处理228\n11.4.3　构建模型231\n11.4.4　训练模型234\n11.4.5　随机采样，对模型进行测试235\n11.4.6　可视化注意力236\n11.5　小结237\n第12章　实战生成式模型238\n12.1　DeepDream模型238\n12.1.1　Deep Dream原理238\n12.1.2　DeepDream算法流程239\n12.1.3　用PyTorch实现Deep Dream240\n12.2　风格迁移243\n12.2.1　内容损失244\n12.2.2　风格损失245\n12.2.3　用PyTorch实现神经网络风格迁移247\n12.3　PyTorch实现图像修复252\n12.3.1　网络结构252\n12.3.2　损失函数252\n12.3.3　图像修复实例253\n12.4　PyTorch实现DiscoGAN255\n12.4.1　DiscoGAN架构256\n12.4.2　损失函数258\n12.4.3　DiscoGAN实现258\n12.4.4　用PyTorch实现从边框生成鞋子260\n12.5　小结262\n第13章　Caffe2模型迁移实例263\n13.1　Caffe2简介263\n13.2　Caffe如何升级到Caffe2264\n13.3　PyTorch如何迁移到Caffe2265\n13.4　小结268\n第14章　AI新方向：对抗攻击269\n14.1　对抗攻击简介269\n14.1.1　白盒攻击与黑盒攻击270\n14.1.2　无目标攻击与有目标攻击270\n14.2　常见对抗样本生成方式271\n14.2.1　快速梯度符号法271\n14.2.2　快速梯度算法271\n14.3　PyTorch实现对抗攻击272\n14.3.1　实现无目标攻击272\n14.3.2　实现有目标攻击274\n14.4　对抗攻击和防御措施276\n14.4.1　对抗攻击276\n14.4.2　常见防御方法分类276\n14.5　总结277\n第15章　强化学习278\n15.1　强化学习简介278\n15.2　Q-Learning原理281\n15.2.1　Q-Learning主要流程281\n15.2.2　Q函数282\n15.2.3　贪婪策略283\n15.3　用PyTorch实现Q-Learning283\n15.3.1　定义Q-Learing主函数283\n15.3.2　执行Q-Learing284\n15.4　SARSA算法285\n15.4.1　SARSA算法主要步骤285\n15.4.2　用PyTorch实现SARSA算法286\n15.5　小结287\n第16章　深度强化学习288\n16.1　DQN算法原理288\n16.1.1　Q-Learning方法的局限性289\n16.1.2　用DL处理RL需要解决的问题289\n16.1.3　用DQN解决方法289\n16.1.4　定义损失函数290\n16.1.5　DQN的经验回放机制290\n16.1.6　目标网络290\n16.1.7　网络模型291\n16.1.8　DQN算法291\n16.2　用PyTorch实现DQN算法292\n16.3　小结295\n附录A　PyTorch0.4版本变更296\n附录B　AI在各行业的最新应用301","ebook_url":"https:\/\/read.douban.com\/ebook\/125619299\/","pages":"307","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33511165.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33511165.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33511165.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34873001\/","id":"34873001","publisher":"机械工业出版社","isbn10":"7111637178","isbn13":"9787111637172","title":"Python深度学习：基于PyTorch","url":"https:\/\/api.douban.com\/v2\/book\/34873001","alt_title":"","author_intro":"★吴茂贵\n资深大数据和人工智能技术专家，就职于中国外汇交易中心，在BI、数据挖掘与分析、数据仓库、机器学习等领域工作超过20年。在基于Spark、TensorFlow、PyTorch、Keras等的机器学习和深度学习方面有大量的工程实践实践。著有《Python深度学习：基于TensorFlow》《深度实践Spark机器学习》《自己动手做大数据系统》等著作。\n★郁明敏\n资深商业分析师，从事互联网金融算法研究工作，专注于大数据、机器学习以及数据可视化的相关领域，擅长 Python、Hadoop、Spark 等技术，拥有丰富的实战经验。曾获“江苏省TI杯大学生电子竞技大赛”二等奖和“华为杯全国大学生数学建模大赛”二等奖。\n★杨本法\n高级算法工程师，在流程优化、数据分析、数据挖掘等领域有10余年实战经验，熟悉Hadoop和Spark技术栈。有大量工程实践经验，做过的项目包括：推荐系统、销售预测系统、舆情监控系统、拣货系统、报表可视化、配送路线优化系统等。\n★李涛\n资深AI技术工程师，对PyTorch、Caffe、TensorFlow等深度学习框架以及计算机视觉技术有深刻的理解和丰富的实践经验，曾经参与和主导过服务机器人、无人售后店、搜索排序等多个人工智能相关的项目。\n★张粤磊\n资深大数据技术专家，飞谷云创始人，有10余年一线数据数据挖掘与分析实战经验。先后在咨询、金融、互联网行业担任大数据平台的技术负责人或架构师。","summary":"这是一本基于最新的Python和PyTorch版本的深度学习著作，旨在帮助读者低门槛进入深度学习领域，轻松速掌握深度学习的理论知识和实践方法，快速实现从入门到进阶的转变。\n本书是多位人工智能技术专家和大数据技术专家多年工作经验的结晶，从工具使用、技术原理、算法设计、案例实现等多个维度对深度学习进行了系统的讲解。内容选择上，广泛涉猎、重点突出、注重实战；内容安排上，实例切入、由浅入深、循序渐进；表达形式上，深度抽象、化繁为简、用图说话。\n本书共16章，分为三部分：\n第一部分（第1~4章） PyTorch基础\n首先讲解了机器学习和数据科学中必然会用到的工具Numpy的使用，然后从多个角度讲解了Pytorch的必备基础知识，最后详细讲解了Pytorch的神经网络工具箱和数据处理工具箱。\n第二部分（第5~8章） 深度学习基础\n\n这部分从技术原理、算法设计、实践技巧等维度讲解了机器学习和深度学习的经典理理论、算法以及提升深度学习模型性能的多种技巧，涵盖视觉处理、NLP和生成式深度学习等主题。\n第三部分（第9~16章） 深度学习实践\n这部分从工程实践的角度讲解了深度学习的工程方法和在一些热门领域的实践方案，具体包括人脸识别、图像修复、图像增强、风格迁移、中英文互译、生成式对抗网络、对抗攻击、强化学习、深度强化学习等内容。","ebook_price":"45.00","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"89元"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["刘衍琦","詹福宇","蒋献文","周华英"],"pubdate":"2017-6","tags":[{"count":7,"name":"计算机视觉","title":"计算机视觉"},{"count":6,"name":"《matlab计算机视觉与深度学习实战》","title":"《matlab计算机视觉与深度学习实战》"},{"count":5,"name":"matlab","title":"matlab"},{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"计算机视觉,matlab,科学","title":"计算机视觉,matlab,科学"},{"count":1,"name":"科学","title":"科学"},{"count":1,"name":"akb","title":"akb"},{"count":1,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29471412.jpg","binding":"平装","translator":[],"catalog":"第 1 章\t基于直方图优化的图像去雾技术\t1\n1.1\t案例背景 1\n1.2\t理论基础 1\n1.2.1    空域图像增强  1\n1.2.2    直方图均衡化  2\n1.3\t程序实现 3\n1.3.1    设计 GUI 界面  4\n1.3.2    全局直方图处理  4\n1.3.3    局部直方图处理  7\n1.3.4    Retinex 增强处理  9\n1.4\t延伸阅读  13\n1.5\t参考文献  13\n第 2 章   基于 形态学的权重自适应图像去噪 \t14\n2.1\t案例背景  14\n2.2\t理论基础  15\n2.2.1    图像去噪方法 15\n2.2.2    数学形态学原理 16\n2.2.3    权重自适应的多结构形态学去噪 16\n2.3\t程序实现  17\n2.4\t延伸阅读  22\n2.5\t参考文献  23\n第 3 章   基于多尺度形态学提取眼前节组织 \t24\n3.1\t案例背景  24\n3.2\t理论基础  25\n3.3\t程序实现  28\n3.3.1    多尺度边缘 28\n3.3.2    主处理函数 29\n3.3.3    形态学处理 31\n3.4\t延伸阅读  33\n3.5\t参考文献  33\n第 4 章   基于 Hough 变化的答题卡识别 \t34\n4.1\t案例背景  34\n4.2\t理论基础  34\n4.2.1    图像二值化 35\n4.2.2    倾斜校正 35\n4.2.3    图像分割 38\n4.3\t程序实现  40\n4.4\t延伸阅读  51\n4.5\t参考文献  51\n第 5 章\t基于阈值分割的车牌定位识别\t52\n5.1\t案例背景  52\n5.2\t理论基础  52\n5.2.1    车牌图像处理 53\n5.2.2    车牌定位原理 57\n5.2.3    车牌字符处理 57\n5.2.4    字符识别 59\n5.3\t程序实现  61\n5.4\t延伸阅读  69\n5.5\t参考文献  69\n第 6 章   基于分水岭分割进行肺癌诊断 \t70\n6.1\t案例背景  70\n6.2\t理论基础  70\n6.2.1    模拟浸水的过程 71\n6.2.2    模拟降水的过程 71\n6.2.3    过度分割问题 71\n6.2.4    标记分水岭分割算法 71\n6.3\t程序实现  72\n6.4\t延伸阅读  77\n6.5\t参考文献  78\n第 7 章   基于主成分分析的人脸二维码识别 \t79\n7.1\t案例背景  79\n7.2\t理论基础  79\n7.2.1    QR 编码简介  80\n7.2.2    QR 编码译码  82\n7.2.3    主成分分析方法 84\n7.3\t程序实现  86\n7.3.1    人脸建库 86\n7.3.2    人脸识别 87\n7.3.3    人脸二维码 88\n7.4\t延伸阅读  93\n7.5\t参考文献  93\n第 8 章   基于知识库的手写体数字识别 \t94\n8.1\t案例背景  94\n8.2\t理论基础  94\n8.2.1    算法流程 94\n8.2.2    特征提取 95\n8.2.3    模式识别 96\n8.3\t程序实现  97\n8.3.1    图像处理 97\n8.3.2    特征提取 98\n8.3.3    模式识别  101\n8.4\t延伸阅读 102\n8.4.1    识别器选择  102\n8.4.2    提高识别率  102\n8.5\t参考文献 102\n第 9 章   基于特征匹配的英文印刷字符识别 \t103\n9.1\t案例背景 103\n9.2\t理论基础 104\n9.2.1    图像预处理  104\n9.2.2    图像识别技术  105\n9.3\t程序实现 106\n9.4\t延伸阅读 112\n9.5\t参考文献 112\n第 10 章   基于不变矩的数字验证码识别 \t113\n10.1\t案例背景  113\n10.2\t理论基础  114\n10.3\t程序实现  114\n10.3.1    设计 GUI 界面· 114\n10.3.2    载入验证码图像 115\n10.3.3    验证码图像去噪 117\n10.3.4    验证码数字定位 118\n10.3.5    验证码归一化 121\n10.3.6    验证码数字识别 122\n10.3.7    手动确认并入库 125\n10.3.8    重新生成模板库 127\n10.4\t延伸阅读  129\n10.5\t参考文献  130\n第 11 章   基于小波技术进行图像融合 \t131\n11.1\t案例背景  131\n11.2\t理论基础  132\n11.3\t程序实现  134\n11.3.1    GUI 设计 134\n11.3.2    图像载入 135\n11.3.3    小波融合 136\n11.4\t延伸阅读  139\n11.5\t参考文献  139\n第 12 章   基于块匹配的全景图像拼接 \t140\n12.1\t案例背景  140\n12.2\t理论基础  140\n12.2.1    图像匹配 141\n12.2.2    图像融合 143\n12.3\t程序实现  144\n12.3.1    设计 GUI 144\n12.3.2    载入图片 145\n12.3.3    图像匹配 147\n12.3.4    图像拼接 150\n12.4\t延伸阅读  156\n12.5\t参考文献  156\n第 13 章   基于霍夫曼图像压缩重建 \t157\n13.1\t案例背景  157\n13.2\t理论基础  157\n13.2.1    霍夫曼编码的步骤 158\n13.2.2    霍夫曼编码的特点 158\n13.3\t程序实现  160\n13.3.1    设计 GUI 160\n13.3.2    压缩重构 161\n13.3.3    效果对比 166\n13.4\t延伸阅读  168\n13.5\t参考文献  169\n第 14 章   基于主成分分析的图像压缩和重建 \t170\n14.1\t案例背景  170\n14.2\t理论基础  170\n14.2.1    主成分降维分析原理 170\n14.2.2    由得分矩阵重建样本 171\n14.2.3    主成分分析数据压缩比 172\n14.2.4    基于主成分分析的图像压缩 172\n14.3\t程序实现  173\n14.3.1    主成分分析源代码 173\n14.3.2    图像和样本间转换 174\n14.3.3    基于主成分分析的图像压缩 175\n14.4\t延伸阅读  178\n14.5\t参考文献  179\n第 15 章   基于小波的图像压缩技术 \t180\n15.1\t案例背景  180\n15.2\t理论基础  181\n15.3\t程序实现  183\n15.4\t延伸阅读  191\n15.5\t参考文献  191\n第 16 章   基于 Hu 不变矩的图像检索技术 \t192\n16.1\t案例背景  192\n16.2\t理论基础  192\n16.3\t程序实现  194\n16.3.1    图像预处理 194\n16.3.2    计算不变矩 194\n16.3.3    图像检索 196\n16.3.4    结果分析 198\n16.4\t延伸阅读  201\n16.5\t参考文献  202\n第 17 章   基于 Harris 的角点特征检测 \t203\n17.1\t案例背景  203\n17.2\t理论基础  204\n17.2.1    Harris 基本原理  204\n17.2.2    Harris 算法流程  206\n17.2.3    Harris 角点性质  206\n17.3\t程序实现  208\n17.3.1    Harris 算法代码  208\n17.3.2    角点检测实例 209\n17.4\t延伸阅读  210\n17.5\t参考文献  211\n第 18 章   基于 GUI 搭建通用视频处理工具 \t212\n18.1\t案例背景  212\n18.2\t理论基础  212\n18.3\t程序实现  214\n18.3.1    GUI 设计 214\n18.3.2    GUI 实现 215\n18.4\t延伸阅读  226\n18.5\t参考文献  226\n第 19 章   基于语音识别的信号灯图像模拟控制技术 \t227\n19.1\t案例背景  227\n19.2\t理论基础  227\n19.3\t程序实现  229\n19.4\t延伸阅读  239\n19.5\t参考文献  240\n第 20 章   基于帧间差法进行视频目标检测 \t241\n20.1\t案例背景  241\n20.2\t理论基础  241\n20.2.1    帧间差分法 242\n20.2.2    背景差分法 243\n20.2.3    光流法 243\n20.3\t程序实现  244\n20.4\t延伸阅读  253\n20.5\t参考文献  253\n第 21 章   路面裂缝检测识别系统设计 \t254\n21.1\t案例背景  254\n21.2\t理论基础  254\n21.2.1    图像灰度化 255\n21.2.2    图像滤波 257\n21.2.3    图像增强 259\n21.2.4    图像二值化 260\n21.3\t程序实现  262\n21.4\t延伸阅读  274\n21.5\t参考文献  274\n第 22 章   基于 K-means 聚类算法的图像区域分割 \t275\n22.1\t案例背景  275\n22.2\t理论基础  275\n22.2.1    K-means 聚类算法原理  275\n22.2.2    K-means 聚类算法的要点  276\n22.2.3    K-means 聚类算法的缺点  277\n22.2.4    基于 K-means 图像分割 278\n22.3\t程序实现  278\n22.3.1    样本之间的巨鹿 278\n22.3.2    提取特征向量 279\n22.3.3    图像聚类分割 280\n22.4\t延伸阅读  282\n22.5\t参考文献  283\n第 23 章   基于光流场的交通汽车检测跟踪 \t284\n23.1\t案例背景  284\n23.2\t理论基础  284\n23.2.1    光流法检测运动原理 284\n23.2.2    光流的主要计算方法 285\n23.2.3    梯度光流场约束方程 287\n23.2.4    Horn-Schunck 光流算法 288\n23.3\t程序实现  290\n23.3.1    计算视觉系统工具箱简介 290\n23.3.2    基于光流场检测汽车运动 291\n23.3.3    搭建 Simulink 运动检测模型 295\n23.4\t延伸阅读  297\n23.5\t参考文献  298\n第 24 章   基于 Simulink 进行图像和视频处理 \t299\n24.1\t案例背景  299\n24.2\t模块介绍  299\n24.2.1    分析和增强模块库（Analysis & Enhancement）· 300\n24.2.2    转化模块库（Conversions） 301\n24.2.3    滤波 3 模块库（Filtering）  301\n24.2.4    几何变换模块库（Geometric Transformations） 302\n24.2.5    形态学操作模块库（Morphological Operations） 302\n24.2.6    输入模块库（Sources） 303\n24.2.7    输出模块库（Sinks）· 303\n24.2.8    统计模块库（Statistics） 304\n24.2.9    文本和图形模块库（Text & Graphic）· 304\n24.2.10    变换模块库（Transforms） 305\n24.2.11    其他工具模块库（Utilities）  305\n24.3\t仿真案例  306\n24.3.1    搭建组织模型 306\n24.3.2    仿真执行模型 308\n24.3.3    代码自动生成 309\n24.4\t延伸阅读  314\n24.5\t参考文献  316\n第 25 章   基于小波变换的数字水印技术 \t317\n25.1\t案例背景  317\n25.2\t理论基础  317\n25.2.1    数字水印技术原理 318\n25.2.2    典型的数字水印算法 320\n25.2.3    数字水印攻击和评价 322\n25.2.4    基于小波的水印技术 323\n25.3\t程序实现  326\n25.3.1    准备载体和水印图像 326\n25.3.2    小波数字水印的嵌入 327\n25.3.3    小波数字水印的提取 331\n25.3.4    小波水印的攻击试验 333\n25.4\t延伸阅读  337\n25.5\t参考文献  337\n第 26 章   基于最小误差法的胸片分割 \t339\n26.1\t案例背景  339\n26.2\t理论基础  339\n26.2.1    图像增强 340\n26.2.2    区域选择 340\n26.2.3    形态学滤波 341\n26.2.4    最小误差法胸片分割 342\n26.3\t程序实现  343\n26.3.1    设计 GUI 界面· 343\n26.3.2    图像预处理 344\n26.3.3    最小误差法分割 348\n26.3.4    形态学后处理 350\n26.4\t延伸阅读  353\n26.5\t参考文献  353\n第 27 章   基于区域生长的肝脏影像分割系统 \t354\n27.1\t案例背景  354\n27.2\t理论基础  355\n27.2.1    阈值分割 355\n27.2.2    区域生长 355\n27.2.3    基于阈值预分割的区域生长 356\n27.3\t程序实现  357\n27.4\t延伸阅读  361\n27.5\t参考文献  361\n第 28 章   基于深度学习的汽车目标检测 \t362\n28.1\t案例背景  362\n28.2\t理论基础  363\n28.2.1    基本架构 363\n28.2.2    卷积层 363\n28.2.3    池化层 365\n28.3\t程序实现  365\n28.3.1    加载数据 365\n28.3.2    构建 CNN 网络 367\n28.3.3    训练 CNN 网络 368\n28.3.4    评估训练效果 370\n28.4\t延伸阅读  372\n28.5\t参考文献  372\n第 29 章   基于计算机视觉的自动驾驶应用 \t374\n29.1\t案例背景  374\n29.2\t理论基础  375\n29.2.1    环境感知 375\n29.2.2    行为决策 375\n29.2.3    路径规划 376\n29.2.4    运动控制 376\n29.3\t程序实现  376\n29.3.1    传感器数据载入 376\n29.3.2    追踪器创建 378\n29.3.3    碰撞预警 380\n29.4\t延伸阅读  385\n29.5\t参考文献  385\n第 30 章   基于深度学习的视觉场景识别 \t386\n30.1\t案例背景  386\n30.2\t理论基础  387\n30.2.1    发展历程 387\n30.2.2    算法思想 387\n30.3\t程序实现  388\n30.3.1    环境配置 388\n30.3.2    数据集制作 389\n30.3.3    网络训练 391\n30.3.4    网络测试 397\n30.4\t延伸阅读  400\n30.5\t参考文献  400","pages":"424","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29471412.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29471412.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29471412.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27065606\/","id":"27065606","publisher":"电子工业出版社","isbn10":"7121315505","isbn13":"9787121315503","title":"MATLAB计算机视觉与深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/27065606","alt_title":"","author_intro":"","summary":"《MATLAB 计算机视觉与深度学习实战》详细讲解了30个 MATLAB 计算机视觉与深度学习案例（含可运行程序），涉及雾霾去噪、答题卡自动阅卷、肺部图像分割、小波数字水印、图像检索、人脸二维码识别、车牌定位及识别、霍夫曼图像压缩、手写数字识别、英文字符文本识别、眼前节组织提取、全景图像拼接、小波图像融合、基于语音识别的音频信号模拟灯控、路面裂缝检测识别、视频运动估计追踪、Simulink 图像处理、胸片及肝脏分割、基于深度学习的汽车目标检测、基于计算机视觉的自动驾驶应用、基于深度学习的视觉场景识别等多项重要技术，涵盖了数字图像处理中几乎所有的基本模块，并延伸到了深度学习的理论及其应用方面。\n工欲善其事，必先利其器，《MATLAB 计算机视觉与深度学习实战》对每个数字图像处理的知识点都提供了丰富生动的案例素材，并详细讲解了其 MATLAB 实验的核心程序，通过对这些示例程序的阅读理解和仿真运行，读者可以更加深刻地理解图像处理的内容，并且更加熟练地掌握 MATLAB 中各种函数在图像处理领域中的用法。\n《MATLAB计算机视觉与深度学习实战》以案例为基础，结构布局紧凑，内容深入浅出，实验简捷高效，适合计算机、信号通信和自动化等相关专业的教师、本科生、研究生，以及广大从事数字图像处理的工程研发人员阅读参考。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"75个有关神经网络建模强化学习与迁移学习的解决方案","author":[],"pubdate":"","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"达内","title":"达内"},{"count":1,"name":"理工","title":"理工"},{"count":1,"name":"Python","title":"Python"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29818795.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29818795.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29818795.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29818795.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30273744\/","id":"30273744","publisher":"","isbn10":"7111598725","isbn13":"9787111598725","title":"Python深度学习实战(75个有关神经网络建模强化学习与迁移学习的解决方案)\/深度学习系","url":"https:\/\/api.douban.com\/v2\/book\/30273744","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":10,"average":"6.2","min":0},"subtitle":"","author":["（日）巣笼悠辅"],"pubdate":"2017-7-14","tags":[{"count":9,"name":"深度学习","title":"深度学习"},{"count":5,"name":"计算科学","title":"计算科学"},{"count":3,"name":"Java","title":"Java"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"Java Deep Learning Essentials","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29507664.jpg","binding":"平装","translator":["陈澎 王磊 陆明"],"catalog":"译者序\n前言\n第1章深度学习概述\n1.1人工智能的变迁\n1.1.1人工智能的定义\n1.1.2人工智能曾经的辉煌\n1.1.3机器学习的演化\n1.1.4机器学习的局限性\n1.2人与机器的区分因素\n1.3人工智能与深度学习\n1.4小结\n第2章机器学习算法——为深度学习做准备\n2.1入门\n2.2机器学习中的训练需求\n2.3监督学习和无监督学习\n2.3.1支持向量机\n2.3.2隐马尔可夫模型\n2.3.3神经网络\n2.3.4逻辑回归\n2.3.5增强学习\n2.4机器学习应用流程\n2.5神经网络的理论和算法\n2.5.1单层感知器\n2.5.2逻辑回归\n2.5.3多类逻辑回归\n2.5.4多层感知器\n2.6小结\n第3章深度信念网络与栈式去\n噪自编码器\n3.1神经网络的没落\n3.2神经网络的复兴\n3.2.1深度学习的进化——突破是什么\n3.2.2预训练的深度学习\n3.3深度学习算法\n3.3.1限制玻尔兹曼机\n3.3.2深度信念网络\n3.3.3去噪自编码器\n3.3.4栈式去噪自编码器\n3.4小结\n第4章dropout和卷积神经网络\n4.1没有预训练的深度学习算法\n4.2dropout\n4.3卷积神经网络\n4.3.1卷积\n4.3.2池化\n4.3.3公式和实现\n4.4小结\n第5章探索Java深度学习库——DL4J、ND4J以及其他\n5.1从零实现与使用库\/框架\n5.2DL4J和 ND4J 的介绍\n5.3使用 ND4J 实现\n5.4使用DL4J实现\n5.4.1设置\n5.4.2构建\n5.4.3CNNMnistExample.java\/LenetMnistExample.java\n5.4.4学习速率的优化\n5.5小结\n第6章实践应用——递归神经网络等\n6.1深度学习热点\n6.1.1图像识别\n6.1.2自然语言处理\n6.2深度学习的挑战\n6.3最大化深度学习概率和能力的方法\n6.3.1面向领域的方法\n6.3.2面向分解的方法\n6.3.3面向输出的方法\n6.4小结\n第7章其他重要的深度\n学习库\n7.1Theano\n7.2TensorFlow\n7.3Caffe\n7.4小结\n第8章未来展望\n8.1深度学习的爆炸新闻\n8.2下一步的展望\n8.3对深度学习有用的新闻资源\n8.4小结","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29507664.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29507664.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29507664.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27103059\/","id":"27103059","publisher":"机械工业出版社","isbn10":"711157298X","isbn13":"9787111572985","title":"深度学习：Java语言实现","url":"https:\/\/api.douban.com\/v2\/book\/27103059","alt_title":"Java Deep Learning Essentials","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"49"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["酆士昌"],"pubdate":"20040501","tags":[{"count":2,"name":"编程","title":"编程"},{"count":2,"name":"llmp,","title":"llmp,"},{"count":2,"name":"Gentoo","title":"Gentoo"},{"count":1,"name":"gentoo","title":"gentoo"},{"count":1,"name":"Linux\/Unix","title":"Linux\/Unix"},{"count":1,"name":"0","title":"0"},{"count":1,"name":"...","title":"..."}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s1383211.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s1383211.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s1383211.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s1383211.jpg"},"alt":"https:\/\/book.douban.com\/subject\/1356146\/","id":"1356146","publisher":"文魁","isbn10":"9861252142","isbn13":"9789861252148","title":"Linux深度學習－Gentoo Linux實戰架設.","url":"https:\/\/api.douban.com\/v2\/book\/1356146","alt_title":"","author_intro":"","summary":"精簡與自制的系統\n超過六千個線上下載的套件\n隨時保持線上最新的套件\n透過簡單的參數彈性的調整套件的模組\n支援X86、Pentium、Power PC、Ultra Sparc、Alpha\n擁有支援64bits CPU的版本\n多樣的核心與檔案系統可供選擇","price":"NT$ 560"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"基于R语言","author":["[美] Joshua F. Wiley 威利"],"pubdate":"2017-9-1","tags":[{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"R","title":"R"},{"count":2,"name":"数据分析","title":"数据分析"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"理工","title":"理工"},{"count":1,"name":"图书馆k","title":"图书馆k"}],"origin_title":"R deep learning Essentials","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29551734.jpg","binding":"平装","translator":["高蓉"],"catalog":"版权\n版权声明\n内容提要\n作者简介\n审阅人简介\n前言\n第1章　深度学习入门\n第2章　训练预测模型\n第3章　防止过拟合\n第4章　识别异常数据\n第5章　训练深度预测模型\n第6章　调节和优化模型\n参考文献","pages":"154","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29551734.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29551734.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29551734.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27147339\/","id":"27147339","publisher":"人民邮电出版社","isbn10":"7115464154","isbn13":"9787115464156","title":"深度学习精要","url":"https:\/\/api.douban.com\/v2\/book\/27147339","alt_title":"R deep learning Essentials","author_intro":"","summary":"本书重点介绍如何将R语言和深度学习模型或深度神经网络结合起来，解决实际的应用需求。全书共6章，分别介绍了深度这习基础知识、训练预测模型、如何防止过拟合、识别异常数据、训练深度预测模型以及调节和优化模型等内容。\n本书适合了解机器学习概念和R语言并想要使用R提供的包来探索深度学习应用的读者学习参考。","price":"CNY 49.00"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["[美]詹妮弗·弗雷德里克斯"],"pubdate":"2015-7-1","tags":[{"count":5,"name":"教育","title":"教育"},{"count":2,"name":"课堂管理","title":"课堂管理"},{"count":2,"name":"育儿","title":"育儿"},{"count":2,"name":"方法论","title":"方法论"},{"count":2,"name":"学习研究","title":"学习研究"},{"count":1,"name":"合作学习","title":"合作学习"},{"count":1,"name":"专注力","title":"专注力"},{"count":1,"name":"专业类-教师知识\/教练技能","title":"专业类-教师知识\/教练技能"}],"origin_title":"Eight Myths of Student Disengagement:Creating Classrooms of Deep Learning","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28260307.jpg","binding":"平装","translator":["宋伟"],"catalog":"致谢\n关于作者\n关于联合撰稿人\n引言\n第一章\n方法1：正确理解专注力的含义，掌握评估专注力的方法\n三种专注力水平的案例分析\n如何正确理解专注力\n为什么要进行专注力评估\n专注力的稳定性、持续时间和变化\n评估专注力的方法\n第二章\n方法2：了解除学生动机之外影响学生专注力的其他因素\n课堂学习任务对专注力的影响\n师生关系对专注力的影响\n同学关系对专注力的影响\n第三章\n方法3：通过课外活动与家长的支持提高学习专注力\n参加课外活动对学业表现的影响\n不同环境下专注力的区别\n自我决定理论和专注力\n家长的支持与学生专注力的关系\n家长参与孩子教育所面临的阻碍\n提高家长在孩子教育上的参与度\n第四章\n方法4：创造使学生专注力更高的课堂任务\n为专注力而设计的课堂任务\n课堂任务的认知组成\n真实情境任务\n真实情境授课方法\n真实情境教学所面临的挑战\n执行认知复杂教学任务的策略\n第五章\n方法5：建立有效的师生关系\n师生关系对学生专注力和成就的影响\n有效的师生关系的基本特征\n在课堂上建立关联性\n支持学生的自主性\n满足学生对能力提升与获得成功的需求\n老师如何提高学生的认知专注力\n培养高质量的师生关系所面临的挑战\n与后进生建立积极的关系\n第六章\n方法6：通过合作与协作学习，打造高效的分组学习\n为什么同学关系很重要\n教师对学生的态度和教学实践对同学关系的影响\n同学间社交活动如何影响专注力\n合作学习和协作学习\n分组学习的挑战\n支持合作和协作学习的核心策略\n建立课堂社群\n第七章\n方法7：使所有学生拥有持久专注力\n为什么防止专注力低下非常重要\n专注力低下的风险因素\n学生为什么专注力低下\n男孩与专注力低下\n学业成绩差与专注力低下\n有行为问题历史的学生与专注力低下\n通过老师、家长的干预提高专注力\n第八章\n方法8：付出努力，而不是被动等待学生专注力的提高","pages":"256","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28260307.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28260307.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28260307.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26453990\/","id":"26453990","publisher":"中国青年出版社","isbn10":"7515333553","isbn13":"9787515333557","title":"提高学生学习专注力的8个方法：打造深度学习课堂","url":"https:\/\/api.douban.com\/v2\/book\/26453990","alt_title":"Eight Myths of Student Disengagement:Creating Classrooms of Deep Learning","author_intro":"詹妮弗·弗雷德里克斯，康涅狄格学院人类发展学教授，专注力和动机研究领域首屈一指的研究者，最早提出专注力是一个多维度概念。她的研究领域涵盖学习专注力、学习动机、课外活动参与等方面，其关于学习专注力的项目获得了美国教育研究协会与教育研究所的资助。目前，詹妮弗正在执行由美国国家科学基金会拨款的一个三年期项目，研究学生在数学和科学课上的参与度与专注力。","summary":"在学校中，尽管有些学生在学习，或者说至少看起来在学习，但他们并没有专注于学习，没有全情投入到学习中。本书介绍了关于专注力的最新研究成果，并探讨了如何将这些研究成果运用到课堂实践中。\n为什么有那么多学生在学校里专注力低下？如何区分学生专注力高和专注力低的课堂？从课外环境中学生的表现我们可以学到什么，并运用到课堂上？课堂任务的类型、师生交流以及同学间的互动对专注力会有什么影响？有没有可能创造出所有学生专注力很高的课堂氛围？本书的目的便是解决上述问题，帮助老师打造所有学生高度参与、深度学习的课堂。\n通过进入课堂观察、采访、问卷调查，作者深入了解了学生专注力低的因素。作者认为只有同时从学生的行为、情感和认知三个维度考虑，才能真正实现深度学习。本书从这三个维度展开，提供了8个提高学生专注力的方法。本书的“专注力实践”部分，由3名中小学老师撰写，分享了她们打造深度学习课堂的具体方法与案例。","price":"35"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"批判性思维与自主性探究式学习","author":["莫妮卡·R.马丁内斯","丹尼斯·麦格拉思"],"pubdate":"2019-6-6","tags":[{"count":6,"name":"教育改革","title":"教育改革"},{"count":3,"name":"教育","title":"教育"},{"count":3,"name":"学习","title":"学习"},{"count":2,"name":"核心能力打造","title":"核心能力打造"},{"count":2,"name":"学习方法","title":"学习方法"},{"count":1,"name":"思维","title":"思维"},{"count":1,"name":"1","title":"1"}],"origin_title":"Deeper Learning：How Eight Innovative Public Schools Are Transforming Education in the Twenty-First Century","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33321551.jpg","binding":"精装","translator":["唐奇"],"catalog":"第一章  联  系\n这所学校可能适合我\n推陈出新的社团\n迎新仪式\n互联的社团\n如果墙会说话\n民主、自治和灵活性\n团结力量大\n深度学习蓝图\n第二章  赋  权\n“孩子们希望这样学习”\n实践出真知\n无聊的反义词\n项目的优点与难点\n为人师表\n批判性思维\n“学校就是修改作业的地方”\n学生带头\n展示与评价\n安全网\n深度学习蓝图\n第三章  情 境 化\n登山纪录片\n万物皆联系\n失落的环节\n让问题做向导\n“如果学校就是现实生活呢？”\n专业学习社团、评价和高预期\n学习是一趟旅程\n深度学习蓝图\n第四章  延  伸\n大开眼界\n伙伴的力量\n位置，位置，位置\n受益终生的“好伙伴”\n劳动力储备的下降\n“伙伴”和社区能得到什么？\n强大人际网络的艺术\n深度学习蓝图\n第五章  激  励\n投石问路\n点燃引信\n解开耳机线\n拒绝千篇一律\n“双修”课程的力量\n从最想要的结果开始\n深度学习蓝图\n第六章  联  网\n新闻无处不在\n现实的字节\n预备，点击\n研究、反思和修改的合作社团\n走向世界\n出发前的准备\n错误的联网方式\n深度学习的联网方式\n深度学习蓝图\n第七章  投  资\n更美好的生活\n不尽如人意\n深度学习为什么至关重要","ebook_url":"https:\/\/read.douban.com\/ebook\/125442604\/","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33321551.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33321551.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33321551.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34464347\/","id":"34464347","publisher":"中国人民大学出版社","isbn10":"7300269400","isbn13":"9787300269405","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34464347","alt_title":"Deeper Learning：How Eight Innovative Public Schools Are Transforming Education in the Twenty-First Century","author_intro":"莫妮卡•R.马丁内斯（Monica R. Martinez）\n美国XQ研究院首席学校支持官。作为新技术联盟（New Tech Network）的前主席和知识工场（KnowledgeWorks）的前副主席，她曾被奥巴马任命为拉丁裔优质教育总统顾问委员会成员。\n丹尼斯•麦格拉思（Dennis McGrath）\n美国费城社区学院社会学教授，曾获克里斯蒂安.R和玛丽•F•林德贝克杰出教育奖，与马丁•B.斯皮尔合著《社区学院的学术危机》一书。","summary":"AI时代，今天的学生如何面对明天与智能机器人的竞争？如何让学生不在是为明天可能消失的工作所学?他们应该具备哪些核心素养和能力？如何培养这些核心素养和能力？\n本书作者，教育战略家莫妮卡•R.马丁内斯和社会学家丹尼斯•麦格拉思提出深度学习的目标即培养“学会学习的能力”。认为深度学习的过程不仅能让学生掌握课业内容，而且能够培养批判性思维和解决复杂问题的能力，培养合作和有效沟通的能力，使学生成为拥有探究精神的自主学习者。  本书基于美国八所公立高中的案例，阐述了“深度学习”的六项核心策略。\n（1）赋权，让学生成为学习的主宰；\n(2)   情境化，按主题整合多学科内容；\n（3）力求真实，让学生与专业领域专家共同工作；\n（4）延伸，将学习延伸到校外；\n（5）激励，为每个学生提供定制化学习；\n（6）联网，让技术成为深化学生学习的工具。\n这八所学校的实践证明，恰恰是那些被调动了自主性学习与探究热情的学生，对知识的掌握远远超越了传统的死记硬背模式下的学生。本书为教师、教育政策制定者提供了教育改革和课程改革的范例，也为学生和家长了解探究式学习方式提供了切实的帮助。","ebook_price":"23.40","price":"39"},{"rating":{"max":10,"numRaters":179,"average":"5.6","min":0},"subtitle":"彻底解决你的知识焦虑","author":["今井睦美"],"pubdate":"2018-4-17","tags":[{"count":37,"name":"学习方法","title":"学习方法"},{"count":26,"name":"方法论","title":"方法论"},{"count":22,"name":"学习","title":"学习"},{"count":19,"name":"自我认知","title":"自我认知"},{"count":18,"name":"日本","title":"日本"},{"count":16,"name":"记忆","title":"记忆"},{"count":12,"name":"认知科学","title":"认知科学"},{"count":7,"name":"自我完善","title":"自我完善"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29740565.jpg","binding":"平装","translator":["罗梦迪"],"catalog":"前言\n第一章　记忆与知识\n1．过目不忘的秘密\n2．走出知识误区\n第二章　如何创建知识体系\n1．从力所能及的事情做起\n2．学习词语含义的方法\n3．知识系统的构建\n4．概念的创造\n第三章　学习必须跨越的障碍\n1．连小孩都懂的物理法则\n2．错误的图式\n3．臆想的陷阱\n4．母语的图式和外语的学习\n5．克服错误的图式\n第四章　深度学习的方法\n1．何为熟练\n2．技能的自动化与动作记忆\n3．直观能力从何而来\n第五章　熟练带来的大脑变化\n1．大脑的构造与熟练\n2．大脑是怎样变化的\n3．向他人学习时大脑的变化\n4．直觉在哪里\n第六章　学习思维与批判性思维\n1．知识观决定学习\n2．如何获得活知识\n3．背诵真的无济于事吗\n4．活知识与认识论\n第七章　成为超一流达人\n1．如何训练\n2．是努力还是才能\n3．熟练与创造性\n4．所谓的天才是怎样的人\n终章　探究者的培养\n1．培养探究者的简单铁则\n2．在游戏中培养探究心\n3．自主学习\n结语\n参考文献","ebook_url":"https:\/\/read.douban.com\/ebook\/51263313\/","pages":"145","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29740565.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29740565.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29740565.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30194996\/","id":"30194996","publisher":"北京联合出版公司","isbn10":"7559614477","isbn13":"9787559614476","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30194996","alt_title":"","author_intro":"今井睦美\n日本知名认知科学家\n日本庆应义塾大学、美国西北大学心理学博士，现任庆应义塾大学环境信息学部教授，活跃于日本和国际学术界的认知科学、发展心理学、语言心理学专家，著有《新•人类的学习》《语言与思考》《语言与身体性》《解开语言发展之谜》《记忆语言的计划》等著作。","summary":"任何领域的一流达人，都是不停学习并付诸实践的探究者，本书能让你的认知升级，彻底改造你的大脑。\n——今井睦美\n“自主学习”、“一万小时”、“高效记忆”、“批判性思维”、“解决问题的能力”……学习概念层出不穷，哪一种才是适合你的学习方法？\n日本知名认知科学家今井睦美在这本书里深度探究，什么才是有效、长期的学习，在终身学习时代，如何解放大脑，学到极致。\n解读所谓天才的思维结构，揭开成为高手的秘密；破除自主学习、“一万小时”等概念误区，帮助你找到更适用的学习方式。","ebook_price":"16.80","price":"42.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"主流框架和编程实战","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30314852\/","id":"30314852","publisher":"","isbn10":"7111592395","isbn13":"9787111592396","title":"深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30314852","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"內行人的做法","author":["Josh Patterson","Adam Gibson"],"pubdate":"2019-1","tags":[],"origin_title":"Deep Learning: A Practitioner’s Approach","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s30457684.jpg","binding":"平装","translator":["藍子軒"],"catalog":"前言\nchapter 01　機器學習\nchapter 02　神經網路和深度學習的基礎\nchapter 03　深度網路基礎\nchapter 04　深度網路的主要架構\nchapter 05　打造深度網路\nchapter 06　深度網路的調整\nchapter 07　特定深度網路架構的調整\nchapter 08　向量化\nchapter 09　Spark 上使用深度學習與 DL4J\nappendix A　什麼是人工智慧？\nappendix B　RL4J 與強化學習\nappendix C　大家都應該知道的幾個數字\nappendix D　神經網路與反向傳播：數學做法\nappendix E　使用 ND4J API\nappendix F　使用 DataVec\nappendix G　使用 DL4J 的源程式碼\nappendix H　設定 DL4J 專案\nappendix I　設定 DL4J 專案\nappendix J　DL4J 安裝問題排除\n索引","pages":"576","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s30457684.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s30457684.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s30457684.jpg"},"alt":"https:\/\/book.douban.com\/subject\/31542571\/","id":"31542571","publisher":"歐萊禮","isbn10":"9865020262","isbn13":"9789865020262","title":"深度學習","url":"https:\/\/api.douban.com\/v2\/book\/31542571","alt_title":"Deep Learning: A Practitioner’s Approach","author_intro":"Josh Patterson\nJosh Patterson is currently VP of Field Engineering for Skymind. Previously, Josh worked as a Principal Solutions Architect at Cloudera and as a machine learning and distributed systems engineer at the Tennessee Valley Authority.\nAdam Gibson\nAdam Gibson is the CTO of Skymind. Adam has worked with Fortune 500 companies, hedge funds, PR firms, and startup accelerators to create their machine learning projects. He has a strong track record helping companies handle and interpret big realtime data.","summary":"雖然人們對機器學習的興趣已來到很高的程度，但過高的期望往往無法讓專案走得太遠。機器學習（尤其是深度神經網路）在您的組織中，究竟能發揮什麼樣真正的作用呢？這本實戰指南不僅提供此主題相關的最實用資訊，還可協助您開始構建高效的深度學習網路。\n本書提供了許多關於深度學習調整、平行化、向量化與構建流程的基礎知識。雖然本書是引用開源Deeplearning4j（DL4J）函式庫來開發生產級工作流程，但裡頭所介紹的基礎知識，適用於任何函式庫。透過真實世界中的範例，您將學習到如何運用DL4J訓練深度網路架構，以及在Spark與Hadoop上運行深度學習工作流程的方法與策略。\n■ 深入了解機器學習、尤其是深度學習的整體概念\n■ 了解神經網路進化到深度網路的歷程\n■ 探索一些主要的深度網路架構，包括卷積網路（CNN）與遞廻網路（RNN）\n■ 學習如何針對特定的問題，找出正確對應的深度網路架構\n■ 針對一般神經網路與特定的深度網路架構，完整介紹調整相關的基礎知識\n■ 透過DL4J的工作流程工具DataVec，把向量化技術運用到不同的資料型態上\n■ 了解如何在Spark與Hadoop 上，以原生方式使用DL4J","price":"NT$780"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"使用TensorFlow","author":["Giancarlo Zaccone"],"pubdate":"2017-1-11","tags":[{"count":2,"name":"深度学习","title":"深度学习"}],"origin_title":"Getting started with TensorFlow","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29332712.jpg","binding":"平装","translator":["傅運文"],"catalog":"Chapter 1 TensorFlow：基本概念\n機器學習與深度學習的基礎\nTensorFlow：總體概述\nPython的基礎\n安裝TensorFlow\n第一次實地操作\n資料流圖形\nTensorFlow程式設計模型\n如何使用TensorBoard\n總結\nChapter 2 用TensorFlow求解數學問題\n張量資料結構\n複數及碎形（fractals）\n計算梯度（gradient）\n隨機數值\n總結\nChapter 3 機器學習簡介與應用\n線性迴歸演算法\n分類（Classifiers）\n資料群集（Data clustering）\n總結\nChapter 4 類神經網路簡介\n什麼是類神經網路？\n單層感知器\n邏輯斯迴歸（logistic regression）\n多層感知器\n多層感知器函數近似（function approximation）\n總結\nChapter 5 深度學習\n深度學習技術\n卷積神經網路CNN\nCNN架構\nCNN的TensorFlow實作\n遞迴神經網路RNN\nRNN架構\nLSTM網路\n使用TensorFlow進行自然語言處理\n總結\nChapter 6 GPU程式設計和TensorFlow服務\nGPU程式設計\nTensorFlow服務（TensorFlow Serving）\n如何安裝TensorFlow Serving\n如何使用TensorFlow Serving\n訓練和輸出模型\n執行session\n載入與輸出一個TensorFlow模型\n測試伺服器\n總結","pages":"160","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29332712.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29332712.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29332712.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26970253\/","id":"26970253","publisher":"博碩","isbn10":"9864341790","isbn13":"9789864341795","title":"深度學習快速入門","url":"https:\/\/api.douban.com\/v2\/book\/26970253","alt_title":"Getting started with TensorFlow","author_intro":"Giancarlo Zaccone\n在科學和工業領域擁有10 多年專案管理研究的經驗。他在國家研究委員會C.N.R 擔任研究員，在那裡，他參與了平行數值計算和科學可視化相關的研究專案。\n目前，他是一家諮詢公司的高級軟體工程師，維護太空和國防應用軟體系統。Giancarlo 擁有那不勒斯的Federico II 物理學碩士學位，並研習了羅馬La Sapienza科學計算二級研究生碩士學程。\n他也是《Python Parallel Programming Cookbook》的作者。\n你可以透過it.linkedin.com\/in\/giancarlozaccone 與他取得聯繫。","summary":"約莫20年前，小編正在知識工程實驗室做研究時，人工智慧與機器學習是當時研究室的研究主軸，人工智慧更是資訊工程與科學博士班資格考的科目之一。然而在哪個年代，有許多教授並不看好這個領域能在短期內獲得突飛猛進的成果，原因在於，相關理論研究都已存在數十年了，即便是1997年廣為人知的深藍超級電腦，也只是靠著優異的硬體設備來打敗西洋棋王（採用的僅僅是暴力搜尋法，沒什麼好做學問的）。而圍棋規則所造成的複雜度（分支過多，導致無法單純依靠硬體設備來求勝）一直無法在人工智慧上取得突破。\n2016年情勢有所轉變，AlphaGo終於打敗了圍棋棋王，貢獻者黃士傑說明了所使用的是「深度學習」，這下子可不得了，「深度學習」霎那間熱門起來了，連帶再次炒熱了機器學習領域。在眾多求職網站上，到處都可以找到徵求具有深度學習專長的職缺，並且薪資頗高。對此，有許多離開校園五年以上的職場高手也想躍躍欲試，但又對於本身的能力有所懷疑，最常聽到他們這樣說：「人工智慧我學得還不錯，機器學習也修過一次課，但從沒學過深度學習耶！」如果您也是這樣的人，那麼這本書可以做為您快速入門「深度學習」的參考書。\n其實說到底，「深度學習」仍舊是由機器學習的一環衍生出來的，而機器學習又是人工智慧的一環；講得更明白一點，深度學習有時其實不過就是一種特殊的類神經網路罷了，聽到「類神經網路」，您應該覺得熟悉多了吧！或許您同時也會覺得，那好像也沒什麼了不起。\n的確如此，先來看看AlphaGo貢獻者黃士傑的博士論文吧，那是關於蒙地卡羅樹枝搜尋法在電腦圍棋程式的運用。您或許會問，蒙地卡羅方法不是幾十年前就發明了嗎？是的，AlphaGo當然沒有那麼簡單，但現今與數十年前最主要的變化是GPU誕生了，並且效能獲得大幅提升且日益普及（成本下降），而「深度學習」充分利用了這一點，將相關演算法的運算分配給為數眾多的GPU核心去處理，達到了效能上的要求。\n為了快速理解「深度學習」，小編替各位讀者挑選了本書，作為深度學習的入門書籍（這或許是第一本關於深度學習的繁體中文書籍），深度學習的原理與技術細節其實不只一種，各家大廠對此都投入頗深，當中又以Google堪稱現今人工智慧領域的霸主。因此小編選了這本書，因為AlphaGo正是由Google研發出來的，而為了讓更多人參與科技的發展，Google甚至提供了TensorFlow這個可有效運用GPU的深度學習框架，以開放原始碼的方式提供給所有IT技術人員，以期集合眾人之力來改變這個世界。\n話說，TensorFlow雖然因著深度學習而紅，但萬丈高樓平地起，蒙地卡羅方法的關鍵在於加入了機率這個概念，因此，本書將從使用TensorFlow求解數學問題開始介紹，進而朝向機器學習與類神經網路邁進，在此同時，您將回顧以往熟悉的線性迴歸、分類（Classifiers）與最近鄰居演算法、群集（clustering）與k-means演算法、單層感知器、邏輯斯迴歸、多層感知器等等知識，並使用TensorFlow來建立模型與求解問題。到了本書的後半段，將正式進入深度學習與GPU程式設計的議題，包含卷積神經網路CNN與遞迴神經網路RNN等兩種最知名的深度學習模型，並且在本書的末尾，也將介紹一個TensorFlow Serving，它是一種RPC，可以提供客戶端服務，伺服器可成功載入並執行經過訓練的TensorFlow模型，讓您沒有太多硬體上的顧慮。這使得實驗室裡的機器學習模型得以正式成為生產系統。\n不用再徬徨，現在就透過《深度學習快速入門—使用TensorFlow》這本書，展開您的深度學習的旅程吧！","price":"NT$360"},{"rating":{"max":10,"numRaters":29,"average":"5.1","min":0},"subtitle":"","author":["廖星宇"],"pubdate":"2017-10-1","tags":[{"count":16,"name":"深度学习","title":"深度学习"},{"count":14,"name":"pytorch","title":"pytorch"},{"count":6,"name":"deeplearning","title":"deeplearning"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"编程","title":"编程"},{"count":1,"name":"理学\/工学","title":"理学\/工学"},{"count":1,"name":"中文版","title":"中文版"},{"count":1,"name":"中国","title":"中国"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29585093.jpg","binding":"平装","translator":[],"catalog":"第 1 章 深度学习介绍 1\n1.1 人工智能 1\n1.2 数据挖掘、机器学习与深度学习2\n1.2.1 数据挖掘 3\n1.2.2 机器学习 3\n1.2.3 深度学习 4\n1.3 学习资源与建议 8\n第 2 章 深度学习框架 11\n2.1 深度学习框架介绍 . 11\n2.2 PyTorch 介绍. 13\n2.2.1 什么是 PyTorch. 13\n2.2.2 为何要使用 PyTorch 14\n2.3 配置 PyTorch 深度学习环境 15\n2.3.1 操作系统的选择. 15\n2.3.2 Python 开发环境的安装 16\n2.3.3 PyTorch 的安装. 18\n第 3 章 多层全连接神经网络 24\n3.1 热身：PyTorch 基础 24\n3.1.1 Tensor（张量）. 24\n3.1.2 Variable（变量）26\n3.1.3 Dataset（数据集）28\n3.1.4 nn.Module（模组） 29\n3.1.5 torch.optim（优化） 30\n3.1.6 模型的保存和加载 31\n3.2 线性模型 32\n3.2.1 问题介绍 32\n3.2.2 一维线性回归33\n3.2.3 多维线性回归34\n3.2.4 一维线性回归的代码实现. 35\n3.2.5 多项式回归 38\n3.3 分类问题 42\n3.3.1 问题介绍 42\n3.3.2 Logistic 起源 42\n3.3.3 Logistic 分布 42\n3.3.4 二分类的 Logistic 回归 43\n3.3.5 模型的参数估计. 44\n3.3.6 Logistic 回归的代码实现45\n3.4 简单的多层全连接前向网络 . 49\n3.4.1 模拟神经元 49\n3.4.2 单层神经网络的分类器 50\n3.4.3 激活函数 51\n3.4.4 神经网络的结构. 54\n3.4.5 模型的表示能力与容量 55\n3.5 深度学习的基石：反向传播算法57\n3.5.1 链式法则 57\n3.5.2 反向传播算法58\n3.5.3 Sigmoid 函数举例58\n3.6 各种优化算法的变式59\n3.6.1 梯度下降法 59\n3.6.2 梯度下降法的变式 62\n3.7 处理数据和训练模型的技巧 . 64\n3.7.1 数据预处理 64\n3.7.2 权重初始化 66\n3.7.3 防止过拟合 67\n3.8 多层全连接神经网络实现 MNIST 手写数字分类 69\n3.8.1 简单的三层全连接神经网络70\n3.8.2 添加激活函数70\n3.8.3 添加批标准化71\n3.8.4 训练网络 71\n第 4 章 卷积神经网络 76\n4.1 主要任务及起源 76\n4.2 卷积神经网络的原理和结构 . 77\n4.2.1 卷积层80\n4.2.2 池化层84\n4.2.3 全连接层 85\n4.2.4 卷积神经网络的基本形式. 85\n4.3 PyTorch 卷积模块 . 87\n4.3.1 卷积层87\n4.3.2 池化层88\n4.3.3 提取层结构 90\n4.3.4 如何提取参数及自定义初始化 91\n4.4 卷积神经网络案例分析. 92\n4.4.1 LeNet. 93\n4.4.2 AlexNet94\n4.4.3 VGGNet 95\n4.4.4 GoogLeNet . 98\n4.4.5 ResNet100\n4.5 再实现 MNIST 手写数字分类 . 103\n4.6 图像增强的方法 105\n4.7 实现 cifar10 分类 107\n第 5 章 循环神经网络 111\n5.1 循环神经网络111\n5.1.1 问题介绍 112\n5.1.2 循环神经网络的基本结构. 112\n5.1.3 存在的问题 115\n5.2 循环神经网络的变式：LSTM 与 GRU 116\n5.2.1 LSTM. 116\n5.2.2 GRU. 119\n5.2.3 收敛性问题 120\n5.3 循环神经网络的 PyTorch 实现 122\n5.3.1 PyTorch 的循环网络模块122\n5.3.2 实例介绍 127\n5.4 自然语言处理的应用131\n5.4.1 词嵌入131\n5.4.2 词嵌入的 PyTorch 实现 133\n5.4.3 N Gram 模型 133\n5.4.4 单词预测的 PyTorch 实现134\n5.4.5 词性判断 136\n5.4.6 词性判断的 PyTorch 实现137\n5.5 循环神经网络的更多应用140\n5.5.1 Many to one 140\n5.5.2 Many to Many（shorter）141\n5.5.3 Seq2seq141\n5.5.4 CNN+RNN . 142\n第 6 章 生成对抗网络 144\n6.1 生成模型 144\n6.1.1 自动编码器 145\n6.1.2 变分自动编码器. 150\n6.2 生成对抗网络153\n6.2.1 何为生成对抗网络 153\n6.2.2 生成对抗网络的数学原理. 160\n6.3 Improving GAN164\n6.3.1 Wasserstein GAN. 164\n6.3.2 Improving WGAN167\n6.4 应用介绍 168\n6.4.1 Conditional GAN. 168\n6.4.2 Cycle GAN . 170\n第 7 章 深度学习实战 173\n7.1 实例一——猫狗大战：运用预训练卷积神经网络进行特征提取与预测 . 173\n7.1.1 背景介绍 174\n7.1.2 原理分析 174\n7.1.3 代码实现 177\n7.1.4 总结. 183\n7.2 实例二——Deep Dream：探索卷积神经网络眼中的世界183\n7.2.1 原理介绍 184\n7.2.2 预备知识：backward . 185\n7.2.3 代码实现 190\n7.2.4 总结. 195\n7.3 实例三——Neural-Style：使用 PyTorch 进行风格迁移196\n7.3.1 背景介绍 196\n7.3.2 原理分析 197\n7.3.3 代码实现 199\n7.3.4 总结. 205\n7.4 实例四——Seq2seq：通过 RNN 实现简单的 Neural Machine Translation . 205\n7.4.1 背景介绍 206\n7.4.2 原理分析 206\n7.4.3 代码实现 209\n7.4.4 总结. 221","pages":"232","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29585093.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29585093.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29585093.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27176661\/","id":"27176661","publisher":"电子工业出版社","isbn10":"7121326205","isbn13":"9787121326202","title":"深度学习入门之PyTorch","url":"https:\/\/api.douban.com\/v2\/book\/27176661","alt_title":"","author_intro":"廖星宇，目前就读于中国科学技术大学应用数学系，获得国家一等奖学金。在个人博客、知乎等平台上发布多篇关于深度学习的文章，具有一定的阅读量和人气。","summary":"《深度学习入门之PyTorch》深度学习如今已经成为科技领域最炙手可热的技术，在《深度学习入门之PyTorch》中，我们将帮助你入门深度学习。《深度学习入门之PyTorch》将从机器学习和深度学习的基础理论入手，从零开始学习 PyTorch，了解 PyTorch 基础，以及如何用 PyTorch 框架搭建模型。通过阅读《深度学习入门之PyTorch》，你将学到机器学习中的线性回归和 Logistic 回归、深度学习的优化方法、多层全连接神经网络、卷积神经网络、循环神经网络，以及生成对抗网络，最后通过实战了解深度学习前沿的研究成果，以及 PyTorch 在实际项目中的应用。《深度学习入门之PyTorch》将理论和代码相结合，帮助读者更好地入门深度学习，适合任何对深度学习感兴趣的人阅读。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["程显毅"],"pubdate":"","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":2,"name":"R","title":"R"},{"count":1,"name":"未来","title":"未来"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29880501.jpg","binding":"","translator":[],"catalog":"前言\n第1章引言\n1.1关于深度学习\n1.1.1深度学习兴起的渊源\n1.1.2深度学习总体框架\n1.1.3深度学习本质\n1.1.4深度学习应用\n1.2前向反馈神经网络FNN\n1.2.1多层感知器\n1.2.2神经元的作用\n1.2.3激活函数\n1.2.4学习算法\n1.3R语言基础\n1.3.1入门\n1.3.2基本语法\n1.3.3数据\n1.3.4绘图\n1.3.5数据准备\n1.3.6基本运算\n1.4FNN的R实现\n1.5学习指南\n第2章深度神经网络DNN\n2.1DNN原理\n2.2DNN应用\n2.2.1提高雾天视觉能见度\n2.2.2打击黑客和网络犯罪\n2.2.3图像压缩\n2.2.4函数逼近\n2.3DNN应用需要注意的一些问题\n2.3.1神经元数量\n2.3.2最佳层数的选择\n2.3.3训练时间过长\n2.3.4过拟合\n2.4DNN应用技巧\n2.5单响应变量DNN的R实现\n2.6多响应变量DNN的R实现\n2.7学习指南\n第3章卷积神经网络CNN\n3.1CNN原理\n3.1.1局部感知\n3.1.2权值共享\n3.1.3多卷积核\n3.1.4池化\n3.2多层卷积\n3.2.1ImageNet-2010网络结构\n3.2.2DeepID网络结构\n3.3CNN的R实现\n3.4学习指南\n第4章递归神经网络RNN\n4.1RNN原理\n4.2Elman网络\n4.2.1承接层神经元的作用\n4.2.2信息流动\n4.2.3Elman网络应用\n4.3Jordan网络\n4.3.1Jordan网络结构\n4.3.2Jordan网络应用\n4.4RNN的R实现\n4.5学习指南\n第5章自编码网络AE\n5.1无监督学习过程\n5.2AE基本结构\n5.2.1降维问题\n5.2.2特征抽取\n5.3稀疏自动编码网络SAE\n5.3.1Kullback-Leibler散度\n5.3.2使用SAE注意事项\n5.4SAE的R实现\n5.5学习指南\n第6章堆栈自编码网络SA\n6.1SA原理\n6.2SA的R实现\n6.3降噪自编码网络DAE\n6.3.1随机掩蔽的椒盐噪声\n6.3.2DAE基本任务\n6.3.3标准化堆栈降噪自编码网络\n6.4DAE的R实现\n6.5学习指南\n第7章受限玻耳兹曼机RBM\n7.1RBM原理\n7.1.1玻耳兹曼机的四类知识\n7.1.2能量和概率的作用\n7.1.3联合概率分布表示的自编码网络\n7.1.4模型学习的目标\n7.2训练技巧\n7.2.1技巧1：Gibbs采样\n7.2.2技巧2: 最小化KL距离\n7.2.3技巧3：使用RLU激活函数\n7.2.4技巧4：模拟退火\n7.3对深度学习的质疑\n7.4RBM应用\n7.4.1肝癌分类的RBM\n7.4.2麻醉镇定作用预测的RBM\n7.5RBM的R实现\n7.6学习指南\n第8章深度置信网络DBN\n8.1DBN原理\n8.2应用案例\n8.3DBN的R实现\n8.4学习指南\n第9章MXNetR\n9.1MXNet技术特性\n9.2MXNetR安装\n9.2.1安装MXNet基本需求\n9.2.2MXNet云设置\n9.2.3MXNet安装方法\n9.2.4MXNetR安装方法\n9.2.5常见的安装问题\n9.3MXNetR在深度学习中的应用\n9.3.1二分类模型\n9.3.2回归模型与自定义神经网络\n9.3.3手写数字竞赛\n9.3.4图像识别应用\n9.4学习指南\n第10章word2vec的R语言实现\n10.1word2vec词向量由来\n10.1.1统计语言模型\n10.1.2神经网络概率语言模型\n10.2word2vec——词向量特征提取模型\n10.2.1词向量\n10.2.2CBOW的分层网络结构——HCBOW\n10.2.3word2vec流程\n10.3word2vec 的R实现\n10.3.1tmcn.word2vec包\n10.3.2word2vec自编译函数\n10.3.3使用tmcn.word2vec和word2vec注意的问题\n10.4学习指南\n第11章R语言其他深度学习包\n11.1darch包\n11.2Rdbn包\n11.2.1Rdbn原理\n11.2.2Rdbn安装\n11.2.3Rdbn应用\n11.3H2O 包\n11.3.1H2O原理\n11.3.2H2O应用\n11.4deepnet包\n11.5mbench包\n11.6AMORE包\n11.7学习指南\n附录\n附录A深度学习发展史\n附录B深度学习的未来——GAN\n附录CR包分类\n参考文献\n后记","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29880501.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29880501.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29880501.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27085471\/","id":"27085471","publisher":"机械工业出版社","isbn10":"7111570731","isbn13":"9787111570738","title":"深度学习与R语言","url":"https:\/\/api.douban.com\/v2\/book\/27085471","alt_title":"","author_intro":"","summary":"近年来，深度学习可谓是机器学习方向的明星概念，不同的深度学习模型分别在图像处理与自然语言处理等任务中取得了前所未有的好成绩。\n在许多场合都有这样的需求“如何对感兴趣的领域快速理解和使用深度学习技术?”答案涉及复杂的数学、编程语言(如C、C++和Java)。但随着R的兴起,现在使用深度学习技术比以往更容易。因为R易学易用，不要求很扎实的编程基础，它被广泛地应用于机器学习实践和教学中。即使对R语言不是很了解的用户也可以通过一些包来搭建深度学习网络。\n全书11章，分为原理篇（第1~8章）和应用篇（第9~11章）。原理篇按照深度学习的发展过程，主要讨论了浅层神经网络、深度神经网络、卷积神经网络、递归神经网络、自编码网络、受限玻耳兹曼机和深度置信网。应用篇讨论R环境部署深度学习环境的一些策略，包括：MXNetR、H2O和其他深度学习R包以及一些典型的应用。\n本书可用作本科高年级机器学习课程参考书或数据科学课程教材，也可供对人工智能、机器学习感兴趣的读者参考阅读。","price":""},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["集智俱乐部"],"pubdate":"2019-8","tags":[{"count":8,"name":"深度学习","title":"深度学习"},{"count":6,"name":"pytorch","title":"pytorch"},{"count":4,"name":"集智俱乐部","title":"集智俱乐部"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33452791.jpg","binding":"平装","translator":[],"catalog":"目　　录\n第　1章 深度学习简介　1\n1．1　深度学习与人工智能　1\n1．2　深度学习的历史渊源　2\n1．2．1　从感知机到人工神经网络　3\n1．2．2　深度学习时代　4\n1．2．3　巨头之间的角逐　5\n1．3　深度学习的影响因素　6\n1．3．1　大数据　6\n1．3．2　深度网络架构　7\n1．3．3　GPU　11\n1．4　深度学习为什么如此成功　11\n1．4．1　特征学习（representation learning）　11\n1．4．2　迁移学习（transfer learning）　12\n1．5　小结　13\n参考文献　14\n第　2章 PyTorch简介　15\n2．1　PyTorch安装　15\n2．2　初识PyTorch　15\n2．2．1　与Python的完美融合　16\n2．2．2　张量计算　16\n2．2．3　动态计算图　20\n2．3　PyTorch实例：预测房价　27\n2．3．1　准备数据　27\n2．3．2　模型设计　28\n2．3．3　训练　29\n2．3．4　预测　31\n2．3．5　术语汇总　32\n2．4　小结　33\n第3章　单车预测器：你的第 一个\n神经网络　35\n3．1　共享单车的烦恼　35\n3．2　单车预测器1．0　37\n3．2．1　神经网络简介　37\n3．2．2　人工神经元　38\n3．2．3　两个隐含层神经元　40\n3．2．4　训练与运行　42\n3．2．5　失败的神经预测器　43\n3．2．6　过拟合　48\n3．3　单车预测器2．0　49\n3．3．1　数据的预处理过程　49\n3．3．2　构建神经网络　52\n3．3．3　测试神经网络　55\n3．4　剖析神经网络Neu　57\n3．5　小结　61\n3．6　Q&A　61\n第4章　机器也懂感情——中文情绪\n分类器　63\n4．1　神经网络分类器　64\n4．1．1　如何用神经网络做分类　64\n4．1．2　分类问题的损失函数　66\n4．2　词袋模型分类器　67\n4．2．1　词袋模型简介　68\n4．2．2　搭建简单文本分类器　69\n4．3　程序实现　70\n4．3．1　数据获取　70\n4．3．2　数据处理　74\n4．3．3　文本数据向量化　75\n4．3．4　划分数据集　76\n4．3．5　建立神经网络　78\n4．4　运行结果　80\n4．5　剖析神经网络　81\n4．6　小结　85\n4．7　Q&A　85\n第5章　手写数字识别器——认识卷积\n神经网络　87\n5．1　什么是卷积神经网络　88\n5．1．1　手写数字识别任务的CNN\n网络及运算过程　88\n5．1．2　卷积运算操作　90\n5．1．3　池化操作　96\n5．1．4　立体卷积核　97\n5．1．5　超参数与参数　98\n5．1．6　其他说明　99\n5．2　手写数字识别器　100\n5．2．1　数据准备　100\n5．2．2　构建网络　103\n5．2．3　运行模型　105\n5．2．4　测试模型　106\n5．3　剖析卷积神经网络　107\n5．3．1　第 一层卷积核与特征图　107\n5．3．2　第二层卷积核与特征图　109\n5．3．3　卷积神经网络的健壮性试验　110\n5．4　小结　112\n5．5　Q&A　112\n5．6　扩展阅读　112\n第6章　手写数字加法机——迁移学习　113\n6．1　什么是迁移学习　114\n6．1．1　迁移学习的由来　114\n6．1．2　迁移学习的分类　115\n6．1．3　迁移学习的意义　115\n6．1．4　如何用神经网络实现迁移\n学习　116\n6．2　应用案例：迁移学习如何抗击贫困　118\n6．2．1　背景介绍　118\n6．2．2　方法探寻　119\n6．2．3　迁移学习方法　120\n6．3　蚂蚁还是蜜蜂：迁移大型卷积神经\n网络　121\n6．3．1　任务描述与初步尝试　121\n6．3．2　ResNet与模型迁移　122\n6．3．3　代码实现　123\n6．3．4　结果分析　127\n6．3．5　更多的模型与数据　128\n6．4　手写数字加法机　128\n6．4．1　网络架构　128\n6．4．2　代码实现　129\n6．4．3　训练与测试　136\n6．4．4　结果　138\n6．4．5　大规模实验　138\n6．5　小结　143\n6．6　实践项目：迁移与效率　143\n第7章　你自己的Prisma——图像\n风格迁移　145\n7．1　什么是风格迁移　145\n7．1．1　什么是风格　145\n7．1．2　风格迁移的涵义　146\n7．2　风格迁移技术发展简史　147\n7．2．1　神经网络之前的风格迁移　147\n7．2．2　特定风格的实现　148\n7．3　神经网络风格迁移　149\n7．3．1　神经网络风格迁移的优势　150\n7．3．2　神经网络风格迁移的基本\n思想　150\n7．3．3　卷积神经网络的选取　151\n7．3．4　内容损失　152\n7．3．5　风格损失　152\n7．3．6　风格损失原理分析　153\n7．3．7　损失函数与优化　156\n7．4　神经网络风格迁移实战　157\n7．4．1　准备工作　157\n7．4．2　建立风格迁移网络　159\n7．4．3　风格迁移训练　162\n7．5　小结　165\n7．6　扩展阅读　165\n第8章　人工智能造假术——图像生成\n与对抗学习　166\n8．1　反卷积与图像生成　169\n8．1．1　CNN回顾　169\n8．1．2　反卷积操作　171\n8．1．3　反池化过程　173\n8．1．4　反卷积与分数步伐　174\n8．1．5　输出图像尺寸公式　175\n8．1．6　批正则化技术　176\n8．2　图像生成实验1——最小均方误差\n模型　177\n8．2．1　模型思路　177\n8．2．2　代码实现　178\n8．2．3　运行结果　182\n8．3　图像生成实验2——生成器-识别器\n模型　184\n8．3．1　生成器-识别器模型的实现　184\n8．3．2　对抗样本　187\n8．4　图像生成实验3——生成对抗网络\nGAN　190\n8．4．1　GAN的总体架构　191\n8．4．2　程序实现　192\n8．4．3　结果展示　195\n8．5　小结　197\n8．6　Q&A　197\n8．7　扩展阅读　198\n第9章　词汇的星空——神经语言模型\n与Word2Vec　199\n9．1　词向量技术介绍　199\n9．1．1　初识词向量　199\n9．1．2　传统编码方式　200\n9．2　NPLM：神经概率语言模型　201\n9．2．1　NPLM的基本思想　202\n9．2．2　NPLM的运作过程详解　202\n9．2．3　读取NPLM中的词向量　205\n9．2．4　NPLM的编码实现　206\n9．2．5　运行结果　209\n9．2．6　NPLM的总结与局限　211\n9．3　Word2Vec　211\n9．3．1　CBOW模型和Skip-gram模型的结构　211\n9．3．2　层级软最大　213\n9．3．3　负采样　213\n9．3．4　总结及分析　214\n9．4　Word2Vec的应用　214\n9．4．1　在自己的语料库上训练Word2Vec词向量　214\n9．4．2　调用现成的词向量　216\n9．4．3　女人-男人＝皇后-国王　218\n9．4．4　使用向量的空间位置进行词对词翻译　220\n9．4．5　Word2Vec小结　221\n9．5　小结　221\n9．5　Q&A　222\n第　10章 LSTM作曲机——序列生成\n模型　224\n10．1　序列生成问题　224\n10．2　RNN与LSTM　225\n10．2．1　RNN　226\n10．2．2　LSTM　231\n10．3　简单01序列的学习问题　235\n10．3．1　RNN的序列学习　236\n10．3．2　LSTM的序列学习　245\n10．4　LSTM作曲机　248\n10．4．1　MIDI文件　248\n10．4．2　数据准备　249\n10．4．3　模型结构　249\n10．4．4　代码实现　250\n10．5　小结　259\n10．6　Q&A　259\n10．7　扩展阅读　259","pages":"331","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33452791.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33452791.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33452791.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34787473\/","id":"34787473","publisher":"人民邮电出版社","isbn10":"7115516057","isbn13":"9787115516053","title":"深度学习原理与PyTorch实战","url":"https:\/\/api.douban.com\/v2\/book\/34787473","alt_title":"","author_intro":"集智俱乐部（Swarma Club），成立于2003年，是一个从事学术研究、享受科学乐趣的探索者团体。倡导以平等开放的态度、科学实证的精神，进行跨学科的研究与交流，力图搭建一个中国的“没有围墙的研究所”。目前已出版著 作有《科学的极致：漫谈人工智能》和《走近 2050：注意力、互联网与人工智能》，译作有《深度思考：人工智能的终点与人类创造力的起点》。","summary":"本书是一本系统介绍深度学习及开源框架PyTorch的入门书。全书注重实战，每章围绕一个有意思的实战案例展开，不仅循序渐进地讲解了PyTorch的基本使用、神经网络的搭建、卷积神经网络和循环神经网络的实现，而且全面深入地介绍了计算机视觉、自然语言处理、迁移学习，以及对抗学习和深度强化学习等前沿技术。读者通过阅读本书，可以轻松入门深度学习，学会构造一个图像识别器，生成逼真的图画，让机器理解单词与文本，让机器作曲，教会机器玩游戏，还可以实现一个简单的机器翻译系统。\n本书适用于人工智能行业的软件工程师、对人工智能感兴趣的学生，也非常适合作为深度学习培训教程。","series":{"id":"13000","title":"图灵原创"},"price":"58"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"卷积神经网络从入门到精通","author":["李玉鑑 张婷 单传辉 刘兆英"],"pubdate":"2018-1-1","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"电子信息","title":"电子信息"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33312793.jpg","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33312793.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33312793.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33312793.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30763985\/","id":"30763985","publisher":"机械工业出版社","isbn10":"711160279X","isbn13":"9787111602798","title":"深度学习:卷积神经网络从入门到精通","url":"https:\/\/api.douban.com\/v2\/book\/30763985","alt_title":"","author_intro":"","summary":"本书专注讨论深度学习中应用非常广泛的模型——卷积神经网络，该模型特别适用于图像分类和识别、目标分割和检测以及人工智能游戏方面，受众对象包括计算机、自动化、信号处理、机电工程、应用数学等相关专业的研究生、教师以及算法工程师和科研工作者。本书的最大特色是对卷积神经网络进行由浅入深的分类描述，依次包括：现代雏形、突破模型、应变模型、加深模型、跨连模型、区域模型、分割模型、特殊模型、强化模型和顶尖成就。这种分类框架是在模型概述和预备知识的基础上逐步展开的，既方便读者入门学习，又有助于读者深入钻研。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"79元"},{"rating":{"max":10,"numRaters":14,"average":"7.0","min":0},"subtitle":"用Python快速学习深度神经网络","author":["N.D Lewis"],"pubdate":"2018-7","tags":[{"count":5,"name":"深度学习","title":"深度学习"},{"count":4,"name":"人工智能","title":"人工智能"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"計算機","title":"計算機"},{"count":1,"name":"神经网络","title":"神经网络"},{"count":1,"name":"开发","title":"开发"},{"count":1,"name":"Python","title":"Python"}],"origin_title":"Deep Learning Step by Step with Python: A very Gentle Introduction to Deep Neural Networks for Practice Data Science By N.D Lewis","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29864471.jpg","binding":"","translator":[],"catalog":"第 1 章 如何阅读本书……………………………………………………………………… 1\n1.1 获取Python ……………………………………………………………………… 2\n1.1.1 学习Python …………………………………………………………… 3\n1.1.2 软件包 …………………………………………………………………… 3\n1.2 不需要等待 ……………………………………………………………………… 3\n1.3 小结 ……………………………………………………………………………… 4\n附注 ……………………………………………………………………………………… 5\n第 2 章 深度学习入门……………………………………………………………………… 6\n2.1 为什么要学习深度学习 ………………………………………………………… 7\n2.1.1 最后一子 ………………………………………………………………… 8\n2.1.2 一件怪事 ………………………………………………………………… 8\n2.1.3 两类人 …………………………………………………………………… 9\n2.2 什么是深度学习 …………………………………………………………………10\n2.2.1 成功的蓝图 ………………………………………………………………10\n2.2.2 有监督学习和无监督学习 ……………………………………………… 11\n2.2.3 深度学习的流程 ………………………………………………………… 11\n2.3 深度学习能解决什么问题 ……………………………………………………… 12\n2.4 哪些领域使用深度学习 …………………………………………………………14\n2.4.1 深度学习能揭开永葆青春的秘密吗 …………………………………… 15\n2.4.2 衰老的挑战 ……………………………………………………………… 15\n2.4.3 众多的理论 ……………………………………………………………… 16\n2.4.4 数据科学家的答案 ……………………………………………………… 16\n2.5 想使用深度学习——却不知如何开始 ………………………………………… 17\n2.6 小结 ………………………………………………………………………………18\n附注 ………………………………………………………………………………………18\n第3 章 神经网络基础………………………………………………………………………27\n3.1 历史备忘录 ………………………………………………………………………28\n3.2 神经网络的拓扑结构 ……………………………………………………………29\n3.3 神经元的作用 ……………………………………………………………………30\n人工神经元 ………………………………………………………………………31\n3.4 理解激活函数 ……………………………………………………………………31\n3.4.1 数学计算 …………………………………………………………………32\n3.4.2 sigmoid 函数 ……………………………………………………………34\n3.4.3 运算成本 …………………………………………………………………34\n3.5 神经网络如何进行学习 …………………………………………………………35\n基本算法 …………………………………………………………………………36\n3.6 解释梯度下降算法 ………………………………………………………………37\n3.6.1 误差曲面 …………………………………………………………………38\n3.6.2 随机梯度下降 ………………………………………………………… 39\n3.7 小结 …………………………………………………………………………… 39\n附注 …………………………………………………………………………………… 40\n第4 章 深度神经网络简介…………………………………………………………………42\n4.1 深度神经网络简析 ………………………………………………………………43\n4.2 怎样在一分钟内解释深度神经网络 ………………………………………… 44\n4.2.1 如何看待DNN ……………………………………………………… 44\n4.2.2 统计学家的视角 …………………………………………………………45\n4.2.3 一个关键的观点 …………………………………………………………45\n4.3 深度神经网络的3 种使用方式 …………………………………………………45\n4.3.1 增强雾天的可视性 ………………………………………………………46\n4.3.2 打击黑客犯罪 ……………………………………………………………50\n4.3.3 不可思议的缩略图 ……………………………………………………… 51\n4.4 如何快速地近似任何函数 ………………………………………………………54\n4.4.1 一个用Python 构建深度神经网络的极简方法 ………………………55\n4.4.2 生成示例 …………………………………………………………………56\n4.4.3 检查样本 …………………………………………………………………57\n4.4.4 格式化数据 ………………………………………………………………58\n4.4.5 拟合模型 …………………………………………………………………60\n4.4.6 性能表现评估 …………………………………………………………… 61\n4.5 有监督学习概述 …………………………………………………………………62\n4.5.1 有监督学习的目标 ………………………………………………………63\n4.5.2 无监督学习 ………………………………………………………………63\n4.5.3 半监督学习 ………………………………………………………………64\n4.6 小结 ………………………………………………………………………………65\n附注 ………………………………………………………………………………………65\n第5 章 如何构建可定制的深度预测模型…………………………………………………70\n5.1 一个深度神经网络预测的实际应用 …………………………………………… 71\n5.1.1 样本数据和神经网络 …………………………………………………… 71\n5.1.2 可靠的性能表现 …………………………………………………………72\n5.2 明确预测目标 ……………………………………………………………………72\n5.3 获取数据的拷贝 …………………………………………………………………74\n5.4 标准化的重要性 …………………………………………………………………75\n5.5 使用训练样本和测试样本 ………………………………………………………76\n5.6 创建深度神经网络回归模型的极简方式 ………………………………………78\n5.7 学习速率详解 ……………………………………………………………………79\n5.7.1 选择最佳值 …………………………………………………………… 80\n5.7.2 如果将模型拟合到数据 …………………………………………………81\n5.8 评估模型在训练集性能表现的几种方式 ………………………………………81\n5.8.1 均方差 ……………………………………………………………………82\n5.8.2 获取预测和度量性能 ……………………………………………………83\n5.9 小结 ………………………………………………………………………………83\n附注 …………………………………………………………………………………… 84\n第6 章 提高性能的一些技巧 ………………………………………… 85\n6.1 sigmoid 激活函数的局限 ………………………………………………………86\n6.2 选择最佳层数的原则 ………………………………………………………… 89\n6.3 如何快速改进模型 ………………………………………………………………92\n6.4 避免过度拟合 ………………………………………………………………… 93\n6.5 应该包含多少个神经元 …………………………………………………………95\n6.6 评估测试数据集上的性能 ………………………………………………………96\n6.7 冻结网络权重 ……………………………………………………………………97\n6.8 保存网络以供将来使用 ……………………………………………………… 98\n6.9 小结 …………………………………………………………………………… 99\n附注 …………………………………………………………………………………… 99\n第7 章 二元分类神经网络的奥秘 ……………………………………101\n7.1 感人至深——创造奇迹 ……………………………………………………… 102\n7.1.1 一项二元分类任务 …………………………………………………… 103\n7.1.2 有用的结果 …………………………………………………………… 103\n7.2 了解分类目标 ………………………………………………………………… 104\n7.3 使用Python 从网络下载数据 ……………………………………………… 105\n7.4 处理缺失的观测值 …………………………………………………………… 107\n7.5 保存数据 ……………………………………………………………………… 111\n7.6 冲量简单入门 ………………………………………………………………… 112\n7.7 留出法的秘密 ………………………………………………………………… 113\n7.8 如何用Python 快速构建一个深度神经网络二元分类器 ………………… 115\n7.8.1 生成训练集和测试集 ………………………………………………… 117\n7.8.2 指定模型 ……………………………………………………………… 117\n7.8.3 拟合模型 ……………………………………………………………… 118\n7.8.4 混淆矩阵 ……………………………………………………………… 119\n7.9 小结 …………………………………………………………………………… 120\n附注 …………………………………………………………………………………… 120\n第8 章 构建优秀模型之道 ……………………………………………123\n8.1 尝试最简单的想法提高成功率 ……………………………………………… 124\n8.2 辍学的威力 …………………………………………………………………… 124\n8.3 相似性 ………………………………………………………………………… 126\n8.4 共适应 ………………………………………………………………………… 126\n8.5 一个教训 ……………………………………………………………………… 127\n8.6 双曲正切激活函数的威力以及如何有效地使用 …………………………… 127\n8.7 如何从小批量方法中获益 …………………………………………………… 128\n8.8 重建模型 ……………………………………………………………………… 129\n8.9 关于不平衡样本你应该知道的事 …………………………………………… 131\n8.9.1 核心问题 ……………………………………………………………… 131\n8.9.2 查看测试集上的表现 ………………………………………………… 133\n8.10 小结 …………………………………………………………………………… 134\n附注 …………………………………………………………………………………… 134\n第9 章 深度神经网络在多元分类问题的简单应用 …………………136\n9.1 分类问题描述 ………………………………………………………………… 138\n9.1.1 查看样本 ……………………………………………………………… 139\n9.1.2 检查目标对象 ………………………………………………………… 140\n9.2 关于softmax 激活函数的说明 ……………………………………………… 140\n9.3 使用rmsprop 算法构建多项式模型 ……………………………………… 141\n9.3.1 关于rmsprop 算法的说明 ………………………………………… 143\n9.3.2 模型性能表现 ………………………………………………………… 144\n9.4 Adagrad 学习算法概述 ……………………………………………………… 144\n9.5 如何尝试其他学习算法 ……………………………………………………… 146\n9.5.1 Nesterov 的加速梯度下降算法 …………………………………… 146\n9.5.2 尝试冲量法 …………………………………………………………… 147\n9.5.3 常规随机梯度下降法 ………………………………………………… 148\n9.5.4 在模型中使用Adadelta 算法 ……………………………………… 149\n9.5.5 测试集性能表现 ……………………………………………………… 150\n9.6 小结 …………………………………………………………………………… 152\n9.7 结束语 ………………………………………………………………………… 152\n附注 …………………………………………………………………………………… 152","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29864471.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29864471.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29864471.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30283570\/","id":"30283570","publisher":"","isbn10":"7115482489","isbn13":"9787115482488","title":"Python深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30283570","alt_title":"Deep Learning Step by Step with Python: A very Gentle Introduction to Deep Neural Networks for Practice Data Science By N.D Lewis","author_intro":"尼格尔·刘易斯（N.D. Lewis）是一位数据科学和预测领域的讲师、作者和研究者。他在华尔街和伦敦从事投资管理工作多年，编著了统计、数据科学和量化模型方面的数本图书，并且在大学里开设深度学习、机器学习和数据分析应用等方面的课程。","summary":"本书是使用Python 进行深度学习实践的一本初学指南。本书并未罗列大量的公式，而是通过一些实用的实际案例，以简单直白的方式介绍深度神经网络的两项任务——分类和回归，解析深度学习模型中的一些核心问题，以期让读者对深度学习的全貌有一个清晰的认识。 本书共9 章，分别介绍了深度学习基础理论、神经网络基础知识、构建定制化深度预测模型、性能提升技术、二元分类的神经网络应用等内容，并借助Python 语言对基本算法和实现模型进行了探索。 本书适合期望用较短时间在深度神经网络领域初试牛刀的读者，也适合深度学习的初学者以及业内人士参考。","series":{"id":"43598","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["[意]安东尼奥·古利(Antonio Gulli)","[印]苏伊特·帕尔(Sujit Pal)"],"pubdate":"2018-7","tags":[{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"Deep Learning with Keras","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32325397.jpg","binding":"","translator":["王海玲"],"catalog":"","pages":"232","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32325397.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32325397.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32325397.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30310974\/","id":"30310974","publisher":"人民邮电出版社","isbn10":"7115482225","isbn13":"9787115482228","title":"Keras深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/30310974","alt_title":"Deep Learning with Keras","author_intro":"","summary":"作为一款轻量级、模块化的开源深度学习框架， Keras 以容易上子、利于快速原型实现、能够与TensorFlow 和Theano 等后端计算平台很好兼容等优点， 深受众多开发人 员和研究人员的喜爱。\n本书结合大量实例，简明扼要地介绍了目前热门的神经网络技术和深度学习技术 。从经典的多层感知机到用于图像处理的深度卷积网络，从处理序列化数据的循环网络到伪造仿真数据的生成对抗网络，从词嵌入到AI 游戏应用中的强化学习，引领读者一层一层揭开深度学习的面纱， 并在逐渐清晰的理论框架下， 提供多个Python编码实例，方便读者动手实践。\n通过阅读本书， 读者不仅能学会使用Keras 快捷构建各个类型的深度网络，还可以按需自定义网络层和后端功能， 从而提升自己的AI 编程能力，在成为深度学习专家的路上更进一步。","series":{"id":"43598","title":"深度学习系列"},"price":"59.00 元"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["刘祥龙","杨晴虹","谭中意","蒋晓琳"],"pubdate":"2018-6","tags":[{"count":2,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33497036.jpg","binding":"平装","translator":[],"catalog":"序\n前言\n致谢\n第1章数学基础与Python库1\n1.1Python是进行人工智能编程的\n主要语言1\n1.2数学基础4\n1.2.1线性代数基础4\n1.2.2微积分基础8\n1.3Python库的操作17\n1.3.1numpy操作17\n1.3.2matplotlib操作23\n本章小结27\n第2章深度学习概论与PaddlePaddle入门28\n2.1人工智能、机器学习与深度学习29\n2.1.1人工智能30\n2.1.2机器学习30\n2.1.3深度学习31\n2.2深度学习的发展历程32\n2.2.1神经网络的第一次高潮32\n2.2.2神经网络的第一次寒冬33\n2.2.3神经网络的第二次高潮34\n2.2.4神经网络的第二次寒冬35\n2.2.5深度学习的来临35\n2.2.6深度学习崛起的时代背景36\n2.3深度学习的应用场景36\n2.3.1图像与视觉37\n2.3.2语音识别37\n2.3.3自然语言处理38\n2.3.4个性化推荐38\n2.4常见的深度学习网络结构39\n2.4.1全连接网络结构39\n2.4.2卷积神经网络40\n2.4.3循环神经网络41\n2.5机器学习回顾41\n2.5.1线性回归的基本概念42\n2.5.2数据处理44\n2.5.3模型概览45\n2.5.4效果展示46\n2.6深度学习框架简介47\n2.6.1深度学习框架的作用47\n2.6.2常见的深度学习框架48\n2.6.3PaddlePaddle简介49\n2.6.4PaddlePaddle使用49\n2.7PaddlePaddle实现51\n本章小结60\n第3章深度学习的单层网络61\n3.1Logistic回归模型62\n3.1.1Logistic回归概述62\n3.1.2损失函数64\n3.1.3Logistic回归的梯度下降66\n3.2实现Logistic回归模型71\n3.2.1Python版本72\n3.2.2PaddlePaddle版本81\n本章小结90\n第4章浅层神经网络92\n4.1神经网络92\n4.1.1神经网络的定义及其结构92\n4.1.2神经网络的计算94\n4.2BP算法100\n4.2.1逻辑回归与BP算法101\n4.2.2单样本双层神经网络的BP算法101\n4.2.3多个样本神经网络BP算法105\n4.3BP算法实践108\n4.3.1Python版本109\n4.3.2PaddlePaddle版本116\n本章小结122\n第5章深层神经网络123\n5.1深层网络介绍123\n5.1.1深度影响算法能力124\n5.1.2网络演化过程与常用符号125\n5.2传播过程127\n5.2.1神经网络算法核心思想127\n5.2.2深层网络前向传播过程128\n5.2.3深层网络后向传播过程129\n5.2.4传播过程总结130\n5.3网络的参数132\n5.4代码实现133\n5.4.1Python版本133\n5.4.2PaddlePaddle版本136\n本章小结140\n第6章卷积神经网络141\n6.1图像分类问题描述141\n6.2卷积神经网络介绍142\n6.2.1卷积层142\n6.2.2ReLU激活函数147\n6.2.3池化层148\n6.2.4Softmax分类层149\n6.2.5主要特点151\n6.2.6经典神经网络架构152\n6.3PaddlePaddle实现159\n6.3.1数据介绍159\n6.3.2模型概览160\n6.3.3配置说明160\n6.3.4应用模型168\n本章小结169\n第7章个性化推荐170\n7.1问题描述170\n7.2传统推荐方法171\n7.2.1基于内容的推荐172\n7.2.2协同过滤推荐173\n7.2.3混合推荐175\n7.3深度学习推荐方法176\n7.3.1YouTube的深度神经网络推荐系统176\n7.3.2融合推荐系统178\n7.4个性化推荐系统在PaddlePaddle上的实现180\n7.4.1数据准备180\n7.4.2模型配置182\n7.4.3模型训练184\n7.4.4模型测试188\n本章小结188\n第8章个性化推荐的分布式实现190\n8.1PaddlePaddleCloud介绍190\n8.2PaddlePaddleCloud使用192\n8.2.1创建集群192\n8.2.2配置集群192\n8.2.3配置客户端193\n8.3个性化推荐在PaddlePaddleCloud上的实现194\n8.3.1提交单节点任务194\n8.3.2个性化推荐在PaddlePaddleCloud上的实现196\n本章小结199\n第9章广告CTR预估200\n9.1CTR预估简介200\n9.1.1CTR定义201\n9.1.2CTR与推荐算法的异同202\n9.1.3CTR预估的评价指标202\n9.2CTR预估的基本过程205\n9.2.1CTR预估的三个阶段206\n9.2.2CTR预估中的特征预处理206\n9.3CTR预估的常见模型208\n9.3.1LR模型208\n9.3.2GBDT模型210\n9.3.3GBDT+LR模型212\n9.3.4FM+DNN模型214\n9.3.5MLR模型215\n9.4CTR预估在工业上的实现217\n9.5CTR预估在PaddlePaddle上的实现218\n9.5.1数据集218\n9.5.2预测模型选择和构建219\n9.5.3PaddlePaddle完整实现222\n本章小结226\n第10章算法优化227\n10.1基础知识227\n10.1.1训练、验证和测试集227\n10.1.2偏差和方差228\n10.2评估229\n10.2.1选定评估目标229\n10.2.2迭代过程230\n10.2.3欠拟合和过拟合230\n10.3调优策略231\n10.3.1降低偏差231\n10.3.2降低方差236\n10.4超参数调优242\n10.4.1随机搜索和网格搜索242\n10.4.2超参数范围243\n10.4.3分阶段搜索243\n10.4.4例子：对学习率的调整244\n本章小结245","pages":"246","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33497036.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33497036.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33497036.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30281903\/","id":"30281903","publisher":"机械工业出版社","isbn10":"7111600460","isbn13":"9787111600466","title":"PaddlePaddle深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/30281903","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"69"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["缪鹏"],"pubdate":"2019-1-1","tags":[{"count":3,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算机视觉","title":"计算机视觉"},{"count":1,"name":"历史","title":"历史"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32316396.jpg","binding":"平装","translator":[],"catalog":"目录\n第1章 深度学习与计算机视觉1\n1.1 图像基础3\n1.2 深度学习与神经网络基础4\n1.2.1 函数的简单表达5\n1.2.2 函数的矩阵表达5\n1.2.3 神经网络的线性变换6\n1.2.4 神经网络的非线性变换6\n1.2.5 深层神经网络6\n1.2.6 神经网络的学习过程8\n1.3 卷积神经网络CNN9\n1.4 基础开发环境搭建14\n1.5 本章总结15\n第2章 OpenCV入门16\n2.1 读图、展示和保存新图17\n2.2 像素点及局部图像18\n2.3 基本线条操作19\n2.4 平移20\n2.5 旋转20\n2.6 缩放21\n2.6.1 邻近插值22\n2.6.2 双线性插值22\n2.7 翻转23\n2.8 裁剪23\n2.9 算术操作23\n2.10 位操作24\n2.11 Masking操作25\n2.12 色彩通道分离与融合26\n2.13 颜色空间转换27\n2.14 颜色直方图28\n2.15 平滑与模糊29\n2.16 边缘检测31\n2.17 人脸和眼睛检测示例32\n2.18 本章总结35\n第3章 常见深度学习框架36\n3.1 PyTorch38\n3.1.1 Tensor39\n3.1.2 Autograd42\n3.1.3 Torch.nn43\n3.2 Chainer45\n3.2.1 Variable46\n3.2.2 Link与Function47\n3.2.3 Chain50\n3.2.4 optimizers5...","pages":"249","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32316396.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32316396.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32316396.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30607940\/","id":"30607940","publisher":"清华大学出版社","isbn10":"7302517908","isbn13":"9787302517900","title":"深度学习实践:计算机视觉","url":"https:\/\/api.douban.com\/v2\/book\/30607940","alt_title":"","author_intro":"缪鹏，某985高校物理硕士，长期从事企业虚拟化和深度学习图像算法方面的工作。现为广州棒谷科技有限公司AI－CV核心成员，负责团队图像分类、搜索与图像合成核心算法开发。","summary":"本书主要介绍了深度学习在计算机视觉方面的应用及工程实践，以Python 3为开发语言，并结合当前主流的深度学习框架进行实例展示。主要内容包括：OpenCV入门、深度学习框架介绍、图像分类、目标检测与识别、图像分割、图像搜索以及图像生成等，涉及到的深度学习框架包括PyTorch、TensorFlow、Keras、Chainer、MXNet等。通过本书，读者能够了解深度学习在计算机视觉各个方向的应用以及最新进展。 本书的特点是依托工业环境的实践经验，具备较强的实用性和专业性。适合于广大计算机视觉工程领域的从业者、深度学习爱好者、相关专业的大学生和研究生以及对计算机视觉感兴趣的爱好者 使用。\n本书着重介绍深度学习在计算机视觉方面的应用和工程实践。\n结合主流深度学习框架PyTorch、TensorFlow、Keras、Chainer、MXNet等进行示例演示。\n本书主要基于开源项目，提供示例代码，通过在不同的应用场景下使用不同的主流框架，使读者能够对不同的应用场景及框架有较全面的认识。\n通过本书，读者能够了解深度学习在计算机视觉各个方向的应用及最新进展。\n本书的特点是依托工业环境的实践经验，具备较强的实用性和专业性。适合于广大计算机视觉和深度学习从业者、大学生和研究生，以及对计算机视觉工程领域感兴趣的爱好者学习。","price":"67.20元"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["吴岸城"],"pubdate":"2017-7","tags":[{"count":6,"name":"深度学习","title":"深度学习"},{"count":4,"name":"计算机","title":"计算机"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29501055.jpg","binding":"平装","translator":[],"catalog":"1  开始\t1\n1.1  从传统的软件工程思维转型\t1\n1.2  建立算法思维\t2\n1.2.1  算法的开发流程\t3\n1.2.2  做算法的步骤\t4\n1.2.3  英特的总结\t8\n1.3  观察！观察！观察！重要的事情说三遍\t11\n2  文本分析实战\t15\n2.1  第一个文本问题\t15\n2.1.1  邮件标题的预处理\t15\n2.1.2  选用算法\t18\n2.1.3  用CNN做文本分类\t21\n2.2  情感分类\t24\n2.2.1  先分析需求\t24\n2.2.2  词法分析\t25\n2.2.3  机器学习\t28\n2.2.4  试试LSTM模型\t30\n2.3  文本深度特征提取\t31\n2.3.1  词特征表示\t31\n2.3.2  句子特征表示\t42\n2.3.3  深度语义模型\t51\n3  做一个对话机器人\t53\n3.1  理解人类提问\t56\n3.2  答案的抽取和选择\t57\n3.3  蕴含关系\t62\n3.4  生成式对话模型（Generative Model）\t63\n3.5  判断机器人说话的准确性\t69\n3.6  智能对话的总结和思考\t70\n4  视觉识别\t73\n4.1  从人脸识别开始\t74\n4.1.1  OpenCV能做什么\t74\n4.1.2  检测精度的进化：Dlib\t79\n4.1.3  表情识别：Openface\t83\n4.2  深度卷积网络\t87\n4.2.1  CNN的演化过程\t87\n4.2.2  深度卷积和更深的卷积\t96\n4.2.3  实现更深的卷积网络\t103\n4.2.4  残差网络的实现\t108\n4.2.5  十全大补药：通用的提高精度的方法\t111\n4.2.6  图像训练需要注意的地方\t116\n4.3  目标检测\t125\n4.3.1  用SSD来实现目标检测应用\t133\n4.3.2  SSD训练源码提示\t136\n4.4  视觉领域的应用\t138\n4.4.1  艺术风格画\t138\n4.4.2  看图说话：用文字描述一幅图像（BiRNN+CNN）\t140\n4.4.3  CNN的有趣应用：语音识别\t142\n5  强化学习实践\t145\n5.1  吃豆子和强化学习\t145\n5.2  马尔科夫决策过程\t147\n5.3  理解Q网络\t150\n5.4  模拟物理世界：OpenAI\t152\n5.5  实现一个DQN\t154\n5.5.1  DQN代码实现\t154\n5.5.2  DQN过程的图表化\t160\n5.6  关于强化学习的思考\t163\n5.6.1  强化学习的特殊性\t163\n5.6.2  知识的形成要素：记忆\t165\n5.6.3  终极理想：终身学习\t170\n6  预测与推荐\t173\n6.1  从Google的感冒预测说起\t173\n6.2  股票预测（一）\t175\n6.2.1  股票业务整理\t176\n6.2.2  数据获取和准备\t179\n6.2.3  模型搭建\t183\n6.2.4  优化\t186\n6.2.5  后续\t187\n6.3  股票预测（二）\t189\n6.4  深度学习在推荐领域的应用：Lookalike算法\t197\n6.4.1  调研\t198\n6.4.2  实现\t201\n6.4.3  结果\t205\n6.4.4  总结探讨\t205\n参考文献\t207","pages":"304","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29501055.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29501055.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29501055.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27094855\/","id":"27094855","publisher":"电子工业出版社","isbn10":"7121317931","isbn13":"9787121317934","title":"深度学习算法实践","url":"https:\/\/api.douban.com\/v2\/book\/27094855","alt_title":"","author_intro":"","summary":"《深度学习算法实践》以一位软件工程师在工作中遇到的问题为主线，阐述了如何从软件工程思维向算法思维转变、如何将任务分解成算法问题，并结合程序员在工作中经常面临的产品需求，详细阐述了应该怎样从算法的角度看待、分解需求，并结合经典的任务对深度学习算法做了清晰的分析。\n《深度学习算法实践》在表达上深入浅出，让有志于学习深度学习的读者，能够快速地理解核心所在，并顺利上手实践。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00"},{"rating":{"max":10,"numRaters":15,"average":"6.7","min":0},"subtitle":"","author":["林大贵"],"pubdate":"2018-1-1","tags":[{"count":9,"name":"机器学习","title":"机器学习"},{"count":7,"name":"TensorFlow","title":"TensorFlow"},{"count":7,"name":"Keras","title":"Keras"},{"count":7,"name":"DeepLearning","title":"DeepLearning"},{"count":4,"name":"Python","title":"Python"},{"count":2,"name":"tensorflow","title":"tensorflow"},{"count":1,"name":"入门","title":"入门"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29751784.jpg","binding":"","translator":[],"catalog":"第1章 人工智能、机器学习与深度学习简介 1\n1.1 人工智能、机器学习、深度学习的关系 2\n1.2 机器学习介绍 4\n1.3 机器学习分类 4\n1.4 深度学习简介 7\n1.5 结论 8\n第2章 深度学习的原理 9\n2.1 神经传导的原理 10\n2.2 以矩阵运算仿真神经网络 13\n2.3 多层感知器模型 14\n2.4 使用反向传播算法进行训练 16\n2.5 结论 21\n第3章 TensorFlow与Keras介绍 22\n3.1 TensorFlow架构图 23\n3.2 TensorFlow简介 24\n3.3 TensorFlow程序设计模式 26\n3.4 Keras介绍 27\n3.5 Keras程序设计模式 28\n3.6 Keras与TensorFlow比较 29\n3.7 结论 30\n第4章 在Windows中安装TensorFlow与Keras 31\n4.1 安装Anaconda 32\n4.2 启动命令提示符 35\n4.3 建立TensorFlow的Anaconda虚拟环境 37\n4.4 在Anaconda虚拟环境安装TensorFlow与Keras 40\n4.5 启动Jupyter Notebook 42\n4.6 结论 48\n第5章 在Linux Ubuntu中安装TensorFlow与Keras 49\n5.1 安装Anaconda 50\n5.2 安装TensorFlow与Keras 52\n5.3 启动Jupyter Notebook 53\n5.4 结论 54\n第6章 Keras MNIST手写数字识别数据集 55\n6.1 下载MNIST数据 56\n6.2 查看训练数据 58\n6.3 查看多项训练数据images与label 60\n6.4 多层感知器模型数据预处理 62\n6.5 features数据预处理 62\n6.6 label数据预处理 64\n6.7 结论 65\n第7章 Keras多层感知器识别手写数字 66\n7.1 Keras多元感知器识别MNIST手写数字图像的介绍 67\n7.2 进行数据预处理 69\n7.3 建立模型 69\n7.4 进行训练 73\n7.5 以测试数据评估模型准确率 77\n7.6 进行预测 78\n7.7 显示混淆矩阵 79\n7.8 隐藏层增加为1000个神经元 81\n7.9 多层感知器加入DropOut功能以避免过度拟合 84\n7.10 建立多层感知器模型包含两个隐藏层 86\n7.11 结论 89\n第8章 Keras卷积神经网络识别手写数字 90\n8.1 卷积神经网络简介 91\n8.2 进行数据预处理 97\n8.3 建立模型 98\n8.4 进行训练 101\n8.5 评估模型准确率 104\n8.6 进行预测 104\n8.7 显示混淆矩阵 105\n8.8 结论 107\n第9章 Keras CIFAR-10图像识别数据集 108\n9.1 下载CIFAR-10数据 109\n9.2 查看训练数据 111\n9.3 查看多项images与label 112\n9.4 将images进行预处理 113\n9.5 对label进行数据预处理 114\n9.6 结论 115\n第10章 Keras卷积神经网络识别CIFAR-10图像 116\n10.1 卷积神经网络简介 117\n10.2 数据预处理 118\n10.3 建立模型 119\n10.4 进行训练 123\n10.5 评估模型准确率 126\n10.6 进行预测 126\n10.7 查看预测概率 127\n10.8 显示混淆矩阵 129\n10.9 建立3次的卷积运算神经网络 132\n10.10 模型的保存与加载 135\n10.11 结论 136\n第11章 Keras泰坦尼克号上的旅客数据集 137\n11.1 下载泰坦尼克号旅客数据集 138\n11.2 使用Pandas DataFrame读取数据并进行预处理 140\n11.3 使用Pandas DataFrame进行数据预处理 142\n11.4 将DataFrame转换为Array 143\n11.5 将ndarray特征字段进行标准化 145\n11.6 将数据分为训练数据与测试数据 145\n11.7 结论 147\n第12章 Keras多层感知器预测泰坦尼克号上旅客的生存概率 148\n12.1 数据预处理 149\n12.2 建立模型 150\n12.3 开始训练 152\n12.4 评估模型准确率 155\n12.5 加入《泰坦尼克号》电影中Jack与Rose的数据 156\n12.6 进行预测 157\n12.7 找出泰坦尼克号背后的感人故事 158\n12.8 结论 160\n第13章 IMDb网络电影数据集与自然语言处理 161\n13.1 Keras自然语言处理介绍 163\n13.2 下载IMDb数据集 167\n13.3 读取IMDb数据 169\n13.4 查看IMDb数据 172\n13.5 建立token 173\n13.6 使用token将“影评文字”转换成“数字列表” 174\n13.7 让转换后的数字长度相同 174\n13.8 结论 176\n第14章 Keras建立MLP、RNN、LSTM模型进行IMDb情感分析 177\n14.1 建立多层感知器模型进行IMDb情感分析 178\n14.2 数据预处理 179\n14.3 加入嵌入层 180\n14.4 建立多层感知器模型 181\n14.5 训练模型 182\n14.6 评估模型准确率 184\n14.7 进行预测 185\n14.8 查看测试数据预测结果 185\n14.9 查看《美女与野兽》的影评 187\n14.10 预测《美女与野兽》的影评是正面或负面的 190\n14.11 文字处理时使用较大的字典提取更多文字 192\n14.12 RNN模型介绍 193\n14.13 使用Keras RNN模型进行IMDb情感分析 195\n14.14 LSTM模型介绍 197\n14.15 使用Keras LSTM模型进行IMDb情感分析 199\n14.16 结论 200\n第15章 TensorFlow程序设计模式 201\n15.1 建立“计算图” 202\n15.2 执行“计算图” 204\n15.3 TensorFlow placeholder 206\n15.4 TensorFlow数值运算方法介绍 207\n15.5 TensorBoard 208\n15.6 建立一维与二维张量 211\n15.7 矩阵基本运算 212\n15.8 结论 214\n第16章 以TensorFlow张量运算仿真神经网络的运行 215\n16.1 以矩阵运算仿真神经网络 216\n16.2 以placeholder传入X值 220\n16.3 创建layer函数以矩阵运算仿真神经网络 222\n16.4 建立layer_debug函数显示权重与偏差 225\n16.5 结论 226\n第17章 TensorFlow MNIST手写数字识别数据集 227\n17.1 下载MNIST数据 228\n17.2 查看训练数据 229\n17.3 查看多项训练数据images与labels 232\n17.4 批次读取MNIST数据 234\n17.5 结论 235\n第18章 TensorFlow多层感知器识别手写数字 236\n18.1 TensorFlow建立多层感知器辨识手写数字的介绍 237\n18.2 数据准备 239\n18.3 建立模型 239\n18.4 定义训练方式 242\n18.5 定义评估模型准确率的方式 243\n18.6 进行训练 244\n18.7 评估模型准确率 249\n18.8 进行预测 249\n18.9 隐藏层加入更多神经元 250\n18.10 建立包含两个隐藏层的多层感知器模型 251\n18.11 结论 252\n第19章 TensorFlow卷积神经网络识别手写数字 253\n19.1 卷积神经网络简介 254\n19.2 进行数据预处理 255\n19.3 建立共享函数 256\n19.4 建立模型 258\n19.5 定义训练方式 264\n19.6 定义评估模型准确率的方式 264\n19.7 进行训练 265\n19.8 评估模型准确率 266\n19.9 进行预测 267\n19.10 TensorBoard 268\n19.11 结论 270\n第20章 TensorFlow GPU版本的安装 271\n20.1 确认显卡是否支持CUDA 273\n20.2 安装CUDA 274\n20.3 安装cuDNN 278\n20.4 将cudnn64_5.dll存放的位置加入Path环境变量 281\n20.5 在Anaconda建立TensorFlow GPU虚拟环境 283\n20.6 安装TensorFlow GPU版本 285\n20.7 安装Keras 286\n20.8 结论 286\n第21章 使用GPU加快TensorFlow与Keras训练 287\n21.1 启动TensorFlow GPU环境 288\n21.2 测试GPU与CPU执行性能 293\n21.3 超出显卡内存的限制 296\n21.4 以多层感知器的实际范例比较CPU与GPU的执行速度 297\n21.5 以CNN的实际范例比较CPU与GPU的执行速度 299\n21.6 以Keras Cifar CNN的实际范例比较CPU与GPU的执行速度 302\n21.7 结论 304\n附录A 本书范例程序的下载与安装说明 305\nA.1 在Windows系统中下载与安装范例程序 306\nA.2 在Ubuntu Linux系统中下载与安装范例程序 310","pages":"311","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29751784.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29751784.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29751784.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30206042\/","id":"30206042","publisher":"清华大学出版社","isbn10":"7302493022","isbn13":"9787302493020","title":"TensorFlow+Keras深度学习人工智能实践应用","url":"https:\/\/api.douban.com\/v2\/book\/30206042","alt_title":"","author_intro":"林大贵，从事IT行业多年，在系统设计、网站开发、数字营销、商业智慧、大数据、机器学习等领域具有丰富的实战经验。","summary":"本书提供安装、上机操作指南，同时辅以大量范例程序介绍TensorFlow + Keras深度学习方面的知识。本书分9部分，共21章，内容主要包括基本概念介绍、TensorFlow 与 Keras 的安装、Keras MNIST手写数字识别、Keras CIFAR-10照片图像物体识别、Keras多层感知器预测泰坦尼克号上旅客的生存概率、使用Keras MLP、RNN、LSTM进行IMDb自然语言处理与情感分析、以TensorFlow张量运算仿真神经网络的运行、TensorFlow MNIST手写数字识别、使用GPU大幅加快深度学习训练。\nTensorFlow + Keras深度学习方面的知识不需要具备高等数学模型、算法等专业知识，读者只需要具备基本的Python程序设计能力，按照本书的步骤循序渐进地学习，就可以了解深度学习的基本概念，进而实际运用深度学习的技术。","price":""},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["王晓华"],"pubdate":"2017-12-1","tags":[{"count":8,"name":"深度学习","title":"深度学习"},{"count":4,"name":"TensorFlow","title":"TensorFlow"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29670246.jpg","binding":"平装","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/50924277\/","pages":"458","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29670246.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29670246.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29670246.jpg"},"alt":"https:\/\/book.douban.com\/subject\/28550511\/","id":"28550511","publisher":"清华大学出版社","isbn10":"7302487952","isbn13":"9787302487951","title":"TensorFlow深度学习应用实践","url":"https:\/\/api.douban.com\/v2\/book\/28550511","alt_title":"","author_intro":"","summary":"本书总的指导思想是在掌握深度学习的基本知识和特性的基础上，培养使用TensorFlow进行实际编程以解决图像处理相关问题的能力。全书力求深入浅出，通过通俗易懂的语言和详细的程序分析，介绍TensorFlow的基本用法、高级模型设计和对应的程序编写。 本书共22章，内容包括Python类库的安装和使用、TensorFlow基本数据结构和使用、TensorFlow数据集的创建与读取、人工神经网络、反馈神经网络、全卷积神经网络的理论基础、深度学习模型的创建、模型的特性、算法、ResNet、Slim、GAN等。本书强调理论联系实际，重点介绍TensorFlow编程解决图像识别的应用，提供了大量数据集，并以代码的形式实现了深度学习模型，以供读者参考。 本书既可作为学习人工神经网络、深度学习、TensorFlow程序设计以及图像处理等相关内容的程序设计人员培训和自学用书，也可作为高等院校和培训机构相关专业的教材。","ebook_price":"44.50","price":"89.00"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["杨云","杜飞"],"pubdate":"2017-12","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29693155.jpg","binding":"","translator":[],"catalog":"目 录\n第1章 深度学习的发展介绍 1\n1.1 如何阅读本书 3\n1.2 深度学习沉浮史 3\n1.2.1 模拟生物大脑的疯狂远古时代 4\n1.2.2 联结主义近代 5\n1.2.3 百花齐放，层次结构主导，模型巨大的当代 6\n1.3 Python简易教程 7\n1.3.1 Anaconda搭建 7\n1.3.2 IPython Notebook使用 7\n1.3.3 Python基本用法 8\n1.3.4 NumPy 15\n1.3.5 Matplotlib 23\n1.4 参考文献 25\n第2章 机器学习快速入门 27\n2.1 学习算法 28\n2.1.1 学习任务 29\n2.1.2 性能度量 30\n2.1.3 学习经验 32\n2.2 代价函数 33\n2.2.1 均方误差函数 33\n2.2.2 极大似然估计 34\n2.3 梯度下降法 36\n2.3.1 批量梯度下降法 38\n2.3.2 随机梯度下降法 39\n2.4 过拟合与欠拟合 40\n2.4.1 没免费午餐理论 42\n2.4.2 正则化 43\n2.5 超参数与验证集 44\n2.6 Softmax编码实战 46\n2.6.1 编码说明 49\n2.6.2 熟练使用CIFAR-10 数据集 50\n2.6.3 显式循环计算损失函数及其梯度 53\n2.6.4 向量化表达式计算损失函数及其梯度 56\n2.6.5 最小批量梯度下降算法训练Softmax分类器 57\n2.6.6 使用验证数据选择超参数 61\n2.7 参考代码 68\n2.8 参考文献 70\n第3章 前馈神经网络 72\n3.1 神经元 73\n3.1.1 Sigmoid神经元 74\n3.1.2 Tanh神经元 75\n3.1.3 ReLU神经元 76\n3.2 前馈神经网络 80\n3.2.1 输出层单元 80\n3.2.2 隐藏层单元 80\n3.2.3 网络结构设计 81\n3.3 BP算法 82\n3.4 深度学习编码实战上 86\n3.4.1 实现仿射传播 88\n3.4.2 实现ReLU传播 91\n3.4.3 组合单层神经元 93\n3.4.4 实现浅层神经网络 96\n3.4.5 实现深层全连接网络 101\n3.5 参考代码 109\n3.6 参考文献 113\n第4章 深度学习正则化 115\n4.1 参数范数惩罚 116\n4.1.1 L2参数正则化 118\n4.1.2 L1正则化 119\n4.2 参数绑定与参数共享 120\n4.3 噪声注入与数据扩充 120\n4.4 稀疏表征 122\n4.5 早停 123\n4.6 Dropout 126\n4.6.1 个体与集成 126\n4.6.2 Dropout 127\n4.7 深度学习编码实战中 129\n4.7.1 Dropout传播 131\n4.7.2 组合Dropout传播层 134\n4.7.3 Dropout神经网络 136\n4.7.4 解耦训练器trainer 138\n4.7.5 解耦更新器updater 143\n4.7.6 正则化实验 145\n4.8 参考代码 148\n4.9 参考文献 150\n第5章 深度学习优化 152\n5.1 神经网络优化困难 153\n5.1.1 局部最优 153\n5.1.2 鞍点 154\n5.1.3 梯度悬崖 154\n5.1.4 梯度消失或梯度爆炸 155\n5.1.5 梯度不精确 156\n5.1.6 优化理论的局限性 156\n5.2 随机梯度下降 156\n5.3 动量学习法 158\n5.4 AdaGrad和RMSProp 159\n5.5 Adam 160\n5.6 参数初始化策略 161\n5.7 批量归一化 163\n5.7.1 BN算法详解 163\n5.7.2 BN传播详解 165\n5.8 深度学习编码实战下 166\n5.8.1 Momentum 167\n5.8.2 RMSProp 171\n5.8.3 Adam 172\n5.8.4 更新规则比较 174\n5.8.5 BN前向传播 176\n5.8.6 BN反向传播 180\n5.8.7 使用BN的全连接网络 182\n5.8.8 BN算法与权重标准差比较 188\n5.9 参考代码 191\n5.10 参考文献 195\n第6章 卷积神经网络 196\n6.1 卷积操作 197\n6.2 卷积的意义 198\n6.2.1 稀疏连接 199\n6.2.2 参数共享 200\n6.3 池化操作 201\n6.4 设计卷积神经网络 204\n6.4.1 跨步卷积 204\n6.4.2 零填充 205\n6.4.3 非共享卷积 206\n6.4.4 平铺卷积 207\n6.5 卷积网络编码练习 208\n6.5.1 卷积前向传播 209\n6.5.2 卷积反向传播 212\n6.5.3 最大池化前向传播 215\n6.5.4 最大池化反向传播 218\n6.5.5 向量化执行 220\n6.5.6 组合完整卷积层 223\n6.5.7 浅层卷积网络 224\n6.5.8 空间批量归一化 229\n6.6 参考代码 233\n6.7 参考文献 237\n第7章 循环神经网络 238\n7.1 循环神经网络 239\n7.1.1 循环神经元展开 239\n7.1.2 循环网络训练 240\n7.2 循环神经网络设计 242\n7.2.1 双向循环网络结构 242\n7.2.2 编码-解码网络结构 243\n7.2.3 深度循环网络结构 244\n7.3 门控循环神经网络 245\n7.3.1 LSTM 246\n7.3.2 门控循环单元 249\n7.4 RNN编程练习 250\n7.4.1 RNN单步传播 252\n7.4.2 RNN时序传播 255\n7.4.3 词嵌入 258\n7.4.4 RNN输出层 261\n7.4.5 时序Softmax损失 262\n7.4.6 RNN图片说明任务 264\n7.5 LSTM编程练习 269\n7.5.1 LSTM单步传播 269\n7.5.2 LSTM时序传播 273\n7.5.3 LSTM实现图片说明任务 276\n7.6 参考代码 278\n7.6.1 RNN参考代码 278\n7.6.2 LSTM参考代码 282\n7.7 参考文献 285\n第8章 TensorFlow快速入门 287\n8.1 TensorFlow介绍 288\n8.2 TensorFlow 1.0安装指南 289\n8.2.1 双版本切换Anaconda 289\n8.2.2 安装CUDA 8.0 291\n8.2.3 安装cuDNN 292\n8.2.4 安装TensorFlow 293\n8.2.5 验证安装 294\n8.3 TensorFlow基础 295\n8.3.1 Tensor 295\n8.3.2 TensorFlow核心API教程 296\n8.3.3 tf.train API 299\n8.3.4 tf.contrib.learn 301\n8.4 TensorFlow构造CNN 305\n8.4.1 构建Softmax模型 305\n8.4.2 使用TensorFlow训练模型 307\n8.4.3 使用TensorFlow评估模型 308\n8.4.4 使用TensorFlow构建卷积神经网络 308\n8.5 TensorBoard快速入门 311\n8.5.1 TensorBoard可视化学习 312\n8.5.2 计算图可视化 316","ebook_url":"https:\/\/read.douban.com\/ebook\/51047354\/","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29693155.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29693155.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29693155.jpg"},"alt":"https:\/\/book.douban.com\/subject\/29954762\/","id":"29954762","publisher":"清华大学出版社","isbn10":"730249102X","isbn13":"9787302491026","title":"深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/29954762","alt_title":"","author_intro":"","summary":"","ebook_price":"34.50","price":""},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2016-1-1","tags":[{"count":2,"name":"教育","title":"教育"},{"count":2,"name":"学习研究","title":"学习研究"},{"count":1,"name":"M","title":"M"}],"origin_title":"迈克尔·富兰","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"169","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/26932493\/","id":"26932493","publisher":"西南师范大学出版社","isbn10":"7562177120","isbn13":"9787562177128","title":"极富空间：新教育学如何实现深度学习","url":"https:\/\/api.douban.com\/v2\/book\/26932493","alt_title":"迈克尔·富兰","author_intro":"","summary":"","price":"30"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["王海良","李卓桓","林旭鸣"],"pubdate":"2018-11","tags":[{"count":14,"name":"智能问答","title":"智能问答"},{"count":11,"name":"深度学习","title":"深度学习"},{"count":5,"name":"人工智能","title":"人工智能"},{"count":4,"name":"NLP","title":"NLP"},{"count":3,"name":"计算科学","title":"计算科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"中文分词","title":"中文分词"},{"count":1,"name":"【考虑】","title":"【考虑】"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29920404.jpg","binding":"平装","translator":[],"catalog":"1 概述1\n1.1 智能问答：让机器更好地服务于人  1\n1.2 问答系统类型介绍  2\n1.2.1 基于事实的问答系统  3\n1.2.2 基于常见问题集的问答系统  3\n1.2.3 开放域的问答系统  4\n1.3 使用本书附带的源码程序  4\n1.3.1 安装依赖软件  4\n1.3.2 下载源码  5\n1.3.3 执行示例程序  5\n1.3.4 联系我们  6\n1.4 全书结构  6\n2 机器学习基础8\n2.1 线性代数  8\n2.1.1 标量、向量、矩阵和张量  8\n2.1.2 矩阵运算  9\n2.1.3 特殊类型的矩阵  10\n2.1.4 线性相关  11\n2.1.5 范数  12\n2.2 概率论基础  12\n2.2.1 随机变量  13\n2.2.2 期望和方差  13\n2.2.3 伯努利分布  14\n2.2.4 二项分布  14\n2.2.5 泊松分布  15\n2.2.6 正态分布  15\n2.2.7 条件概率、联合概率和全概率  17\n2.2.8 先验概率与后验概率  18\n2.2.9 边缘概率  18\n2.2.10 贝叶斯公式  18\n2.2.11 最大似然估计算法  19\n2.2.12 线性回归模型  20\n2.2.13 逻辑斯蒂回归模型  21\n2.3 信息论基础  22\n2.3.1 熵  23\n2.3.2 联合熵和条件熵  23\n2.3.3 相对熵与互信息  24\n2.3.4 信道和信道容量  25\n2.3.5 最大熵模型  26\n2.3.6 信息论与机器学习  29\n2.4 统计学习  29\n2.4.1 输入空间、特征空间与输出空间  30\n2.4.2 向量表示  30\n2.4.3 数据集  31\n2.4.4 从概率到函数  31\n2.4.5 统计学习三要素  32\n2.5 隐马尔可夫模型  33\n2.5.1 随机过程和马尔可夫链  33\n2.5.2 隐马尔可夫模型的定义  36\n2.5.3 三个基本假设及适用场景  37\n2.5.4 概率计算问题之直接计算  39\n2.5.5 概率计算问题之前向算法  40\n2.5.6 概率计算问题之后向算法  42\n2.5.7 预测问题之维特比算法  45\n2.5.8 学习问题之Baum-Welch 算法  48\n2.6 条件随机场模型  52\n2.6.1 超越HMM  52\n2.6.2 项目实践  55\n2.7 总结  59\n3 自然语言处理基础60\n3.1 中文自动分词  60\n3.1.1 有向无环图  61\n3.1.2 最大匹配算法  63\n3.1.3 算法评测  69\n3.1.4 由字构词的方法  72\n3.2 词性标注  77\n3.2.1 词性标注规范  77\n3.2.2 隐马尔可夫模型词性标注  79\n3.3 命名实体识别  81\n3.4 上下文无关文法  82\n3.4.1 原理介绍  83\n3.4.2 算法浅析  83\n3.5 依存关系分析  84\n3.5.1 算法浅析  85\n3.5.2 项目实践  92\n3.5.3 小结  94\n3.6 信息检索系统  95\n3.6.1 什么是信息检索系统  95\n3.6.2 衡量信息检索系统的关键指标  95\n3.6.3 理解非结构化数据  97\n3.6.4 倒排索引  98\n3.6.5 处理查询  100\n3.6.6 项目实践  102\n3.6.7 Elasticsearch  103\n3.6.8 小结  112\n3.7 问答语料  113\n3.7.1 WikiQA  113\n3.7.2 中文版保险行业语料库InsuranceQA  113\n3.8 总结  115\n4 深度学习初步116\n4.1 深度学习简史  116\n4.1.1 感知机  116\n4.1.2 寒冬和复苏  117\n4.1.3 走出实验室  118\n4.1.4 寒冬再临  119\n4.1.5 走向大规模实际应用  119\n4.2 基本架构  120\n4.2.1 神经元  121\n4.2.2 输入层、隐藏层和输出层  122\n4.2.3 标准符号  123\n4.3 神经网络是如何学习的  124\n4.3.1 梯度下降  124\n4.3.2 反向传播理论  127\n4.3.3 神经网络全连接层的实现  130\n4.3.4 使用简单神经网络实现问答任务  131\n4.4 调整神经网络超参数  136\n4.4.1 超参数  136\n4.4.2 参考建议  137\n4.5 卷积神经网络与池化  138\n4.5.1 简介  138\n4.5.2 卷积层的前向传播  139\n4.5.3 池化层的前向传播  141\n4.5.4 卷积层的实现  141\n4.5.5 池化层的实现  145\n4.5.6 使用卷积神经网络实现问答任务  148\n4.6 循环神经网络及其变种  149\n4.6.1 简介  149\n4.6.2 循环神经网络  149\n4.6.3 长短期记忆单元和门控循环单元  153\n4.6.4 循环神经网络的实现  156\n4.6.5 使用循环神经网络实现问答任务  159\n4.7 简易神经网络工具包  160\n5 词向量实现及应用161\n5.1 语言模型  161\n5.1.1 评测  162\n5.1.2 ARPA 格式介绍  162\n5.1.3 项目实践  163\n5.2 One-hot 表示法  164\n5.3 词袋模型  165\n5.4 NNLM 和RNNLM  165\n5.5 word2vec  168\n5.5.1 C-BOW 的原理  169\n5.5.2 Skip-gram 的原理  172\n5.5.3 计算效率优化  174\n5.5.4 项目实践  179\n5.6 GloVe  189\n5.6.1 GloVe 的原理  189\n5.6.2 GloVe 与word2vec 的区别和联系  191\n5.6.3 项目实践  193\n5.7 fastText  198\n5.7.1 fastText 的原理  198\n5.7.2 fastText 与word2vec 的区别和联系  200\n5.7.3 项目实践  201\n5.8 中文近义词工具包  204\n5.8.1 安装  205\n5.8.2 接口  205\n5.9 总结  205\n6 社区问答中的QA 匹配206\n6.1 社区问答任务简介  206\n6.2 孪生网络模型  207\n6.3 QACNN 模型  207\n6.3.1 模型构建  207\n6.3.2 实验结果  214\n6.4 Decomposable Attention 模型  214\n6.4.1 模型介绍  214\n6.4.2 模型构建  216\n6.5 多比较方式的比较–集成模型  216\n6.5.1 模型介绍  216\n6.5.2 模型构建  218\n6.6 BiMPM 模型  219\n6.6.1 模型介绍  219\n6.6.2 模型构建  221\n7 机器阅读理解222\n7.1 完型填空型机器阅读理解任务  222\n7.1.1 CNN\/Daily Mail 数据集  222\n7.1.2 Children’s Book Test（CBT）数据集  223\n7.1.3 GA Reader 模型  226\n7.1.4 SA Reader 模型  227\n7.1.5 AoA Reader 模型  228\n7.2 答案抽取型机器阅读理解任务  230\n7.2.1 SQuAD 数据集  231\n7.2.2 MS MARCO 数据集  232\n7.2.3 TriviaQA 数据集  234\n7.2.4 DuReader 数据集  235\n7.2.5 BiDAF 模型  235\n7.2.6 R-Net 模型  237\n7.2.7 S-Net 模型  240\n7.3 答案选择型机器阅读理解任务  243\n7.4 展望  245\n参考文献246","pages":"264","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29920404.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29920404.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29920404.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30376066\/","id":"30376066","publisher":"电子工业出版社","isbn10":"7121349213","isbn13":"9787121349218","title":"智能问答与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30376066","alt_title":"","author_intro":"王海良，Chatopera联合创始人、CEO，微软人工智能最有价值专家。毕业于北京邮电大学，加入IBM工作四年，先后工作于软件开发实验室和创新中心，从2016年开始工作于创业公司，三角兽AI算法工程师，呤呤英语AI产品负责人，负责智能对话系统研发。\n李卓桓，PreAngel合伙人，Plug and Play投资合伙人。拥有25年编程经验，曾任优酷网首席科学家、叽歪网创始人，水木清华BBS站长，紫霞BBS站长。Conversational AI实践者，热爱滑雪、跑酷、滑雪伞等极限运动。\n林旭鸣，北京邮电大学模式识别实验室研究生，目前的研究方向为深度学习、自然语言处理与机器阅读理解。本科期间曾获得国家奖学金，研究生期间多次在数据类竞赛中取得Top 3的成绩。曾在百度、滴滴出行、微软等公司实习。","summary":"《智能问答与深度学习》面向在校学生或计算机软件从业人员，由浅入深地介绍了人工智能在文本任务中的应用。《智能问答与深度学习》不但介绍了自然语言处理、深度学习和机器阅读理解等基础知识，还简述了信息论、人工智能等的发展过程。","series":{"id":"41172","title":"博文视点AI系列"},"price":"69"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"核心技术与案例实战","author":["言有三"],"pubdate":"2019-4-1","tags":[{"count":4,"name":"深度学习","title":"深度学习"},{"count":2,"name":"图像识别","title":"图像识别"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32311668.jpg","binding":"平装","translator":[],"catalog":"","pages":"482","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32311668.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32311668.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32311668.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33435472\/","id":"33435472","publisher":"机械工业出版社","isbn10":"7111624726","isbn13":"9787111624721","title":"深度学习之图像识别：核心技术与案例实战","url":"https:\/\/api.douban.com\/v2\/book\/33435472","alt_title":"","author_intro":"","summary":"本书全面介绍了深度学习在图像处理领域中的核心技术与应用。书中不但重视基础理论的讲解，而且从第4章开始的每章都提供了一到两个不同难度的案例供读者实践，读者可以在已有代码的基础上进行修改和改进，从而加深对所学知识的理解。本书共10章，首先从深度学习的基础概念开始，介绍了神经网络的基础知识和深度学习中的优化技术；然后系统地介绍了深度学习中与数据相关的知识，包括经典数据集的设计、数据集的增强以及数据的获取与整理；接着重点针对图像开发领域，用3章内容系统地介绍了深度学习在图像分类、图像分割和目标检测3个领域的核心技术与应用，这些内容的讲解均结合实战案例展开；另外，还对深度学习中损失函数的发展、数据和模型的可视化以及模型的压缩和优化进行了详细介绍，为读者设计和训练更加实用的模型提供了指导；最后以微信小程序平台为依托，介绍了微信小程序前后端开发技术，完成了深度学习的模型部署，让本书的内容形成了一个完整的闭环。本书理论与实践结合，深度与广度兼具，特别适合深度学习领域的相关技术人员与爱好者阅读，尤其适合基于深度学习的图像从业人员阅读，以全方位了解深度学习在图像领域中的技术全貌。另外，本书还适合作为相关培训机构的深度学习教材使用。","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"量化","title":"量化"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34447679\/","id":"34447679","publisher":"","isbn10":"711500479X","isbn13":"9787115004796","title":"深度学习入门 基于Python的理论与实现+深度学习的数学+Python深度学习（套装共3册）","url":"https:\/\/api.douban.com\/v2\/book\/34447679","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34448305\/","id":"34448305","publisher":"","isbn10":"7115004692","isbn13":"9787115004697","title":"深度学习经典教程：深度学习+动手学深度学习（套装共2册）","url":"https:\/\/api.douban.com\/v2\/book\/34448305","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"深度学习：走向核心素养","author":["马云鹏"],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32273646.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32273646.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32273646.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32273646.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33387860\/","id":"33387860","publisher":"教育科学出版社","isbn10":"7519118452","isbn13":"9787519118457","title":"深度学习教学改进丛书 深度学习：走向核心素养（学科教学指南·小学数学）","url":"https:\/\/api.douban.com\/v2\/book\/33387860","alt_title":"","author_intro":"","summary":"","price":"35元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"深度学习：走向核心素养","author":["胡久华"],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32273650.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32273650.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32273650.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32273650.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33387866\/","id":"33387866","publisher":"教育科学出版社","isbn10":"7519118444","isbn13":"9787519118440","title":"深度学习教学改进丛书 深度学习：走向核心素养（学科教学指南·初中化学）","url":"https:\/\/api.douban.com\/v2\/book\/33387866","alt_title":"","author_intro":"","summary":"","price":"28元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"基于物联网云平台的智能应用","author":[],"pubdate":"2018-1-1","tags":[{"count":1,"name":"物联网","title":"物联网"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29692949.jpg","binding":"平装","translator":[],"catalog":"出版者的话\n前言\n作者简介\n第1章 认知计算与大数据科学 1\n1.1 数据科学简介 1\n1.1.1 数据科学与相关学科 1\n1.1.2 下一个十年的新兴技术 3\n1.1.3 驱动认知计算的五种关键技术（SMACT） 7\n1.2 社交媒体和移动云计算 10\n1.2.1 社交网络和Web服务网站 10\n1.2.2 移动蜂窝核心网络 12\n1.2.3 移动设备和互联网边缘网络 13\n1.2.4 移动云计算环境 15\n1.3 大数据采集、挖掘和分析 15\n1.3.1 海量数据的大数据价值链 16\n1.3.2 大数据的采集与预处理 17\n1.3.3 数据质量控制、表示和数据库模型 19\n1.3.4 云分析系统的发展 19\n1.4 机器智能和大数据应用 21\n1.4.1 数据挖掘与机器学习 21\n1.4.2 大数据应用概述 23\n1.4.3 认知计算概述 26\n1.5 本章小结 28\n1.6 本章习题 28\n1.7 参考文献 29\n第2章 智慧云与虚拟化技术 31\n2.1 云计算模型和云服务 31\n2.1.1 基于服务的云分类 31\n2.1.2 云服务平台的多层发展 34\n2.1.3 支持大数据存储和处理引擎的云平台 37\n2.1.4 支持大数据分析的云资源 38\n2.2 虚拟机和Docker容器的创建 40\n2.2.1 云平台资源的虚拟化 40\n2.2.2 虚拟机管理程序和虚拟机 41\n2.2.3 Docker引擎和应用程序容器 43\n2.2.4 容器和虚拟机的发展 45\n2.3 云架构和虚拟资源管理 46\n2.3.1 三种云平台架构 46\n2.3.2 虚拟机管理和灾难恢复 48\n2.3.3 创建私有云的Eucalyptus和OpenStack 50\n2.3.4 Docker容器调度和业务流程 52\n2.3.5 建立混合云的VMware云操作系统 53\n2.4 IaaS、PaaS和SaaS云的案例研究 55\n2.4.1 基于分布式数据中心的AWS云 55\n2.4.2 AWS云服务产品 56\n2.4.3 PaaS：谷歌AppEngine及其他 59\n2.4.4 SaaS：Salesforce云 61\n2.5 移动云与云间的混搭服务 63\n2.5.1 微云网关的移动云 63\n2.5.2 跨云平台的混搭服务 66\n2.5.3 混搭服务Skyline的发现 68\n2.5.4 混搭服务的动态组成 70\n2.6 本章小结 71\n2.7 本章习题 71\n2.8 参考文献 74\n第3章 物联网的传感、移动和认知系统 75\n3.1 物联网感知与关键技术 75\n3.1.1 物联网感知技术 75\n3.1.2 物联网关键技术 77\n3.2 物联网体系结构和交互框架 78\n3.2.1 物联网体系结构 78\n3.2.2 本地定位技术与全球定位技术 79\n3.2.3 传统物联网系统与以云为中心的物联网应用 80\n3.2.4 物联网与环境交互框架 83\n3.3 RFID 85\n3.3.1 射频识别技术和标签设备 85\n3.3.2 RFID系统架构 86\n3.3.3 物联网支持的供应链管理 87\n3.4 传感器、无线传感器网络和全球定位系统 88\n3.4.1 传感器的硬件和操作系统 89\n3.4.2 基于智能手机的传感 93\n3.4.3 无线传感器网络和体域网 94\n3.4.4 全球定位系统 96\n3.5 认知计算技术与原型系统 99\n3.5.1 认知科学和神经信息学 99\n3.5.2 脑启发计算芯片和系统 100\n3.5.3 谷歌大脑团队项目 102\n3.5.4 物联网环境下的认知服务 104\n3.5.5 增强和虚拟现实应用 105\n3.6 本章小结 107\n3.7 本章习题 107\n3.8 参考文献 109\n第4章 NB-IoT技术与架构 111\n4.1 NB-IoT概述 111\n4.1.1 NB-IoT的背景 111\n4.1.2 NB-IoT发展简史与标准化进程 111\n4.2 NB-IoT的特性与关键技术 113\n4.2.1 NB-IoT的特性 113\n4.2.2 NB-IoT的基础理论与关键技术 118\n4.3 NB-IoT与几种技术的对比 120\n4.3.1 NB-IoT与eMTC技术的对比 120\n4.3.2 NB-IoT与其他无线通信技术的对比 123\n4.4 NB-IoT的智能应用 126\n4.4.1 NB-IoT的应用场景 126\n4.4.2 NB-IoT的应用范例 127\n4.5 NB-IoT的安全需求 128\n4.5.1 感知层 129\n4.5.2 传输层 129\n4.5.3 应用层 130\n4.6 本章小结 130\n4.7 本章习题 130\n4.8 参考文献 131\n第5章 有监督的机器学习 135\n5.1 机器学习简介 135\n5.1.1 学习方式简介 135\n5.1.2 主要算法简介 136\n5.1.3 监督学习和无监督学习 138\n5.1.4 机器学习主要流派 139\n5.2 回归分析 140\n5.2.1 简介 140\n5.2.2 线性回归 141\n5.2.3 逻辑回归 144\n5.3 有监督的分类算法 146\n5.3.1 最近邻分类 146\n5.3.2 决策树 148\n5.3.3 基于规则的分类 151\n5.3.4 支持向量机 155\n5.4 贝叶斯与组合算法 157\n5.4.1 朴素贝叶斯 158\n5.4.2 贝叶斯网络 161\n5.4.3 随机森林和组合方法 164\n5.5 本章小结 167\n5.6 本章习题 167\n5.7 参考文献 170\n第6章 无监督学习和算法选择 172\n6.1 无监督学习简介和关联分析 172\n6.1.1 无监督的机器学习 172\n6.1.2 关联分析和频繁项集 172\n6.1.3 关联规则的产生 175\n6.2 聚类分析 177\n6.2.1 聚类分析简介 178\n6.2.2 K均值聚类 178\n6.2.3 凝聚层次聚类 180\n6.2.4 基于密度的聚类 183\n6.3 降维算法和学习模型 186\n6.3.1 常见的降维算法简介 186\n6.3.2 主成分分析法 187\n6.3.3 其他学习方式 190\n6.4 基于模型性能选择合适的算法 192\n6.4.1 评估机器学习模型的性能 192\n6.4.2 过拟合现象和解决方案 194\n6.4.3 欠拟合现象和解决方案 196\n6.4.4 根据数据集选择机器学习算法 198\n6.5 本章小结 199\n6.6 本章习题 199\n6.7 参考文献 202\n第7章 深度学习 203\n7.1 简介 203\n7.1.1 深度学习模仿人的感知 203\n7.1.2 生物神经元和人工神经元 205\n7.1.3 深度学习和浅层学习 206\n7.2 人工神经网络 207\n7.2.1 感知器 207\n7.2.2 多层人工神经网络 208\n7.2.3 人工神经网络的前向传播和后向传播 209\n7.3 堆叠自编码和深信念网络 213\n7.3.1 自编码器 213\n7.3.2 堆叠自编码器 215\n7.3.3 限制波兹曼机 216\n7.3.4 深信念网络 221\n7.4 卷积神经网络 222\n7.4.1 卷积操作 222\n7.4.2 池化 225\n7.4.3 训练卷积神经网络 226\n7.4.4 LeNet-5各层设置 227\n7.4.5 其他深度学习神经网络 227\n7.5 本章小结 231\n7.6 本章习题 231\n7.7 参考文献 233\n第8章 生成对抗式网络与深度学习应用 235\n8.1 生成对抗式网络及其发展 235\n8.1.1 生成对抗式网络 235\n8.1.2 深度卷积生成对抗式网络 238\n8.1.3 InfoGAN 239\n8.1.4 SeqGAN 240\n8.2 基于深度学习的文本情感分类 242\n8.2.1 文本情感分类 242\n8.2.2 文本预处理 242\n8.2.3 基于卷积神经网络的文本情感分类 244\n8.2.4 基于LSTM神经网络的文本情感分类 245\n8.2.5 基于C-LSTM神经网络的文本情感分类 248\n8.2.6 基于深度学习的文本情感分类实现 250\n8.2.7 实验环境和数据 251\n8.2.8 超参数调节 251\n8.2.9 实验结果分析 255\n8.3 基于卷积神经网络的人脸识别 257\n8.3.1 人脸识别的CNN结构 257\n8.3.2 人脸识别的CNN实现 259\n8.3.3 评价指标 261\n8.3.4 数据获取 261\n8.3.5 数据预处理 262\n8.3.6 人脸识别实验 264\n8.4 基于卷积神经网络的语音情感识别 267\n8.4.1 语音情感识别简介 267\n8.4.2 语音情感识别技术 267\n8.4.3 语音情感识别系统实现 268\n8.5 本章小结 272\n8.6 本章习题 272\n8.7 参考文献 273\n第9章 深度学习和社交媒体分析应用 275\n9.1 深度学习系统和社交媒体行业 275\n9.1.1 深度学习系统和软件支持 275\n9.1.2 增强学习原则 277\n9.1.3 社交媒体行业及其影响 278\n9.2 使用ANN和CNN算法的文本和图像识别 279\n9.2.1 在ANN中使用TensorFlow进行数字识别 280\n9.2.2 使用卷积神经网络进行数字识别 281\n9.2.3 使用卷积神经网络进行人脸识别 284\n9.2.4 使用卷积神经网络进行医疗文本分析 285\n9.3 深度增强学习的应用 291\n9.3.1 DeepMind利用深度增强学习玩游戏 291\n9.3.2 深度增强学习算法 292\n9.3.3 深度增强学习训练平台——OpenAI Gym 294\n9.3.4 AlphaGo原理解析 296\n9.4 社交媒体应用程序的数据分析 299\n9.4.1 社交媒体应用中的大数据需求 300\n9.4.2 社交网络和图表分析 301\n9.4.3 预测分析软件工具 306\n9.4.4 社交网络中的社区检测 307\n9.5 本章小结 310\n9.6 本章习题 310\n9.7 参考文献 311\n第10章 医疗认知系统与健康大数据应用 313\n10.1 健康监护问题和医疗认知工具 313\n10.1.1 健康监护和慢性疾病检测问题 313\n10.1.2 通用机器学习应用的软件库 315\n10.2 物联网和基于机器人的健康监护系统与应用 316\n10.2.1 物联网传感器用于身体信号的收集 316\n10.2.2 基于云的健康监护系统 317\n10.2.3 运动促进和智能服装 319\n10.2.4 健康监护机器人和移动健康云 321\n10.3 健康监护应用的大数据分析 323\n10.3.1 健康监护大数据预处理 323\n10.3.2 疾病检测的预测分析 324\n10.3.3 五种疾病检测方法的性能分析 328\n10.3.4 疾病控制相关的移动大数据 331\n10.4 情感控制的健康监护应用 333\n10.4.1 精神健康监护系统的基础 333\n10.4.2 情感控制计算和服务 334\n10.4.3 基于物联网和云的情感交互 336\n10.4.4 基于机器人技术的情感控制 338\n10.4.5 用于未来健康监护应用的智能认知系统 340\n10.5 基于生物信息学的医疗认知系统 342\n10.5.1 将基因组测序应用于诊断 342\n10.5.2 重塑生物医学 342\n10.5.3 从健康治疗到健康监护和预防 343\n10.6 本章小结 343\n10.7 本章习题 344\n10.8 参考文献 345\n第11章 认知车联网与5G认知系统 348\n11.1 5G的演进 348\n11.1.1 移动蜂窝网络的演进 348\n11.1.2 5G驱动力 349\n11.2 5G关键技术 350\n11.2.1 网络架构设计 350\n11.2.2 5G网络代表性服务能力 352\n11.2.3 5G与认知计算 354\n11.3 认知车联网基本架构 356\n11.3.1 基础架构层 356\n11.3.2 认知层 357\n11.3.3 应用层 357\n11.4 认知车联网通信模式 358\n11.4.1 车–云通信 358\n11.4.2 云–车通信 359\n11.4.3 车–车通信 359\n11.5 车联网缓存策略研究 359\n11.5.1 缓存问题 359\n11.5.2 评价指标 360\n11.6 车载云计算 361\n11.6.1 车载云模式 361\n11.6.2 车载云卸载策略 363\n11.7 5G认知系统 363\n11.7.1 网络架构 363\n11.7.2 5G认知系统的通信方式 365\n11.7.3 5G认知系统的核心组件 365\n11.8 5G认知系统的关键技术 366\n11.8.1 无线接入网络的关键技术 366\n11.8.2 核心网的关键技术 366\n11.8.3 认知引擎的关键技术 367\n11.9 5G认知系统的应用 367\n11.9.1 5G 认知系统的应用实例 367\n11.9.2 认知系统的应用分析 369\n11.10 本章小结 369\n11.11 本章习题 369\n11.12 参考文献 370","pages":"370","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29692949.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29692949.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29692949.jpg"},"alt":"https:\/\/book.douban.com\/subject\/29951949\/","id":"29951949","publisher":"机械工业出版社","isbn10":"7111584961","isbn13":"9787111584964","title":"认知计算与深度学习(基于物联网云平台的智能应用)\/计算机科学丛书","url":"https:\/\/api.douban.com\/v2\/book\/29951949","alt_title":"","author_intro":"陈敏 华中科技大学计算机学院教授、博士生导师，嵌入与普适计算实验室主任。23岁获华南理工大学通信与信息系统博士学位，曾在韩国首尔大学、加拿大不列颠哥伦比亚大学从事博士后研究，曾任韩国首尔大学助理教授。2012年入选国家第二批青年千人计划。主要研究方向是物联网、大数据分析与认知计算。\n他发表国际学术论文300多篇，80篇发表于IEEE\/ACM计算机与通信领域核心期刊。他的论文在谷歌学术中引用超过10500次，其中10篇第壹作者论著引用超过3400次，H指数为50。近三年以来连续入选爱思唯尔计算机类中国高被引学者。他曾获IEEE ICC 2012、IEEE IWCMC 2016等国际大会佳论文奖，2017年获IEEE通信协会Fred W. Ellersick奖。他曾任IEEE ICC 2012通信理论程序委员会主席及IEEE ICC 2013无线网络程序委员会主席等，2014年被选为IEEE 计算机协会大数据技术委员会主席。\n黄铠（Kai Hwang） 计算机系统和互联网技术领域的国际知名学者。他拥有加州大学伯克利分校博士学位，主要研究领域为计算机体系结构、并行处理、云计算、分布式系统和网络安全，目前是美国南加州大学（USC）电子工程与计算机科学系终身教授。他曾在普渡大学任教多年，并先后在清华大学、香港大学、台湾大学和浙江大学担任特聘讲座教授。他在专业领域发表了250篇科学论文，截至2017年在谷歌学术中引用超过16800次，H指数为55。他还是IEEE计算机协会的终身会士（Life Fellow）。\n他创作或合著了10余本学术专著，包括《高级计算机体系结构》（1992）、《云计算与分布式系统》（2011）和《智能云计算与机器学习》（2018）等。他曾担任《并行与分布式计算》（JPDC）杂志主编28年，还曾担任IEEE 《云计算会刊》（TCC）、《并行和分布式系统》（TPDS）、《服务计算》（TSC）以及《大数据智能》杂志的编委。他于2012年获得国际云计算大会（IEEE CloudCom）终身成就奖，2004年获得中国计算机学会（CCF）首届海外杰出贡献奖。\n多年来，他在南加州大学和普渡大学共培养博士生21人，其中4人晋升为IEEE 会士，1人为IBM会士。他在IEEE与ACM国际会议和全球领先的大学发表了60多次主题演讲和杰出讲座。他曾在IBM研究院、Intel公司、富士通研究院、麻省理工学院林肯实验室、加州理工学院喷气推进实验室（JPL）、台湾工业技术研究院（ITRI）、法国国家计算科学研究中心（ENRIA）和中国科学院计算所担任高级顾问或首席科学家。他目前的科研兴趣集中于云计算、物联网、机器智能和大数据在医疗保健与移动社交网络上的应用。","summary":"这本书融合了大数据理论与智能云(物联网)的新技术。数据分析师和计算机科学家必须学会如何有效地使用云和物联网来发现新的知识，进而才能明智地做出重要决策。本书旨在缩短这些学习方向之间的差距,并鼓励数据科学家和云计算科学家之间的相互学习与合作。书中将大数据集成理论、云设计原则、物联网传感、机器学习、数据分析、Hadoop和Spark编程等融为一体，目标是在物联网传感、机器学习和分析系统的支持下，完成有效的智能云大数据计算操作。","series":{"id":"1163","title":"计算机科学丛书"},"price":"99.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"基于R语言","author":["[英] 尼格尔·刘易斯(N.D. Lewis)"],"pubdate":"2018-6","tags":[],"origin_title":"Deep Learning Made Easy with R: A Gentle Introduction For Data Science","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32332108.jpg","binding":"平装","translator":["沙灜"],"catalog":"版权声明\n内容提要\n致谢\n序\n前言\n资源与支持\n第1章　简介\n第2章　深度神经网络\n第3章　Elman神经网络\n第4章　Jordan神经网络\n第5章　自编码器的秘密\n第6章　堆叠自编码器简介\n第7章　限制玻尔兹曼机\n第8章　深度信念网络","pages":"200","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32332108.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32332108.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32332108.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30264744\/","id":"30264744","publisher":"人民邮电出版社","isbn10":"7115477779","isbn13":"9787115477774","title":"深度学习实践指南 基于R语言","url":"https:\/\/api.douban.com\/v2\/book\/30264744","alt_title":"Deep Learning Made Easy with R: A Gentle Introduction For Data Science","author_intro":"","summary":"深度学习的概念源于人工神经网络的研究，它是机器学习中一种基于对数据进行表征学习的方法。\n本书是一本详细的、实用的深度学习实践指南。它共有8 章，详细讲解了深度神经网络、Elman 神经网络、Jordan 神经网络、自编码器、堆叠自编码器、限制玻尔兹曼机的相关知识。本书并没有详细介绍那些深奥的数字公式，它旨在解释深度学习模型是如何工作的，让读者学会如何构建成功的深度学习模型，并将其用于数据挖掘，从而让读者迅速地学以致用，可以用深度学习构建更智能的应用。\n本书适合数据科学家、各领域的研究人员阅读，也适合其他对深度学习感兴趣的人士阅读。","series":{"id":"43598","title":"深度学习系列"},"price":"69.00元"},{"rating":{"max":10,"numRaters":105,"average":"8.4","min":0},"subtitle":"","author":["陈仲铭","彭凌西"],"pubdate":"2018-8","tags":[{"count":50,"name":"深度学习","title":"深度学习"},{"count":41,"name":"好书，值得一读","title":"好书，值得一读"},{"count":20,"name":"人工智能","title":"人工智能"},{"count":17,"name":"适合初学者","title":"适合初学者"},{"count":13,"name":"通俗易懂","title":"通俗易懂"},{"count":13,"name":"科技","title":"科技"},{"count":12,"name":"计算机","title":"计算机"},{"count":8,"name":"深入浅出","title":"深入浅出"}],"origin_title":"深度学习原理与实践","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29849654.jpg","binding":"平装","translator":[],"catalog":"序\n前言\n第1章 初探深度学习\n第2章 人工神经网络\n第3章 深度学习基础及技巧\n第4章 卷积神经网络\n第5章 卷积神经网络视觉盛宴\n第6章 卷积神经网络进阶示例\n第7章 循环神经网络\n第8章 循环神经网络进阶序列长期记忆","pages":"326","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29849654.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29849654.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29849654.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30304398\/","id":"30304398","publisher":"人民邮电出版社","isbn10":"7115483671","isbn13":"9787115483676","title":"深度学习原理与实践","url":"https:\/\/api.douban.com\/v2\/book\/30304398","alt_title":"深度学习原理与实践","author_intro":"西安电子科技大学软件工程硕士。曾就职于海格通讯人工智能算法部门，统筹负责人工智能算法、图像算法、深度学习等研究。曾在国内核心期刊发表多篇关于无人驾驶汽车相关论文。在信息项目方面，曾研究和参与激光点云三维扫描、大数据信息推荐系统、融合多传感器的无人驾驶系统、机器学习和数据统计建模等多个项目设计，期间多次获国家级创新项目奖。此外，还作为讲师和技术顾问为多家机构提供关于数据建模、深度学习等咨询和培训。","summary":"本书详细介绍了目前深度学习相关的常用网络模型（ANN、CNN、RNN），以及不同网络模型的算法原理和核心思想。本书利用大量的实例代码对网络模型进行了分析，这些案例能够加深读者对网络模型的认识。此外，本书还提供完整的进阶内容和对应案例，让读者全面深入地了解深度学习的知识和技巧，达到学以致用的目的。\n适用于大数据平台系统工程师、算法工程师、数据科学家，可作为对人工智能和深度学习感兴趣的计算机相关从业人员的学习用书，也可作为计算机等相关专业的师生用书和培训学校的教材。","series":{"id":"43598","title":"深度学习系列"},"price":"89"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["【美】布兰登?里根  罗伯特?阿道夫  保罗?沃特莫  古杨?魏  大卫?布鲁克斯"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32294719.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32294719.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32294719.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32294719.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33413861\/","id":"33413861","publisher":"机械工业出版社","isbn10":"7111622480","isbn13":"9787111622482","title":"当计算机体系结构遇到深度学习：面向计算机体系结构设计师的深度学习概论","url":"https:\/\/api.douban.com\/v2\/book\/33413861","alt_title":"","author_intro":"","summary":"","series":{"id":"42552","title":"智能科学与技术丛书"},"price":"69元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34922448\/","id":"34922448","publisher":"","isbn10":"7519120554","isbn13":"9787519120559","title":"深度学习教学改进丛书 深度学习：走向核心素养（学科教学指南·初中数学）","url":"https:\/\/api.douban.com\/v2\/book\/34922448","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["[印] 萨扬·穆霍帕迪亚（Sayan Mukhopadhyay）"],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33469311.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"156","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33469311.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33469311.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33469311.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30772568\/","id":"30772568","publisher":"机械工业出版社","isbn10":"7111617029","isbn13":"9787111617020","title":"Python高级数据分析：机器学习、深度学习和NLP实例","url":"https:\/\/api.douban.com\/v2\/book\/30772568","alt_title":"","author_intro":"","summary":"","series":{"id":"42242","title":"数据分析与决策技术丛书"},"price":"59元"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["李玉鑑","张婷"],"pubdate":"2016-10-1","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":1,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29434296.jpg","binding":"平装","translator":[],"catalog":"前言\n第一部分 基础理论\n目 录\n第1章概述 2\n1.1深度学习的起源和发展 2\n1.2深层网络的特点和优势 4\n1.3深度学习的模型和算法 7\n第2章预备知识 9\n2.1矩阵运算 9\n2.2概率论的基本概念 11\n2.2.1概率的定义和性质 l1\n2.2.2 随机变量和概率密度\n函数 l2\n2.2.3期望和方差． 13\n2.3信息论的基本概念． 14\n2.4概率图模型的基本概念 15\n2.5概率有向图模型 16\n2.6概率无向图模型 20\n2.7部分有向无圈图模型 22\n2.8条件随机场 24\n2.9马尔可夫链 26\n2.10概率图模型的学习 28\n2.11概率图模型的推理 29\n2.12马尔可夫链蒙特卡罗方法 31\n2.13玻耳兹曼机的学习 32\n2.14通用反向传播算法 35\n2.15通用逼近定理 37\n第3章受限玻耳兹曼机 38\n3.1 受限玻耳兹曼机的标准\n模型 38\n3.2受限玻耳兹曼机的学习算法 40\n3.3 受限玻耳兹曼机的变种模型 44\n第4章 自编码器 48\n4.1 自编码器的标准模型 48\n4.2 自编码器的学习算法 50\n4.3 自编码器的变种模型 53\n第5章深层信念网络 57\n5.1 深层信念网络的标准模型 57\n5.2深层信念网络的生成学习\n算法 60\n5.3深层信念网络的判别学习算法 62\n5.4深层信念网络的变种模型 63\n第6章深层玻耳兹曼机 64\n6.1 深层玻耳兹曼机的标准模型 64\n6.2深层玻耳兹曼机的生成学习\n算法 65\n6.3 深层玻耳兹曼机的判别学习\n算法 69\n6.4深层玻耳兹曼机的变种模型 69\n第7章和积网络 72\n7.1 和积网络的标准模型 72\n7.2和积网络的学习算法 74\n7.3和积网络的变种模型 77\n第8章卷积神经网络 78\n8.1卷积神经网络的标准模型 78\n8.2卷积神经网络的学习算法 81\n8.3卷积神经网络的变种模型 83\n第9章深层堆叠网络 一86\n9.1 深层堆叠网络的标准模型 86\n9.2深层堆叠网络的学习算法 87\n9.3深层堆叠网络的变种模型 88\n第1 0章循环神经网络 89\n10.1循环神经网络的标准模型 89\n10.2循环神经网络的学习算法 91\n10.3循环神经网络的变种模型 92\n第1 1章长短时记忆网络 94\n11.1长短时记忆网络的标准模型 94\n11.2长短时记忆网络的学习算法 96\n11.3长短时记忆网络的变种模型 98\n第12章深度学习的混合模型、\n广泛应用和开发工具 102\n12.1深度学习的}昆合模型 102\n12.2深度学习的广泛应用 104\n12.2.1 图像和视频处理 104\n12.2.2语音和音频处理 106\n12.2.3 自然语言处理 108\n12.2.4其他应用 109\n12.3深度学习的开发工具 110\n第1 3章深度学习的总结、\n批评和展望 114\n第二部分案例分析\n第14章实验背景 一118\n14.1运行环境 118\n14.2实验数据 118\n14.3代码工具 120\n第1 5章 自编码器降维案例 一121\n15.1 自编码器降维程序的模块\n简介 121\n15.2 自编码器降维程序的运行\n过程 122\n15.3 自编码器降维程序的代码\n分析 127\n15.3.1 关键模块或函数的主要\n功能 127\n15.3.2主要代码分析及注释 128\n15.4 自编码器降维程序的使用\n技巧 138\n第1 6章深层感知器识别案例 139\n16.1 深层感知器识别程序的模块\n简介 139\n16.2深层感知器识别程序的运行\n过程 140\n16.3深层感知器识别程序的代码\n分析 143\n16.3.1 关键模块或函数的主要\n功能 143\n16.3.2主要代码分析及注释 l43\n16.4深层感知器识别程序的使用\n技巧 148\n第1 7章深层信念网络生成\n案例 149\n17.1 深层信念网络生成程序的模块\n简介 149\n17.2深层信念网络生成程序的运行\n过程 150\n17.3深层信念网络生成程序的代码\n分析 153\n第18章深层信念网络分类案例163\n第19章深层玻耳兹曼机识别案例202\n第20章卷积神经网络识别案例221\n第21章循环神经网络填充案例236\n第22章长短时忆网络分类案例245\n附录263\n参考文献269","pages":"292","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29434296.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29434296.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29434296.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27028490\/","id":"27028490","publisher":"机械工业出版社","isbn10":"7111550757","isbn13":"9787111550754","title":"深度学习导论及案例分析","url":"https:\/\/api.douban.com\/v2\/book\/27028490","alt_title":"","author_intro":"李玉鑑（ 鉴 ）　北京工业大学教授，博士生导师。华中科技大学本科毕业，中国科学院数学研究所硕士毕业，中国科学院半导体研究所博士毕业，北京邮电大学博士后出站。曾在中国科学院生物物理所工作，对意识的本质问题关注过多年，并在《21世纪100个交叉科学难题》上发表《揭开意识的奥秘》一文，提出了解决意识问题的认知相对论纲领，对脑计划和类脑研究具有宏观指导意义。长期围绕人工智能的核心目标，在神经网络、自然语言处理、模式识别和机器学习等领域开展教学、科研工作，发表国内外期刊、会议论文数十篇，是本书的*一作者。\n目录","summary":"本书不仅介绍了深度学习的起源和发展、强调了深层网络的特点和优势，说明了判别模型和生成模型的相关概念，还详述了深度学习的9种重要模型及其学习算法、变种模型和混杂模型，包括受限玻耳兹曼机、自编码器、深层信念网络、深层玻耳兹曼机、和积网络、卷积神经网络、深层堆叠网络、循环神经网络和长短时记忆网络，以及它们在图像处理、语音处理和自然语言处理等领域的广泛应用。同时分析了一系列深度学习的基本案例。\n本书每个案例包括模块简介、运行过程、代码分析和使用技巧4个部分，层次结构清晰，利于读者的选择和学习并在应用中拓展思路。涉及的编程语言有3种：Matlab、Python和C++。其中，很多深度学习程序是用Matlab编写的，可以直接运行；如果使用Python语言编写深度学习程序，则可以调用Theano开源库；若使用C++语言，则可以调用Caffe开源库。","price":"59"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["谢琼"],"pubdate":"2018-7-1","tags":[{"count":2,"name":"神经网络","title":"神经网络"},{"count":2,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29969505.jpg","binding":"平装","translator":[],"catalog":"第1章　人工智能极简历史　1\n1.1　重要的奠基时期　2\n1.1.1　神经元的研究和人工神经元模型的提出　2\n1.1.2　计算机和程序的出现　3\n1.1.3　图灵测试的提出　4\n1.2　人工智能的诞生　4\n1.3　第一个快速发展期　5\n1.4　人工智能的第一个寒冬　5\n1.5　人工智能研究的沉默探索与复苏　6\n1.6　人工智能的第二个冬天　9\n1.7　再一次腾飞　9\n1.7.1　计算机综合计算能力的大幅提升　9\n1.7.2　大数据的出现　11\n1.7.3　神经网络研究的成熟化　11\n1.8　未来展望　13\n1.9　本章小结：历史指引未来　18\n第2章　开发环境准备　19\n2.1　安装Python　20\n2.1.1　Windows操作系统下安装Python　20\n2.1.2　Mac OS X操作系统下安装Python　29\n2.1.3　Linux操作系统下安装Python　30\n2.2　安装TensorFlow　30\n2.3　打造更舒适的开发环境　32\n2.3.1　修改Windows资源管理器的一些显示设置　32\n2.3.2　命令提示符CMD的替代方案　34\n2.3.3　文本文件编辑器　36\n2.3.4　Python语言专用的开发工具　40\n2.4　知识背景准备　45\n2.4.1　怎样输入Python程序　45\n2.4.2　怎样执行Python程序　45\n2.4.3　变量　46\n2.4.4　函数（方法）　50\n2.4.5　对象　51\n2.4.6　条件判断与分支　53\n2.4.7　循环　54\n2.4.8　注释　55\n2.4.9　程序运行时出现错误怎么办　55\n2.4.10　本章小结：一段示例代码　56\n第3章　初识TensorFlow　57\n3.1　三好学生成绩问题的引入　58\n3.2　搭建解决三好学生成绩问题的神经网络　58\n3.3　训练神经网络　62\n3.4　本章小结：解决的第一个问题　68\n3.5　练习　68\n第4章　简化神经网络模型　69\n4.1　在程序运行中查看变量取值　70\n4.2　张量概念的引入　70\n4.3　用向量重新组织输入数据　72\n4.4　简化的神经网络模型　75\n4.5　概念补充——标量、多维数组等　76\n4.5.1　标量　76\n4.5.2　多维数组　76\n4.5.3　张量的阶和形态　77\n4.6　在TensorFlow中查看和设定张量的形态　78\n4.7　用softmax函数来规范可变参数　81\n4.8　本章小结：线性问题　83\n4.9　练习　84\n第5章　用神经网络解决非线性问题　85\n5.1　非线性问题的引入　86\n5.1.1　三好学生评选结果问题　86\n5.1.2　二分类问题：是否为三好学生　86\n5.1.3　非线性问题　87\n5.2　设计神经网络模型　88\n5.2.1　激活函数sigmoid　88\n5.2.2　使用sigmoid函数后的神经网络模型　89\n5.2.3　实现本模型的代码　89\n5.3　准备训练数据　90\n5.3.1　随机数　90\n5.3.2　产生随机训练数据　90\n5.4　完整的训练代码　92\n5.4.1　使用随机数据进行训练　92\n5.4.2　加入偏移量b加快训练过程　94\n5.5　进阶：批量生成随机训练数据　97\n5.6　本章小结：非线性问题　100\n5.7　练习　100\n第6章　从文件中载入训练数据　101\n6.1　用纯文本文件准备训练数据　102\n6.1.1　数据的数字化　102\n6.1.2　训练数据的格式　102\n6.1.3　数据整理　103\n6.1.4　使用CSV格式文件辅助处理数据　104\n6.2　加载文件中的训练数据　106\n6.2.1　加载函数　106\n6.2.2　非数字列的舍弃　106\n6.2.3　非数字列与数字列的转换　107\n6.2.4　行数据的分拆及如何“喂”给训练过程　108\n6.3　本章小结：读取训练数据最常用的方式　110\n6.4　练习　110\n第7章　多层全连接神经网络　111\n7.1　身份证问题的引入　112\n7.2　问题分析　112\n7.3　单层网络的模型　112\n7.4　多层全连接神经网络　115\n7.4.1　矩阵乘法　115\n7.4.2　如何用矩阵乘法实现全连接层　116\n7.4.3　使用均方误差作为计算误差的方法　119\n7.4.4　激活函数tanh　120\n7.4.5　新的模型　121\n7.5　身份证问题新模型的代码实现　121\n7.6　进一步优化模型和代码　124\n7.7　本章小结：多层、全连接、线性与非线性　125\n7.8　练习　126\n第8章　保存和载入训练过程　127\n8.1　保存训练过程　128\n8.2　载入保存的训练过程并继续训练　130\n8.3　通过命令行参数控制是否强制重新开始训练　132\n8.4　训练过程中手动保存　135\n8.5　保存训练过程前征得同意　137\n8.6　本章小结：善于利用保存和载入训练过程　139\n8.7　练习　139\n第9章　查看图形化的模型　140\n9.1　数据流图的概念　141\n9.2　用TensorBoard查看数据流图　141\n9.3　控制TensorBoard图中对象的名称　143\n9.4　本章小结：图形化的模型　145\n9.5　练习　145\n第10章　用训练好的模型进行预测　146\n10.1　从命令行参数读取需要预测的数据　147\n10.2　从文件中读取数据进行预测　149\n10.3　从任意字符串中读取数据进行预测　152\n10.4　本章小结：预测与训练的区别　154\n10.5　练习　154\n第11章　用高级工具简化建模和训练过程　155\n11.1　Keras框架介绍　156\n11.2　用Keras实现神经网络模型　156\n11.3　用Keras进行预测　158\n11.4　保存和载入Keras模型　160\n11.5　本章小结：方便与灵活度的取舍　161\n11.6　练习　161\n第12章　在其他语言中调用TensorFlow模型　162\n12.1　如何保存模型　163\n12.2　在Java语言中载入TensorFlow模型并进行预测计算　165\n12.3　在Go语言中载入TensorFlow模型并进行预测计算　167\n12.4　本章小结：仅能预测　167\n第13章　用卷积神经网络进行图像识别　169\n13.1　情凭谁来定错对——一首歌引出的对错问题　170\n13.2　卷积神经网络介绍　170\n13.2.1　卷积神经网络的基本概念　170\n13.2.2　数字图片在计算机中的表达形式　170\n13.2.3　卷积层的具体计算过程　172\n13.2.4　卷积层的原理和优点　174\n13.2.5　卷积神经网络的典型结构　177\n13.3　用卷积网络实现图像识别　177\n13.3.1　钩叉问题的图像数据格式　177\n13.3.2　准备钩叉问题的训练数据　178\n13.3.3　设计钩叉问题的神经网络模型并实现　179\n13.4　本章小结：进一步优化的方向　183\n13.5　练习　183\n第14章　循环神经网络初探　184\n14.1　循环神经网络简介　185\n14.2　长短期记忆模型LSTM的作用　186\n14.3　汇率预测问题的引入　186\n14.4　用于汇率预测的LSTM神经网络模型　187\n14.5　实现汇率预测LSTM网络的代码　188\n14.6　用循环神经网络来进行自然语言处理　193\n14.7　本章小结：时序有关问题　195\n14.8　练习　195\n第15章　优化器的选择与设置　196\n15.1　优化器的作用　197\n15.2　梯度下降算法　197\n15.3　学习率的影响　198\n15.4　主流优化方法介绍　199\n15.5　优化器效率对比　200\n15.6　本章小结：渡河之筏　203\n第16章　下一步学习方向指南　204\n16.1　更多的激活函数　205\n16.2　更多的隐藏层类型　205\n16.3　确定最适合的神经网络类型　206\n16.4　GPU版本　206\n16.5　有监督学习与无监督学习　207\n16.6　深度学习进阶　207\n16.7　升级到最新的TensorFlow版本　207\n16.8　本章小结：最后的实例　208","pages":"350","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29969505.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29969505.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29969505.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30310954\/","id":"30310954","publisher":"","isbn10":"7115483620","isbn13":"9787115483621","title":"深度学习-基于Python语言和TensorFlow平台","url":"https:\/\/api.douban.com\/v2\/book\/30310954","alt_title":"","author_intro":"谢琼 计算机软件、通信行业和外语在线教育领域资深专家，国家认证高级系统分析师。在大型国企和世界50强IT跨国公司从事计算机系统、电信行业项目、外语在线教育项目、人工智能\/深度学习领域项目多年，曾主持编写国家电信行业安全标准，项目经验丰富，是人工智能英语分析系统“小仙英语伴读”的创始人。课程教授方式深入浅出，对实例的讲解简单易懂，易于理解，尤其适合入门学习者。","summary":"本书从人工智能发展的简要历程和深度学习概念的介绍开始，深入浅出地讲解了如何使用人工智能神经网络（尤其是当前最具潜力与热度的深度学习理论和技术）来解决实际问题。认真阅读完本书，即可掌握深度学习技术的基础知识、重要概念、主要方法和部分最佳实践，并具备足够继续往下深造的自学能力。\n本书中的案例均是结合生活中真实场景的鲜活实例，配合从零开始循序渐进的讲解，并尽量避开枯燥的数学理论和烦琐的推导过程，非常适合希望快速入门的学习者和技术人员，也适合希望简要了解人工智能、神经网络、深度学习基本概念和思维方法的读者。","price":"49.8"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"全彩精装版","author":[],"pubdate":"2019-6","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32978307.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32978307.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32978307.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32978307.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34111741\/","id":"34111741","publisher":"人民邮电出版社","isbn10":"7115505837","isbn13":"9787115505835","title":"动手学深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34111741","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"akb","title":"akb"},{"count":1,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33313786.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33313786.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33313786.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33313786.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30630593\/","id":"30630593","publisher":"","isbn10":"7111603036","isbn13":"9787111603030","title":"深度学习：核心技术、工具与案例解析","url":"https:\/\/api.douban.com\/v2\/book\/30630593","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"56.90元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["高随祥","文新","马艳军","李轩涯"],"pubdate":"2019-9-1","tags":[{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"python","title":"python"},{"count":1,"name":"NLP","title":"NLP"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33507111.jpg","binding":"平装","translator":[],"catalog":"","pages":"272","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33507111.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33507111.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33507111.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34855413\/","id":"34855413","publisher":"清华大学出版社","isbn10":"730253439X","isbn13":"9787302534396","title":"深度学习导论与应用实践","url":"https:\/\/api.douban.com\/v2\/book\/34855413","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":2,"name":"CV，特征描述子","title":"CV，特征描述子"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33514884.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33514884.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33514884.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33514884.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34815745\/","id":"34815745","publisher":"","isbn10":"7115505888","isbn13":"9787115505880","title":"计算机视觉度量 从特征描述到深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34815745","alt_title":"","author_intro":"","summary":"","series":{"id":"47813","title":"国外著名高等院校信息科学与技术优秀教材"},"price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["段金菊"],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33504630.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33504630.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33504630.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33504630.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30904230\/","id":"30904230","publisher":"科学出版社","isbn10":"7030565169","isbn13":"9787030565167","title":"学习科学视域下的网络深度学习：理论·技术·趋势","url":"https:\/\/api.douban.com\/v2\/book\/30904230","alt_title":"","author_intro":"","summary":"","price":"71.20元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"运用Python实现高级深度学习模型","author":["[印度]莫希特·赛瓦克（Mohit Sewak）等"],"pubdate":"","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"好多书可下","title":"好多书可下"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32304056.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"181","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32304056.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32304056.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32304056.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33426332\/","id":"33426332","publisher":"机械工业出版社","isbn10":"7111621964","isbn13":"9787111621966","title":"实用卷积神经网络:运用Python实现高级深度学习模型","url":"https:\/\/api.douban.com\/v2\/book\/33426332","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"69元"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["刘焱"],"pubdate":"2018-1","tags":[{"count":5,"name":"安全","title":"安全"},{"count":4,"name":"信息安全","title":"信息安全"},{"count":3,"name":"深度学习","title":"深度学习"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"web","title":"web"},{"count":1,"name":"中国","title":"中国"},{"count":1,"name":"2018","title":"2018"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29655818.jpg","binding":"","translator":[],"catalog":"对本书的赞誉\n序\n前言\n第1章　打造深度学习工具箱1\n1.1　TensorFlow1\n1.1.1　安装1\n1.1.2　使用举例3\n1.2　TFLearn3\n1.3　PaddlePaddle4\n1.3.1　安装5\n1.3.2　使用举例6\n1.4　Karas7\n1.5　本章小结9\n第2章　卷积神经网络10\n2.1　传统的图像分类算法10\n2.2　基于CNN的图像分类算法11\n2.2.1　局部连接11\n2.2.2　参数共享13\n2.2.3　池化15\n2.2.4　典型的CNN结构及实现16\n2.2.5　AlexNet的结构及实现19\n2.2.6　VGG的结构及实现24\n2.3　基于CNN的文本处理29\n2.3.1　典型的CNN结构30\n2.3.2　典型的CNN代码实现30\n2.4　本章小结32\n第3章　循环神经网络33\n3.1　循环神经算法概述34\n3.2　单向循环神经网络结构与实现36\n3.3　双向循环神经网络结构与实现38\n3.4　循环神经网络在序列分类的应用41\n3.5　循环神经网络在序列生成的应用42\n3.6　循环神经网络在序列标记的应用43\n3.7　循环神经网络在序列翻译的应用44\n3.8　本章小结46\n第4章　基于OpenSOC的机器学习框架47\n4.1　OpenSOC框架47\n4.2　数据源系统48\n4.3　数据收集层53\n4.4　消息系统层57\n4.5　实时处理层60\n4.6　存储层62\n4.6.1　HDFS62\n4.6.2　HBase64\n4.6.3　Elasticsearch65\n4.7　分析处理层66\n4.8　计算系统67\n4.9　实战演练72\n4.10　本章小结77\n第5章　验证码识别78\n5.1　数据集79\n5.2　特征提取80\n5.3　模型训练与验证81\n5.3.1　K近邻算法81\n5.3.2　支持向量机算法81\n5.3.3　深度学习算法之MLP82\n5.3.4　深度学习算法之CNN83\n5.4　本章小结87\n第6章　垃圾邮件识别88\n6.1　数据集89\n6.2　特征提取90\n6.2.1　词袋模型90\n6.2.2　TF-IDF模型93\n6.2.3　词汇表模型95\n6.3　模型训练与验证97\n6.3.1　朴素贝叶斯算法97\n6.3.2　支持向量机算法100\n6.3.3　深度学习算法之MLP101\n6.3.4　深度学习算法之CNN102\n6.3.5　深度学习算法之RNN106\n6.4　本章小结108\n第7章　负面评论识别109\n7.1　数据集110\n7.2　特征提取112\n7.2.1　词袋和TF-IDF模型112\n7.2.2　词汇表模型114\n7.2.3　Word2Vec模型和Doc2Vec模型115\n7.3　模型训练与验证119\n7.3.1　朴素贝叶斯算法119\n7.3.2　支持向量机算法122\n7.3.3　深度学习算法之MLP123\n7.3.4　深度学习算法之CNN124\n7.4　本章小结127\n第8章　骚扰短信识别128\n8.1　数据集129\n8.2　特征提取130\n8.2.1　词袋和TF-IDF模型130\n8.2.2　词汇表模型131\n8.2.3　Word2Vec模型和Doc2Vec模型132\n8.3　模型训练与验证134\n8.3.1　朴素贝叶斯算法134\n8.3.2　支持向量机算法136\n8.3.3　XGBoost算法137\n8.3.4　深度学习算法之MLP140\n8.4　本章小结141\n第9章　Linux后门检测142\n9.1　数据集142\n9.2　特征提取144\n9.3　模型训练与验证145\n9.3.1　朴素贝叶斯算法145\n9.3.2　XGBoost算法146\n9.3.3　深度学习算法之多层感知机148\n9.4　本章小结149\n第10章　用户行为分析与恶意行为检测150\n10.1　数据集151\n10.2　特征提取152\n10.2.1　词袋和TF-IDF模型152\n10.2.2　词袋和N-Gram模型154\n10.2.3　词汇表模型155\n10.3　模型训练与验证156\n10.3.1　朴素贝叶斯算法156\n10.3.2　XGBoost算法157\n10.3.3　隐式马尔可夫算法159\n10.3.4　深度学习算法之MLP164\n10.4　本章小结166\n第11章　WebShell检测167\n11.1　数据集168\n11.1.1　WordPress168\n11.1.2　PHPCMS170\n11.1.3　phpMyAdmin170\n11.1.4　Smarty171\n11.1.5　Yii171\n11.2　特征提取172\n11.2.1　词袋和TF-IDF模型172\n11.2.2　opcode和N-Gram模型174\n11.2.3　opcode调用序列模型180\n11.3　模型训练与验证181\n11.3.1　朴素贝叶斯算法181\n11.3.2　深度学习算法之MLP182\n11.3.3　深度学习算法之CNN184\n11.4　本章小结188\n第12章　智能扫描器189\n12.1　自动生成XSS攻击载荷190\n12.1.1　数据集190\n12.1.2　特征提取194\n12.1.3　模型训练与验证195\n12.2　自动识别登录界面198\n12.2.1　数据集198\n12.2.2　特征提取199\n12.2.3　模型训练与验证201\n12.3　本章小结203\n第13章　DGA域名识别204\n13.1　数据集206\n13.2　特征提取207\n13.2.1　N-Gram模型207\n13.2.2　统计特征模型208\n13.2.3　字符序列模型210\n13.3　模型训练与验证210\n13.3.1　朴素贝叶斯算法210\n13.3.2　XGBoost算法212\n13.3.3　深度学习算法之多层感知机215\n13.3.4　深度学习算法之RNN218\n13.4　本章小结221\n第14章　恶意程序分类识别222\n14.1　数据集223\n14.2　特征提取226\n14.3　模型训练与验证228\n14.3.1　支持向量机算法228\n14.3.2　XGBoost算法229\n14.3.3　深度学习算法之多层感知机230\n14.4　本章小结231\n第15章　反信用卡欺诈232\n15.1　数据集232\n15.2　特征提取234\n15.2.1　标准化234\n15.2.2　标准化和降采样234\n15.2.3　标准化和过采样236\n15.3　模型训练与验证239\n15.3.1　朴素贝叶斯算法239\n15.3.2　XGBoost算法243\n15.3.3　深度学习算法之多层感知机247\n15.4　本章小结251","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29655818.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29655818.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29655818.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27619865\/","id":"27619865","publisher":"机械工业出版社","isbn10":"7111584473","isbn13":"9787111584476","title":"Web安全之深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/27619865","alt_title":"","author_intro":"刘焱 百度安全Web防护产品线负责人，负责百度安全的Web安全产品，包括防DDoS、Web应用防火墙、Web威胁感知、服务器安全以及安全数据分析等，具有近十年云安全及企业安全从业经历，全程参与了百度企业安全建设。研究兴趣包括机器学习、Web安全、僵尸网络、威胁情报等。他是FreeBuf专栏作家、i春秋知名讲师，多次在OWASP 、电子学会年会等发表演讲，参与编写了《大数据安全标准白皮书》。他还建立了微信公众号“兜哥带你学安全”，分享了大量信息安全技术知识。AI+安全畅销书《Web安全之机器学习》的作者。","summary":"在现今的互联网公司中，产品线绵延复杂，安全防御体系无时无刻不在应对新的挑战。哪怕是拥有丰富工作经验的安全从业者，在面对层出不穷的攻击手段和海量日志数据时也会望洋兴叹。机器学习、深度学习是这些问题天然契合的解决方案，在数据量以指数级不断增长的未来，甚至有可能是唯一的出路。当AI遇到安全时，如何快速进化，本书给出了实战方案。 　　本书是《Web安全之机器学习入门》之后又一作品。本书首先介绍如何打造自己的深度学习工具箱，包括TensorFlow、TFLearn等深度学习库的安装以及使用方法。接着介绍卷积神经网络和循环神经网络这两大深度学习算法的基础知识。特别着重介绍在生产环境搭建深度学习平台需要使用的开源组件，包括Logstash、Kafka、Storm、Spark等。随后讲解了11个使用机器学习技术解决实际安全问题的案例，包括验证码识别、垃圾邮件识别、负面评论识别、骚扰短信识别、Linux后门检测、恶意操作行为检测、Webshell检测、智能扫描、DGA域名检测、恶意程序分类识别、反信用卡欺诈。本书针对每一个算法都给出了具体案例，理论结合实际，讲解清晰，文笔幽默，适合有信息安全基础知识的网络开发与运维技术人员参考，主要内容包括：\n- 如何基于TensorFlow和TFLearn打造自己的深度学习工具箱。\n- 如何基于Logstash、Kafka、Storm、Spark等打造深度学习的生产环境。\n- 如何在MNIST数据集上实现验证码识别。\n- 如何在安然数据集上实现垃圾邮件检测。\n- 如何在IMDB数据集上实现负面评论识别。\n- 如何在SMSSpamCollection数据集上实现骚扰短信识别。\n- 如何在ADFA-LD数据集上实现Linux后门检测。\n- 如何在SEA数据集上实现恶意操作行为检测。\n- 如何在MIST数据集上实现恶意程序分类识别。\n- 如何在Kaggle公开的数据集上实现信用卡欺诈检测。\n- 如何在GitHub公开的数据集上实现Webshell检测，智能扫描和DGA域名检测。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"79"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["龙飞","王永兴"],"pubdate":"2017-9-1","tags":[{"count":2,"name":"机器学习","title":"机器学习"},{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29664168.jpg","binding":"","translator":[],"catalog":"","pages":"189","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29664168.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29664168.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29664168.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27664033\/","id":"27664033","publisher":"","isbn10":"7302482780","isbn13":"9787302482789","title":"深度学习：入门与实践","url":"https:\/\/api.douban.com\/v2\/book\/27664033","alt_title":"","author_intro":"","summary":"《深度学习：入门与实践》由一线资深技术专家撰写，凝结了其自身多年的实践经验，阐述了深度学习的发展历程、相关概念和工作原理，介绍了两个当前流行的深度学习工具：Caffe 和TensorFlow ，并且初步探讨了强化学习的基本原理和应用。为了帮助初学者快速上手，《深度学习：入门与实践》注重从总体框架和脉络上把握深度学习技术，同时在阐述原理时配以简单的实例供读者印证。\n《深度学习：入门与实践》语言生动风趣，以通俗的语言讲述复杂的原理，循循善诱，深入浅出，深度学习：入门与实践适合有志于从事人工智能、深度学习相关研究的信息类专业的高年级本科生或研究生阅读，也可供业界准备或正在从事深度学习、机器视觉等相关研发工作的工程技术人员参考。","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["刘凡平","等"],"pubdate":"2018-3-1","tags":[{"count":1,"name":"图书馆","title":"图书馆"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29745963.jpg","binding":"平装","translator":[],"catalog":"基础篇\n第1章  时代崛起  2\n1.1  概要  2\n1.1.1  基本概念  2\n1.1.2  深度学习与机器学习的关系  4\n1.1.3  深度学习与人工智能的关系  5\n1.2  历史发展  5\n1.2.1  神经网络发展历史  5\n1.2.2  人工智能发展历史  7\n1.3  应用领域  8\n1.3.1  智能个人助理  8\n1.3.2  智能安防  9\n1.3.3  无人驾驶  9\n1.3.4  电商零售  11\n1.3.5  智慧医疗  11\n1.3.6  金融服务  12\n1.3.7  智能教育  13\n1.4  未来猜想  14\n1.4.1  人文的快速发展  14\n1.4.2  人类也是“机器人”  14\n1.4.3  新的不平等现象  15\n1.5  本章小结  16\n第2章  数学理论基础  17\n2.1  向量  17\n2.1.1  相关概念  17\n2.1.2  向量的线性相关性  18\n2.1.3  向量的外积  18\n2.1.4  向量夹角与余弦相似性  18\n2.1.5  实例：基于向量夹角的文本相似性分析  19\n2.2  矩阵  20\n2.2.1  矩阵乘法  20\n2.2.2  克罗内克积  21\n2.3  导数  22\n2.3.1  概述  22\n2.3.2  一般运算法则  22\n2.3.3  链式求导法则  23\n2.4  数值计算  23\n2.4.1  误差  23\n2.4.2  距离  24\n2.4.3  数值归一化  26\n2.5  概率分布  26\n2.5.1  二项分布  26\n2.5.2  超几何分布  27\n2.5.3  泊松分布  27\n2.5.4  指数分布  28\n2.5.5  正态分布  29\n2.6  参数估计  29\n2.6.1  概率  29\n2.6.2  贝叶斯估计  30\n2.6.3  最大似然估计  31\n2.6.4  最大后验估计  32\n2.7  回归分析  33\n2.7.1  线性回归  33\n2.7.2  逻辑回归  36\n2.8  判定问题  39\n2.8.1  P问题  39\n2.8.2  NP问题  39\n2.8.3  NP-Complete问题  40\n2.8.4  NP-Hard问题  40\n2.9  本章小结  41\n第3章  机器学习概要  42\n3.1  机器学习的类型  42\n3.1.1  有监督学习  42\n3.1.2  无监督学习  43\n3.1.3  强化学习  43\n3.2  机器学习中常见的函数  44\n3.2.1  激活函数  44\n3.2.2  损失函数  47\n3.2.3  核函数  48\n3.3  机器学习中的重要参数  49\n3.3.1  学习速率  49\n3.3.2  动量系数  50\n3.3.3  偏置项  50\n3.4  拟合问题  51\n3.4.1  过拟合现象  51\n3.4.2  欠拟合现象  52\n3.4.3  解决过拟合问题的一般方法  52\n3.4.4  实例：拟合与二元一次方程求解  55\n3.5  交叉检验  55\n3.5.1  数据类型种类  55\n3.5.2  留一交叉验证  57\n3.5.3  K折交叉验证  57\n3.6  线性可分与不可分  58\n3.7  机器学习的学习特征  59\n3.8  产生式模型与判别式模型  60\n3.9  机器学习效果的一般评价指标  61\n3.10  本章小结  63\n第4章  神经网络基础  64\n4.1  概述  64\n4.1.1  神经网络模型  64\n4.1.2  经典的神经网络结构  65\n4.1.3  一般业务场景中神经网络适应性  66\n4.1.4  神经网络的深度  67\n4.2  常见学习方法  67\n4.2.1  误差修正学习  67\n4.2.2  赫布学习规则  68\n4.2.3  最小均方规则  69\n4.2.4  竞争学习规则  70\n4.2.5  其他学习规则  71\n4.3  优化方法：梯度下降  72\n4.3.1  概述  72\n4.3.2  梯度下降法  72\n4.3.3  梯度下降的优化算法  74\n4.3.4  梯度消失问题  76\n4.3.5  示例：利用梯度下降法求函数极值  77\n4.4  常见的神经网络类型  78\n4.4.1  前馈型神经网络  78\n4.4.2  反馈型神经网络  79\n4.4.3  自组织竞争型神经网络  79\n4.5  深度学习中常见的网络类型  80\n4.5.1  卷积神经网络  80\n4.5.2  循环神经网络  80\n4.5.3  深度信念网络  80\n4.5.4  生成对抗网络  81\n4.5.5  深度强化学习  81\n4.6  其他神经网络与深度学习  82\n4.6.1  随机神经网络  82\n4.6.2  量子神经网络  82\n4.6.3  迁移学习  82\n4.7  深度学习与多层神经网络的关系  83\n4.8  调参技巧  84\n4.9  本章小结  85\n进阶篇\n第5章  前馈型神经网络  88\n5.1  概述  88\n5.2  常见结构  88\n5.3  单层感知器网络  89\n5.3.1  原理  89\n5.3.2  网络结构  90\n5.3.3  实例一：基于单层感知器“与”运算  90\n5.3.4  实例二：利用感知器判定零件是否合格  91\n5.4  BP神经网络  93\n5.4.1  概述  93\n5.4.2  反向传播算法  93\n5.4.3  异或问题的解决  96\n5.4.4  避免病态结果  98\n5.4.5  实例：基于多层感知器的手写体数字识别  99\n5.5  径向基函数神经网络  101\n5.5.1  原理介绍  101\n5.5.2  中心选择方法  102\n5.5.3  训练过程  103\n5.5.4  径向基函数神经网络与BP神经网络的差异  104\n5.6  本章小结  105\n第6章  反馈型神经网络  107\n6.1  概述  107\n6.1.1  基本原理  107\n6.1.2  与前馈型神经网络的差异  108\n6.2  Hopfield神经网络  109\n6.3  Elman神经网络  112\n6.3.1  结构组成  112\n6.3.2  学习算法  112\n6.4  递归神经网络  113\n6.4.1  产生背景  114\n6.4.2  基本结构  115\n6.4.3  前向计算过程  116\n6.4.4  反向传播：BPTS算法  117\n6.4.5  应用场景  118\n6.4.6  递归神经网络的结构改进  118\n6.4.7  应用实例  121\n6.5  本章小结  124\n第7章  自组织竞争型神经网络  125\n7.1  概述  125\n7.1.1  一般网络模型  125\n7.1.2  工作原理  126\n7.1.3  实例：用竞争学习规则进行模式分类  127\n7.2  常见的聚类方法  129\n7.2.1  系统聚类法  129\n7.2.2  基于划分的聚类算法  130\n7.2.3  基于密度的聚类算法  131\n7.2.4  基于层次的聚类算法  132\n7.3  自组织映射网络  134\n7.3.1  概述  134\n7.3.2  训练算法  134\n7.3.3  实例：利用自组织映射网络划分城市群  135\n7.3.4  优劣势分析  136\n7.4  其他自组织竞争型神经网络  137\n7.4.1  自适应共振理论  137\n7.4.2  对偶传播神经网络  138\n7.5  本章小结  139\n高阶篇\n第8章  卷积神经网络  142\n8.1  概述  142\n8.1.1  发展背景  142\n8.1.2  基本概念  143\n8.1.3  基本网络结构  144\n8.2  卷积  145\n8.2.1  卷积的物理意义  145\n8.2.2  卷积的理解  145\n8.2.3  卷积的实例  147\n8.3  卷积核  148\n8.3.1  卷积核的含义  148\n8.3.2  卷积操作  150\n8.3.3  卷积核的特征  150\n8.4  卷积神经网络中各层工作原理  151\n8.4.1  卷积层  151\n8.4.2  下采样层  151\n8.4.3  Softmax层  152\n8.5  卷积神经网络的逆向过程  153\n8.6  常见卷积神经网络结构  154\n8.6.1  LeNet-5  154\n8.6.2  AlexNet  155\n8.7  应用场景与效果评估  157\n8.7.1  场景1：图像分类  157\n8.7.2  场景2：目标检测  158\n8.7.3  场景3：实例分割  159\n8.8  Maxout Networks  160\n8.9  本章小结  162\n第9章  循环神经网络  163\n9.1  概述  163\n9.2  一般循环神经网络  164\n9.2.1  概述  164\n9.2.2  单向循环神经网络  165\n9.2.3  双向循环神经网络  166\n9.2.4  深度循环神经网络  167\n9.3  训练算法：BPTT算法  168\n9.3.1  前向计算  168\n9.3.2  误差项计算  169\n9.3.3  权值梯度计算  169\n9.3.4  梯度爆炸与梯度消失问题  170\n9.4  长短时记忆网络  170\n9.4.1  背景  170\n9.4.2  核心思想  171\n9.4.3  详细结构  172\n9.4.4  训练过程  176\n9.4.5  相关变种简介  181\n9.5  常见循环神经网络结构  182\n9.5.1  N比N结构  182\n9.5.2  N比1结构  183\n9.5.3  1比N结构  183\n9.5.4  N比M结构  184\n9.6  与自然语言处理结合  185\n9.7  实例：文本自动生成  186\n9.8  本章小结  187\n第10章  深度信念网络  188\n10.1  概要  188\n10.1.1  背景  188\n10.1.2  基本结构  188\n10.2  受限玻尔兹曼机  190\n10.2.1  概述  190\n10.2.2  逻辑结构  192\n10.2.3  对比分歧算法  194\n10.3  训练过程  194\n10.3.1  工作流程  194\n10.3.2  调优过程  195\n10.4  本章小结  196\n第11章  生成对抗网络  197\n11.1  概述  197\n11.1.1  背景概要  197\n11.1.2  核心思想  198\n11.1.3  基本工作流程  199\n11.2  朴素生成对抗网络  201\n11.2.1  网络结构  201\n11.2.2  实例：基于朴素生成对抗网络生成手写体数字  203\n11.3  深度卷积生成对抗网络  206\n11.3.1  产生背景  206\n11.3.2  模型改进  206\n11.3.3  网络结构  207\n11.3.4  实例：基于深度卷积对抗网络生成手写体数字  208\n11.4  条件生成对抗网络  212\n11.4.1  网络结构  212\n11.4.2  实例：CGAN结合DCGAN生成手写体数字  213\n11.5  瓦瑟斯坦生成对抗网络  214\n11.5.1  概述  214\n11.5.2  差异化  215\n11.5.3  实例：WGAN结合DCGAN生成手写体数字  216\n11.6  生成对抗网络的探索  217\n11.6.1  价值与意义  217\n11.6.2  面临的问题  218\n11.6.3  应用场景示例  218\n11.6.4  未来探索  220\n11.7  本章小结  220\n第12章  深度强化学习  221\n12.1  概述  221\n12.1.1  概要  221\n12.1.2  基本原理  222\n12.2  马尔科夫决策过程  223\n12.2.1  马尔科夫过程  223\n12.2.2  隐马尔科夫模型  224\n12.2.3  马尔科夫决策过程  225\n12.3  深度强化学习算法  229\n12.3.1  DQN算法  229\n12.3.2  A3C算法  231\n12.3.3  UNREAL算法  231\n12.4  强化学习的探索  232\n12.4.1  应用场景探索  232\n12.4.2  面临的问题  233\n12.5  本章小结  234","ebook_url":"https:\/\/read.douban.com\/ebook\/59774632\/","pages":"252","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29745963.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29745963.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29745963.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30190231\/","id":"30190231","publisher":"电子工业出版社","isbn10":"7121337185","isbn13":"9787121337185","title":"神经网络与深度学习应用实战","url":"https:\/\/api.douban.com\/v2\/book\/30190231","alt_title":"","author_intro":"","summary":"《神经网络与深度学习应用实战》结合实际应用介绍神经网络和深度学习等技术领域相关信息。从结构上重点介绍了前馈型神经网络、反馈型神经网络，以及自组织竞争型神经网络，并针对当下深度学习中比较重要的网络进行了详细介绍，包括卷积神经网络、循环（递归）神经网络、深度信念网络、生成对抗网络，以及深度强化学习。《神经网络与深度学习应用实战》不仅能让读者对当前神经网络和深度学习技术有体系的认知，更能让读者在人工智能领域进行一些深入思考。","ebook_price":"41.40","series":{"id":"41172","title":"博文视点AI系列"},"price":"CNY 69.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"算法原理与编程实战","author":["蒋子阳"],"pubdate":"2019-1-1","tags":[{"count":3,"name":"机器学习","title":"机器学习"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"【已购】","title":"【已购】"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s30012399.jpg","binding":"平装","translator":[],"catalog":"第一部分探索深度学习之方式的开始\n第1章开篇\n1.1人工智能的发展\n1.1.1萌芽\n1.1.2复苏\n1.1.3现代实践：大数据+深度神经网络模型\n1.2大数据\n1.3机器学习与深度学习\n1.3.1机器学习\n1.3.2深度学习\n1.3.3同人工智能的关系\n1.4人工神经网络与TensorFlow\n1.4.1人工神经网络\n1.4.2TensorFlow\n1.5其他主流深度学习框架介绍\n1.5.1Caffe\n1.5.2Torch\n1.5.3Theano\n1.5.4MXNet\n1.5.5Keras\n1.6机器学习的常见任务\n1.6.1分类\n1.6.2回归\n1.6.3去噪\n1.6.4转录\n1.6.5机器翻译\n1.6.6异常检测\n1.6.7结构化输出\n1.7深度学习的现代应用\n1.7.1计算机视觉\n1.7.2自然语言处理\n1.7.3语音识别\n第2章安装TensorFlow\n2.1安装前的须知\n2.1.1检查硬件是否达标\n2.1.2推荐选用GPU进行训练\n2.1.3为什么选择Linux系统\n2.1.4为什么选择Python语言\n2.2安装Anaconda\n2.3TensorFlow的两个主要依赖包\n2.3.1Protocol Buffer\n2.3.2Bazel\n2.4安装CUDA和cuDNN\n2.4.1CUDA\n2.4.2cuDNN\n2.5正式安装TensorFlow\n2.5.1使用pip安装\n2.5.2从源代码编译并安装\n2.6测试你的TensorFlow\n2.6.1运行向量相加的例子\n2.6.2加载过程存在的一些问题\n2.7推荐使用IDE\n第3章TensorFlow编程策略\n3.1初识计算图与张量\n3.2计算图——TensorFlow的计算模型\n3.3张量——TensorFlow的数据模型\n3.3.1概念\n3.3.2使用张量\n3.4会话——TensorFlow的运行模型\n3.4.1TensorFlow系统结构概述\n3.4.2简单使用会话\n3.4.3使用with\/as环境上下文管理器\n3.4.4Session的参数配置\n3.4.5placeholder机制\n3.5TensorFlow变量\n3.5.1创建变量\n3.5.2变量与张量\n3.6管理变量的变量空间\n3.6.1get_variable()函数\n3.6.2variable_scope()与name_scope()\n第二部分TensorFlow实现深度网络\n第4章深度前馈神经网络\n4.1网络的前馈方式\n4.2全连接\n4.2.1神经元与全连接结构\n4.2.2前向传播算法\n4.3线性模型的局限性\n4.4激活函数\n4.4.1常用激活函数\n4.4.2激活函数实现去线性化\n4.5多层网络解决异或运算\n4.6损失函数\n4.6.1经典损失函数\n4.6.2自定义损失函数\n第5章优化网络的方法\n5.1基于梯度的优化\n5.1.1梯度下降算法\n5.1.2随机梯度下降\n5.2反向传播\n5.2.1简要解释反向传播算法\n5.2.2自适应学习率算法\n5.2.3TensorFlow提供的优化器\n5.3学习率的独立设置\n5.3.1指数衰减的学习率\n5.3.2其他优化学习率的方法\n5.4拟合\n5.4.1过拟合和欠拟合\n5.4.2正则化的方法\n5.4.3Bagging方法\n5.4.4Dropout方法\n第6章全连神经网络的经典实践\n6.1MNIST数据集\n6.2网络的设计\n6.3超参数和验证集\n6.4与简单模型的对比\n第7章卷积神经网络\n7.1准备性的认识\n7.1.1图像识别与经典数据集\n7.1.2卷积网络的神经科学基础\n7.1.3卷积神经网络的历史\n7.2卷积\n7.2.1卷积运算\n7.2.2卷积运算的稀疏连接\n7.2.3卷积运算的参数共享\n7.2.4卷积运算的平移等变\n7.2.5多卷积核\n7.2.6卷积层的代码实现\n7.3池化\n7.3.1池化过程\n7.3.2常用池化函数\n7.3.3池化层的代码实现\n7.4实现卷积神经网络的简例\n7.4.1卷积神经网络的一般框架\n7.4.2用简单卷积神经网络实现Cifar-10数据集分类\n7.5图像数据处理\n7.5.1图像编解码处理\n7.5.2翻转图像\n7.5.3图像色彩调整\n7.5.4图像标准化处理\n7.5.5调整图像大小\n7.5.6图像的标注框\n第8章经典卷积神经网络\n8.1LeNet-5卷积网络模型\n8.1.1模型结构\n8.1.2TensorFlow实现\n8.2AlexNet卷积网络模型\n8.2.1模型结构\n8.2.2TensorFlow实现\n8.3VGGNet卷积网络模型\n8.3.1模型结构\n8.3.2TensorFlow实现\n8.4InceptionNet-V3卷积网络模型\n8.4.1模型结构\n8.4.2Inception V3 Module的实现\n8.4.3使用Inception V3完成模型迁移\n8.5ResNet卷积网络模型\n8.5.1模型结构\n8.5.2TensorFlow实现\n第9章循环神经网络\n9.1循环神经网络简介\n9.1.1循环神经网络的前向传播程序设计\n9.1.2计算循环神经网络的梯度\n9.1.3循环神经网络的不同设计模式\n9.2自然语言建模与词向量\n9.2.1统计学语言模型\n9.2.2Word2Vec\n9.2.3用TensorFlow实现Word2Vec\n9.3LSTM实现自然语言建模\n9.3.1长短时记忆网络（LSTM）\n9.3.2LSTM在自然语言建模中的应用\n9.3.3循环神经网络的Dropout\n9.4循环神经网络的变种\n9.4.1双向循环神经网络\n9.4.2深层循环神经网络\n第10章深度强化学习\n10.1理解基本概念\n10.2深度强化学习的思路\n10.3典型应用场景举例\n10.3.1场景1：机械臂自控\n10.3.2场景2：自动游戏系统\n10.3.3场景3：自动驾驶\n10.3.4场景4：智能围棋系统\n10.4Q学习与深度Q网络\n10.4.1Q学习与深度Q学习\n10.4.2深度Q网络\n第三部分TensorFlow的使用进阶\n第11章数据读取\n11.1文件格式\n11.1.1TFRecord格式\n11.1.2CSV格式\n11.2队列\n11.2.1数据队列\n11.2.2文件队列\n11.3使用多线程处理输入的数据\n11.3.1使用Coordinator类管理线程\n11.3.2使用QueueRunner创建线程\n11.4组织数据batch\n第12章模型持久化\n12.1通过代码实现\n12.2模型持久化的原理\n12.2.1model.ckpt.mate文件\n12.2.2从.index与.data文件读取变量的值\n12.3持久化的MNIST手写字识别\n12.4PB文件\n第13章TensorBoard可视化\n13.1TensorBoard简要介绍\n13.2MNIST手写字识别的可视化\n13.2.1实现的过程\n13.2.2标量数据可视化结果\n13.2.3图像数据可视化结果\n13.2.4计算图可视化结果\n13.3其他监控指标可视化\n第14章加速计算\n14.1TensorFlow支持的设备\n14.2TensorFlow单机实现\n14.2.1查看执行运算的设备\n14.2.2device()函数的使用\n14.3并行训练的原理\n14.3.1数据并行\n14.3.2模型并行\n14.4单机多GPU加速TensorFlow程序\n14.4.1实现的过程\n14.4.2多GPU并行的可视化\n14.5分布式TensorFlow概述","pages":"596","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s30012399.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s30012399.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s30012399.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30468262\/","id":"30468262","publisher":"中国水利水电出版社","isbn10":"7517068229","isbn13":"9787517068228","title":"TensorFlow深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30468262","alt_title":"","author_intro":"蒋子阳，多年专业编程工作经验，曾参与多个机器人目标识别与定位等深度学习相关项目，擅长图像识别算法、语音识别算法等。涉及行业包括金融、证券、汽车、公共安全等领域。近年来，本人对机器学习及深度学习进行了深入研究，随着TensorFlow的出现，开始将精力转移到TensorFlow深度学习算法原理的研究中，并专门推导过其中的大部分算法，对该框架有着独特的认识和深入的理解。","summary":"TensorFlow是谷歌研发的人工智能学习系统，是一个用于数值计算的开源软件库。《TensorFlow深度学习算法原理与编程实战》以基础+实践相结合的形式，详细介绍了TensorFlow深度学习算法原理及编程技巧。通读全书，读者不仅可以系统了解深度学习的相关知识，还能对使用TensorFlow进行深度学习算法设计的过程有更深入的理解。\n《TensorFlow深度学习算法原理与编程实战》共14章，主要内容有：人工智能、大数据、机器学习和深度学习概述；深度学习及TensorFlow框架的相关背景；TensorFlow的安装；TensorFlow编程策略；深度前馈神经网络；优化网络的方法；全连神经网络的经典实践；卷积神经网络的基础知识；经典卷积神经网络的TensorFlow实现；循环神经网络及其应用；深度强化学习概述；TensorFlow读取数据的API；TensorFlow持久化模型的API；可视化工具TensorBoard的使用；TensorFlow使用多GPU或并行的方式加速计算等。\n《TensorFlow深度学习算法原理与编程实战》内容通俗易懂，案例丰富，实用性强，特别适合对人工智能、深度学习感兴趣的的相关从业人员阅读，也适合没有相关基础但是对该方面研究充满兴趣的爱好者阅读。","price":"99.80元"},{"rating":{"max":10,"numRaters":10,"average":"6.5","min":0},"subtitle":"谷歌工程师前沿解读人工智能","author":["日经大数据"],"pubdate":"2018-7","tags":[{"count":5,"name":"深度学习","title":"深度学习"},{"count":3,"name":"科普","title":"科普"},{"count":3,"name":"人工智能","title":"人工智能"},{"count":2,"name":"商业","title":"商业"},{"count":1,"name":"自助机","title":"自助机"},{"count":1,"name":"未购买","title":"未购买"},{"count":1,"name":"上图","title":"上图"},{"count":1,"name":"2019","title":"2019"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29941774.jpg","binding":"平装","translator":["王星星"],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29941774.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29941774.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29941774.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30397083\/","id":"30397083","publisher":"华中科技大学出版社","isbn10":"7568042332","isbn13":"9787568042338","title":"深度学习的商业化应用","url":"https:\/\/api.douban.com\/v2\/book\/30397083","alt_title":"","author_intro":"","summary":"","price":"35"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"图像处理入门","author":["[中]杨培文","[中]胡博强"],"pubdate":"2018-10-1","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"理学\/工学","title":"理学\/工学"},{"count":1,"name":"中文版","title":"中文版"},{"count":1,"name":"中国","title":"中国"},{"count":1,"name":"2010s","title":"2010s"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29896312.jpg","binding":"平装","translator":[],"catalog":"第1章  搭建指定的开发环境1\n1.1  为什么要使用指定的开发环境1\n1.2  硬件准备2\n1.2.1  在亚马#租用云GPU服务器2\n1.2.2  在腾讯云租用GPU服务器4\n1.2.3  在云服务器中开启搭载开发环境的Docker服务8\n1.3  软件准备9\n1.3.1  在Ubuntu 16.04下配置环境9\n1.3.2  在CentOS 7下配置环境12\n1.4  参考文献及网页链接12\n第2章  温故知新——机器学习基础知识13\n2.1  人工智能、机器学习与深度学习13\n2.2  训练一个传统的机器学习模型15\n2.2.1  第#步，观察数据16\n2.2.2  第#步，预览数据17\n2.3  数据挖掘与训练模型29\n2.3.1  第#步，准备数据29\n2.3.2  第#步，挖掘数据特征31\n2.3.3  第三步，使用模型37\n2.3.4  第四步，代码实战44\n2.4  参考文献及网页链接49\n第3章  数形结合——图像处理基础知识50\n3.1  读取图像文件进行基本操作51\n3.1.1  使用python-opencv读取图片51\n3.1.2  借助python-opencv进行不同编码格式的转换52\n3.1.3  借助python-opencv改变图片尺寸53\n3.2  用简单的矩阵操作处理图像53\n3.2.1  对图像进行复制与粘贴53\n3.2.2  把图像当成矩阵进行处理——二维码转换成矩阵54\n3.3  使用OpenCV“抠图”——基于颜色通道以及形态特征59\n3.4  基于传统特征的传统图像分类方法64\n3.4.1  将图片简化为少数区域并计算每个区域轮廓特征的方向66\n3.4.2  将HOG变换运用在所有正负样本中68\n3.4.3  训练模型70\n3.4.4  将训练好的分类器运用在新的图片中71\n3.5  参考文献及网页链接73\n第4章  继往开来——使用深度神经网络框架74\n4.1  从逻辑回归说起74\n4.2  深度学习框架76\n4.3  基于反向传播算法的自动求导77\n4.4  简单的深度神经网络框架实现80\n4.4.1  数据结构部分81\n4.4.2  计算图部分83\n4.4.3  使用方法85\n4.4.4  训练模型86\n4.5  参考文献及网页链接89\n第5章  排列组合——深度神经网络框架的模型元件90\n5.1  常用层92\n5.1.1  Dense92\n5.1.2  Activation92\n5.1.3  Dropout93\n5.1.4  Flatten94\n5.2  卷积层94\n5.2.1  Conv2D94\n5.2.2  Cropping2D101\n5.2.3  ZeroPadding2D101\n5.3  池化层102\n5.3.1  MaxPooling2D102\n5.3.2  AveragePooling2D102\n5.3.3  GlobalAveragePooling2D103\n5.4  正则化层与过拟合104\n5.5  反卷积层105\n5.6  循环层109\n5.6.1  SimpleRNN109\n5.6.2  LSTM109\n5.6.3  GRU110\n5.7  参考文献及网页链接110\n第6章  少量多次——深度神经网络框架的输入处理112\n6.1  批量生成训练数据113\n6.2  数据增强115\n6.3  参考文献及网页链接117\n第7章  愚公移山——深度神经网络框架的模型训练118\n7.1  随机梯度下降119\n7.2  动量法120\n7.3  自适应学习率算法121\n7.4  实验案例124\n7.5  参考文献及网页链接128\n第8章  小试牛刀——使用深度神经网络进行CIFAR-10数据分类129\n8.1  上游部分——基于生成器的批量生成输入模块131\n8.2  核心部分——用各种零件搭建深度神经网络131\n8.3  下游部分——使用凸优化模块训练模型132\n8.4  参考文献及网页链接133\n第9章  见多识广——使用迁移学习提升准确率134\n9.1  猫狗大战1.0——使用卷积神经网络直接进行训练135\n9.1.1  导入数据135\n9.1.2  可视化137\n9.1.3  分割训练集和验证集138\n9.1.4  搭建模型140\n9.1.5  模型训练141\n9.1.6  总结142\n9.2  猫狗大战2.0——使用ImageNet数据集预训练模型142\n9.2.1  迁移学习142\n9.2.2  数据预处理143\n9.2.3  搭建模型143\n9.2.4  模型可视化144\n9.2.5  训练模型145\n9.2.6  提交到kaggle评估146\n9.3  猫狗大战3.0——使用多种预训练模型组合提升表现146\n9.3.1  载入数据集147\n9.3.2  使用正确的预处理函数147\n9.3.3  搭建特征提取模型并导出特征147\n9.3.4  搭建并训练全连接分类器模型148\n9.3.5  在测试集上预测149\n9.4  融合模型150\n9.4.1  获取特征150\n9.4.2  数据持久化151\n9.4.3  构建模型151\n9.4.4  在测试集上预测152\n9.5  总结153\n9.6  参考文献及网页链接154\n第10章  看图识字——使用深度神经网络进行文字识别155\n10.1  使用卷积神经网络进行端到端学习155\n10.1.1  编写数据生成器157\n10.1.2  使用生成器157\n10.1.3  构建深度卷积神经网络158\n10.1.4  模型可视化158\n10.1.5  训练模型160\n10.1.6  计算模型总体准确率161\n10.1.7  测试模型161\n10.1.8  模型总结162\n10.2  使用循环神经网络改进模型162\n10.2.1  CTC Loss163\n10.2.2  模型结构164\n10.2.3  模型可视化165\n10.2.4  数据生成器167\n10.2.5  评估模型168\n10.2.6  评估回调169\n10.2.7  训练模型169\n10.2.8  测试模型171\n10.2.9  再次评估模型171\n10.2.10  总结173\n10.3  识别四则混合运算验证码（初赛）173\n10.3.1  问题描述174\n10.3.2  数据集探索174\n10.3.3  模型结构176\n10.3.4  结果可视化181\n10.3.5  总结182\n10.4  识别四则混合运算验证码（决赛）183\n10.4.1  问题描述183\n10.4.2  数据集探索184\n10.4.3  数据预处理186\n10.4.4  模型结构192\n10.4.5  生成器195\n10.4.6  模型的训练197\n10.4.7  预测结果198\n10.4.8  模型结果融合199\n10.4.9  其他尝试200\n10.4.10  小结202\n10.5  参考文献及网页链接203","ebook_url":"https:\/\/read.douban.com\/ebook\/107787134\/","pages":"203","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29896312.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29896312.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29896312.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30352300\/","id":"30352300","publisher":"清华大学出版社","isbn10":"7302511020","isbn13":"9787302511021","title":"深度学习技术","url":"https:\/\/api.douban.com\/v2\/book\/30352300","alt_title":"","author_intro":"","summary":"本书从机器学习、图像处理的基本概念入手，逐步阐述深度学习图像处理技术的基本原理以及简单的实现。继而以几个实战案例来介绍如何使用深度学习方法，在数据分析竞赛中取得较高的排名。#后，通过一个实战案例，介绍如何将模型放入 iOS 程序，制作相应的人工智能手机App。\n本书适用于对深度学习有兴趣、希望入门这一领域的理工科大学生、研究生，以及希望了解该领域基本原理的软件开发人员。此外，本书所有案例均提供了云环境上的代码，便于读者复现结果，并进行深入学习。","ebook_price":"41.40","price":"69.00元"},{"rating":{"max":10,"numRaters":40,"average":"7.4","min":0},"subtitle":"AI时代的数据处理与最佳实践","author":["张玉宏"],"pubdate":"2018-6","tags":[{"count":26,"name":"深度学习","title":"深度学习"},{"count":21,"name":"人工智能","title":"人工智能"},{"count":14,"name":"适合初学者","title":"适合初学者"},{"count":12,"name":"通俗易懂","title":"通俗易懂"},{"count":10,"name":"文笔流畅","title":"文笔流畅"},{"count":9,"name":"可读性强","title":"可读性强"},{"count":7,"name":"图文并茂","title":"图文并茂"},{"count":3,"name":"科学","title":"科学"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29807185.jpg","binding":"平装","translator":[],"catalog":"第１章  一入侯门“深”似海，深度学习深几许  1\n1.1  深度学习的巨大影响  2\n1.2  什么是学习  4\n1.3  什么是机器学习  4\n1.4  机器学习的4个象限  5\n1.5  什么是深度学习  6\n1.6  “恋爱”中的深度学习  7\n1.7  深度学习的方法论  9\n1.8  有没有浅层学习  13\n1.9  本章小结  14\n1.10  请你思考  14\n参考资料  14\n第2章  人工“碳”索意犹尽，智能“硅”来未可知  16\n2.1  信数据者得永生吗  17\n2.2  人工智能的“江湖定位”  18\n2.3  深度学习的归属  19\n2.4  机器学习的形式化定义  21\n2.5  为什么要用神经网络  24\n2.6  人工神经网络的特点  26\n2.7  什么是通用近似定理  27\n2.8  本章小结  31\n2.9  请你思考  31\n参考资料  31\n第3章  “机器学习”三重门，“中庸之道”趋若人  33\n3.1  监督学习  34\n3.1.1  感性认知监督学习  34\n3.1.2  监督学习的形式化描述  35\n3.1.3  k-近邻算法  37\n3.2  非监督学习  39\n3.2.1  感性认识非监督学习  39\n3.2.2  非监督学习的代表—K均值聚类  41\n3.3  半监督学习  45\n3.4  从“中庸之道”看机器学习  47\n3.5  强化学习  49\n3.6  本章小结  52\n3.7  请你思考  53\n参考资料  53\n第4章  人生苦短对酒歌， 我用Python乐趣多  55\n4.1  Python概要  56\n4.1.1  为什么要用Python  56\n4.1.2  Python中常用的库  58\n4.2  Python的版本之争  61\n4.3  Python环境配置  65\n4.3.1  Windows下的安装与配置  65\n4.3.2  Mac下的安装与配置  72\n4.4  Python编程基础  76\n4.4.1  如何运行Python代码  77\n4.4.2  代码缩进  79\n4.4.3  注释  80\n4.4.4  Python中的数据结构  81\n4.4.5  函数的设计  93\n4.4.6  模块的导入与使用  101\n4.4.7  面向对象程序设计  102\n4.5  本章小结  112\n4.6  请你思考  112\n参考资料  113\n第5章  机器学习终觉浅，Python带我来实践  114\n5.1  线性回归  115\n5.1.1  线性回归的概念  115\n5.1.2  简易线性回归的Python实现详解  119\n5.2  k-近邻算法  139\n5.2.1  k-近邻算法的三个要素  140\n5.2.2  k-近邻算法实战  143\n5.2.3  使用scikit-learn实现k-近邻算法  155\n5.3  本章小结  162\n5.4  请你思考  162\n参考资料  162\n第6章  神经网络不胜语，M-P模型似可寻  164\n6.1  M-P神经元模型是什么  165\n6.2  模型背后的那些人和事  167\n6.3  激活函数是怎样的一种存在  175\n6.4  什么是卷积函数  176\n6.5  本章小结  177\n6.6  请你思考  178\n参考资料  178\n第7章  Hello World感知机，懂你我心才安息  179\n7.1  网之初，感知机  180\n7.2  感知机名称的由来  180\n7.3  感性认识“感知机”  183\n7.4  感知机是如何学习的  185\n7.5  感知机训练法则  187\n7.6  感知机的几何意义  190\n7.7  基于Python的感知机实战  191\n7.8  感知机的表征能力  196\n7.9  本章小结  199\n7.10  请你思考  199\n参考资料  199\n第8章  损失函数减肥用，神经网络调权重  201\n8.1  多层网络解决“异或”问题  202\n8.2  感性认识多层前馈神经网络  205\n8.3  是浅而“胖”好，还是深而“瘦”佳  209\n8.4  分布式特征表达  210\n8.5  丢弃学习与集成学习  211\n8.6  现实很丰满，理想很骨感  212\n8.7  损失函数的定义  213\n8.8  热力学定律与梯度弥散  215\n8.9  本章小结  216\n8.10  请你思考  216\n参考资料  217\n第9章  山重水复疑无路，最快下降问梯度  219\n9.1  “鸟飞派”还飞不  220\n9.2  1986年的那篇神作  221\n9.3  多层感知机网络遇到的大问题  222\n9.4  神经网络结构的设计  225\n9.5  再议损失函数  227\n9.6  什么是梯度  229\n9.7  什么是梯度递减  231\n9.8  梯度递减的线性回归实战  235\n9.9  什么是随机梯度递减  238\n9.10  利用SGD解决线性回归实战  240\n9.11  本章小结  247\n9.12  请你思考  248\n参考资料  248\n第10章  BP算法双向传，链式求导最缠绵  249\n10.1  BP算法极简史  250\n10.2  正向传播信息  251\n10.3  求导中的链式法则  255\n10.4  误差反向传播  264\n10.4.1  基于随机梯度下降的BP算法  265\n10.4.2  输出层神经元的权值训练  267\n10.4.3  隐含层神经元的权值训练  270\n10.4.4  BP算法的感性认知  273\n10.4.5  关于BP算法的补充说明  278\n10.5  BP算法实战详细解释  280\n10.5.1  初始化网络  280\n10.5.2  信息前向传播  282\n10.5.3  误差反向传播  285\n10.5.4  训练网络（解决异或问题）  288\n10.5.5  利用BP算法预测小麦品种的分类  293\n10.6  本章小结  301\n10.7  请你思考  302\n参考资料  304\n第11章  一骑红尘江湖笑，TensorFlow谷歌造  305\n11.1  TensorFlow概述  306\n11.2  深度学习框架比较  309\n11.2.1  Theano  309\n11.2.2  Keras  310\n11.2.3  Caffe  311\n11.2.4  PyTorch  312\n11.3  TensorFlow的安装  313\n11.3.1  Anaconda的安装  313\n11.3.2  TensorFlow的CPU版本安装  315\n11.3.3  TensorFlow的源码编译  323\n11.4  Jupyter Notebook的使用  331\n11.4.1  Jupyter Notebook的由来  331\n11.4.2  Jupyter Notebook的安装  333\n11.5  TensorFlow中的基础语法  337\n11.5.1  什么是数据流图  338\n11.5.2  构建第一个TensorFlow数据流图  339\n11.5.3  可视化展现的TensorBoard  342\n11.5.4  TensorFlow的张量思维  346\n11.5.5  TensorFlow中的数据类型  348\n11.5.6  TensorFlow中的操作类型  353\n11.5.7  TensorFlow中的Graph对象  356\n11.5.8  TensorFlow中的Session  358\n11.5.9  TensorFlow中的placeholder  361\n11.5.10  TensorFlow中的Variable对象  363\n11.5.11  TensorFlow中的名称作用域  365\n11.5.12  张量的Reduce方向  367\n11.6  手写数字识别MNIST  372\n11.6.1  MNIST数据集简介  373\n11.6.2  MNIST数据的获取与预处理  375\n11.6.3  分类模型的构建—Softmax Regression  378\n11.7  TensorFlow中的Eager执行模式  394\n11.7.1  Eager执行模式的背景  394\n11.7.2  Eager执行模式的安装  395\n11.7.3  Eager执行模式的案例  395\n11.7.4  Eager执行模式的MNIST模型构建  398\n11.8  本章小结  401\n11.9  请你思考  402\n参考资料  403\n第12章  全面连接困何处，卷积网络显神威  404\n12.1  卷积神经网络的历史  405\n12.1.1  眼在何方？路在何方？  405\n12.1.2  卷积神经网络的历史脉络  406\n12.1.3  那场著名的学术赌局  410\n12.2  卷积神经网络的概念  412\n12.2.1  卷积的数学定义  412\n12.2.2  生活中的卷积  413\n12.3  图像处理中的卷积  414\n12.3.1  计算机“视界”中的图像  414\n12.3.2  什么是卷积核  415\n12.3.3  卷积在图像处理中的应用  418\n12.4  卷积神经网络的结构  420\n12.5  卷积层要义  422\n12.5.1  卷积层的设计动机  422\n12.5.2  卷积层的局部连接  427\n12.5.3  卷积层的3个核心概念  428\n12.6  细说激活层  434\n12.6.1  两个看似闲扯的问题  434\n12.6.2  追寻问题的本质  435\n12.6.3  ReLU的理论基础  437\n12.6.4  ReLU的不足之处  441\n12.7  详解池化层  442\n12.8  勿忘全连接层  445\n12.9  本章小结  446\n12.10  请你思考  447\n参考资料  448\n第13章  纸上谈兵终觉浅，绝知卷积要编程  450\n13.1  TensorFlow的CNN架构  451\n13.2  卷积层的实现  452\n13.2.1  TensorFlow中的卷积函数  452\n13.2.2  图像处理中的常用卷积核  456\n13.3  激活函数的使用  460\n13.3.1  Sigmoid函数  460\n13.3.2  Tanh函数  461\n13.3.3  修正线性单元——ReLU  462\n13.3.4  Dropout函数  462\n13.4  池化层的实现  466\n13.5  规范化层  470\n13.5.1  为什么需要规范化  470\n13.5.2  局部响应规范化  472\n13.5.3  批规范化  475\n13.6  卷积神经网络在MNIST分类器中的应用  480\n13.6.1  数据读取  480\n13.6.2  初始化权值和偏置  480\n13.6.3  卷积和池化  482\n13.6.4  构建第一个卷积层  482\n13.6.5  构建第二个卷积层  483\n13.6.6  实现全连接层  484\n13.6.7  实现Dropout层  485\n13.6.8  实现Readout层  485\n13.6.9  参数训练与模型评估  485\n13.7  经典神经网络——AlexNet的实现  488\n13.7.1  AlexNet的网络架构  488\n13.7.2  数据读取  490\n13.7.3  初始化权值和偏置  491\n13.7.4  卷积和池化  491\n13.7.5  局部响应归一化层  492\n13.7.6  构建卷积层  492\n13.7.7  实现全连接层和Dropout层  493\n13.7.8  实现Readout层  494\n13.7.9  参数训练与模型评估  494\n13.8  本章小结  495\n13.9  请你思考  496\n参考资料  496\n第14章  循环递归RNN，序列建模套路深  498\n14.1  你可能不具备的一种思维  499\n14.2  标准神经网络的缺陷所在  501\n14.3  RNN简史  502\n14.3.1  Hopfield网络  503\n14.3.2  Jordan递归神经网络  504\n14.3.3  Elman递归神经网络  505\n14.3.4  RNN的应用领域  506\n14.4  RNN的理论基础  506\n14.4.1  Elman递归神经网络  506\n14.4.2  循环神经网络的生物学机理  508\n14.5  RNN的结构  509\n14.6  循环神经网络的训练  512\n14.6.1  问题建模  512\n14.6.2  确定优化目标函数  513\n14.6.3  参数求解  513\n14.7  基于RNN的TensorFlow实战——正弦序列预测  514\n14.7.1  生成数据  516\n14.7.2  定义权值和偏置  517\n14.7.3  前向传播  519\n14.7.4  定义损失函数  522\n14.7.5  参数训练与模型评估  522\n14.8  本章小结  524\n14.9  请你思考  524\n参考资料  525\n第15章  LSTM长短记，长序依赖可追忆  526\n15.1  遗忘是好事还是坏事  527\n15.2  施密德胡伯是何人  527\n15.3  为什么需要LSTM  529\n15.4  拆解LSTM  530\n15.4.1  传统RNN的问题所在  530\n15.4.2  改造的神经元  531\n15.5  LSTM的前向计算  533\n15.5.1  遗忘门  534\n15.5.2  输入门  535\n15.5.3  候选门  536\n15.5.4  输出门  537\n15.6  LSTM的训练流程  539\n15.7  自然语言处理的一个假设  540\n15.8  词向量表示方法  542\n15.8.1  独热编码表示  543\n15.8.2  分布式表示  545\n15.8.3  词嵌入表示  547\n15.9  自然语言处理的统计模型  549\n15.9.1  NGram模型  549\n15.9.2  基于神经网络的语言模型  550\n15.9.3  基于循环神经网络的语言模型  553\n15.9.4  LSTM语言模型的正则化  556\n15.10  基于Penn Tree Bank的自然语言处理实战  560\n15.10.1  下载及准备PTB数据集  561\n15.10.2  导入基本包  562\n15.10.3  定义相关的参数  562\n15.10.4  语言模型的实现  563\n15.10.5  训练并返回perplexity值  573\n15.10.6  定义主函数并运行  575\n15.10.7  运行结果  578\n15.11  本章小结  579\n15.12  请你思考  580\n参考资料  580\n第16章  卷积网络虽动人，胶囊网络更传“神”  583\n16.1  从神经元到神经胶囊  584\n16.2  卷积神经网络面临的挑战  584\n16.3  神经胶囊的提出  588\n16.4  神经胶囊理论初探  591\n16.4.1  神经胶囊的生物学基础  591\n16.4.2  神经胶囊网络的哲学基础  592\n16.5  神经胶囊的实例化参数  594\n16.6  神经胶囊的工作流程  598\n16.6.1  神经胶囊向量的计算  598\n16.6.2  动态路由的工作机理  600\n16.6.3  判断多数字存在性的边缘损失函数  606\n16.6.4  胶囊神经网络的结构  607\n16.7  CapsNet的验证与实验  614\n16.7.1  重构和预测效果  614\n16.7.2  胶囊输出向量的维度表征意义  616\n16.7.3  重叠图像的分割  617\n16.8  神经胶囊网络的TensorFlow实现  618\n16.8.1  导入基本包及读取数据集  619\n16.8.2  图像输入  619\n16.8.3  卷积层Conv1的实现  619\n16.8.4  PrimaryCaps层的实现  620\n16.8.5  全连接层  622\n16.8.6  路由协议算法  628\n16.8.7  估计实体出现的概率  630\n16.8.8  损失函数的实现  631\n16.8.9  额外设置  639\n16.8.10  训练和评估  640\n16.8.11  运行结果  643\n16.9  本章小结  644\n16.10  请你思考  645\n16.11  深度学习美在何处  646\n参考资料  647\n后记  648\n索引  651","ebook_url":"https:\/\/read.douban.com\/ebook\/58720233\/","pages":"682","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29807185.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29807185.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29807185.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30255692\/","id":"30255692","publisher":"电子工业出版社","isbn10":"7121342464","isbn13":"9787121342462","title":"深度学习之美","url":"https:\/\/api.douban.com\/v2\/book\/30255692","alt_title":"","author_intro":"张玉宏，2012年于电子科技大学取得博士学位，2009—2011年美国西北大学访问学者，电子科技大学博士后，现执教于河南工业大学。\n中国计算机协会（CCF）会员，CCF YOCSEF郑州2018—2019年度副主席，ACM\/IEEE会员。《品味大数据》一书作者。主要研究方向为大数据、人工智能、技术哲学。发表学术论文20余篇，国内外学术作品7部。阿里云云栖社区专栏作家，博文累计阅读逾百万次。","summary":"深度学习是人工智能的前沿技术。《深度学习之美：AI时代的数据处理与最佳实践》深入浅出地介绍了深度学习的相关理论和实践，《深度学习之美：AI时代的数据处理与最佳实践》共分16章，采用理论和实践双主线写作方式。第1章给出深度学习的大图。第2章和第3章，讲解了机器学习的相关基础理论。第4章和第5章，讲解了Python基础和基于Python的机器学习实战。第6至10章，先后讲解了M-P模型、感知机、多层神经网络、BP神经网络等知识。第11章讲解了被广泛认可的深度学习框架TensorFlow。第12章和第13章详细讲解了卷积神经网络，并给出了相关的实战项目。第14章和第15章，分别讲解了循环递归网络和长短期记忆（LSTM）网络。第16章讲解了神经胶囊网络，并给出了神经胶囊网络设计的详细论述和实践案例分析。\n《深度学习之美：AI时代的数据处理与最佳实践》结构完整、行文流畅，是一本难得的零基础入门、图文并茂、通俗易懂、理论结合实战的深度学习书籍。","ebook_price":"89.60","series":{"id":"41172","title":"博文视点AI系列"},"price":"128"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"语音识别技术实践","author":["柳若边"],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32271450.jpg","binding":"平装-胶订","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/120601661\/","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32271450.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32271450.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32271450.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30771282\/","id":"30771282","publisher":"清华大学出版社","isbn10":"7302516928","isbn13":"9787302516927","title":"深度学习:语音识别技术实践","url":"https:\/\/api.douban.com\/v2\/book\/30771282","alt_title":"","author_intro":"","summary":"","ebook_price":"57.85","price":"89元"},{"rating":{"max":10,"numRaters":12,"average":"4.2","min":0},"subtitle":"","author":["毗湿奴•布拉马尼亚(Vishnu Subramanian)"],"pubdate":"2019-4","tags":[{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"编程","title":"编程"},{"count":2,"name":"深度学习","title":"深度学习"},{"count":2,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32327993.jpg","binding":"平装","translator":["王海玲","刘江峰"],"catalog":"第 1章　PyTorch与深度学习 1\n1．1　人工智能　1\n1．2　机器学习　3\n1．3　深度学习　4\n1．3．1　深度学习的应用　4\n1．3．2　深度学习的浮夸宣传　6\n1．3．3　深度学习发展史　6\n1．3．4　为何是现在　7\n1．3．5　硬件可用性　7\n1．3．6　数据和算法　8\n1．3．7　深度学习框架　9\n1．4　小结　10\n第　2章 神经网络的构成　11\n2．1　安装PyTorch　11\n2．2　实现第 一个神经网络　12\n2．2．1　准备数据　13\n2．2．2　为神经网络创建数据　20\n2．2．3　加载数据　24\n2．3　小结　25\n第3章　深入了解神经网络　26\n3．1　详解神经网络的组成部分　26\n3．1．1　层—神经网络的基本组成　27\n3．1．2　非线性激活函数　29\n3．1．3　PyTorch中的非线性激活函数　32\n3．1．4　使用深度学习进行图像分类　36\n3．2　小结　46\n第4章　机器学习基础　47\n4．1　三类机器学习问题　47\n4．1．1　有监督学习　48\n4．1．2　无监督学习　48\n4．1．3　强化学习　48\n4．2　机器学习术语　49\n4．3　评估机器学习模型　50\n4．4　数据预处理与特征工程　54\n4．4．1　向量化　54\n4．4．2　值归一化　54\n4．4．3　处理缺失值　55\n4．4．4　特征工程　55\n4．5　过拟合与欠拟合　56\n4．5．1　获取更多数据　56\n4．5．2　缩小网络规模　57\n4．5．3　应用权重正则化　58\n4．5．4　应用dropout　58\n4．5．5　欠拟合　60\n4．6　机器学习项目的工作流　60\n4．6．1　问题定义与数据集创建　60\n4．6．2　成功的衡量标准　61\n4．6．3　评估协议　61\n4．6．4　准备数据　62\n4．6．5　模型基线　62\n4．6．6　大到过拟合的模型　63\n4．6．7　应用正则化　63\n4．6．8　学习率选择策略　64\n4．7　小结　65\n第5章　深度学习之计算机视觉　66\n5．1　神经网络简介　66\n5．2　从零开始构建CNN模型　69\n5．2．1　Conv2d　71\n5．2．2　池化　74\n5．2．3　非线性激活—ReLU　75\n5．2．4　视图　76\n5．2．5　训练模型　77\n5．2．6　狗猫分类问题—从零开始构建CNN　80\n5．2．7　利用迁移学习对狗猫分类　82\n5．3　创建和探索VGG16模型　84\n5．3．1　冻结层　85\n5．3．2　微调VGG16模型　85\n5．3．3　训练VGG16模型　86\n5．4　计算预卷积特征　88\n5．5　理解CNN模型如何学习　91\n5．6　CNN层的可视化权重　94\n5．7　小结　95\n第6章　序列数据和文本的深度学习　96\n6．1　使用文本数据　96\n6．1．1　分词　98\n6．1．2　向量化　100\n6．2　通过构建情感分类器训练词向量　104\n6．2．1　下载IMDB数据并对文本分词　104\n6．2．2　构建词表　106\n6．2．3　生成向量的批数据　107\n6．2．4　使用词向量创建网络模型　108\n6．2．5　训练模型　109\n6．3　使用预训练的词向量　110\n6．3．1　下载词向量　111\n6．3．2　在模型中加载词向量　112\n6．3．3　冻结embedding层权重　113\n6．4　递归神经网络（RNN）　113\n6．5　LSTM　117\n6．5．1　长期依赖　117\n6．5．2　LSTM网络　117\n6．6　基于序列数据的卷积网络　123\n6．7　小结　125\n第7章　生成网络　126\n7．1　神经风格迁移　126\n7．1．1　加载数据　129\n7．1．2　创建VGG模型　130\n7．1．3　内容损失　131\n7．1．4　风格损失　131\n7．1．5　提取损失　133\n7．1．6　为网络层创建损失函数　136\n7．1．7　创建优化器　136\n7．1．8　训练　137\n7．2　生成对抗网络（GAN）　138\n7．3　深度卷机生成对抗网络　139\n7．3．1　定义生成网络　140\n7．3．2　定义判别网络　144\n7．3．3　定义损失函数和优化器　145\n7．3．4　训练判别网络　145\n7．3．5　训练生成网络　146\n7．3．6　训练整个网络　147\n7．3．7　检验生成的图片　148\n7．4　语言建模　150\n7．4．1　准备数据　151\n7．4．2　生成批数据　152\n7．4．3　定义基于LSTM的模型　153\n7．4．4　定义训练和评估函数　155\n7．4．5　训练模型　157\n7．5　小结　159\n第8章　现代网络架构　160\n8．1　现代网络架构　160\n8．1．1　ResNet　160\n8．1．2　Inception　168\n8．2　稠密连接卷积网络（DenseNet）　175\n8．2．1　DenseBlock　175\n8．2．2　DenseLayer　176\n8．3　模型集成　180\n8．3．1　创建模型　181\n8．3．2　提取图片特征　182\n8．3．3　创建自定义数据集和数据加载器　183\n8．3．4　创建集成模型　184\n8．3．5　训练和验证模型　185\n8．4　encoder-decoder架构　186\n8．4．1　编码器　188\n8．4．2　解码器　188\n8．5　小结　188\n第9章　未来走向　189\n9．1　未来走向　189\n9．2　回顾　189\n9．3　有趣的创意应用　190\n9．3．1　对象检测　190\n9．3．2　图像分割　191\n9．3．3　PyTorch中的OpenNMT　192\n9．3．4　Allen NLP　192\n9．3．5　fast．ai—神经网络不再神秘　192\n9．3．6　Open Neural Network Exchange　192\n9．4　如何跟上前沿　193\n9．5　小结　193","pages":"193","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32327993.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32327993.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32327993.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33408564\/","id":"33408564","publisher":"人民邮电出版社","isbn10":"7115508984","isbn13":"9787115508980","title":"PyTorch深度学习","url":"https:\/\/api.douban.com\/v2\/book\/33408564","alt_title":"","author_intro":"","summary":"深度学习为世界上的智能系统（比如Google Voice、Siri和Alexa）提供了动力。随着硬件（如GPU）和软件框架（如PyTorch、Keras、TensorFlow和CNTK）的进步以及大数据的可用性，人们在文本、视觉和分析等领域更容易实施相应问题的解决方案。\n本书对当今前沿的深度学习库PyTorch进行了讲解。凭借其易学习性、高效性以及与Python开发的天然亲近性，PyTorch获得了深度学习研究人员以及数据科学家们的关注。本书从PyTorch的安装讲起，然后介绍了为现代深度学习提供驱动力的多个基础模块，还介绍了使用CNN、RNN、LSTM以及其他网络模型解决问题的方法。本书对多个先进的深度学习架构的概念（比如ResNet、DenseNet、Inception和Seq2Seq）进行了阐述，但没有深挖其背后的数学细节。与GPU计算相关的知识、使用PyTorch训练模型的方法，以及用来生成文本和图像的复杂神经网络（如生成网络），也在本书中有所涵盖。\n学完本书后，读者可以使用PyTorch轻松开发深度学习应用程序。","price":"55.00"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2019-5","tags":[],"origin_title":"[印]拉蒂普·杜瓦","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33313659.jpg","binding":"","translator":["罗娜,祁佳康"],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33313659.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33313659.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33313659.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34435543\/","id":"34435543","publisher":"机械工业出版社","isbn10":"7111626273","isbn13":"9787111626275","title":"Keras深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/34435543","alt_title":"[印]拉蒂普·杜瓦","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["Bharath Ramsundar，Reza Bosagh Zadeh"],"pubdate":"2019-8","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"TensorFlow for Deep Learning","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33460075.jpg","binding":"平装","translator":["邹伟 姚新新 呙平"],"catalog":"目录\n前言 1\n第1章 深度学习概述 5\n1.1 机器学习吞噬计算机科学 .5\n1.2 深度学习原型 6\n1.3 深度学习架构 10\n1.4 深度学习框架 19\n1.5 小结 20\n第2章 TensorFlow原型概述 21\n2.1 张量介绍 21\n2.2 TensorFlow中的基本计算 32\n2.3 命令式和声明式编程 40\n2.4 小结 44\n第3章 使用TensorFlow进行线性和Logistic回归 45\n3.1 数学回顾 45\n3.2 学习TensorFlow 56\n3.3 在TensorFlow中训练线性和Logistics模型 66\n3.4 小结 78\n第4章 全连接深层网络 81\n4.1 什么是全连接深层网络？ 81\n4.2 全连接网络中的“神经元”.83\n4.3 训练全连接神经网络 89\n4.4 在TensorFlow中实现 95\n4.5 小结 .100\n第5章 超参数优化 103\n5.1 模型评估与超参数优化 .104\n5.2 指标，指标，指标  105\n5.3 超参数调优算法 111\n5.4 小结 .117\n第6章 卷积神经网络 118\n6.1卷积结构概述 119\n6.2 卷积网络的应用 125\n6.3 用TensorFlow训练卷积网络 132\n6.4 小结 .144\n第7章 递归神经网络 145\n7.1 递归结构概述 .146\n7.2 循环神经元 148\n7.3 递归模型的应用 150\n7.4 神经网络图灵机 153\n7.5 递归神经网络的实际应用 155\n7.6 处理Penn Treebank语料库 155\n7.7 小结  163\n第8章 强化学习 164\n8.1 马尔科夫决策过程 .168\n8.2 强化学习算法 .170\n8.3 强化学习的局限性 .174\n8.4 玩转tic-tac-toe 175\n8.5 A3C算法 187\n8.6 小结 .196\n第9章 训练大型深度网络 .198\n9.1 为深度网络自定义硬件 .198\n9.2 使用CPU训练 199\n9.3 分布式深度网络训练 204\n9.4 在Cifar10上与多GPS进行数据并行训练 206\n9.5 小结 .215\n第10章 深度学习的未来 216\n10.1 技术行业以外的深度学习 .216\n10.2 道德地使用深度学习 219\n10.3 通用人工智能是否迫在眉睫？ .221\n10.4 接下来，何去何从？ 222","pages":"223","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33460075.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33460075.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33460075.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34779865\/","id":"34779865","publisher":"中国电力出版社","isbn10":"7519830314","isbn13":"9787519830311","title":"基于TensorFlow的深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34779865","alt_title":"TensorFlow for Deep Learning","author_intro":"Bharath Ramsundar是研发主管和DeepChem.io的创始人，DeepChem是一个开源的用于药物发现的Tensorflow包，他博士毕业于斯坦福大学计算机科学专业。Reza Bosagh Zadeh是Matroid公司CEO、斯坦福大学助理教授，讲授研究生机器学习和算法课程。他的工作兴趣点是机器学习、分布式计算，以及应用离散数学。他建立了Twitter的who-to-follow系统。\n邹伟，睿客邦创始人，南昌航天大学双师型教师、天津大学创业导师、山东交通学院客座教授、中国医药教育协会老年医学健康分会学术委员。创立的睿客邦与国内十多所高校建立了AI联合实验室，完成和在研30多个人工智能工业项目，广泛应用于医疗、交通、油田、气象、银行等多个领域，致力于人工智能新技术的实践和应用。","summary":"本书通过实践示例教你深度学习的概念，并从根本上帮助你理解深度学习的基础知识。本书是理想的学习实际深度学习模型设计的指南，对于熟悉脚本编程却不需要设计学习算法的专家和科学家也很有帮助。 本书的主要内容有：\n学习TensorFlow基础，包括如何进行基本运算。\n建立简单的学习系统来理解数学基础。\n深入理解在数千应用中效果良好的全连接深度网络。\n使用超参优化，将原型转换成高质量的模型。\n使用卷积神经网络处理图像。\n使用循环神经网络处理自然语言数据集。\n使用强化学习解决譬如三连棋等游戏。","series":{"id":"697","title":"O'reilly系列"},"price":"58.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["刘爱国"],"pubdate":"2019-10","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33542444.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33542444.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33542444.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33542444.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34922576\/","id":"34922576","publisher":"上海教育出版社","isbn10":"7544495655","isbn13":"9787544495653","title":"行走的教室：跨学科深度学习新空间","url":"https:\/\/api.douban.com\/v2\/book\/34922576","alt_title":"","author_intro":"","summary":"","series":{"id":"45187","title":"新中教育丛书"},"price":"58元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2019-7","tags":[{"count":1,"name":"智能摘要","title":"智能摘要"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33534291.jpg","binding":"","translator":[],"catalog":"第一部分文本摘要技术\n第1 章文本摘要概述\n1.1 摘要技术的需求\n1.2 自动文本摘要的应用\n1.3 文本摘要分类\n第2 章摘要评价方法\n2.1 评价数据\n2.2 评价指标\n2.3 总结\n第二部分信息抽取\n第3 章文本表示\n3.1 词级表示\n3.2 句级表示\n3.3 文档级表示\n第4 章命名实体识别\n4.1 命名实体识别简介\n4.2 命名实体识别方法\n第5 章抽取式摘要\n5.1 无监督方法\n5.2 有监督方法\n5.3 强化学习\n5.4 总结\n第三部分文本生成\n第6 章神经网络文本生成模型\n6.1 语言模型\n6.2 “编码-解码” 网络框架\n6.3 “序列到序列” 生成模型\n6.4 网络训练\n6.5 面临的问题\n第7 章生成式摘要\n7.1 未登录词问题解决方案\n7.2 生成重复词问题解决方案\n7.3 生成错误关系问题\n7.4 长文本摘要生成问题\n7.4.1 注意力改进方法\n强化学习优化的生成式摘要\n7.6 抽取器+ 生成器\n7.7 总结\n附录 专用名词缩写\n索引\n后记\n参考文献","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33534291.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33534291.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33534291.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34464719\/","id":"34464719","publisher":"北京理工大学出版社","isbn10":"7568269027","isbn13":"9787568269025","title":"智能摘要与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34464719","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33547670.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33547670.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33547670.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33547670.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34452897\/","id":"34452897","publisher":"","isbn10":"7030612981","isbn13":"9787030612984","title":"中国电子信息工程科技发展研究  深度学习专题","url":"https:\/\/api.douban.com\/v2\/book\/34452897","alt_title":"","author_intro":"","summary":"","series":{"id":"50266","title":"中国电子信息工程科技发展研究"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2019-6","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32334215.jpg","binding":"平装","translator":[],"catalog":"第　1章 深度学习　1\n1．1　引言　1\n1．2　深度学习框架简介　1\n1．3　数学基础知识　3\n1．3．1　线性代数相关知识　3\n1．3．2　概率论相关知识　10\n1．3．3　导数相关知识　13\n1．4　简单的深度学习理论知识　14\n1．5　小结　19\n第　2章 PaddlePaddle的安装　20\n2．1　引言　20\n2．2　计算机配置　20\n2．3　安装前的检查　20\n2．4　使用pip安装　21\n2．5　使用Docker安装　23\n2．6　从源码编译并生成安装包　25\n2．6．1　在本地编译并生成安装包　25\n2．6．2　在Docker中编译并生成\n安装包　28\n2．7　编译Docker镜像　29\n2．8　在Windows操作系统中安装\nPaddlePaddle的方法　30\n2．8．1　在Windows系统中安装\nDocker容器　30\n2．8．2　在Windows系统中\n安装Ubuntu　35\n2．8．3　在Windows 10中安装Linux\n子系统　41\n2．9　测试安装效果　43\n2．10　小结　45\n第3章　使用MNIST数据集实现手写\n数字识别　46\n3．1　引言　46\n3．2　数据集　46\n3．3　定义神经网络模型　47\n3．4　开始训练模型　50\n3．4．1　导入依赖包　50\n3．4．2　初始化Paddle　51\n3．4．3　获取训练器　51\n3．4．4　开始训练　52\n3．5　使用参数预测　54\n3．5．1　初始化PaddlePaddle　54\n3．5．2　获取训练好的参数　54\n3．5．3　读取图片　54\n3．5．4　开始预测　55\n3．6　小结　56\n第4章　CIFAR数据集中彩色图像的\n识别　57\n4．1　引言　57\n4．2　数据集　57\n4．3　定义神经网络模型　59\n4．4　开始训练模型　61\n4．4．1　导入依赖包　62\n4．4．2　初始化Paddle　62\n4．4．3　获取参数　62\n4．4．4　创建训练器　63\n4．4．5　开始训练　64\n4．5　使用参数预测　67\n4．6　使用其他神经模型　69\n4．7　小结　70\n第5章　自定义图像数据集的识别　72\n5．1　引言　72\n5．2　网络爬虫技术　72\n5．2．1　网络爬虫的整体框架　72\n5．2．2　URL管理器　74\n5．2．3　网页下载器　75\n5．2．4　网页解析器　76\n5．3　网络爬虫实例　77\n5．3．1　调度器的使用　79\n5．3．2　URL管理器的使用　80\n5．3．3　网页下载器的使用　81\n5．3．4　网页解析器的使用　82\n5．3．5　数据收集器的使用　83\n5．3．6　运行代码　84\n5．4　数据集　88\n5．4．1　生成图像列表　89\n5．4．2　读取数据　92\n5．5　定义神经网络　96\n5．6　使用PaddlePaddle开始训练　97\n5．6．1　创建训练器　98\n5．6．2　开始训练　99\n5．7　使用PaddlePaddle预测　102\n5．8　小结　104\n第6章　验证码的识别　105\n6．1　引言　105\n6．2　数据集的获取　105\n6．2．1　下载验证码　106\n6．2．2　修改验证码的文件名　107\n6．2．3　裁剪验证码　108\n6．2．4　生成图像列表　110\n6．3　读取数据　111\n6．4　使用PaddlePaddle开始训练　112\n6．5　使用PaddlePaddle预测　118\n6．5．1　裁剪验证码　118\n6．5．2　预测图像　119\n6．5．3　标签转成字符　120\n6．6　小结　121\n第7章　场景文字识别　122\n7．1　引言　122\n7．2　数据集　122\n7．3　定义神经网络模型　123\n7．4　数据的读取　128\n7．4．1　读取图像列表　128\n7．4．2　生成标签字典　129\n7．4．3　读取训练数据　131\n7．5　训练模型　133\n7．5．1　训练准备　133\n7．5．2　安装libwarpctc．so库　135\n7．5．3　开始训练　136\n7．6　开始预测　137\n7．7　小结　140\n第8章　验证码端到端的识别　141\n8．1　引言　141\n8．2　数据集　141\n8．3　生成图像列表文件　143\n8．4　数据的读取　144\n8．4．1　读取数据并存储成列表　144\n8．4．2　生成和读取标签字典　145\n8．4．3　读取训练和测试的数据　146\n8．5　定义网络模型　147\n8．6　生成训练器　150\n8．7　定义训练　151\n8．8　启动训练　152\n8．9　开始预测　153\n8．10　小结　156\n第9章　车牌端到端的识别　157\n9．1　引言　157\n9．2　车牌数据的采集　157\n9．2．1　车牌数据的下载　157\n9．2．2　命名车牌图像　159\n9．2．3　车牌定位　159\n9．2．4　灰度化图像　163\n9．3　数据的读取　164\n9．3．1　生成列表文件　164\n9．3．2　以列表方式读取数据　165\n9．3．3　生成和读取标签字典　166\n9．3．4　训练数据和测试数据的\n读取　167\n9．4　定义神经网络　169\n9．5　开始训练　171\n9．6　开始预测　173\n9．7　小结　176\n第　10章 使用VOC数据集实现目标\n检测　177\n10．1　引言　177\n10．2　VOC数据集　177\n10．2．1　下载VOC数据集　178\n10．2．2　生成图像列表　179\n10．3　数据预处理　180\n10．4　SSD神经网络　182\n10．5　训练模型　186\n10．6　评估模型　189\n10．7　预测数据　191\n10．7．1　预测并保存预测\n结果　191\n10．7．2　显示画出的框　193\n10．8　小结　195\n第　11章 通过自定义图像数据集实现\n目标检测　196\n11．1　引言　196\n11．2　数据集　196\n11．2．1　下载车牌数据　196\n11．2．2　重命名图像　197\n11．3　标注数据集　198\n11．3．1　安装LabelImg　198\n11．3．2　使用LabelImg　198\n11．3．3　生成图像列表　201\n11．4　训练模型　202\n11．4．1　预训练模型处理　202\n11．4．2　开始训练　203\n11．5　评估模型　204\n11．6　预测图片　205\n11．6．1　获取预测结果　205\n11．6．2　显示预测结果　206\n11．7　小结　208\n第　12章 使用PaddlePaddle Fluid　209\n12．1　引言　209\n12．2　Fluid版本　209\n12．3　定义神经网络　210\n12．4　训练程序　212\n12．4．1　定义数据　213\n12．4．2　定义平均正确率　213\n12．4．3　定义测试程序　213\n12．4．4　定义优化方法　214\n12．5　训练模型　214\n12．5．1　定义调试器　215\n12．5．2　获取数据　215\n12．5．3　开始训练　216\n12．5．4　保存预测模型　217\n12．6　预测模型　217\n12．7　小结　219\n第　13章 可视化工具VisualDL的\n使用　220\n13．1　引言　220\n13．2　VisualDL的介绍　220\n13．3　VisualDL的安装　222\n13．3．1　使用pip安装　223\n13．3．2　使用源码安装　224\n13．4　简单使用VisualDL　224\n13．5　在PaddlePaddle中使用\nVisualDL　226\n13．5．1　定义VisualDL\n组件　226\n13．5．2　编写PaddlePaddle\n代码　227\n13．5．3　把数据添加到\nVisualDL中　229\n13．6　小结　232\n第　14章 把PaddlePaddle部署到网站\n服务器上　233\n14．1　引言　233\n14．2　开发环境　233\n14．3　Flask的使用　234\n14．3．1　安装Flask　234\n14．3．2　测试Flask框架是否安装\n成功　234\n14．3．3　文件上传　235\n14．4　使用PaddlePaddle预测　237\n14．4．1　获取预测模型　237\n14．4．2　部署PaddlePaddle　238\n14．5　小结　242\n第　15章 把PaddlePaddle应用到\nAndroid手机　244\n15．1　引言　244\n15．2　编译PaddlePaddle库　244\n15．2．1　使用Docker编译\nPaddlePaddle库　244\n15．2．2　使用Linux编译\nPaddlePaddle库　247\n15．3　MobileNet神经网络　250\n15．4　训练模型　254\n15．5　编写预测代码　258\n15．6　合并模型　261\n15．7　移植到Android　262\n15．7．1　加载PaddlePaddle库　262\n15．7．2　加载合并的模型　263\n15．7．3　开发Android程序　263\n15．8　小结　272","pages":"272","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32334215.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32334215.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32334215.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33474865\/","id":"33474865","publisher":"","isbn10":"711550332X","isbn13":"9787115503329","title":"深度学习实战之PaddlePaddle","url":"https:\/\/api.douban.com\/v2\/book\/33474865","alt_title":"","author_intro":"","summary":"本书全面讲解了深度学习框架PaddlePaddle，并结合典型案例，阐述了PaddlePaddle的具体应用。本书共15章。第 1 章介绍了深度学习及其主流框架；第2章介绍了几种不同的PaddlePaddle安装方式；第3章使用MNIST数据集实现手写数字识别；第4章介绍CIFAR彩色图像识别；第5章介绍了自定义数据集的识别；第6章介绍了验证码的识别；第7章介绍了场景文字的识别；第8章实现了验证码的端到端的识别；第9～11章讲解了车牌识别、使用SSD神经网络完成目标检测；第12章和第13章介绍了Fluid、可视化工具VisualDL；第 14 章和第 15 章介绍了如何在服务器端与Android移动终端使用PaddlePaddle进行项目实践。\n本书适合机器学习爱好者、程序员、人工智能方面的从业人员阅读，也可以作为大专院校相关专业的师生用书和培训学校的教材。","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["世界人工智能大会组委会"],"pubdate":"2019-10","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33531471.jpg","binding":"精装","translator":[],"catalog":"前言\n畅想篇\n人类与人工智能的未来—技术、社会，以及生命存在的形态\n马云、埃隆 · 马斯克 002\n自我优化的人工智能将开启人工智能的真正未来\n于尔根 · 施米德胡贝 017\n人工智能为什么还没有意识\n李德毅 025\n生态篇\n迎接可知、可控、可用、可靠的“AI ”时代\n马化腾 034\n人工智能技术、应用与政府战略\n汤姆 · 米切尔 039\n发展负责任的人工智能\n沈向洋 046\n“三滴水”激活人工智能创新源泉\n汤晓鸥 051\n多学科交叉合作推动人工智能新突破\n吴朝晖 057\n重塑计算产业生态，加速人工智能发展\n汪涛 060\n移动通信技术助力人工智能的愿景成真\n洪曜庄 066\n连通，是人工智能和自然智能的关键\n马雷克 · 米凯利维茨 073\n从科学技术到生产力—打造人工智能的闭环\n朱明杰 078\n人工智能：创新与资本\n沈南鹏、程维、周曦、陈天石、林晨曦 084\n科技篇\n人工智能的新方向\n拉吉 · 瑞迪 102\n人工智能的发展进程\n贾扬清 109\n未来人工智能的发展特征\n陈杰 116\n关于机器学习未来的思考\n周志华 119\n数据科学中的10大研究挑战\n周以真 127\n数据智能：机遇和挑战\n蔡天文 135\n多智能体时代是人工智能的未来\n迈克尔 · 伍尔德里奇 143\n人工智能的最后一公里—联邦学习的最新应用\n杨强 151\n产业篇\n人工智能是新电力\n吴恩达 158\nAI 时代：传统企业的历史机遇\n李开复 165\n拥抱人工智能红利时代\n刘庆峰 171\n人工智能时代背景下的科技担当与企业转型\n陈黎明 179\n机器学习的云端复兴\n斯瓦米 · 西瓦苏布拉曼尼 182\n人工智能芯片：架构和应用\n陆永青 186\n人工智能发展观：传承与创新\n徐立 193\n人工智能产业赋能的方向与瓶颈\n李强、肖京、黄晓庆、陈海波 200\n附录一 2019世界人工智能大会回顾 215\n后记 239","pages":"256","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33531471.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33531471.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33531471.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34907506\/","id":"34907506","publisher":"上海科学技术出版社","isbn10":"7547846386","isbn13":"9787547846384","title":"智联世界：埃隆·马斯克、马云、马化腾、沈南鹏等三十多位人工智能顶级学术大咖、知名行业领袖，把脉AI趋势，聚焦深度学习、大数据、算法。","url":"https:\/\/api.douban.com\/v2\/book\/34907506","alt_title":"","author_intro":"世界人工智能大会组委会：世界人工智能大会是由国家发展改革委、科技部、工业和信息化部、国家网信办、中国科学院、中国工程院和上海市人民政府共同主办的人工智能国际性行业盛会。大会组委会由各主办单位组成，组委会办公室设在上海市经济和信息化委员会。","summary":"精选2019世界人工智能大会主论坛嘉宾和部分主题论坛嘉宾演讲内容，全面呈现世界人工智能*发展态势，展望未来智能世界的无限可能。人工智能是人类智慧的结晶，它和人类的未来都掌握在我们自己手中。当人工智能延伸到每一个角落、连接起每一个人，世界将会怎样，我们又该怎样应对？通过*学术大咖、知名行业领袖的分享，读者能够获得有益的启示，做出自己的回答。","price":"69元"}]}
2	{"count":100,"start":100,"total":292,"books":[{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34435722\/","id":"34435722","publisher":"","isbn10":"7513062536","isbn13":"9787513062534","title":"机器学习、深度学习与强化学习","url":"https:\/\/api.douban.com\/v2\/book\/34435722","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34870140\/","id":"34870140","publisher":"","isbn10":"7111635132","isbn13":"9787111635130","title":"Scala机器学习：构建现实世界机器学习和深度学习项目","url":"https:\/\/api.douban.com\/v2\/book\/34870140","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["Phil Kim"],"pubdate":"2018-3","tags":[{"count":11,"name":"Matlab","title":"Matlab"},{"count":8,"name":"神经网络","title":"神经网络"},{"count":7,"name":"机器学习","title":"机器学习"},{"count":3,"name":"编程","title":"编程"},{"count":3,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29742933.jpg","binding":"平装","translator":[],"catalog":"目    录\n第1章　机器学习  1\n1.1  什么是机器学习  2\n1.2  机器学习面临的挑战  4\n1.2.1  过拟合  5\n1.2.2  克服过拟合  7\n1.3  机器学习的类型  9\n1.4  本章小结  13\n第2章　神经网络  15\n2.1  神经网络的节点  15\n2.2  神经网络的层  17\n2.3  神经网络的监督学习  21\n2.4  训练单层神经网络：delta规则  22\n2.5  广义delta规则  25\n2.6  SGD、Batch和Mini Batch  26\n2.6.1  SGD  26\n2.6.2  Batch  27\n2.6.3  Mini Batch  27\n2.7  delta规则示例  29\n2.8  SGD方法的实现  30\n2.9  Batch方法的实现  32\n2.10  SGD与Batch的比较  34\n2.11  单层神经网络的局限性  36\n2.12  究竟发生了什么？  38\n2.13  本章小结  40\n第3章　多层神经网络的训练  41\n3.1  反向传播算法  42\n3.2  反向传播示例  46\n3.2.1  XOR问题  48\n3.2.2  动量  50\n3.3  代价函数与学习规则  53\n3.4  交叉熵函数示例  57\n3.5  交叉熵函数  58\n3.6  代价函数比较  60\n3.7  本章小结  62\n第4章　神经网络与分类问题  63\n4.1  二元分类  63\n4.2  多元分类  66\n4.3  多元分类示例  71\n4.4  本章小结  78\n第5章　深度学习  79\n5.1  深度神经网络的改进  80\n5.1.1  梯度消失  81\n5.1.2  过拟合  82\n5.1.3  计算负载  83\n5.2  ReLU与Dropout的实例  84\n5.2.1  ReLU函数  85\n5.2.2  Dropout  88\n5.3  本章小结  93\n第6章　卷积神经网络  95\n6.1  卷积神经网络架构  95\n6.2  卷积层  97\n6.3  池化层  101\n6.4  MNIST示例  102\n6.5  本章小结  116","pages":"132","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29742933.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29742933.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29742933.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30197362\/","id":"30197362","publisher":"清华大学出版社","isbn10":"7302496382","isbn13":"9787302496380","title":"MATLAB深度学习 机器学习、神经网络与人工智能","url":"https:\/\/api.douban.com\/v2\/book\/30197362","alt_title":"","author_intro":"Phil Kim博士是一名经验丰富的MATLAB程序员和用户。他致力于研究来源于人工智能的海量数据的处理算法，并且研究机器学习。他曾任韩国航天航空研究院高级研究员。在该院他的主要任务是开发用于无人驾驶飞行器的自主飞行算法和机载软件。他在攻读博士学位期间开发了一款名为Clickey的屏幕键盘程序，该程序成为他当前就任韩国国家康复研究院高级研究员的桥梁。","summary":"MATLAB深度学习\n在《MATLAB深度学习　机器学习、神经网络与人工智能》深入浅出的指导方式下，开启MATLAB深度学习与人工智能之旅吧！《MATLAB深度学习　机器学习、神经网络与人工智能》开篇介绍机器学习的基础知识，然后逐渐铺开，分别讨论神经网络、深度学习以及卷积神经网络。为将理论知识与实际应用完美结合，《MATLAB深度学习　机器学习、神经网络与人工智能》将\nMATLAB作为书中示例及案例分析的基础编程语言和开发工具。\n通过学习《MATLAB深度学习　机器学习、神经网络与人工智能》，你将能应对当今现实世界中的一些大数据、智能机器人以及其他复杂数据问\n题。你将体会到，在当前的智能数据分析与应用中，深度学习是机器学习领域更高级、更智能\n的方面。\n主要内容\n● 使用MATLAB进行深度学习\n● 学习单层神经网络和多层神经网络\n● 应用卷积层与池化层\n● 用卷积层和池化层构建MNIST示例\n图书特色：\n★行文通俗易懂，多简单明了的图示，少数学公式\n★不懂数学和编程没关系，可以跳过公式和代码，迅速了解机器学习、神经网络、多层神经网络、深度学习的发展脉络与概念关系\n★只需矩阵、函数等简单的数学知识，就可以跟随作者上手深度学习编程\n★丰富的Matlab范例代码，工科学生，都能马上上手\n编辑推荐：\n《MATLAB深度学习　机器学习、神经网络与人工智能》是一本关于深度学习的入门书籍。\n作者Phil Kim博士是一位研究人工智能数据处理及机器学习的技术专家，同时具有丰富的 MATLAB 编程及应用经验。这使得本书既有理论深度，又紧密结合实际。\n《MATLAB深度学习　机器学习、神经网络与人工智能》不仅适用于在深度学习领域开展研究的科研人员，也适用于深度学习应用的开发者。\n本书深入浅出地介绍人工智能、机器学习、神经网络、深度学习这些关键概念以及它们之间的关联，并着重介绍监督学习这类机器学习方法。\n为便于读者理解，本书提供了大量示例， 并利用 MATLAB 语言完成了代码实现。结合对代码的分析与讲解，致力于使读者更清晰地理解书中所涉及的理论知识。\n源代码下载二维码见书封底。","price":"49.8"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"基于scikit-learn与TensorFlow的高效开发实战","author":["刘长龙"],"pubdate":"2019-3","tags":[{"count":5,"name":"计算机科学","title":"计算机科学"},{"count":4,"name":"统计学与机器学习","title":"统计学与机器学习"},{"count":4,"name":"机器学习","title":"机器学习"},{"count":3,"name":"深度学习","title":"深度学习"},{"count":3,"name":"人工智能","title":"人工智能"},{"count":2,"name":"计算科学","title":"计算科学"},{"count":2,"name":"Machine","title":"Machine"},{"count":1,"name":"编程\/算法","title":"编程\/算法"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s30026434.jpg","binding":"平装","translator":[],"catalog":"第1章  机器学习基础  1\n1.1  引言  1\n1.1.1  为什么使用机器学习  2\n1.1.2  机器学习与数据挖掘  4\n1.1.3  机器学习与人工智能  5\n1.2  机器学习的一般流程  7\n1.2.1  定义问题  7\n1.2.2  收集数据  8\n1.2.3  比较算法与模型  9\n1.2.4  应用模型  10\n1.3  学习策略  10\n1.3.1  有监督学习  11\n1.3.2  无监督学习  14\n1.3.3  强化学习  16\n1.3.4  综合模型与工具  18\n1.4  评估理论  19\n1.4.1  划分数据集  19\n1.4.2  交叉验证  21\n1.4.3  评估指标  22\n1.4.4  拟合不足与过度拟合  25\n1.5  本章内容回顾  26\n第2章  Python基础工具  27\n2.1  Numpy  28\n2.1.1  Numpy与Scipy的分工  28\n2.1.2  ndarray构造  29\n2.1.3  数据类型  32\n2.1.4  访问与修改  33\n2.1.5  轴  35\n2.1.6  维度操作  38\n2.1.7  合并与拆分  40\n2.1.8  增与删  41\n2.1.9  全函数  42\n2.1.10  广播  42\n2.2  Matplot  43\n2.2.1  点线图  44\n2.2.2  子视图  50\n2.2.3  图像  53\n2.2.4  等值图  57\n2.2.5  三维绘图  58\n2.2.6  从官网学习  59\n2.3  Scipy  60\n2.3.1  数学与物理常数  61\n2.3.2  特殊函数库  62\n2.3.3  积分  64\n2.3.4  优化  65\n2.3.5  插值  67\n2.3.6  离散傅里叶  68\n2.3.7  卷积  70\n2.3.8  线性分析  71\n2.3.9  概率统计  73\n2.4  本章内容回顾  77\n第3章  有监督学习：分类与回归  79\n3.1  线性回归  80\n3.1.1  何谓线性模型  80\n3.1.2  最小二乘法  81\n3.1.3  最小二乘法的不足  82\n3.1.4  岭回归  85\n3.1.5  Lasso回归  87\n3.2  梯度下降  90\n3.2.1  假设函数与损失函数  90\n3.2.2  随机梯度下降  92\n3.2.3  实战：SGDRegressor和SGDClassifier  93\n3.2.4  增量学习  94\n3.3  支持向量机  95\n3.3.1  最优超平面  95\n3.3.2  软间隔  97\n3.3.3  线性不可分问题  98\n3.3.4  核函数  99\n3.3.5  实战：scikit-learn中的SVM  100\n3.4  朴素贝叶斯分类  101\n3.4.1  基础概率  102\n3.4.2  贝叶斯分类原理  103\n3.4.3  高斯朴素贝叶斯  105\n3.4.4  多项式朴素贝叶斯  106\n3.4.5  伯努利朴素贝叶斯  107\n3.5  高斯过程  107\n3.5.1  随机过程  108\n3.5.2  无限维高斯分布  109\n3.5.3  实战：gaussian_process工具包  111\n3.6  决策树  114\n3.6.1  最易于理解的模型  114\n3.6.2  熵的作用  115\n3.6.3  实战：DecisionTreeClassifier与DecisionTreeRegressor  117\n3.6.4  树的可视化  118\n3.7  集成学习  119\n3.7.1  偏差与方差  120\n3.7.2  随机森林  121\n3.7.3  自适应增强  124\n3.8  综合话题  126\n3.8.1  参数与非参数学习  127\n3.8.2  One-Vs-All与One-Vs-One  127\n3.8.3  评估工具  129\n3.8.4  超参数调试  131\n3.8.5  多路输出  134\n3.9  本章内容回顾  134\n第4章  无监督学习：聚类  136\n4.1  动机  137\n4.2  K-means  138\n4.2.1  算法  139\n4.2.2  实战：scikit-learn聚类调用  141\n4.2.3  如何选择K值  144\n4.3  近邻算法  145\n4.3.1  生活化的理解  145\n4.3.2  有趣的迭代  146\n4.3.3  实战：AffinityPropagation类  147\n4.4  高斯混合模型  149\n4.4.1  中心极限定理  150\n4.4.2  最大似然估计  151\n4.4.3  几种协方差矩阵类型  152\n4.4.4  实战：GaussianMixture类  154\n4.5  密度聚类  156\n4.5.1  凸数据集  157\n4.5.2  密度算法  158\n4.5.3  实战：DBSCAN类  159\n4.6  BIRCH  160\n4.6.1  层次模型综述  161\n4.6.2  聚类特征树  162\n4.6.3  实战：BIRCH相关调用  164\n4.7  距离计算  166\n4.7.1  闵氏距离  166\n4.7.2  马氏距离  167\n4.7.3  余弦相似度  168\n4.7.4  时间序列比较  169\n4.7.5  杰卡德相似度  169\n4.8  聚类评估  170\n4.9  本章内容回顾  172\n第5章  无监督学习：数据降维  173\n5.1  主成分分析  174\n5.1.1  寻找方差最大维度  174\n5.1.2  用PCA降维  177\n5.1.3  实战：用PCA寻找主成分  178\n5.2  线性判别分析  181\n5.2.1  双重标准  181\n5.2.2  实战：使用LinearDiscriminantAnalysis  183\n5.3  多维标度法  185\n5.3.1  保留距离信息的线性变换  185\n5.3.2  MDS的重要变形  187\n5.3.3  实战：使用MDS类  188\n5.4  流形学习之Isomap  189\n5.4.1  什么是流形  190\n5.4.2  测地线距离  192\n5.4.3  实战：使用Isomap类  193\n5.5  流形学习之局部嵌入  195\n5.5.1  局部线性嵌入  195\n5.5.2  拉普拉斯特征映射（LE）  198\n5.5.3  调用介绍  200\n5.5.4  谱聚类  201\n5.6  流形学习之t-SNE  203\n5.6.1  用Kullback-Leiber衡量分布相似度  203\n5.6.2  为什么是t-分布  205\n5.6.3  实战：使用TSNE类  206\n5.7  实战：降维模型之比较  207\n5.8  本章内容回顾  210\n第6章  隐马尔可夫模型  212\n6.1  场景建模  213\n6.1.1  两种状态链  213\n6.1.2  两种概率  215\n6.1.3  三种问题  217\n6.1.4  hmmLearn介绍  218\n6.2  离散型分布算法与应用  222\n6.2.1  前向算法与后向算法  222\n6.2.2  MultinomialNB求估计问题  226\n6.2.3  Viterbi算法  227\n6.2.4  MultinomialNB求解码问题  229\n6.2.5  EM算法  232\n6.2.6  Baum-Welch算法  233\n6.2.7  用hmmLearn训练数据  235\n6.3  连续型概率分布  236\n6.3.1  多元高斯分布  237\n6.3.2  GaussianHMM  239\n6.3.3  GMMHMM  240\n6.4  实战：股票预测模型  241\n6.4.1  数据模型  241\n6.4.2  目标  243\n6.4.3  训练模型  243\n6.4.4  分析模型参数  245\n6.4.5  可视化短线预测  247\n6.5  本章内容回顾  250\n第7章  贝叶斯网络  251\n7.1  什么是贝叶斯网络  252\n7.1.1  典型贝叶斯问题  252\n7.1.2  静态结构  253\n7.1.3  联合\/边缘\/条件概率换算  256\n7.1.4  链式法则与变量消元  258\n7.2  网络构建  259\n7.2.1  网络参数估计  260\n7.2.2  启发式搜索  261\n7.2.3  Chow-Liu Tree算法  262\n7.3  近似推理  263\n7.3.1  蒙特卡洛方法  264\n7.3.2  马尔可夫链收敛定理  265\n7.3.3  MCMC推理框架  267\n7.3.4  Gibbs采样  268\n7.3.5  变分贝叶斯  268\n7.4  利用共轭建模  270\n7.4.1  共轭分布  270\n7.4.2  隐含变量与显式变量  272\n7.5  实战：胸科疾病诊断  274\n7.5.1  诊断需求  274\n7.5.2  Python概率工具包  275\n7.5.3  建立模型  276\n7.5.4  MCMC采样分析  278\n7.5.5  近似推理  281\n7.6  本章内容回顾  282\n第8章  自然语言处理  284\n8.1  文本建模  285\n8.1.1  聊天机器人原理  285\n8.1.2  词袋模型  286\n8.1.3  访问新闻资源库  287\n8.1.4  TF-IDF  290\n8.1.5  实战：关键词推举  290\n8.2  词汇处理  294\n8.2.1  中文分词  294\n8.2.2  Word2vec  296\n8.2.3  实战：寻找近似词  298\n8.3  主题模型  303\n8.3.1  三层模型  303\n8.3.2  非负矩阵分解  304\n8.3.3  潜在语意分析  305\n8.3.4  隐含狄利克雷分配  307\n8.3.5  实战：使用工具包  309\n8.4  实战：用LDA分析新闻库  311\n8.4.1  文本预处理  311\n8.4.2  训练与显示  313\n8.4.3  困惑度调参  315\n8.5  本章内容回顾  317\n第9章  深度学习  319\n9.1  神经网络基础  320\n9.1.1  人工神经网络  320\n9.1.2  神经元与激活函数  321\n9.1.3  反向传播  323\n9.1.4  万能网络  325\n9.2  TensorFlow核心应用  328\n9.2.1  张量  329\n9.2.2  开发架构  331\n9.2.3  数据管理  332\n9.2.4  评估器  335\n9.2.5  图与会话  338\n9.2.6  逐代（epoch）训练  341\n9.2.7  图与统计可视化  343\n9.3  卷积神经网络  349\n9.3.1  给深度学习一个理由  349\n9.3.2  CNN结构发展  351\n9.3.3  卷积层  354\n9.3.4  池化层  356\n9.3.5  ReLU与Softmax  357\n9.3.6  Inception与ResNet  359\n9.4  优化  362\n9.4.1  批次规范化  362\n9.4.2  剪枝  364\n9.4.3  算法选择  366\n9.5  循环神经网络与递归神经网络  367\n9.5.1  循环神经网络  368\n9.5.2  长短期记忆（LSTM）  371\n9.5.3  递归神经网络  374\n9.6  前沿精选  377\n9.6.1  物件检测模型  377\n9.6.2  密连卷积网络  381\n9.6.3  胶囊网络  382\n9.7  CNN实战：图像识别  385\n9.7.1  开源图像库CIFAR  385\n9.7.2  项目介绍  388\n9.7.3  构建Graph  389\n9.7.4  优化与训练  392\n9.7.5  运行  394\n9.8  RNN实战：写诗机器人  397\n9.8.1  语言模型  397\n9.8.2  LSTM开发步骤1：网络架构  401\n9.8.3  LSTM开发步骤2：数据加载  402\n9.8.4  LSTM开发步骤3：搭建TensorFlow Graph  403\n9.8.5  LSTM开发步骤4：解析LSTM RNN  404\n9.8.6  LSTM开发步骤5：LSTM中的参数  406\n9.8.7  LSTM开发步骤6：用sequence_loss计算RNN损失值  406\n9.8.8  LSTM开发步骤7：学习速度可调优化器  407\n9.8.9  LSTM开发步骤8：训练  408\n9.8.10  开始写唐诗  410\n9.8.11  写唐诗步骤1：用唐诗语料训练语言模型  410\n9.8.12  写唐诗步骤2：作诗  412\n9.8.13  写唐诗步骤3：作品举例  414\n9.9  本章内容回顾  415\n第10章  强化学习  418\n10.1  场景与原理  419\n10.1.1  借AlphaGo谈人工智能  419\n10.1.2  基于价值的算法Q-Learning与Sarsa  421\n10.1.3  基于策略的算法  424\n10.1.4  基于模型的算法  426\n10.2  OpenAI Gym  427\n10.2.1  环境调用  428\n10.2.2  实战：用Q-Learning开发走迷宫机器人  432\n10.3  深度强化学习  435\n10.3.1  DQN及改进  435\n10.3.2  DPN、DDPG及A3C  436\n10.3.3  实战：用DPN训练月球定点登陆  439\n10.4  博弈原理  444\n10.4.1  深度搜索与广度搜索  444\n10.4.2  完美决策  446\n10.4.3  蒙特卡洛搜索树  448\n10.5  实战：中国象棋版AlphaGo Zero  449\n10.5.1  开源版本AlphaGo Zero  450\n10.5.2  盘面建模  452\n10.5.3  左右互搏  457\n10.5.4  MCTS详解  464\n10.5.5  DDPG详解  468\n10.5.6  运行展示：训练  473\n10.5.7  运行展示：查看统计  475\n10.5.8  运行展示：当头炮、把马跳  475\n10.5.9  运行展示：人机博弈  476\n10.6  本章内容回顾  477\n第11章  模型迁移  478\n11.1  走向移动端  478\n11.1.1  Android上的TensorFlow  479\n11.1.2  iOS上的CoreML  480\n11.2  迁移学习  483\n11.2.1  动机  483\n11.2.2  训练流程  484\n11.3  案例实战：基于TensorFlow Hub的迁移学习开发  485\n11.3.1  下载并训练  485\n11.3.2  检验学习成果  486\n11.3.3  迁移学习开发  487\n11.4  本章内容回顾  488\n后记  489","pages":"512","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s30026434.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s30026434.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s30026434.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30490080\/","id":"30490080","publisher":"电子工业出版社","isbn10":"7121355183","isbn13":"9787121355189","title":"从机器学习到深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30490080","alt_title":"","author_intro":"刘长龙，思维与行动兼备的80后，享受萌生新想法后边开发边思考的创新过程。上海交大硕士毕业后最初任职于上海电信，负责账务与支付系统的开发与实施；之后加入Honeywell负责多个自动化控制产品服务开发、主导了霍尼韦尔中国智能家居在云与大数据上的创新；现在作为思科的工程师在企业内主持多次机器学习技术分享，实现智能文本分析系统、聊天机器人自然语言处理等产品创新；2018年在思科主办，腾讯、网易、诺基亚等共同参与的敏捷与人工智能峰会上担任机器学习算法演讲嘉宾。","summary":"《从机器学习到深度学习：基于scikit-learn与TensorFlow的高效开发实战》是一本场景式的机器学习实践书，笔者努力做到“授人以渔，而非授人以鱼”。理论方面从人工智能（AI）与机器学习（ML）的基本要素讲起，逐步展开有监督学习、无监督学习、强化学习这三大类模型的应用场景与算法原理；实践方面通过金融预测、医疗诊断概率模型、月球登陆器、图像识别、写诗机器人、中国象棋博弈等案例启发读者将机器学习应用在各行各业里，其中后三个案例使用了深度学习技术。\n《从机器学习到深度学习：基于scikit-learn与TensorFlow的高效开发实战》试图用通俗的语言讲解涵盖算法模型的机器学习，主要内容包括机器学习通用概念、三个基本科学计算工具、有监督学习、聚类模型、降维模型、隐马尔可夫模型、贝叶斯网络、自然语言处理、深度学习、强化学习、模型迁移等。在深入浅出地解析模型与算法之后，介绍使用Python相关工具进行开发的方法、解析经典案例，使读者做到“能理解、能设计、能编码、能调试”，没有任何专业基础的读者在学习本书后也能够上手设计与开发机器学习产品。\n《从机器学习到深度学习：基于scikit-learn与TensorFlow的高效开发实战》内容深入浅出、实例典型，适合对机器学习感兴趣的产品设计、技术管理、数据分析、软件开发或学生读者。阅读本书既能了解当前工业界的主流机器学习与深度学习开发工具的使用方法，又能从战略方面掌握如何将人工智能技术应用到自己的企业与产品中。","price":"99.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30545262\/","id":"30545262","publisher":"","isbn10":"7111599942","isbn13":"9787111599944","title":"机器学习与深度学习：通过C语言模拟","url":"https:\/\/api.douban.com\/v2\/book\/30545262","alt_title":"","author_intro":"","summary":"","price":"48.70"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["【美】克里斯·阿尔本（Chris Albon）"],"pubdate":"2019-7","tags":[{"count":14,"name":"机器学习","title":"机器学习"},{"count":11,"name":"Python","title":"Python"},{"count":3,"name":"sklearn","title":"sklearn"},{"count":2,"name":"keras","title":"keras"},{"count":2,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33322876.jpg","binding":"平装","translator":["韩慧昌","林然","徐江"],"catalog":"第1 章　向量、矩阵和数组 ..................................................................... 1\n1.0　简介 .....................................................................................................1\n1.1　创建一个向量 ......................................................................................1\n1.2　创建一个矩阵 ......................................................................................2\n1.3　创建一个稀疏矩阵 ...............................................................................3\n1.4　选择元素 ..............................................................................................5\n1.5　展示一个矩阵的属性 ...........................................................................6\n1.6　对多个元素同时应用某个操作 ............................................................7\n1.7　找到最大值和最小值 ...........................................................................8\n1.8　计算平均值、方差和标准差 ................................................................9\n1.9　矩阵变形 ............................................................................................10\n1.10 转置向量或矩阵 ............................................................... 11\n1.11 展开一个矩阵 ....................................................................................12\n1.12 计算矩阵的秩 ....................................................................................13\n1.13 计算行列式 ........................................................................................14\n1.14 获取矩阵的对角线元素 .....................................................................14\n1.15 计算矩阵的迹 ....................................................................................15\n1.16 计算特征值和特征向量 .....................................................................16\n1.17 计算点积 ...........................................................................................17\n1.18 矩阵的相加或相减 ............................................................................18\n1.19 矩阵的乘法 ........................................................................................19\n1.20 计算矩阵的逆 ....................................................................................20\n1.21 生成随机数 ........................................................................................21\n第2 章　加载数据 ................................................................................ 23\n2.0　简介 ...................................................................................................23\n2.1　加载样本数据集 ................................................................................23\n2.2　创建仿真数据集 ................................................................................25\n2.3　加载CSV 文件 ..................................................................................28\n2.4　加载Excel 文件 .................................................................................29\n2.5　加载JSON 文件 .................................................................................29\n2.6　查询SQL 数据库 ...............................................................................31\n第3 章　数据整理 ................................................................................ 33\n3.0　简介 ...................................................................................................33\n3.1　创建一个数据帧 ................................................................................34\n3.2　描述数据 ............................................................................................35\n3.3　浏览数据帧 ........................................................................................37\n3.4　根据条件语句来选择行 .....................................................................39\n3.5　替换值 ...............................................................................................40\n3.6　重命名列 ............................................................................................41\n3.7　计算最小值、最大值、总和、平均值与计数值 ................................43\n3.8　查找唯一值 ........................................................................................44\n3.9　处理缺失值 ........................................................................................45\n3.10 删除一列 ...........................................................................................47\n3.11 删除一行 ............................................................................................48\n3.12 删除重复行 ........................................................................................49\n3.13 根据值对行分组 ................................................................................51\n3.14 按时间段对行分组 ............................................................................52\n3.15 遍历一个列的数据 ............................................................................54\n3.16 对一列的所有元素应用某个函数 ......................................................55\n3.17 对所有分组应用一个函数 .................................................................56\n3.18 连接多个数据帧 ................................................................................57\n3.19 合并两个数据帧 ................................................................................59\n第4 章　处理数值型数据 ...................................................................... 63\n4.0　简介 ...................................................................................................63\n4.1　特征的缩放 ........................................................................................63\n4.2　特征的标准化 ....................................................................................65\n4.3　归一化观察值 ....................................................................................66\n4.4　生成多项式和交互特征 .....................................................................69\n4.5　转换特征 ............................................................................................70\n4.6　识别异常值 ........................................................................................71\n4.7　处理异常值 ........................................................................................73\n4.8　将特征离散化 ....................................................................................75\n4.9　使用聚类的方式将观察值分组 ..........................................................77\n4.10 删除带有缺失值的观察值 .................................................................79\n4.11 填充缺失值 ........................................................................................81\n第5 章　处理分类数据 ......................................................................... 83\n5.0　简介 ...................................................................................................83\n5.1　对nominal 型分类特征编码 ..............................................................84\n5.2　对ordinal 分类特征编码 ....................................................................86\n5.3　对特征字典编码 ................................................................................88\n5.4　填充缺失的分类值 .............................................................................91\n5.5　处理不均衡分类 ................................................................................93\n第6 章　处理文本 ................................................................................ 97\n6.0　简介 ...................................................................................................97\n6.1　清洗文本 ............................................................................................97\n6.2　解析并清洗HTML ............................................................................99\n6.3　移除标点 .......................................................................................... 100\n6.4　文本分词 .......................................................................................... 101\n6.5　删除停止词（stop word）......................................... 102\n6.6　提取词干 .......................................................................................... 103\n6.7　标注词性 .......................................................................................... 104\n6.8　将文本编码成词袋（Bag of Words）................................................ 107\n6.9　按单词的重要性加权 ....................................... 109\n第7 章　处理日期和时间 .................................................................... 113\n7.0　简介 ................................................................................................. 113\n7.1　把字符串转换成日期 ......................................................... 113\n7.2　处理时区 .......................................................................................... 115\n7.3　选择日期和时间 .............................................................................. 116\n7.4　将日期数据切分成多个特征 ............................................................ 117\n7.5　计算两个日期之间的时间差 ............................................................ 118\n7.6　对一周内的各天进行编码 ............................................................... 119\n7.7　创建一个滞后的特征 ....................................................... 120\n7.8　使用滚动时间窗口 ........................................................................... 121\n7.9　处理时间序列中的缺失值 ............................................................... 123\n第8 章　图像处理 .............................................................................. 127\n8.0　简介 ................................................................................................. 127\n8.1　加载图像 .......................................................................................... 128\n8.2　保存图像 .......................................................................................... 130\n8.3　调整图像大小 .................................................................................. 131\n8.4　裁剪图像 .......................................................................................... 132\n8.5　平滑处理图像 .................................................................................. 133\n8.6　图像锐化 .......................................................................................... 136\n8.7　提升对比度 .................................................................. 138\n8.8　颜色分离 .......................................................................................... 140\n8.9　图像二值化 .......................................... 142\n8.10 移除背景............................................. 144\n8.11 边缘检测 .......................................................................................... 148\n8.12 角点检测 ................................. 150\n8.13 为机器学习创建特征 ................................................. 153\n8.14 将颜色平均值编码成特征 ............................................................... 156\n8.15 将色彩直方图编码成特征 ............................................................... 157\n第9 章　利用特征提取进行特征降维 ................................................... 161\n9.0　简介 ................................................................................................. 161\n9.1　使用主成分进行特征降维 ............................................................... 161\n9.2　对线性不可分数据进行特征降维 .................................................... 164\n9.3　通过最大化类间可分性进行特征降维 ............................................. 166\n9.4　使用矩阵分解法进行特征降维...................................... 169\n9.5　对稀疏数据进行特征降维 ............................................................... 170\n第10 章　使用特征选择进行降维 ........................................................ 173\n10.0　简介........................................................... 173\n10.1　数值型特征方差的阈值化...................................... 173\n10.2　二值特征的方差阈值化............................................ 175\n10.3　处理高度相关性的特征 .......................................... 176\n10.4　删除与分类任务不相关的特征 ...................................................... 178\n10.5　递归式特征消除 ............................................................................ 180\n第11 章　模型评估 ............................................................................ 183\n11.0　简介 ...................................................................... 183\n11.1　交叉验证模型 .......................................... 183\n11.2　创建一个基准回归模型........................................ 187\n11.3　创建一个基准分类模型 .................................. 188\n11.4　评估二元分类器 ................................................ 190\n11.5　评估二元分类器的阈值 ..................................... 193\n11.6　评估多元分类器 .......................................................... 197\n11.7　分类器性能的可视化 ..................................................................... 198\n11.8　评估回归模型 ............................................. 201\n11.9　评估聚类模型 ............................................................ 203\n11.10 创建自定义评估指标 ..................................................................... 204\n11.11 可视化训练集规模的影响 ............................................................. 206\n11.12 生成对评估指标的报告 .................................................... 208\n11.13 可视化超参数值的效果 ................................................. 209\n第12 章　模型选择 ............................................................................ 213\n12.0　简介 .................................................... 213\n12.1　使用穷举搜索选择最佳模型 .......................................................... 213\n12.2　使用随机搜索选择最佳模型 .......................................................... 216\n12.3　从多种学习算法中选择最佳模型.................. 218\n12.4　将数据预处理加入模型选择过程 .............................. 220\n12.5　用并行化加速模型选择 ................................. 221\n12.6　使用针对特定算法的方法加速模型选择 ....................................... 223\n12.7　模型选择后的性能评估 ............................ 224\n第13 章　线性回归 ............................................................................ 227\n13.0　简介 ........................................ 227\n13.1　拟合一条直线 .......................................... 227\n13.2　处理特征之间的影响 ..................................................................... 229\n13.3　拟合非线性关系 ............................................................................ 231\n13.4　通过正则化减少方差 ..................................................................... 233\n13.5　使用套索回归减少特征 .............................................. 235\n第14 章　树和森林 ............................................................................ 237\n14.0　简介 ............................... 237\n14.1　训练决策树分类器 ......................................................................... 237\n14.2　训练决策树回归模型 ..................................................................... 239\n14.3　可视化决策树模型 ......................................................................... 240\n14.4　训练随机森林分类器 ..................................................................... 243\n14.5　训练随机森林回归模型 ............................ 244\n14.6　识别随机森林中的重要特征 .......................................................... 245\n14.7　选择随机森林中的重要特征 .......................................................... 248\n14.8　处理不均衡的分类 ......................................................................... 249\n14.9　控制决策树的规模 ......................................................................... 250\n14.10 通过boosting 提高性能 ................................................................ 252\n14.11 使用袋外误差（Out-of-Bag Error）评估随机森林模型 ................ 253\n第15 章　KNN ................................................................................... 255\n15.0　简介 ................................................................... 255\n15.1　找到一个观察值的最近邻 ................................................. 255\n15.2　创建一个KNN 分类器................................................................... 258\n15.3　确定最佳的邻域点集的大小 .......................................................... 260\n15.4　创建一个基于半径的最近邻分类器 ......................... 261\n第16 章　逻辑回归 ............................................................................ 263\n16.0　简介 ............................................................... 263\n16.1　训练二元分类器 ............................................................................ 263\n16.2　训练多元分类器 ............................................................................ 265\n16.3　通过正则化来减小方差 ............................................. 266\n16.4　在超大数据集上训练分类器 .......................................................... 267\n16.5　处理不均衡的分类 ......................................................................... 269\n第17 章　支持向量机 ......................................................................... 271\n17.0　简介 ..................................................................... 271\n17.1　训练一个线性分类器 ..................................................................... 271\n17.2　使用核函数处理线性不可分的数据 ..................................... 274\n17.3　计算预测分类的概率 ..................................................................... 278\n17.4　识别支持向量 ....................................................... 279\n17.5　处理不均衡的分类 ......................................................................... 281\n第18 章　朴素贝叶斯 ......................................................................... 283\n18.0　简介 ............................................................. 283\n18.1　为连续的数据训练分类器 ............................................. 284\n18.2　为离散数据和计数数据训练分类器 ............................... 286\n18.3　为具有二元特征的数据训练朴素贝叶斯分类器 ............................ 287\n18.4　校准预测概率 ........................................ 288\n第19 章　聚类 ................................................................................... 291\n19.0　简介 ................................................................ 291\n19.1　使用K-Means 聚类算法 ................................................................ 291\n19.2　加速K-Means 聚类 ........................................................................ 294\n19.3　使用Meanshift 聚类算法 ............................................................... 295\n19.4　使用DBSCAN 聚类算法 ............................................................... 296\n19.5　使用层次合并聚类算法 .......................................... 298\n第20 章　神经网络 ............................................................................ 301\n20.0　简介 ...................................................................... 301\n20.1　为神经网络预处理数据 .................................................... 302\n20.2　设计一个神经网络 ......................................................................... 304\n20.3　训练一个二元分类器 ..................................................................... 307\n20.4　训练一个多元分类器 ..................................................................... 309\n20.5　训练一个回归模型 ......................................................................... 311\n20.6　做预测 ........................................................................................... 313\n20.7　可视化训练历史 ............................................................................ 315\n20.8　通过权重调节减少过拟合 ..................................... 318\n20.9　通过提前结束减少过拟合 ........................................ 320\n20.10 通过Dropout 减少过拟合 ............................................................. 322\n20.11 保存模型训练过程 ......................................................................... 324\n20.12 使用k 折交叉验证评估神经网络 ................................................ 326\n20.13 调校神经网络 ........................................................................ 328\n20.14 可视化神经网络 ............................................................................ 331\n20.15 图像分类 ....................................................................................... 333\n20.16 通过图像增强来改善卷积神经网络的性能 .............................. 337\n20.17 文本分类 ....................................................................................... 339\n第21 章　保存和加载训练后的模型 ..................................................... 343\n21.0　简介 ....................................................................................... 343\n21.1　保存和加载scikit-learn 模型 ......................................................... 343\n21.2　保存和加载Keras 模型 .................................................................. 345","pages":"368","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33322876.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33322876.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33322876.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34466254\/","id":"34466254","publisher":"电子工业出版社","isbn10":"7121369621","isbn13":"9787121369629","title":"Python机器学习手册：从数据预处理到深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34466254","alt_title":"","author_intro":"","summary":"《Python机器学习手册：从数据预处理到深度学习》采用基于任务的方式来介绍如何在机器学习中使用Python。书中有近200个独立的解决 方案，针对的都是数据科学家或机器学习工程师在构建模型时可能遇到的常见任务，涵盖从简 单的矩阵和向量运算到特征工程以及神经网络的构建。所有方案都提供了相关代码，读者可以 复制并粘贴这些代码，用在自己的程序中。\n《Python机器学习手册：从数据预处理到深度学习》不是机器学习的入门书，适合熟悉机器学习理论和概念的读者阅读。你可以将本书作 为案头参考书，在机器学习的日常开发中遇到问题时，随时借鉴书中代码，快速解决问题。","price":"89.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34725917\/","id":"34725917","publisher":"","isbn10":"7111627180","isbn13":"9787111627180","title":"强化学习与深度学习：通过C语言模拟","url":"https:\/\/api.douban.com\/v2\/book\/34725917","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["[日]巢笼悠辅"],"pubdate":"2019-11","tags":[{"count":2,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33523088.jpg","binding":"平装","translator":["郑明智"],"catalog":"第1章　数学准备　　001\n1.1 偏微分　　001\n1.1.1　导函数和偏导函数　　001\n1.1.2　微分系数与偏微分系数　　003\n1.1.3　偏微分的基本公式　　006\n1.1.4　复合函数的偏微分　　007\n1.1.5　拓展全微分　　009\n1.2 线性代数　　011\n1.2.1　向量　　011\n1.2.1.1　向量的基础知识　　011\n1.2.1.2　向量的和与标量倍数　　011\n1.2.1.3　向量的内积　　012\n1.2.2　矩阵　　013\n1.2.2.1　矩阵的基础知识　　013\n1.2.2.2　矩阵的和与标量倍数　　014\n1.2.2.3　矩阵的乘积　　014\n1.2.2.4　正则矩阵与逆矩阵　　016\n1.2.2.5　转置矩阵　　017\n1.3 小结　　018\n第2章　Python准备　　019\n2.1 Python　2和Python　3　　020\n2.2 Anaconda发行版　　021\n2.3 Python的基础知识　　025\n2.3.1　Python程序的执行　　025\n2.3.2　数据类型　　026\n2.3.2.1　类型是什么　　026\n2.3.2.2　字符串类型　　027\n2.3.2.3　数值类型　　028\n2.3.2.4　布尔类型　　030\n2.3.3　变量　　031\n2.3.3.1　变量是什么　　031\n2.3.3.2　变量与类型　　032\n2.3.4　数据结构　　033\n2.3.4.1　列表　　033\n2.3.4.2　字典　　034\n2.3.5　运算　　035\n2.3.5.1　运算符与操作数　　035\n2.3.5.2　算术运算的运算符　　036\n2.3.5.3　赋值运算符　　036\n2.3.6　基本结构　　038\n2.3.6.1　if语句　　038\n2.3.6.2　while语句　　039\n2.3.6.3　for语句　　041\n2.3.7　函数　　043\n2.3.8　类　　045\n2.3.9　库　　048\n2.4 NumPy　　049\n2.4.1　NumPy数组　　049\n2.4.2　使用NumPy进行向量和矩阵的计算　　051\n2.4.3　数组和多维数组的生成　　053\n2.4.4　切片　　054\n2.4.5　广播　　056\n2.5 面向深度学习的库　　058\n2.5.1　TensorFlow　　058\n2.5.2　Keras　　059\n2.5.3　参考Theano　　060\n2.6 小结　　063\n第3章　神经网络　　065\n3.1 什么是神经网络　　065\n3.1.1　脑和神经元　　065\n3.1.2　深度学习和神经网络　　066\n3.2 作为电路的神经网络　　067\n3.2.1　简单的模型化　　067\n3.2.2　逻辑电路　　069\n3.2.2.1　逻辑门　　069\n3.2.2.2　与门　　069\n3.2.2.3　或门　　072\n3.2.2.4　非门　　074\n3.3 简单感知机　　075\n3.3.1　模型化　　075\n3.3.2　实现　　077\n3.4 逻辑回归　　081\n3.4.1　阶跃函数与sigmoid函数　　081\n3.4.2　模型化　　082\n3.4.2.1　似然函数与交叉熵误差函数　　082\n3.4.2.2　梯度下降法　　084\n3.4.2.3　随机梯度下降法与小批量梯度下降法　　085\n3.4.3　实现　　086\n3.4.3.1　使用TensorFlow的实现　　086\n3.4.3.2　使用Keras的实现　　092\n3.4.4　拓展sigmoid函数与概率密度函数、累积分布函数　　096\n3.4.5　拓展梯度下降法和局部最优解　　099\n3.5 多分类逻辑回归　　101\n3.5.1　softmax函数　　101\n3.5.2　模型化　　102\n3.5.3　实现　　106\n3.5.3.1　使用TensorFlow的实现　　106\n3.5.3.2　使用Keras的实现　　110\n3.6 多层感知机　　111\n3.6.1　非线性分类　　111\n3.6.1.1　异或门　　111\n3.6.1.2　逻辑门的组合　　113\n3.6.2　模型化　　115\n3.6.3　实现　　119\n3.6.3.1　使用TensorFlow的实现　　119\n3.6.3.2　使用Keras的实现　　122\n3.7 模型的评估　　123\n3.7.1　从分类到预测　　123\n3.7.2　预测的评估　　124\n3.7.3　简单的实验　　126\n3.8 小结　　131\n第4章　深度神经网络　　133\n4.1 进入深度学习之前的准备　　133\n4.2 训练过程中的问题　　138\n4.2.1　梯度消失问题　　138\n4.2.2　过拟合问题　　141\n4.3 训练的高效化　　142\n4.3.1　激活函数　　143\n4.3.1.1　双曲正切函数　　143\n4.3.1.2　ReLU　　145\n4.3.1.3　Leaky ReLU　　147\n4.3.1.4　Parametric ReLU　　149\n4.3.2　Dropout　　152\n4.4 代码的设计　　157\n4.4.1　基本设计　　157\n4.4.1.1　使用TensorFlow的实现　　157\n4.4.1.2　使用Keras的实现　　160\n4.4.1.3　拓展对TensorFlow模型进行类封装　　161\n4.4.2　训练的可视化　　166\n4.4.2.1　使用TensorFlow的实现　　167\n4.4.2.2　使用Keras的实现　　172\n4.5 高级技术　　176\n4.5.1　数据的正则化与权重的初始化　　176\n4.5.2　学习率的设置　　179\n4.5.2.1　动量　　179\n4.5.2.2　Nesterov动量　　180\n4.5.2.3　Adagrad　　181\n4.5.2.4　Adadelta　　182\n4.5.2.5　RMSprop　　184\n4.5.2.6　Adam　　185\n4.5.3　早停法　　187\n4.5.4　Batch Normalization　　190\n4.6 小结　　195\n第5章　循环神经网络　　197\n5.1 基本概念　　197\n5.1.1　时间序列数据　　197\n5.1.2　过去的隐藏层　　199\n5.1.3　基于时间的反向传播算法　　202\n5.1.4　实现　　204\n5.1.4.1　准备时间序列数据　　205\n5.1.4.2　使用TensorFlow的实现　　207\n5.1.4.3　使用Keras的实现　　214\n5.2 LSTM　　215\n5.2.1　LSTM 块　　215\n5.2.2　CEC、输入门和输出门　　217\n5.2.2.1　稳态误差　　217\n5.2.2.2　输入权重冲突和输出权重冲突　　219\n5.2.3　遗忘门　　220\n5.2.4　窥视孔连接　　222\n5.2.5　模型化　　223\n5.2.6　实现　　227\n5.2.7　长期依赖信息的训练评估——Adding Problem　　229\n5.3 GRU　　232\n5.3.1　模型化　　232\n5.3.2　实现　　233\n5.4 小结　　235\n第6章　循环神经网络的应用　　237\n6.1 双向循环神经网络　　237\n6.1.1　未来的隐藏层　　237\n6.1.2　前向、后向传播　　239\n6.1.3　MNIST的预测　　241\n6.1.3.1　转换为时间序列数据　　241\n6.1.3.2　使用TensorFlow的实现　　242\n6.1.3.3　使用Keras的实现　　245\n6.2 循环神经网络编码器- 解码器　　246\n6.2.1　序列到序列模型　　246\n6.2.2　简单的问答系统　　247\n6.2.2.1　设置问题——加法的训练　　247\n6.2.2.2　数据的准备　　248\n6.2.2.3　使用TensorFlow的实现　　251\n6.2.2.4　使用Keras的实现　　260\n6.3 注意力模型　　261\n6.3.1　时间的权重　　261\n6.3.2　LSTM中的注意力机制　　263\n6.4 记忆网络　　265\n6.4.1　记忆外部化　　265\n6.4.2　应用于问答系统　　266\n6.4.2.1　bAbi任务　　266\n6.4.2.2　模型化　　267\n6.4.3　实现　　269\n6.4.3.1　数据的准备　　269\n6.4.3.2　使用TensorFlow的实现　　272\n6.5 小结　　276\n附录　　279\nA.1 模型的保存和读取　　279\nA.1.1　使用TensorFlow时的处理　　279\nA.1.2　使用Keras时的处理　　284\nA.2 TensorBoard　　285\nA.3 tf.contrib.learn　　292","pages":"293","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33523088.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33523088.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33523088.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34892928\/","id":"34892928","publisher":"人民邮电出版社","isbn10":"711551996X","isbn13":"9787115519962","title":"详解深度学习：基于TensorFlow和Keras学习RNN","url":"https:\/\/api.douban.com\/v2\/book\/34892928","alt_title":"","author_intro":"巢笼悠辅（作者）\n日本新闻应用Gunosy和众筹网站READYFOR的创始人之一。曾就职于电通和谷歌纽约分部。辞职后参与了株式会社MICIN的创立工作，致力于人工智能技术在医疗领域的应用。东京大学客座讲师。著作有《深度学习：Java语言实现》。\n郑明智（译者）\n智慧医疗工程师。主要研究方向为医疗领域的自然语言处理及其应用，密切关注大数据、机器学习、深度学习等领域。译作有《松本行弘：编程语言的设计与实现》《深度学习基础与实践》。","summary":"本书着眼于处理时间序列数据的深度学习算法，通过基于Python 语言的库TensorFlow 和Keras来学习神经网络、深度学习的理论和实现。全书共六章，前两章讲解了学习神经网络所需的数学知识和Python 基础知识；中间两章讲解了神经网络的基本算法以及深度学习的基础知识和应用；最后两章详细介绍了专门用于处理时间序列数据的循环神经网络（RNN）。","price":"79.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34904789\/","id":"34904789","publisher":"","isbn10":"7030629450","isbn13":"9787030629456","title":"深度学习视域下MOOC学习活动设计的理论与实践","url":"https:\/\/api.douban.com\/v2\/book\/34904789","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["子由"],"pubdate":"20050101","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s1377529.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s1377529.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s1377529.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s1377529.jpg"},"alt":"https:\/\/book.douban.com\/subject\/1347003\/","id":"1347003","publisher":"博碩","isbn10":"9575277716","isbn13":"9789575277710","title":"深度學習C++","url":"https:\/\/api.douban.com\/v2\/book\/1347003","alt_title":"","author_intro":"","summary":"對許多人而言，學習程式語言的過程通常是枯燥乏味，同時不知有何用處。閱讀本書你將會有完全不同的學習感受，本書透過許多實際有趣的範例，以說清楚，講明白的方式逐步引導你進入C++語言的豐富殿堂。作者特別透過許多在網路上經常詢問的題目，以簡單易懂的方式呈現正統C++語言的設計型式，讓讀者可以藉由本書，循序漸進的學習到C++語言的精華。\n","price":"NT$ 690"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["[意] Giancarlo Zaccone","[埃及] Ahmed Menshawy","[孟加拉] Md. Rezaul Karim"],"pubdate":"2018-4","tags":[{"count":6,"name":"TensorFlow","title":"TensorFlow"},{"count":6,"name":"Python","title":"Python"},{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"神经网络","title":"神经网络"},{"count":3,"name":"没有深度","title":"没有深度"},{"count":3,"name":"入门","title":"入门"},{"count":2,"name":"看看就好","title":"看看就好"},{"count":2,"name":"工程","title":"工程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29731177.jpg","binding":"平装","translator":["李　志"],"catalog":"第1章　深度学习入门　　1\n1.1　机器学习简介　　1\n1.1.1　监督学习　　2\n1.1.2　无监督学习　　2\n1.1.3　强化学习　　3\n1.2　深度学习定义　　3\n1.2.1　人脑的工作机制　　3\n1.2.2　深度学习历史　　4\n1.2.3　应用领域　　5\n1.3　神经网络　　5\n1.3.1　生物神经元　　5\n1.3.2　人工神经元　　6\n1.4　人工神经网络的学习方式　　8\n1.4.1　反向传播算法　　8\n1.4.2　权重优化　　8\n1.4.3　随机梯度下降法　　9\n1.5　神经网络架构　　10\n1.5.1　多层感知器　　10\n1.5.2　DNN架构　　11\n1.5.3　卷积神经网络　　12\n1.5.4　受限玻尔兹曼机　　12\n1.6　自编码器　　13\n1.7　循环神经网络　　14\n1.8　几种深度学习框架对比　　14\n1.9　小结　　16\n第2章　TensorFlow初探　　17\n2.1　总览　　17\n2.1.1　TensorFlow 1.x版本特性　　18\n2.1.2　使用上的改进　　18\n2.1.3　TensorFlow安装与入门　　19\n2.2　在Linux上安装TensorFlow　　19\n2.3　为TensorFlow启用NVIDIA GPU　　20\n2.3.1　第1步：安装NVIDIA CUDA　　20\n2.3.2　　第2步：安装NVIDIA cuDNN v5.1+　　21\n2.3.3　　第3步：确定GPU卡的CUDA计算能力为3.0+　　22\n2.3.4　第4步：安装libcupti-dev库　　22\n2.3.5　　第5步：安装Python\n（或Python 3）　　22\n2.3.6　第6步：安装并升级PIP\n（或PIP3）　　22\n2.3.7　第7步：安装TensorFlow　　23\n2.4　如何安装TensorFlow　　23\n2.4.1　直接使用pip安装　　23\n2.4.2　使用virtualenv安装　　24\n2.4.3　从源代码安装　　26\n2.5　在Windows上安装TensorFlow　　27\n2.5.1　在虚拟机上安装TensorFlow　　27\n2.5.2　直接安装到Windows　　27\n2.6　测试安装是否成功　　28\n2.7　计算图　　28\n2.8　为何采用计算图　　29\n2.9　编程模型　　30\n2.10　数据模型　　33\n2.10.1　阶　　33\n2.10.2　形状　　33\n2.10.3　数据类型　　34\n2.10.4　变量　　36\n2.10.5　取回　　37\n2.10.6　注入　　38\n2.11　TensorBoard　　38\n2.12　实现一个单输入神经元　　39\n2.13　单输入神经元源代码　　43\n2.14　迁移到TensorFlow 1.x版本　　43\n2.14.1　如何用脚本升级　　44\n2.14.2　局限　　47\n2.14.3　手动升级代码　　47\n2.14.4　变量　　47\n2.14.5　汇总函数　　47\n2.14.6　简化的数学操作　　48\n2.14.7　其他事项　　49\n2.15　小结　　49\n第3章　用TensorFlow构建前馈\n神经网络　　51\n3.1　前馈神经网络介绍　　51\n3.1.1　前馈和反向传播　　52\n3.1.2　权重和偏差　　53\n3.1.3　传递函数　　53\n3.2　手写数字分类　　54\n3.3　探究MNIST数据集　　55\n3.4　softmax分类器　　57\n3.5　TensorFlow模型的保存和还原　　63\n3.5.1　保存模型　　63\n3.5.2　还原模型　　63\n3.5.3　softmax源代码　　65\n3.5.4　softmax启动器源代码　　66\n3.6　实现一个五层神经网络　　67\n3.6.1　可视化　　69\n3.6.2　五层神经网络源代码　　70\n3.7　ReLU分类器　　72\n3.8　可视化　　73\n3.9　dropout优化　　76\n3.10　可视化　　78\n3.11　小结　　80\n第4章　TensorFlow与卷积神经网络　　82\n4.1　CNN简介　　82\n4.2　CNN架构　　84\n4.3　构建你的第一个CNN　　86\n4.4　CNN表情识别　　95\n4.4.1　表情分类器源代码　　104\n4.4.2　使用自己的图像测试模型　　107\n4.4.3　源代码　　109\n4.5　小结　　111\n第5章　优化TensorFlow自编码器　　112\n5.1　自编码器简介　　112\n5.2　实现一个自编码器　　113\n5.3　增强自编码器的鲁棒性　　119\n5.4　构建去噪自编码器　　120\n5.5　卷积自编码器　　127\n5.5.1　编码器　　127\n5.5.2　解码器　　128\n5.5.3　卷积自编码器源代码　　134\n5.6　小结　　138\n第6章　循环神经网络　　139\n6.1　RNN的基本概念　　139\n6.2　RNN的工作机制　　140\n6.3　RNN的展开　　140\n6.4　梯度消失问题　　141\n6.5　LSTM网络　　142\n6.6　RNN图像分类器　　143\n6.7　双向RNN　　149\n6.8　文本预测　　155\n6.8.1　数据集　　156\n6.8.2　困惑度　　156\n6.8.3　PTB模型　　156\n6.8.4　运行例程　　157\n6.9　小结　　158\n第7章　GPU计算　　160\n7.1　GPGPU计算　　160\n7.2　GPGPU的历史　　161\n7.3　CUDA架构　　161\n7.4　GPU编程模型　　162\n7.5　TensorFlow中GPU的设置　　163\n7.6　TensorFlow的GPU管理　　165\n7.7　GPU内存管理　　168\n7.8　在多GPU系统上分配单个GPU　　168\n7.9　使用多个GPU　　170\n7.10　小结　　171\n第8章　TensorFlow高级编程　　172\n8.1　Keras简介　　172\n8.2　构建深度学习模型　　174\n8.3　影评的情感分类　　175\n8.4　添加一个卷积层　　179\n8.5　Pretty Tensor　　181\n8.6　数字分类器　　182\n8.7　TFLearn　　187\n8.8　泰坦尼克号幸存者预测器　　188\n8.9　小结　　191\n第9章　TensorFlow高级多媒体编程　　193\n9.1　多媒体分析简介　　193\n9.2　基于深度学习的大型对象检测　　193\n9.2.1　瓶颈层　　195\n9.2.2　使用重训练的模型　　195\n9.3　加速线性代数　　197\n9.3.1　TensorFlow的核心优势　　197\n9.3.2　加速线性代数的准时编译　　197\n9.4　TensorFlow和Keras　　202\n9.4.1　Keras简介　　202\n9.4.2　拥有Keras的好处　　203\n9.4.3　视频问答系统　　203\n9.5　Android上的深度学习　　209\n9.5.1　TensorFlow演示程序　　209\n9.5.2　Android入门　　211\n9.6　小结　　214\n第10章　强化学习　　215\n10.1　强化学习基本概念　　216\n10.2　Q-learning算法　　217\n10.3　OpenAI Gym框架简介　　218\n10.4　FrozenLake-v0实现问题　　220\n10.5　使用TensorFlow实现Q-learning　　223\n10.6　小结　　227","pages":"240","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29731177.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29731177.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29731177.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30186130\/","id":"30186130","publisher":"人民邮电出版社","isbn10":"7115478775","isbn13":"9787115478771","title":"TensorFlow深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30186130","alt_title":"","author_intro":"Giancarlo Zaccone\n在并行计算和可视化方向拥有丰富经验，目前于某咨询公司担任系统和软件工程师。\nMd. Rezaul Karim 拥有近10年软件研发经验，具备扎实的算法和数据结构知识，研究兴趣包括机器学习、深度学习、语义网络等。\nAhmed Menshawy\n爱尔兰都柏林三一学院研究工程师，主要工作是使用ADAPT中心的机器学习和自然语言处理技术成果构建原型和应用，在机器学习和自然语言处理领域拥有多年工作经验。","summary":"本书共分5方面内容：基础知识、关键模块、算法模型、内核揭秘、生态发展。前两方面由浅入深地介绍了TensorFlow 平台，算法模型方面依托TensorFlow 讲解深度学习模型，内核揭秘方面主要分析C++内核中的通信原理、消息管理机制等，最后从生态发展的角度讲解以TensorFlow 为中心的一套开源大数据分析解决方案。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"49.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Josh Patterson"],"pubdate":"2018-2","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29721570.jpg","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29721570.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29721570.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29721570.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30177170\/","id":"30177170","publisher":"东南大学出版社","isbn10":"7564175168","isbn13":"9787564175160","title":"深度学习（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/30177170","alt_title":"","author_intro":"","summary":"尽管人们对于机器学习领域的兴趣已达到高点，过高的期望往往在项目没走多远之前就已经压垮了它。机器学习——特别是深度神经网络——如何才能在你的组织内产生真正的作用？这本容易上手的指南不仅能提供关于该主题最实用的信息，也可以帮助你开始构建高效的深度学习网络。在引入开源Deeplearning4j（DL4J）库用于开发产品级工作流之前，作者Josh Patterson和Adam Gibson介绍了深度学习——调优、并行化、向量化及建立管道——等任何库所需的基础知识。通过真实的案例，你将学会在Spark和Hadoop上用DL4J训练深度网络架构并运行深度学习工作流的方法和策略","price":"99.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30208543\/","id":"30208543","publisher":"","isbn10":"7111588789","isbn13":"9787111588788","title":"基于Theano的深度学习:构建未来与当前的人工大脑","url":"https:\/\/api.douban.com\/v2\/book\/30208543","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["闫涛","周琦"],"pubdate":"2018-4","tags":[{"count":2,"name":"数据分析","title":"数据分析"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"人工智能","title":"人工智能"},{"count":1,"name":"Python","title":"Python"},{"count":1,"name":"AI","title":"AI"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29760872.jpg","binding":"平装","translator":[],"catalog":"第一部分  深度学习算法概述\n第1章  深度学习算法简介\t2\n1.1  神经网络发展简史\t2\n1.1.1  神经网络第一次兴起\t3\n1.1.2  神经网络沉寂期（20世纪80年代—21世纪）\t4\n1.1.3  神经网络技术积累期（20世纪90年代—2006年）\t5\n1.1.4  深度学习算法崛起（2006年至今）\t8\n1.2  深度学习现状\t10\n1.2.1  传统神经网络困境\t10\n1.2.2  深度多层感知器\t12\n1.2.3  深度卷积神经网络\t14\n1.2.4  深度递归神经网络\t15\n1.3  深度学习研究前瞻\t16\n1.3.1  自动编码机\t17\n1.3.2  深度信念网络\t18\n1.3.3  生成式网络最新进展\t19\n1.4  深度学习框架比较\t20\n1.4.1  TensorFlow\t20\n1.4.2  Theano\t21\n1.4.3  Torch\t22\n1.4.4  DeepLearning4J\t23\n1.4.5  Caffe\t23\n1.4.6  MXNet\t24\n1.4.7  CNTK\t27\n1.4.8  深度学习框架造型指导原则\t27\n1.5  深度学习入门路径\t28\n1.5.1  运行MNIST\t28\n1.5.2  深度学习框架的选择\t29\n1.5.3  小型试验网络\t33\n1.5.4  训练生产网络\t33\n1.5.5  搭建生产环境\t34\n1.5.6  持续改进\t35\n第二部分  深度学习算法基础\n第2章  搭建深度学习开发环境\t38\n2.1  安装Python开发环境\t38\n2.1.1  安装最新版本Python\t38\n2.1.2  Python虚拟环境配置\t39\n2.1.3  安装科学计算库\t40\n2.1.4  安装最新版本Theano\t40\n2.1.5  图形绘制\t40\n2.2  NumPy简易教程\t43\n2.2.1  Python基础\t43\n2.2.2  多维数组的使用\t51\n2.2.3  向量运算\t58\n2.2.4  矩阵运算\t60\n2.2.5  线性代数\t62\n2.3  TensorFlow简易教程\t68\n2.3.1  张量定义\t69\n2.3.2  变量和placeholder\t69\n2.3.3  神经元激活函数\t71\n2.3.4  线性代数运算\t72\n2.3.5  操作数据集\t74\n2.4  Theano简易教程\t77\n2.4.1  安装Theano\t77\n2.4.2  Theano入门\t78\n2.4.3  Theano矩阵相加\t79\n2.4.4  变量和共享变量\t80\n2.4.5  随机数的使用\t84\n2.4.6  Theano求导\t84\n2.5  线性回归\t86\n2.5.1  问题描述\t86\n2.5.2  线性模型\t88\n2.5.3  线性回归学习算法\t89\n2.5.4  解析法\t90\n2.5.5  Theano实现\t93\n第3章  逻辑回归\t100\n3.1  逻辑回归数学基础\t100\n3.1.1  逻辑回归算法的直观解释\t100\n3.1.2  逻辑回归算法数学推导\t101\n3.1.3  牛顿法解逻辑回归问题\t103\n3.1.4  通用学习模型\t106\n3.2  逻辑回归算法简单应用\t113\n3.3  MNIST手写数字识别库简介\t124\n3.4  逻辑回归MNIST手写数字识别\t126\n第4章  感知器模型和MLP\t139\n4.1  感知器模型\t139\n4.1.1  神经元模型\t139\n4.1.2  神经网络架构\t143\n4.2  数值计算形式\t144\n4.2.1  前向传播\t144\n4.2.2  误差反向传播\t145\n4.2.3  算法推导\t147\n4.3  向量化表示形式\t152\n4.4  应用要点\t153\n4.4.1  输入信号模型\t154\n4.4.2  权值初始化\t155\n4.4.3  早期停止\t155\n4.4.4  输入信号调整\t156\n4.5  TensorFlow实现MLP\t156\n第5章  卷积神经网络\t174\n5.1  卷积神经网络原理\t174\n5.1.1  卷积神经网络的直观理解\t174\n5.1.2  卷积神经网络构成\t177\n5.1.3  卷积神经网络设计\t191\n5.1.4  迁移学习和网络微调\t193\n5.2  卷积神经网络的TensorFlow实现\t195\n5.2.1  模型搭建\t197\n5.2.2  训练方法\t203\n5.2.3  运行方法\t208\n第6章  递归神经网络\t212\n6.1  递归神经网络原理\t212\n6.1.1  递归神经网络表示方法\t213\n6.1.2  数学原理\t214\n6.1.3  简单递归神经网络应用示例\t219\n6.2  图像标记\t226\n6.2.1  建立开发环境\t226\n6.2.2  图像标记数据集处理\t227\n6.2.3  单步前向传播\t229\n6.2.4  单步反向传播\t231\n6.2.5  完整前向传播\t234\n6.2.6  完整反向传播\t236\n6.2.7  单词嵌入前向传播\t239\n6.2.8  单词嵌入反向传播\t241\n6.2.9  输出层前向\/反向传播\t243\n6.2.10  输出层代价函数计算\t245\n6.2.11  图像标注网络整体架构\t248\n6.2.12  代价函数计算\t249\n6.2.13  生成图像标记\t255\n6.2.14  网络训练过程\t258\n6.2.15  网络持久化\t265\n第7章  长短时记忆网络\t269\n7.1  长短时记忆网络原理\t269\n7.1.1  网络架构\t269\n7.1.2  数学公式\t272\n7.2  MNIST手写数字识别\t274\n第三部分  深度学习算法进阶\n第8章  自动编码机\t286\n8.1  自动编码机概述\t286\n8.1.1  自动编码机原理\t287\n8.1.2  去噪自动编码机\t287\n8.1.3  稀疏自动编码机\t288\n8.2  去噪自动编码机TensorFlow实现\t291\n8.3  去噪自动编码机的Theano实现\t298\n第9章  堆叠自动编码机\t307\n9.1  堆叠去噪自动编码机\t308\n9.2  TensorFlow实现\t322\n9.3  Theano实现\t341\n第10章  受限玻尔兹曼机\t344\n10.1  受限玻尔兹曼机原理\t344\n10.1.1  网络架构\t344\n10.1.2  能量模型\t346\n10.1.3  CD-K算法\t351\n10.2  受限玻尔兹曼机TensorFlow实现\t353\n10.3  受限玻尔兹曼机Theano实现\t362\n第11章  深度信念网络\t381\n11.1  深度信念网络原理\t381\n11.2  深度信念网络TensorFlow实现\t382\n11.3  深度信念网络Theano实现\t403\n第四部分  机器学习基础\n第12章  生成式学习\t420\n12.1  高斯判别分析\t422\n12.1.1  多变量高斯分布\t422\n12.1.2  高斯判决分析公式\t423\n12.2  朴素贝叶斯\t436\n12.2.1  朴素贝叶斯分类器\t436\n12.2.2  拉普拉斯平滑\t439\n12.2.3  多项式事件模型\t441\n第13章  支撑向量机\t444\n13.1  支撑向量机概述\t444\n13.1.1  函数间隔和几何间隔\t445\n13.1.2  最优距离分类器\t448\n13.2  拉格朗日对偶\t448\n13.3  最优分类器算法\t450\n13.4  核方法\t453\n13.5  非线性可分问题\t455\n13.6  SMO算法\t457\n13.6.1  坐标上升算法\t458\n13.6.2  SMO算法详解\t458\n第五部分  深度学习平台API\n第14章  Python Web编程\t462\n14.1  Python Web开发环境搭建\t462\n14.1.1  CherryPy框架\t463\n14.1.2  CherryPy安装\t463\n14.1.3  测试CherryPy安装是否成功\t464\n14.2  最简Web服务器\t465\n14.2.1  程序启动\t465\n14.2.2  显示HTML文件\t466\n14.2.3  静态内容处理\t468\n14.3  用户认证系统\t471\n14.4  AJAX请求详解\t473\n14.4.1  添加数据\t474\n14.4.2  修改数据\t476\n14.4.3  删除数据\t478\n14.4.4  REST服务实现\t479\n14.5  数据持久化技术\t487\n14.5.1  环境搭建\t487\n14.5.2  数据库添加操作\t488\n14.5.3  数据库修改操作\t489\n14.5.4  数据库删除操作\t490\n14.5.5  数据库查询操作\t491\n14.5.6  数据库事务操作\t492\n14.5.7  数据库连接池\t494\n14.6  任务队列\t499\n14.7  媒体文件上传\t502\n14.8  Redis操作\t504\n14.8.1  Redis安装配置\t504\n14.8.2  Redis使用例程\t505\n第15章  深度学习云平台\t506\n15.1  神经网络持久化\t506\n15.1.1  数据库表设计\t506\n15.1.2  整体目录结构\t511\n15.1.3  训练过程及模型文件保存\t512\n15.2  神经网络运行模式\t528\n15.3  AJAX请求调用神经网络\t531\n15.3.1  显示静态网页\t531\n15.3.2  上传图片文件\t540\n15.3.3  AJAX接口\t543\n15.4  请求合法性验证\t545\n15.4.1  用户注册和登录\t546\n15.4.2  客户端生成请求\t553\n15.4.3  服务器端验证请求\t555\n15.5  异步结果处理\t557\n15.5.1  网页异步提交\t557\n15.5.2  应用队列管理模块\t559\n15.5.3  任务队列\t560\n15.5.4  结果队列\t561\n15.5.5  异步请求处理流程\t562\n15.6  神经网络持续改进\t563\n15.6.1  应用遗传算法\t563\n15.6.2  重新训练\t564\n15.6.3  生成式对抗网络\t565\n后  记\t567\n参考文献\t568","pages":"584","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29760872.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29760872.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29760872.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30214615\/","id":"30214615","publisher":"电子工业出版社","isbn10":"7121337932","isbn13":"9787121337932","title":"深度学习算法实践（基于Theano和TensorFlow）","url":"https:\/\/api.douban.com\/v2\/book\/30214615","alt_title":"","author_intro":"","summary":"《深度学习算法实践（基于Theano和TensorFlow）》以深度学习算法入门为主要内容，通过系统介绍Python、NumPy、SciPy等科学计算库，深度学习主流算法，深度学习前沿研究，深度学习服务云平台构建四大主线，向读者系统地介绍了深度学习的主要内容和研究进展。《深度学习算法实践（基于Theano和TensorFlow）》介绍了Python、NumPy、SciPy的使用技巧，面向谷歌推出的开源深度学习框架TensorFlow，向读者展示了利用TensorFlow和Theano框架实现线性回归、逻辑回归、多层感知器、卷积神经网络、递归神经网络、长短时记忆网络、去噪自动编码机、堆叠自动编码机、受限玻尔兹曼机、深度信念网络等，并将这些技术用于MNIST手写数字识别任务。《深度学习算法实践（基于Theano和TensorFlow）》不仅讲述了深度学习算法本身，而且重点讲述了如何将这些深度学习算法包装成Web服务。《深度学习算法实践（基于Theano和TensorFlow）》旨在帮助广大工程技术人员快速掌握深度学习相关理论和实践，并将这些知识应用到实际工作中。\n《深度学习算法实践（基于Theano和TensorFlow）》可以作为各类深度学习培训班的教材，也可以作为全国高等工科院校“深度学习”课程的教材，还可以作为广大人工智能、深度学习领域工程技术人员的参考书。","series":{"id":"41172","title":"博文视点AI系列"},"price":"109"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["唐宏","陈麒","庄一嵘"],"pubdate":"2018-5","tags":[{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29748846.jpg","binding":"平装","translator":[],"catalog":"第 1 章 深度学习简介 ············································································ 1\n1.1 深度学习的发展 ·······································································1\n1.2 深度学习的应用及研究方向 ···················································3\n1.3 深度学习工具介绍和对比 ·······················································4\n1.3.1 Caffe·················································································4\n1.3.2 TensorFlow ······································································5\n1.3.3 Torch ················································································6\n1.4 小结 ···························································································7\n第 2 章 深度学习基本理论 ····································································9\n2.1 深度学习的基本概念 ·······························································9\n2.2 深度学习的训练过程 ·····························································13\n2.3 深度学习的常用模型和方法 ·················································14\n2.4 小结 ·························································································20\n第 3 章 深度学习环境搭建 ································································· 23\n3.1 Caffe 安装 ···············································································23\n3.1.1 安装 Caffe 的相关依赖项·············································24\n3.1.2 安装 NVIDIA 驱动 ·······················································24\n3.1.3 安装 CUDA ···································································27\n3.1.4 配置 cuDNN ··································································30\n3.1.5 源代码编译安装 OpenCV ············································32\n3.1.6 编译 Caffe，并配置 Python 接口 ································34\n3.2 Caffe 框架下的 MNIST 数字识别问题···································41\n3.3 TensorFlow 安装 ······································································42\n3.3.1 基于 pip 安装·································································42\n3.3.2 基于 Anaconda 安装 ······················································46\n3.3.3 基于源代码安装····························································51\n3.3.4 常见安装问题································································56\n3.4 TensorFlow 框架下的 CIFAR 图像识别问题·························59\n3.5 Torch 安装 ···············································································61\n3.5.1 无 CUDA 的 Torch 7 安装 ·············································61\n3.5.2 CUDA 的 Torch 7 安装 ··················································61\n3.6 Torch 框架下 neural-style 图像合成问题······························62\n3.7 小结 ·························································································74\n第 4 章 人脸识别 ················································································· 75\n4.1 人脸识别概述 ·········································································75\n4.2 人脸识别系统设计 ·································································76\n4.2.1 需求分析········································································76\n4.2.2 功能设计········································································77\n4.2.3 模块设计········································································78\n4.3 系统生产环境部署及验证 ·····················································81\n4.3.1 抽帧环境部署································································81\n4.3.2 抽帧功能验证································································82\n4.3.3 OpenFace 环境部署·······················································82\n4.3.4 OpenFace 环境验证·······················································84\n4.4 批量生产 ·················································································90\n4.5 小结 ·······················································································102\n第 5 章 车辆识别 ···············································································103\n5.1 概述 ·······················································································103\n5.2 系统设计 ···············································································104\n5.2.1 需求分析······································································104\n5.2.2 功能设计······································································104\n5.2.3 模块设计······································································105\n5.3 系统生产环境部署及验证 ···················································106\n5.3.1 生产环境部署······························································106\n5.3.2 项目部署······································································107\n5.3.3 环境验证······································································108\n5.4 批量生产 ···············································································109\n5.5 小结 ·······················································································117\n第 6 章 不良视频识别 ······································································· 119\n6.1 概述 ·······················································································119\n6.2 不良图片模型简介 ·······························································120\n6.3 系统设计 ···············································································122\n6.4 系统部署及系统测试验证 ···················································123\n6.5 批量生产 ···············································································125\n6.5.1 批量节目元数据信息检索与筛选······························125\n6.5.2 基于 FFmpeg 的 SDK 抽取视频 I 帧 ··························126\n6.5.3 基于肤色比例检测的快速筛查··································128\n6.5.4 基于 Caffe 框架的不良图片检测································128\n6.6 小结 ·······················································································129\n第 7 章 集群部署与运营维护 ··························································· 131\n7.1 认识 Docker···········································································131\n7.2 基于 Docker 的 TensorFlow 实验环境··································134\n7.3 运营维护 ···············································································137\n7.4 小结 ·······················································································138\n参考文献································································································139","pages":"120","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29748846.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29748846.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29748846.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30203255\/","id":"30203255","publisher":"人民邮电出版社","isbn10":"7115480109","isbn13":"9787115480101","title":"深度学习在动态媒体中的应用与实践","url":"https:\/\/api.douban.com\/v2\/book\/30203255","alt_title":"","author_intro":"唐宏\n中国电信股份有限公司广州研究院数据通信研究所所长、高级工程师，中国电子学会云计算专家委员会委员，中国电信股份有限公司科技委员会数据组副组长，中国SDN产业联盟需求场景与网络架构组组长。主要从事IP承载网、下一代互联网、网络新技术方面的研发与管理工作。","summary":"本书是一本深度学习的基础入门读物，对深度学习的基本理论进行了介绍，主要以Ubuntu系统为例搭建了三大主流框架——Caffe、TensorFlow、Torch，然后分别在3个框架下，通过3个实战项目掌握了框架的使用方法，并详细描述了生产流程，最后讲述了通过集群部署深度学习的项目以及如何进行运营维护的注意事项。","price":"59.00元"},{"rating":{"max":10,"numRaters":15,"average":"3.7","min":0},"subtitle":"","author":["唐进民"],"pubdate":"2018-6","tags":[{"count":7,"name":"深度学习","title":"深度学习"},{"count":5,"name":"python","title":"python"},{"count":4,"name":"PyTorch","title":"PyTorch"},{"count":3,"name":"计算机视觉","title":"计算机视觉"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"计算科学","title":"计算科学"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29776951.jpg","binding":"平装","translator":[],"catalog":"第1章  浅谈人工智能、神经网络和计算机视觉  1\n1.1  人工还是智能  1\n1.2  人工智能的三起两落  2\n1.2.1  两起两落  2\n1.2.2  卷土重来  3\n1.3  神经网络简史  5\n1.3.1  生物神经网络和人工神经网络  5\n1.3.2  M-P模型  6\n1.3.3  感知机的诞生  9\n1.3.4  你好，深度学习  10\n1.4  计算机视觉  11\n1.5  深度学习+  12\n1.5.1  图片分类  12\n1.5.2  图像的目标识别和语义分割  13\n1.5.3  自动驾驶  13\n1.5.4  图像风格迁移  14\n第2章  相关的数学知识  15\n2.1  矩阵运算入门  15\n2.1.1  标量、向量、矩阵和张量  15\n2.1.2  矩阵的转置  17\n2.1.3  矩阵的基本运算  18\n2.2  导数求解  22\n2.2.1  一阶导数的几何意义  23\n2.2.2  初等函数的求导公式  24\n2.2.3  初等函数的和、差、积、商求导  26\n2.2.4  复合函数的链式法则  27\n第3章  深度神经网络基础  29\n3.1  监督学习和无监督学习  29\n3.1.1  监督学习  30\n3.1.2  无监督学习  32\n3.1.3  小结  33\n3.2  欠拟合和过拟合  34\n3.2.1  欠拟合  34\n3.2.2  过拟合  35\n3.3  后向传播  36\n3.4  损失和优化  38\n3.4.1  损失函数  38\n3.4.2  优化函数  39\n3.5  激活函数  42\n3.5.1  Sigmoid  44\n3.5.2  tanh  45\n3.5.3  ReLU  46\n3.6  本地深度学习工作站  47\n3.6.1  GPU和CPU  47\n3.6.2  配置建议  49\n第4章  卷积神经网络  51\n4.1  卷积神经网络基础  51\n4.1.1  卷积层  51\n4.1.2  池化层  54\n4.1.3  全连接层  56\n4.2  LeNet模型  57\n4.3  AlexNet模型  59\n4.4  VGGNet模型  61\n4.5  GoogleNet  65\n4.6  ResNet  69\n第5章  Python基础  72\n5.1  Python简介  72\n5.2  Jupyter Notebook  73\n5.2.1  Anaconda的安装与使用  73\n5.2.2  环境管理  76\n5.2.3  环境包管理  77\n5.2.4  Jupyter Notebook的安装  79\n5.2.5  Jupyter Notebook的使用  80\n5.2.6  Jupyter Notebook常用的快捷键  86\n5.3  Python入门  88\n5.3.1  Python的基本语法  88\n5.3.2  Python变量  92\n5.3.3  常用的数据类型  94\n5.3.4  Python运算  99\n5.3.5  Python条件判断语句  107\n5.3.6  Python循环语句  109\n5.3.7  Python中的函数  113\n5.3.8  Python中的类  116\n5.4  Python中的NumPy  119\n5.4.1  NumPy的安装  119\n5.4.2  多维数组  119\n5.4.3  多维数组的基本操作  125\n5.5  Python中的Matplotlib  133\n5.5.1  Matplotlib的安装  133\n5.5.2  创建图  133\n第6章  PyTorch基础  142\n6.1  PyTorch中的Tensor  142\n6.1.1  Tensor的数据类型  143\n6.1.2  Tensor的运算  146\n6.1.3  搭建一个简易神经网络  153\n6.2  自动梯度  156\n6.2.1  torch.autograd和Variable  156\n6.2.2  自定义传播函数  159\n6.3  模型搭建和参数优化  162\n6.3.1  PyTorch之torch.nn  162\n6.3.2  PyTorch之torch.optim  167\n6.4  实战手写数字识别  169\n6.4.1  torch和torchvision  170\n6.4.2  PyTorch之torch.transforms  171\n6.4.3  数据预览和数据装载  173\n6.4.4  模型搭建和参数优化  174\n第7章  迁移学习  180\n7.1  迁移学习入门  180\n7.2  数据集处理  181\n7.2.1  验证数据集和测试数据集  182\n7.2.2  数据预览  182\n7.3  模型搭建和参数优化  185\n7.3.1  自定义VGGNet  185\n7.3.2  迁移VGG16  196\n7.3.3  迁移ResNet50  203\n7.4  小结  219\n第8章  图像风格迁移实战  220\n8.1  风格迁移入门  220\n8.2  PyTorch图像风格迁移实战  222\n8.2.1  图像的内容损失  222\n8.2.2  图像的风格损失  223\n8.2.3  模型搭建和参数优化  224\n8.2.4  训练新定义的卷积神经网络  226\n8.3  小结  232\n第9章  多模型融合  233\n9.1  多模型融合入门  233\n9.1.1  结果多数表决  234\n9.1.2  结果直接平均  236\n9.1.3  结果加权平均  237\n9.2  PyTorch之多模型融合实战  239\n9.3  小结  246\n第10章  循环神经网络  247\n10.1  循环神经网络入门  247\n10.2  PyTorch之循环神经网络实战  249\n10.3  小结  257\n第11章  自动编码器  258\n11.1  自动编码器入门  258\n11.2  PyTorch之自动编码实战  259\n11.2.1  通过线性变换实现自动编码器模型  260\n11.2.2  通过卷积变换实现自动编码器模型  267\n11.3  小结  273","ebook_url":"https:\/\/read.douban.com\/ebook\/53610479\/","pages":"284","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29776951.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29776951.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29776951.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30231525\/","id":"30231525","publisher":"电子工业出版社","isbn10":"7121341441","isbn13":"9787121341441","title":"深度学习之PyTorch实战计算机视觉","url":"https:\/\/api.douban.com\/v2\/book\/30231525","alt_title":"","author_intro":"唐进民，深入理解深度学习与计算机视觉知识体系，有扎实的Python、PyTorch和数学功底，长期活跃于GitHub、知乎等平台，并分享与深度学习相关的文章，具有一定的阅读量和人气。此前在某AI在线教育平台兼职机器学习入门Mentor，辅导新学员入门机器学习和深度学习。","summary":"计算机视觉、自然语言处理和语音识别是目前深度学习领域很热门的三大应用方向，《深度学习之PyTorch实战计算机视觉》旨在帮助零基础或基础较为薄弱的读者入门深度学习，达到能够独立使用深度学习知识处理计算机视觉问题的水平。通过阅读本书，读者将学到人工智能的基础概念及Python 编程技能，掌握PyTorch 的使用方法，学到深度学习相关的理论知识，比如卷积神经网络、循环神经网络、自动编码器，等等。在掌握深度学习理论和编程技能之后，读者还会学到如何基于PyTorch 深度学习框架实战计算机视觉。《深度学习之PyTorch实战计算机视觉》中的大量实例可让读者在循序渐进地学习的同时，不断地获得成就感。\n《深度学习之PyTorch实战计算机视觉》面向对深度学习技术感兴趣、但是相关基础知识较为薄弱或者零基础的读者。","ebook_price":"47.40","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["魏贞原"],"pubdate":"2018-5","tags":[{"count":1,"name":"科学","title":"科学"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"keras","title":"keras"},{"count":1,"name":"2019阅读","title":"2019阅读"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29776946.jpg","binding":"","translator":[],"catalog":"第一部分  初识\n1  初识深度学习\/2\n1.1  Python的深度学习\/2\n1.2  软件环境和基本要求\/3\n1.2.1  Python和SciPy\/3\n1.2.2  机器学习\/3\n1.2.3  深度学习\/4\n1.3  阅读本书的收获\/4\n1.4  本书说明\/4\n1.5  本书中的代码\/5\n2  深度学习生态圈\/6\n2.1  CNTK\/6\n2.1.1  安装CNTK\/7\n2.1.2  CNTK的简单例子\/8\n2.2  TensorFlow\/8\n2.2.1  TensorFlow介绍\/8\n2.2.2  安装TensorFlow\/9\n2.2.3  TensorFlow的简单例子\/9\n2.3  Keras\/10\n2.3.1  Keras简介\/11\n2.3.2  Keras安装\/11\n2.3.3  配置Keras的后端\/11\n2.3.4  使用Keras构建深度学习模型\/12\n2.4  云端GPUs计算\/13\n第二部分  多层感知器\n3  第一个多层感知器实例：印第安人糖尿病诊断\/16\n3.1  概述\/16\n3.2  Pima Indians数据集\/17\n3.3  导入数据\/18\n3.4  定义模型\/19\n3.5  编译模型\/20\n3.6  训练模型\/21\n3.7  评估模型\/21\n3.8  汇总代码\/22\n4  多层感知器速成\/24\n4.1  多层感知器\/24\n4.2  神经元\/25\n4.2.1  神经元权重\/25\n4.2.2  激活函数\/26\n4.3  神经网络\/27\n4.3.1  输入层（可视层）\/28\n4.3.2  隐藏层\/28\n4.3.3  输出层\/28\n4.4  训练神经网络\/29\n4.4.1  准备数据\/29\n4.4.2  随机梯度下降算法\/30\n4.4.3  权重更新\/30\n4.4.4  预测新数据\/31\n5  评估深度学习模型\/33\n5.1  深度学习模型和评估\/33\n5.2  自动评估\/34\n5.3  手动评估\/36\n5.3.1  手动分离数据集并评估\/36\n5.3.2  k折交叉验证\/37\n6  在Keras中使用Scikit-Learn\/40\n6.1  使用交叉验证评估模型\/41\n6.2  深度学习模型调参\/42\n7  多分类实例：鸢尾花分类\/49\n7.1  问题分析\/49\n7.2  导入数据\/50\n7.3  定义神经网络模型\/50\n7.4  评估模型\/52\n7.5  汇总代码\/52\n8  回归问题实例：波士顿房价预测\/54\n8.1  问题描述\/54\n8.2  构建基准模型\/55\n8.3  数据预处理\/57\n8.4  调参隐藏层和神经元\/58\n9  二分类实例：银行营销分类\/61\n9.1  问题描述\/61\n9.2  数据导入与预处理\/62\n9.3  构建基准模型\/64\n9.4  数据格式化\/66\n9.5  调参网络拓扑图\/66\n10  多层感知器进阶\/68\n10.1  JSON序列化模型\/68\n10.2  YAML序列化模型\/74\n10.3  模型增量更新\/78\n10.4  神经网络的检查点\/81\n10.4.1  检查点跟踪神经网络模型\/82\n10.4.2  自动保存最优模型\/84\n10.4.3  从检查点导入模型\/86\n10.5  模型训练过程可视化\/87\n11  Dropout与学习率衰减92\n11.1  神经网络中的Dropout\/92\n11.2  在Keras中使用Dropout\/93\n11.2.1  输入层使用Dropout\/94\n11.2.2  在隐藏层使用Dropout\/95\n11.2.3  Dropout的使用技巧\/97\n11.3  学习率衰减\/97\n11.3.1  学习率线性衰减\/98\n11.3.2  学习率指数衰减\/100\n11.3.3  学习率衰减的使用技巧\/103\n第三部分  卷积神经网络\n12  卷积神经网络速成\/106\n12.1  卷积层\/108\n12.1.1  滤波器\/108\n12.1.2  特征图\/109\n12.2  池化层\/109\n12.3  全连接层\/109\n12.4  卷积神经网络案例\/110\n13  手写数字识别\/112\n13.1  问题描述\/112\n13.2  导入数据\/113\n13.3  多层感知器模型\/114\n13.4  简单卷积神经网络\/117\n13.5  复杂卷积神经网络\/120\n14  Keras中的图像增强\/124\n14.1  Keras中的图像增强API\/124\n14.2  增强前的图像\/125\n14.3  特征标准化\/126\n14.4  ZCA白化\/128\n14.5  随机旋转、移动、剪切和反转图像\/129\n14.6  保存增强后的图像\/132\n15  图像识别实例：CIFAR-10分类\/134\n15.1  问题描述\/134\n15.2  导入数据\/135\n15.3  简单卷积神经网络\/136\n15.4  大型卷积神经网络\/140\n15.5  改进模型\/145\n16  情感分析实例：IMDB影评情感分析\/152\n16.1  问题描述\/152\n16.2  导入数据\/153\n16.3  词嵌入\/154\n16.4  多层感知器模型\/155\n16.5  卷积神经网络\/157\n第四部分  循环神经网络\n17  循环神经网络速成\/162\n17.1  处理序列问题的神经网络\/163\n17.2  循环神经网络\/164\n17.3  长短期记忆网络\/165\n18  多层感知器的时间序列预测：国际旅行人数预测\/167\n18.1  问题描述\/167\n18.2  导入数据\/168\n18.3  多层感知器\/169\n18.4  使用窗口方法的多层感知器\/172\n19  LSTM时间序列问题预测：国际旅行人数预测177\n19.1  LSTM处理回归问题\/177\n19.2  使用窗口方法的LSTM回归\/181\n19.3  使用时间步长的LSTM回归\/185\n19.4  LSTM的批次间记忆\/188\n19.5  堆叠LSTM的批次间记忆\/192\n20  序列分类：IMDB影评分类\/197\n20.1  问题描述\/197\n20.2  简单LSTM\/197\n20.3  使用Dropout改进过拟合\/199\n20.4  混合使用LSTM和CNN\/201\n21  多变量时间序列预测：PM2.5预报\/203\n21.1  问题描述\/203\n21.2  数据导入与准备\/204\n21.3  构建数据集\/206\n21.4  简单LSTM\/207\n22  文本生成实例：爱丽丝梦游仙境\/211\n22.1  问题描述\/211\n22.2  导入数据\/212\n22.3  分词与向量化\/212\n22.4  词云\/213\n22.5  简单LSTM\/215\n22.6  生成文本\/219\n附录A  深度学习的基本概念\/223\nA.1  神经网络基础\/223\nA.2  卷积神经网络\/227\nA.3  循环神经网络\/229","ebook_url":"https:\/\/read.douban.com\/ebook\/53522433\/","pages":"244","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29776946.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29776946.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29776946.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30231519\/","id":"30231519","publisher":"","isbn10":"7121341476","isbn13":"9787121341472","title":"深度学习：基于Keras的Python实践","url":"https:\/\/api.douban.com\/v2\/book\/30231519","alt_title":"","author_intro":"魏贞原，IBM 高级项目经理，数据分析团队Leader，主要负责银行客户的复杂系统开发。同时是IBMCIC量子计算COE团队的Python 领域专家（Subject Matter Expert），负责量子计算应用的探索工作，对机器学习和深度学习有深入的研究，精通于运用机器学习来解决数据科学的问题。并运营“知之Python”公众号，定期分享 Python 在机器学习和深度学习的实践知识。","summary":"《深度学习：基于Keras的Python实践》本书系统讲解了深度学习的基本知识，以及使用深度学习解决实际问题，详细介绍了如何构建及优化模型，并针对不同的问题给出不同的解决方案，通过不同的例子展示了在具体项目中的应用和实践经验，是一本非常好的深度学习的入门和实践书籍。\n《深度学习：基于Keras的Python实践》以实践为导向，使用Keras 作为编程框架，强调简单、快速地上手建立模型，解决实际项目问题。读者可以通过学习本书，迅速上手实践深度学习，并利用深度学习解决实际问题。\n《深度学习：基于Keras的Python实践》非常适合于项目经理，有意从事机器学习开发的程序员，以及高校在读相关专业的学生。","ebook_price":"35.40","series":{"id":"41172","title":"博文视点AI系列"},"price":"59"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["[印] 迪帕延 • 德夫"],"pubdate":"2018-5","tags":[{"count":3,"name":"大数据","title":"大数据"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"未资源","title":"未资源"},{"count":1,"name":"图灵","title":"图灵"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29765443.jpg","binding":"平装","translator":["范东来","赵运枫","封　强"],"catalog":"第1章　深度学习介绍　　1\n1.1　开始深度学习之旅　　5\n1.1.1　深度前馈网络　　6\n1.1.2　各种学习算法　　6\n1.2　深度学习的相关术语　　10\n1.3　深度学习——一场人工智能革命　　12\n1.4　深度学习网络的分类　　18\n1.4.1　深度生成或无监督模型　　19\n1.4.2　深度判别模型　　20\n1.5　小结　　22\n第2章　大规模数据的分布式深度学习　　23\n2.1　海量数据的深度学习　　24\n2.2　大数据深度学习面临的挑战　　27\n2.2.1　海量数据带来的挑战（第一个V）　　28\n2.2.2　数据多样性带来的挑战（第二个V）　　28\n2.2.3　数据快速处理带来的挑战（第三个V）　　29\n2.2.4　数据真实性带来的挑战（第四个V）　　29\n2.3　分布式深度学习和Hadoop　　29\n2.3.1　Map-Reduce　　31\n2.3.2　迭代Map-Reduce　　31\n2.3.3　YARN　　32\n2.3.4　分布式深度学习设计的重要特征　　32\n2.4　深度学习的开源分布式框架Deeplearning4j　　34\n2.4.1　Deeplearning4j的主要特性　　34\n2.4.2　Deeplearning4j功能总结　　35\n2.5　在Hadoop YARN上配置Deeplearning4j　　35\n2.5.1　熟悉Deeplearning4j　　36\n2.5.2　为进行分布式深度学习集成Hadoop YARN和Spark　　40\n2.5.3　Spark在Hadoop YARN上的内存分配规则　　40\n2.6　小结　　44\n第3章　卷积神经网络　　45\n3.1　卷积是什么　　46\n3.2　卷积神经网络的背景　　47\n3.3　卷积神经网络的基本层　　48\n3.3.1　卷积神经网络深度的重要性　　49\n3.3.2　卷积层　　49\n3.3.3　为卷积层选择超参数　　52\n3.3.4　ReLU层　　56\n3.3.5　池化层　　57\n3.3.6　全连接层　　58\n3.4　分布式深度卷积神经网络　　58\n3.4.1　最受欢迎的深度神经网络及其配置　　58\n3.4.2　训练时间——深度神经网络面临的主要挑战　　59\n3.4.3　将Hadoop应用于深度卷积神经网络　　59\n3.5　使用Deeplearning4j构建卷积层　　61\n3.5.1　加载数据　　61\n3.5.2　模型配置　　62\n3.5.3　训练与评估　　63\n3.6　小结　　64\n第4章　循环神经网络　　65\n4.1　循环网络与众不同的原因　　66\n4.2　循环神经网络　　67\n4.2.1　展开循环计算　　68\n4.2.2　循环神经网络的记忆　　69\n4.2.3　架构　　70\n4.3　随时间反向传播　　71\n4.4　长短期记忆　　73\n4.4.1　随时间深度反向传播的问题　　73\n4.4.2　长短期记忆　　73\n4.5　双向循环神经网络　　75\n4.5.1　循环神经网络的不足　　75\n4.5.2　解决方案　　76\n4.6　分布式深度循环神经网络　　77\n4.7　用Deeplearning4j训练循环神经网络　　77\n4.8　小结　　80\n第5章　受限玻尔兹曼机　　81\n5.1　基于能量的模型　　82\n5.2　玻尔兹曼机　　83\n5.2.1　玻尔兹曼机如何学习　　84\n5.2.2　玻尔兹曼机的不足　　85\n5.3　受限玻尔兹曼机　　85\n5.3.1　基础架构　　85\n5.3.2　受限玻尔兹曼机的工作原理　　86\n5.4　卷积受限玻尔兹曼机　　88\n5.5　深度信念网络　　90\n5.6　分布式深度信念网络　　91\n5.6.1　受限玻尔兹曼机的分布式训练　　91\n5.6.2　深度信念网络的分布式训练　　92\n5.7　用Deeplearning4j实现受限玻尔兹曼机和深度信念网络　　94\n5.7.1　受限玻尔兹曼机　　94\n5.7.2　深度信念网络　　95\n5.8　小结　　97\n第6章　自动编码器　　98\n6.1　自动编码器　　98\n6.2　稀疏自动编码器　　101\n6.2.1　稀疏编码　　101\n6.2.2　稀疏自动编码器　　102\n6.3　深度自动编码器　　104\n6.3.1　训练深度自动编码器　　104\n6.3.2　使用Deeplearning4j实现深度自动编码器　　107\n6.4　降噪自动编码器　　108\n6.4.1　降噪自动编码器的架构　　109\n6.4.2　堆叠式降噪自动编码器　　109\n6.4.3　使用Deeplearning4j实现堆叠式降噪自动编码器　　110\n6.5　自动编码器的应用　　112\n6.6　小结　　112\n第7章　用Hadoop玩转深度学习　　113\n7.1　Hadoop中的分布式视频解码　　114\n7.2　使用Hadoop进行大规模图像处理　　116\n7.3　使用Hadoop进行自然语言处理　　117\n7.3.1　Web爬虫　　118\n7.3.2　自然语言处理的关键词提取和模块　　118\n7.3.3　从页面评估相关关键词　　118\n7.4　小结　　119\n参考文献　　120","pages":"140","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29765443.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29765443.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29765443.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30219200\/","id":"30219200","publisher":"人民邮电出版社","isbn10":"7115482187","isbn13":"9787115482181","title":"Hadoop深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30219200","alt_title":"","author_intro":"Dipayan Dev\n多年大数据开发经验，擅长非关系型数据库技术和Hadoop框架，曾在IEEE和Springer的期刊上多次发表相关研究论文。现任印度PromptCloud公司软件工程师。","summary":"本书主要目标是处理很多深度学习应用的热点问题并向读者披露解决方案的细节。主要内容分为7章：第1章介绍深度学习基础知识，第2章介绍大规模数据的分布式深度学习，第3章介绍卷积神经网络，第4章介绍循环神经网络，第5章介绍受限玻尔兹曼机，第6章介绍自动编码器，第7章介绍如何用Hadoop玩转深度学习。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"39.00元"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["程天恒"],"pubdate":"2018-7","tags":[{"count":3,"name":"深度学习","title":"深度学习"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":1,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29797972.jpg","binding":"","translator":[],"catalog":"第1 章 深度学习简介  1\n1.1 初见  1\n1.2 机器学习  1\n1.3 神经网络  3\n1.4 深度学习介绍  7\n1.5 深度学习应用  8\n1.6 深度学习框架  12\n1.7 深度学习的未来  15\n第2 章 PaddlePaddle 简介  16\n2.1 安装PaddlePaddle  16\n2.2 测试PaddlePaddle  29\n第3 章 初探手写数字识别  31\n第4 章 PaddlePaddle 基本用法  44\n4.1 数据准备  44\n4.2 原始数据读取及预处理  44\n4.3 PaddlePaddle 训练数据  46\n4.4 模型配置  52\n4.5 激活函数  58\n4.6 优化方法  64\n4.7 损失函数  72\n4.8 均方损失函数  73\n4.9 交叉熵损失函数  73\n4.10 Huber 损失函数  74\n4.11 CRF 损失函数  74\n4.12 CTC 损失函数  75\n4.13 反向传播算法  75\n第5 章 卷积神经网络  78\n5.1 卷积神经网络  78\n5.2 实例学习  87\n5.3 拓展  112\n第6 章 循环神经网络  118\n6.1 RNN 简介  118\n6.2 双向循环神经网络  121\n6.3 循环神经网络使用场景  127\n6.4 预测sin 函数序列  129\n6.5 拓展  134\n第7 章 PaddlePaddle 实战  136\n7.1 自编码器  136\n7.2 PaddlePaddle 实现自编码器  137\n7.3 实战OCR 识别（一）  140\n7.4 实战OCR 识别（二）  150\n7.5 情感分析  164\n7.6 Seq2Seq 及其应用  172\n7.7 实现  178\n7.8 Image Caption  194\n第8 章 深度学习新星：生成对抗网络GAN  208\n8.1 生成对抗网络（GAN）  208\n8.2 GAN 的其他应用  213\n第9 章 强化学习与AlphaGo  216","pages":"232","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29797972.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29797972.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29797972.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30253255\/","id":"30253255","publisher":"","isbn10":"7121342472","isbn13":"9787121342479","title":"PaddlePaddle与深度学习应用实战","url":"https:\/\/api.douban.com\/v2\/book\/30253255","alt_title":"","author_intro":"程天恒，从PaddlePaddle框架开源开始使用至今，积累了丰富的使用经验。参加过亚洲超级计算竞赛、RDMA编程比赛等，并在这些比赛中获得过奖项，目前专注于深度学习科研工作，主要研究领域为计算机视觉、深度强化学习。","summary":"深度学习是目前人工智能研究中前沿、有效的一项技术，主要通过构建深度神经网络解决视觉、自然语言处理、语音识别等诸多领域的问题。百度在2016 年发布了国内首个开源深度学习框架PaddlePaddle，简化了深度学习算法的实现步骤，提供了灵活、易用的接口，同时支持分布式训练。\n《PaddlePaddle与深度学习应用实战》由简单的例子引入深度学习和PaddlePaddle 框架，介绍了PaddlePaddle 的安装、测试与基本使用，并结合PaddlePaddle 接口介绍深度学习的基础知识，包括常用的神经网络和算法。最后，通过一系列深度学习项目实例介绍PaddlePaddle 在各种场景和问题中的应用，让读者由浅至深地理解并运用深度学习解决实际问题。","series":{"id":"41172","title":"博文视点AI系列"},"price":"65"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"學歷貶值時代，MIT博士教你從大學就脫穎而出的75個成功法則","author":["Cal Newport"],"pubdate":"2018-4","tags":[{"count":1,"name":"個人管理","title":"個人管理"}],"origin_title":"How to Win at College: Surprising Secrets for Success from the Country's Top Students","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29863815.jpg","binding":"平装","translator":["朱崇旻"],"catalog":"前言\n法則01│不要讀完所有的指定閱讀\n法則02│建立週日儀式\n法則03│每學期至少退選或停修一門課\n法則04│分配到長期作業的當天就動工\n法則05│每天整理床鋪\n法則06│一年申請十項獎學金\n法則07│建立讀書系統\n法則08│結識教授\n法則09│當社團的社長\n法則10│每天讀報紙\n法則11│培養一項勝過所有人的技能\n法則12│避免每天列出代辦事項\n法則13│學會放棄\n法則14│永不睡午覺\n法則15│開學第一週就報名參加活動\n法則16│持續進行某項「大計畫」\n法則17│修藝術史與天文學\n法則18│一學期當一次調分障礙\n法則19│每堂課問一次問題\n法則20│儘快跳入研究圈\n法則21│為實驗室做出貢獻\n法則22│以五十分鐘為單位念書\n法則23│妥善安排空閒時間\n法則24│打扮體面去上課\n法則25│布置你的房間\n法則26│提前兩週開始念書\n法則27│課堂外寫作\n法則28│一天獨自用餐兩次\n法則29│找到你的世外桃源\n法則30│早早修習困難的課程\n法則31│不要在房間裡念書\n法則32│不要和一群人念書\n法則33│加入榮譽學生計畫\n法則34│每天做功課\n法則35│參加客座講座\n法則36│一週運動五天\n法則37│保持聯繫\n法則38│多修一門主修或輔修\n法則39│經常找導師談話\n法則40│不要找正常的工作\n法則41│一份報告用三天寫完\n法則42│不要睡太少，也別睡太飽\n法則43│考前放輕鬆\n法則44│最優先考慮朋友的事\n法則45│不要狂飲\n法則46│別管你同學的成績\n法則47│結識傑出的人才\n法則48│學習傾聽\n法則49│無論如何都不可以熬夜\n法則50│笑口常開\n法則51│選用高品質筆記本\n法則52│記錄每天的工作進度\n法則53│尋找快樂\n法則54│讓野心膨脹\n法則55│參與系上的事務\n法則56│照顧你的成績，但無視你的GPA\n法則57│永遠別翹課\n法則58│自訂工作死線\n法則59│注意飲食健康\n法則60│默默服務\n法則61│寫出普立茲獎等級的作品\n法則62│參加政治集會\n法則63│最大限度利用暑假\n法則64│制定目標，探索新方向\n法則65│課間不要休息\n法則66│不要建立關係網\n法則67│發表專欄文章\n法則68│使用文件櫃\n法則69│找一個秘密讀書空間\n法則70│用「提問記憶法」念書\n法則71│清空收件匣\n法則72│睡前放輕鬆\n法則73│起步快，收尾慢\n法則74│出國交換一學期\n法則75│別留下任何遺憾\n致謝","pages":"224","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29863815.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29863815.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29863815.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30320497\/","id":"30320497","publisher":"時報出版","isbn10":"9571373648","isbn13":"9789571373645","title":"深度學習力","url":"https:\/\/api.douban.com\/v2\/book\/30320497","alt_title":"How to Win at College: Surprising Secrets for Success from the Country's Top Students","author_intro":"卡爾．紐波特 Cal Newport\n1982年出生。2004年畢業於達特茅斯學院，2009年獲得麻省理工學院博士學位。喬治城大學電腦科學系副教授，專精於分散式演算法。\n除了以教授身分研究這個數位時代的理論基礎，他也寫作有關這些技術對我們的工作世界有何影響的文章。他經營的網站「學習客：成功模式解碼」（Study Hacks: Decoding Patterns of Success），提供學習、工作與人生成功的建言，每個月吸引超過10萬名訪客。他在網站上提出「深度工作力」一詞與相關概念，立即獲得熱烈迴響與轉載。《Deep work深度工作力》一出版立即成為《華爾街日報》暢銷書，並獲得《紐約時報》、《經濟學人》和《衛報》的好評。\n另著有《好到沒有人能輕忽你》（So Good They Can’t Ignore You；入選《企業》、《環球郵報》、800-CEO-Read最佳商業書），以及提供非傳統建議給學生的書，包括本書《深度學習力》和《如何成為高中的超級明星》（How to Be a High School Superstar）、《如何當全A學生》（How to Become a Straight-A Student）。他也獲邀在哈佛、普林斯頓、麻省理工學院、達特茅斯、米德爾伯里、喬治城和杜克等美國最頂尖的大學演講這些主題。\n譯者 朱崇旻\n\n曾在美國居住九年，以閱讀為樂，現於台北讀生化科技。喜歡翻譯時推敲琢磨的過程，並認為無論是什麼題材的書，譯者都應該忠實表達出作者的立場。興趣包含寫小說、武術、室內布置和冬眠。","summary":"學歷貶值時代，上大學絕對不只是為了那張畢業證書！\n\n如何利用大學4年培養真正的實力？\n如何在踏出校園之前就替未來做好準備？\n更重要的是……如何在培養競爭力的同時，又能享受充實而美好的校園生活？\n\n可以的！只要用對方法！\n────唯有「深度學習力」，能幫你打下未來競爭力的基礎！\n\n本書作者────卡爾．紐波特Cal Newport\n22歲以最優等第畢業於達特茅斯學院\n27歲取得麻省理工學院博士學位\n34歲成為喬治城大學副教授，出版暢銷書《Deep Work深度工作力》\n\n除了自身擁有極具效率的時間管理方法與極富成效的學習成果，\n卡爾．紐波特也採訪了哈佛大學、史丹佛大學等名校裡最優秀的學生們，\n追問他們有關時間管理、讀書，以及平衡社交與用功的方法。\n\n．該怎麼準備考試和報告？\n．該參加哪些課外活動？\n．該怎麼和教授互動？\n．什麼才是刺激思維又維持樂觀的好方法？\n．該如何平衡愉快的社交生活與雄心勃勃的日程表？\n．怎麼樣才能量身訂製完美的活動，符合你的能力、興趣與喜好？\n\n這些是每個學生都該提出的重要問題，而答案就在本書裡。\n本書列舉了優秀大學生必備的75個成功法則，\n你不必是天才，也不需要超強記憶力，\n就能給自己更好的未來，同時還能享有健康的睡眠與愉快的社交生活。\n\n在擁有足夠智慧與滿腔熱血的年紀，不該浪費你的才華與熱情。\n善用校園的軟硬體資源，結識能給自己啟發與靈感的教授、同學，以豐沛的資源與支援為後盾，\n你可以更有野心、更有計畫地，讓大學4年不光是苦讀或玩樂，更是前途的跳板！\n\n大學時期培養的態度與習慣，將是一生受用無窮的寶藏——\n《深度學習力》就是引領你脫穎而出的一把鑰匙。\n\n\n★ 哈佛大學、史丹佛大學……那些最優秀的學生們這麼做 ★\n\n．不要讀完所有的指定閱讀！\n．每學期至少退選或停修一門課！\n．避免每天列出待辦事項！\n．不要和一群人一起念書！\n．不要找正常的打工！\n．一天獨自用餐兩次！\n．學會放棄！","price":"TWD300"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"通过C语言模拟","author":[],"pubdate":"2018-1","tags":[{"count":1,"name":"自然语言处理","title":"自然语言处理"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"C++","title":"C++"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30314849\/","id":"30314849","publisher":"","isbn10":"7111586573","isbn13":"9787111586579","title":"自然语言处理与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30314849","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["张平"],"pubdate":"2018-10","tags":[{"count":5,"name":"神经网络","title":"神经网络"},{"count":5,"name":"深度学习","title":"深度学习"},{"count":3,"name":"tensorflow","title":"tensorflow"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29877486.jpg","binding":"平装","translator":[],"catalog":"1 深度学习及TensorFlow 简介1\n1.1 深度学习  1\n1.2 TensorFlow 简介及安装  2\n2 基本的数据结构及运算6\n2.1 张量   6\n2.1.1 张量的定义   6\n2.1.2 Tensor 与Numpy 的ndarray 转换  9\n2.1.3 张量的尺寸   10\n2.1.4 图像转换为张量  13\n2.2 随机数   14\n2.2.1 均匀（平均）分布随机数   14\n2.2.2 正态（高斯）分布随机数   15\n2.3 单个张量的运算  17\n2.3.1 改变张量的数据类型   17\n2.3.2 访问张量中某一个区域的值   19\n2.3.3 转置   22\n2.3.4 改变形状  26\n2.3.5 归约运算：求和、平均值、最大（小）值   29\n2.3.6 最大（小）值的位置索引   34\n2.4 多个张量之间的运算   35\n2.4.1 基本运算：加、减、乘、除   35\n2.4.2 乘法   41\n2.4.3 张量的连接   42\n2.4.4 张量的堆叠   44\n2.4.5 张量的对比   48\n2.5 占位符   49\n2.6 Variable 对象  50\n3 梯度及梯度下降法52\n3.1 梯度   52\n3.2 导数计算的链式法则   53\n3.2.1 多个函数和的导数   54\n3.2.2 复合函数的导数  54\n3.2.3 单变量函数的驻点、极值点、鞍点   55\n3.2.4 多变量函数的驻点、极值点、鞍点   57\n3.2.5 函数的泰勒级数展开   60\n3.2.6 梯度下降法   63\n3.3 梯度下降法   73\n3.3.1 Adagrad 法   73\n3.3.2 Momentum 法   75\n3.3.3 NAG 法   77\n3.3.4 RMSprop 法  78\n3.3.5 具备动量的RMSprop 法   80\n3.3.6 Adadelta 法   81\n3.3.7 Adam 法  82\n3.3.8 Batch 梯度下降  84\n3.3.9 随机梯度下降   85\n3.3.10 mini-Batch 梯度下降  86\n3.4 参考文献  86\n4 回归分析88\n4.1 线性回归分析   88\n4.1.1 一元线性回归   88\n4.1.2 保存和加载回归模型   91\n4.1.3 多元线性回归   95\n4.2 非线性回归分析  99\n5 全连接神经网络102\n5.1 基本概念  102\n5.2 计算步骤  104\n5.3 神经网络的矩阵表达   107\n5.4 激活函数  112\n5.4.1 sigmoid 激活函数   112\n5.4.2 tanh 激活函数   113\n5.4.3 ReLU 激活函数  114\n5.4.4 leaky relu 激活函数  115\n5.4.5 elu 激活函数  118\n5.4.6 crelu 激活函数   119\n5.4.7 selu 激活函数   120\n5.4.8 relu6 激活函数   121\n5.4.9 softplus 激活函数   121\n5.4.10 softsign 激活函数   122\n5.5 参考文献  123\n6 神经网络处理分类问题125\n6.1 TFRecord 文件   125\n6.1.1 将ndarray 写入TFRecord 文件  125\n6.1.2 从TFRecord 解析数据  128\n6.2 建立分类问题的数学模型   134\n6.2.1 数据类别（标签）  134\n6.2.2 图像与TFRecrder  135\n6.2.3 建立模型  140\n6.3 损失函数与训练模型   143\n6.3.1 sigmoid 损失函数   143\n6.3.2 softmax 损失函数   144\n6.3.3 训练和评估模型  148\n6.4 全连接神经网络的梯度反向传播   151\n6.4.1 数学原理及示例  151\n6.4.2 梯度消失  166\n7 一维离散卷积168\n7.1 一维离散卷积的计算原理   168\n7.1.1 full 卷积  169\n7.1.2 valid 卷积  170\n7.1.3 same 卷积   170\n7.1.4 full、same、valid 卷积的关系  171\n7.2 一维卷积定理   174\n7.2.1 一维离散傅里叶变换   174\n7.2.2 卷积定理  177\n7.3 具备深度的一维离散卷积   182\n7.3.1 具备深度的张量与卷积核的卷积   182\n7.3.2 具备深度的张量分别与多个卷积核的卷积   183\n7.3.3 多个具备深度的张量分别与多个卷积核的卷积   185\n8 二维离散卷积187\n8.1 二维离散卷积的计算原理   187\n8.1.1 full 卷积  187\n8.1.2 same 卷积   189\n8.1.3 valid 卷积  191\n8.1.4 full、same、valid 卷积的关系  192\n8.1.5 卷积结果的输出尺寸   193\n8.2 离散卷积的性质  194\n8.2.1 可分离的卷积核  194\n8.2.2 full 和same 卷积的性质  195\n8.2.3 快速计算卷积   197\n8.3 二维卷积定理   198\n8.3.1 二维离散傅里叶变换   198\n8.3.2 二维与一维傅里叶变换的关系  201\n8.3.3 卷积定理  203\n8.3.4 利用卷积定理快速计算卷积   203\n8.4 多深度的离散卷积   205\n8.4.1 基本的多深度卷积   205\n8.4.2 一个张量与多个卷积核的卷积  207\n8.4.3 多个张量分别与多个卷积核的卷积   208\n8.4.4 在每一深度上分别卷积  211\n8.4.5 单个张量与多个卷积核在深度上分别卷积   212\n8.4.6 分离卷积  214\n9 池化操作218\n9.1 same 池化  218\n9.1.1 same 最大值池化   218\n9.1.2 多深度张量的same 池化   221\n9.1.3 多个三维张量的same 最大值池化  223\n9.1.4 same 平均值池化   224\n9.2 valid 池化  226\n9.2.1 多深度张量的vaild 池化   228\n9.2.2 多个三维张量的valid 池化  229\n10 卷积神经网络231\n10.1 浅层卷积神经网络   231\n10.2 LeNet   238\n10.3 AlexNet  244\n10.3.1 AlexNet 网络结构详解  244\n10.3.2 dropout 及其梯度下降   247\n10.4 VGGNet  256\n10.5 GoogleNet   264\n10.5.1 网中网结构   264\n10.5.2 Batch Normalization   269\n10.5.3 BN 与卷积运算的关系  273\n10.5.4 指数移动平均   275\n10.5.5 带有BN 操作的卷积神经网络  276\n10.6 ResNet   281\n10.7 参考文献  284\n11 卷积的梯度反向传播286\n11.1 valid 卷积的梯度  286\n11.1.1 已知卷积核，对未知张量求导  286\n11.1.2 已知输入张量，对未知卷积核求导   290\n11.2 same 卷积的梯度  294\n11.2.1 已知卷积核，对输入张量求导  294\n11.2.2 已知输入张量，对未知卷积核求导   298\n12 池化操作的梯度303\n12.1 平均值池化的梯度   303\n12.2 最大值池化的梯度   306\n13 BN 的梯度反向传播311\n13.1 BN 操作与卷积的关系   311\n13.2 示例详解  314\n14 TensorFlow 搭建神经网络的主要函数324","pages":"336","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29877486.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29877486.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29877486.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30333961\/","id":"30333961","publisher":"电子工业出版社","isbn10":"7121347458","isbn13":"9787121347450","title":"图解深度学习与神经网络：从张量到TensorFlow实现","url":"https:\/\/api.douban.com\/v2\/book\/30333961","alt_title":"","author_intro":"张平，数学与应用数学专业，数学功底深厚，算法工程师。主要从事图像算法研究和产品的应用开发。此外，还从事有关深度学习、机器学习、数据挖掘算法的应用研发工作。","summary":"《图解深度学习与神经网络：从张量到TensorFlow实现》是以TensorFlow 为工具介绍神经网络和深度学习的入门书，内容循序渐进，以简单示例和图例的形式，展示神经网络和深度学习背后的数学基础原理，帮助读者更好地理解复杂抽象的公式。同时，采用手动计算和程序代码这两种方式讲解示例，可以更好地帮助读者理解TensorFlow 的常用函数接口，为读者掌握利用TensorFlow 搭建人工智能项目打下良好的基础。\n《图解深度学习与神经网络：从张量到TensorFlow实现》适合神经网络、深度学习、TensorFlow 的入门者阅读。","price":"79.00元"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"人工智能时代，以学生为中心的智慧教学","author":["[美]乔纳森·伯格曼"],"pubdate":"2018-8","tags":[{"count":3,"name":"翻转课堂","title":"翻转课堂"},{"count":1,"name":"家庭作业","title":"家庭作业"},{"count":1,"name":"人工智能教学","title":"人工智能教学"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s30000927.jpg","binding":"","translator":["杨洋\/译"],"catalog":"第 1 章 翻转课堂与深度学习解决方案\n有效解决翻转课堂存在的问题\n翻转学习和布卢姆教育目标分类法\n深度学习\n翻转作业如何打破陈规\n倾听学生的心声\n第 2 章 优质翻转家庭作业\n布置有效的翻转家庭作业\n翻转家庭作业如何改变传统模式\n第 3 章 教师的翻转策略\n让学生主动学习\n不要加重学生负担\n录制互动视频\n创造VS.策划\n教师和家长共同参与\n将学习延伸到家庭\n让课堂时间更有意义\n第 4 章 评估与评分\n让学生负起责任\n启发互动性的技术工具\n先行组织者材料\n填写汇总表\n让学生做纸质笔记还是电子笔记\n用翻转视频问题检查学生对学习内容的理解\n获取每个学生的学习需求\n让学生主导课堂\n让学生提出问题以激发他们的好奇心\n评分方式\n学生如何评估你的翻转课堂\n第 5 章 适合学校、管理层和父母的策略\n认真制定一种新的作业策略\n实践翻转学习的方法\n为学生提供帮助\n支持勇于创新的教师\n翻转会议\n与学生父母交流\n辅助家长去帮助他们的孩子\n第 6 章 翻转课堂与深度学习改变了学校的教育模式","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s30000927.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s30000927.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s30000927.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30455585\/","id":"30455585","publisher":"中国青年出版社","isbn10":"7515351586","isbn13":"9787515351582","title":"翻转课堂与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30455585","alt_title":"","author_intro":"乔纳森 伯格曼：\n数学和科学卓越教学总统奖（该奖项是美国数学和科学教学领域杰出表现的最高认证）得主，翻转课堂先驱，翻转学习创始人，有着25年之久的高中教学经验。他与亚伦?萨姆斯对翻转课堂长达十余年的实践引起了全世界的关注，二人合著的《翻转课堂与慕课教学：一场正在到来的教育变革》和《翻转学习》在全球掀起了“翻转课堂”的变革热潮。","summary":"继畅销书《翻转课堂与慕课教学》后，被誉为翻转课堂先驱的乔纳森 伯格曼在力作《翻转课堂与深度学习》中总结了世界各地翻转课堂所遇到的问题与挑战，揭秘了如何利用翻转课堂回归学习本质，帮助学生深度学习的途径与方法。\n本书阐述了深度学习的挑战、可能性以及教师的成功案例，为教师展示了如何利用翻转视频、学生的翻转作业、教师的翻转策略等进行深度学习。不仅如此，还给教师提供了关于翻转课堂的高效策略和操作方法。","price":"29.8"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"用Python创建神经网络","author":[],"pubdate":"2019-2","tags":[{"count":1,"name":"自然语言处理","title":"自然语言处理"},{"count":1,"name":"NLP","title":"NLP"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"译者序\n前言\n致谢\n关于作者\n关于技术审校人员\n第1章 自然语言处理和深度学习概述 1\n1.1 Python包 2\n1.1.1 NumPy 2\n1.1.2 Pandas 6\n1.1.3 SciPy 9\n1.2 自然语言处理简介 11\n1.2.1 什么是自然语言处理 11\n1.2.2 如何理解人类的语言 11\n1.2.3 自然语言处理的难度是什么 11\n1.2.4 我们想通过自然语言处理获得什么 13\n1.2.5 语言处理中的常用术语 13\n1.3 自然语言处理库 14\n1.3.1 NLTK 14\n1.3.2 TextBlob 15\n1.3.3 SpaCy 17\n1.3.4 Gensim 19\n1.3.5 Pattern 20\n1.3.6 Stanford CoreNLP 21\n1.4 NLP入门 21\n1.4.1 使用正则表达式进行文本搜索 21\n1.4.2 将文本转换为列表 21\n1.4.3 文本预处理 22\n1.4.4 从网页中获取文本 22\n1.4.5 移除停止词 23\n1.4.6 计数向量化 23\n1.4.7 TF-IDF分数 24\n1.4.8 文本分类器 25\n1.5 深度学习简介 25\n1.6 什么是神经网络 27\n1.7 神经网络的基本结构 29\n1.8 神经网络的类型 32\n1.8.1 前馈神经网络 33\n1.8.2 卷积神经网络 33\n1.8.3 循环神经网络 33\n1.8.4 编码器-解码器网络 34\n1.8.5 递归神经网络 35\n1.9 多层感知器 35\n1.10 随机梯度下降 37\n1.11 反向传播 40\n1.12 深度学习库 42\n1.12.1 Theano 42\n1.12.2 Theano安装 43\n1.12.3 Theano示例 44\n1.12.4 TensorFlow 45\n1.12.5 数据流图 46\n1.12.6 TensorFlow安装 47\n1.12.7 TensorFlow示例 47\n1.12.8 Keras 49\n1.13 下一步 52\n第2章 词向量表示 53\n2.1 词嵌入简介 53\n2.2 word2vec 56\n2.2.1 skip-gram模型 58\n2.2.2 模型成分：架构 58\n2.2.3 模型成分：隐藏层 58\n2.2.4 模型成分：输出层 60\n2.2.5 CBOW模型 61\n2.3 频繁词二次采样 61\n2.4 word2vec代码 64\n2.5 skip-gram代码 67\n2.6 CBOW代码 75\n2.7 下一步 83\n第3章 展开循环神经网络 85\n3.1 循环神经网络 86\n3.1.1 什么是循环 86\n3.1.2 前馈神经网络和循环神经网络之间的差异 87\n3.1.3 RNN基础 88\n3.1.4 自然语言处理和RNN 91\n3.1.5 RNN的机制 93\n3.1.6 训练RNN 96\n3.1.7 RNN中隐藏状态的元意义 98\n3.1.8 调整RNN 99\n3.1.9 LSTM网络 99\n3.1.10 序列到序列模型 105\n3.1.11 高级seq2seq模型 109\n3.1.12 序列到序列用例 113\n3.2 下一步 122\n第4章 开发聊天机器人 123\n4.1 聊天机器人简介 123\n4.1.1 聊天机器人的起源 124\n4.1.2 聊天机器人如何工作 125\n4.1.3 为什么聊天机器人拥有如此大的商机 125\n4.1.4 开发聊天机器人听起来令人生畏 126\n4.2 对话型机器人 127\n4.3 聊天机器人：自动文本生成 141\n4.4 下一步 170\n第5章 实现研究论文：情感分类 171\n5.1 基于自注意力机制的句子嵌入 172\n5.1.1 提出的方法 173\n5.1.2 可视化 178\n5.1.3 研究发现 181\n5.2 实现情感分类 181\n5.3 情感分类代码 182\n5.4 模型结果 191\n5.5 可提升空间 196\n5.6 下一步 196","pages":"212","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30487588\/","id":"30487588","publisher":"","isbn10":"7111617193","isbn13":"9787111617198","title":"面向自然语言处理的深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30487588","alt_title":"","author_intro":"","summary":"全书分为5章，通过介绍完整的神经网络模型(包括循环神经网络、长短期记忆网络以及序列到序列模型)实例，向读者阐释用于自然语言处理(NLP)的深度学习概念。前三章介绍NLP和深度学习的基础知识、词向量表示和高级算法，后两章集中介绍实现过程，并使用Python工具TensorFlow和Keras来处理复杂的架构，比如RNN、LSTM和seq2seq。本书遵循循序渐进的方法，最后集合全部知识构建一个问答式聊天机器人系统。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30503811\/","id":"30503811","publisher":"","isbn10":"7111610431","isbn13":"9787111610434","title":"深度学习实践：基于Caffe的解析","url":"https:\/\/api.douban.com\/v2\/book\/30503811","alt_title":"","author_intro":"","summary":"","price":"56.90"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30497758\/","id":"30497758","publisher":"","isbn10":"7111604377","isbn13":"9787111604372","title":"深度学习：R语言实践指南","url":"https:\/\/api.douban.com\/v2\/book\/30497758","alt_title":"","author_intro":"","summary":"","price":"48.70"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30498819\/","id":"30498819","publisher":"","isbn10":"7030594266","isbn13":"9787030594266","title":"正则化深度学习及其在机器人环境感知中的应用","url":"https:\/\/api.douban.com\/v2\/book\/30498819","alt_title":"","author_intro":"","summary":"","price":"57.90"},{"rating":{"max":10,"numRaters":19,"average":"6.0","min":0},"subtitle":"","author":["黄昕","赵伟","王本友","吕慧伟","杨敏"],"pubdate":"2019-1-1","tags":[{"count":21,"name":"推荐系统","title":"推荐系统"},{"count":11,"name":"深度学习","title":"深度学习"},{"count":8,"name":"机器学习","title":"机器学习"},{"count":7,"name":"计算机","title":"计算机"},{"count":5,"name":"编程","title":"编程"},{"count":1,"name":"计算机技术","title":"计算机技术"},{"count":1,"name":"混口饭吃","title":"混口饭吃"},{"count":1,"name":"中国","title":"中国"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29965784.jpg","binding":"平装","translator":[],"catalog":"第1 章什么是推荐系统1\n1.1 推荐系统的概念.1\n1.1.1 推荐系统的基本概念1\n1.1.2 深度学习与推荐系统4\n第2 章深度神经网络.7\n2.1 什么是深度学习.7\n2.1.1 深度学习的三次兴起7\n2.1.2 深度学习的优势9\n2.2 神经网络基础11\n2.2.1 神经元11\n2.2.2 神经网络.12\n2.2.3 反向传播.13\n2.2.4 优化算法.14\n2.3 卷积网络基础17\n2.3.1 卷积层17\n2.3.2 池化层19\n2.3.3 常见的网络结构19\n2.4 循环网络基础21\n2.4.1 时序反向传播算法22\n2.4.2 长短时记忆网络24\n2.5 生成对抗基础25\n2.5.1 对抗博弈.26\n2.5.2 理论推导.27\n2.5.3 常见的生成对抗网络29\niv j 推荐系统与深度学习\n第3 章TensorFlow 平台31\n3.1 什么是TensorFlow 31\n3.2 TensorFlow 安装指南.33\n3.2.1 Windows 环境安装.33\n3.2.2 Linux 环境安装.34\n3.3 TensorFlow 基础.36\n3.3.1 数据流图.36\n3.3.2 会话37\n3.3.3 图可视化.37\n3.3.4 变量37\n3.3.5 占位符38\n3.3.6 优化器38\n3.3.7 一个简单的例子38\n3.4 其他深度学习平台39\n第4 章推荐系统的基础算法42\n4.1 基于内容的推荐算法.42\n4.1.1 基于内容的推荐算法基本流程42\n4.1.2 基于内容推荐的特征提取.45\n4.2 基于协同的推荐算法.47\n4.2.1 基于物品的协同算法49\n4.2.2 基于用户的协同算法57\n4.2.3 基于用户协同和基于物品协同的区别59\n4.2.4 基于矩阵分解的推荐方法.61\n4.2.5 基于稀疏自编码的推荐方法.71\n4.3 基于社交网络的推荐算法80\n4.3.1 基于用户的推荐在社交网络中的应用81\n4.3.2 node2vec 技术在社交网络推荐中的应用85\n4.4 推荐系统的冷启动问题94\n4.4.1 如何解决推荐系统冷启动问题94\n4.4.2 深度学习技术在物品冷启动上的应用101\n目录j v\n第5 章混合推荐系统119\n5.1 什么是混合推荐系统.119\n5.1.1 混合推荐系统的意义120\n5.1.2 混合推荐系统的算法分类.122\n5.2 推荐系统特征处理方法125\n5.2.1 特征处理方法126\n5.2.2 特征选择方法134\n5.3 常见的预测模型141\n5.3.1 基于逻辑回归的模型141\n5.3.2 基于支持向量机的模型.144\n5.3.3 基于梯度提升树的模型.148\n5.4 排序学习150\n5.4.1 基于排序的指标来优化.150\n5.4.2 L2R 算法的三种情形.152\n第6 章基于深度学习的推荐模型156\n6.1 基于DNN 的推荐算法156\n6.2 基于DeepFM 的推荐算法163\n6.3 基于矩阵分解和图像特征的推荐算法171\n6.4 基于循环网络的推荐算法.174\n6.5 基于生成对抗网络的推荐算法.176\n6.5.1 IRGAN 的代码实现.179\n第7 章推荐系统架构设计.183\n7.1 推荐系统基本模型183\n7.2 推荐系统常见架构185\n7.2.1 基于离线训练的推荐系统架构设计185\n7.2.2 面向深度学习的推荐系统架构设计191\n7.2.3 基于在线训练的推荐系统架构设计194\n7.2.4 面向内容的推荐系统架构设计197\n7.3 推荐系统常用组件199\n7.3.1 数据上报常用组件199\nvi j 推荐系统与深度学习\n7.3.2 离线存储常用组件200\n7.3.3 离线计算常用组件200\n7.3.4 在线存储常用组件201\n7.3.5 模型服务常用组件201\n7.3.6 实时计算常用组件201\n7.4 推荐系统常见问题201\n7.4.1 实时性.201\n7.4.2 多样性.202\n7.4.3 曝光打击和不良内容过滤.202\n7.4.4 评估测试.202\n后记.203\n图1.1 淘宝猜你喜欢栏目2\n图1.2 百度指数.4\n图1.3 歌曲词嵌入模型空间向量.6\n图2.1 神经网络的三次兴起8\n图2.2 不同层数的神经网络拟合分界面的能力.10\n图2.3 不同层数的神经网络表示能力10\n图2.4 神经网络的基本结构11\n图2.5 感知器算法12\n图2.6 三层全连接神经网络13\n图2.7 动量对比.16\n图2.8 卷积运算.18\n图2.9 池化层19\n图2.10 LeNet 卷积结构.20\n图2.11 Alex-Net 卷积结构20\n图2.12 RNN 21\n图2.13 LSTM 在t 时刻的内部结构24\n图2.14 GAN 网络25\n图3.1 TensorFlow 安装截图34\n图3.2 TensorBoard 计算37\n图4.1 腾讯视频APP 推荐页面.44\n图4.2 截取自当当网.49\n图4.3 截取自QQ 音乐APP.49\n图4.4 用户购买物品记录50\n图4.5 同时被购买次数矩阵C 51\n图4.6 相似度计算结果1 52\n图4.7 相似度计算结果2 54\nviii j 推荐系统与深度学习\n图4.8 相似度计算结果3 55\n图4.9 截取自当当网.57\n图4.10 物品的倒排索引57\n图4.11 用户评分矩阵.63\n图4.12 Sigma 值64\n图4.13 NewData 值65\n图4.14 Mydata 值65\n图4.15 自编码神经网络模型72\n图4.16 稀疏自编码第一个网络.73\n图4.17 稀疏自编码第二个网络.74\n图4.18 稀疏自编码第三个网络.75\n图4.19 将三个网络组合起来75\n图4.20 社交网络关系图示例81\n图4.21 融入用户关系和物品关系82\n图4.22 社交网络关系图示例86\n图4.23 社交网络关系图示例86\n图4.24 CBOW 和Skip-Gram 示例.88\n图4.25 Skip-Gram 网络结构89\n图4.26 CBOW 网络结构91\n图4.27 word analogy 示例93\n图4.28 某网站登录页面95\n图4.29 QQ 互联开放注册平台1 96\n图4.30 QQ 互联开放注册平台2 97\n图4.31 QQ 互联应用管理页面1 97\n图4.32 QQ 互联应用管理页面2 97\n图4.33 QQ 互联QQ 登录功能获取97\n图4.34 QQ 音乐APP 中的偏好选择98\n图4.35 (a) 为每部电影被打分的分布，(b) 为每个用户打分的分布100\n图4.36 (a) 为每部电影平均分分布，(b) 为每个用户平均分分布.100\n图4.37 基于专家数据的CF 与基于用户数据CF 比较.101\n图目录j ix\n图4.38 音乐频谱示例102\n图4.39 4 个流派的频谱图示例103\n图4.40 CNN 音频分类结构.103\n图4.41 CNN+LSTM 组合音频分类模型.104\n图4.42 分类预测结果的混淆矩阵104\n图4.43 模型倒数第二层128 维向量降维可视化104\n图4.44 微软how-old.net 107\n图4.45 SCUT-FBP 数据集示例图108\n图4.46 脸部截取后的数据集示例图.108\n图4.47 CNN 层数过多，误差反而较大113\n图4.48 残差网络的基本结构113\n图4.49 残差网络完整结构.114\n图5.1 NetFlix 的实时推荐系统的架构图120\n图5.2 整体式混合推荐系统125\n图5.3 并行式混合推荐系统125\n图5.4 流水线式混合推荐系统.125\n图5.5 MDLP 特征离散化130\n图5.6 ChiMerge 特征离散化.131\n图5.7 层次化时间按序列特征.133\n图5.8 Learn to rank 的局限153\n图6.1 Wide & Deep 模型结构157\n图6.2 推荐系统的召回和排序两个阶段158\n图6.3 召回模型结构.159\n图6.4 序列信息160\n图6.5 排序模型结构.161\n图6.6 不同NN 的效果162\n图6.7 DeepFM 模型结构(网络左边为FM 层，右边为DNN 层).164\n图6.8 FM 一阶部分165\n图6.9 FM 二阶部分166\n图6.10 FM\/DNN\/DeepFM 的比较171\nx j 推荐系统与深度学习\n图6.11 电影静止帧图片举例172\n图6.12 Alex-Net 卷积网络.173\n图6.13 左图：时间无关的推荐系统。右图：时间相关的推荐系统174\n图6.14 基于循环神经网络的推荐系统175\n图6.15 判别器177\n图6.16 生成器178\n图6.17 IRGAN 说明179\n图7.1 监督学习基本模型.184\n图7.2 基于离线训练的推荐系统架构设计186\n图7.3 数据上报模块.187\n图7.4 离线训练模块.187\n图7.5 推荐系统中的存储分层.188\n图7.6 在线预测的几个阶段189\n图7.7 推荐系统通用性设计190\n图7.8 面向深度学习的推荐系统架构设计191\n图7.9 利用深度学习进行特征提取192\n图7.10 参数服务器架构193\n图7.11 基于在线训练的推荐系统架构设计195\n图7.12 在线学习之实时特征处理196\n图7.13 面向内容的推荐系统架构设计198\n图7.14 用于推荐的内容池.198\n图7.15 Apache Kafka 逻辑架构.200\n表4.1 用户A 和B 的评分矩阵.43\n表4.2 电影内容特征二进制表示45\n表4.3 人脸魅力值打分不同模型的MAE 比较112\n表4.4 人脸魅力值打分不同模型的MAE 比较117\n\n表4.5 Keras 预训练好的图像分类模型118","pages":"203","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29965784.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29965784.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29965784.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30419577\/","id":"30419577","publisher":"清华大学出版社","isbn10":"7302513635","isbn13":"9787302513636","title":"推荐系统与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30419577","alt_title":"","author_intro":"本书的几位作者都在大型互联网公司从事与推荐系统相关的实践与研究，通过这本书，把推荐系统工作经验予以总结，以帮助想从事推荐系统的工作者或推荐系统爱好者。","summary":"本书的内容设置由浅入深，从传统的推荐算法过渡到近年兴起的深度学习技术。不管是初学者，还是有一定经验的从业人员，相信都能从本书的不同章节中有所收获。 区别于其他推荐算法书籍，本书引入了已被实践证明效果较好的深度学习推荐技术，包括Word2Vec、Wide & Deep、DeepFM、GAN 等技术应用，并给出了相关的实践代码；除了在算法层面讲解推荐系统的实现，还从工程层面详细阐述推荐系统如何搭建.","price":"65.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30439473\/","id":"30439473","publisher":"","isbn10":"7111588738","isbn13":"9787111588733","title":"基于TensorFlow的深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30439473","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30439475\/","id":"30439475","publisher":"","isbn10":"7111608453","isbn13":"9787111608455","title":"深度学习基础教程","url":"https:\/\/api.douban.com\/v2\/book\/30439475","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"TensorFlow","title":"TensorFlow"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30439455\/","id":"30439455","publisher":"","isbn10":"7115478848","isbn13":"9787115478849","title":"深度学习与TensorFlow实战","url":"https:\/\/api.douban.com\/v2\/book\/30439455","alt_title":"","author_intro":"","summary":"","series":{"id":"43598","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30439442\/","id":"30439442","publisher":"","isbn10":"7111615751","isbn13":"9787111615750","title":"TensorFlow深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/30439442","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"ai","title":"ai"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30350006\/","id":"30350006","publisher":"","isbn10":"7111609727","isbn13":"9787111609728","title":"Python深度学习 基于TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/30350006","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29692014.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29692014.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29692014.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29692014.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27618537\/","id":"27618537","publisher":"","isbn10":"7115461015","isbn13":"9787115461018","title":"基于互联网教育环境的深度学习","url":"https:\/\/api.douban.com\/v2\/book\/27618537","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["邢梦来","王硕","孙洋洋"],"pubdate":"2018-8","tags":[{"count":2,"name":"PyTorch","title":"PyTorch"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29835784.jpg","binding":"平装","translator":[],"catalog":"第一部分  理论部分\n第1章  深度学习简介  2\n1.1  深度学习  2\n1.2  神经网络的发展  6\n1.3  深度学习的应用  7\n1.4  常用的数学知识和机器学习算法  8\n1.5  PyTorch简介  11\n1.5.1  PyTorch介绍  11\n1.5.2  使用PyTorch的公司  15\n1.5.3  PyTorch API  16\n1.5.4  为什么选择Python语言  16\n1.5.5  Python语言的特点  16\n1.6  常用的机器学习、深度学习开源框架  17\n1.7  其他常用的模块库  19\n1.8  深度学习常用名词  20\n第2章  PyTorch环境安装  33\n2.1  基于Ubuntu环境的安装  33\n2.1.1  安装Anaconda  35\n2.1.2  设置国内镜像  36\n2.2  Conda命令安装PyTorch  37\n2.3  pip命令安装PyTorch  37\n2.4  配置CUDA  38\n第3章  PyTorch基础知识  40\n3.1  张量  40\n3.2  数学操作  43\n3.3  数理统计  44\n3.4  比较操作  45\n第4章  简单案例入门  47\n4.1  线性回归  47\n4.2  逻辑回归  52\n第5章  前馈神经网络  59\n5.1  实现前馈神经网络  61\n5.2  数据集  68\n5.3  卷积层  72\n5.4  Functional函数  75\n5.5  优化算法  82\n5.6  自动求导机制  85\n5.7  保存和加载模型  87\n5.8  GPU加速运算  87\n第6章  PyTorch可视化工具  89\n6.1  Visdom介绍  89\n6.2  Visdom基本概念  90\n6.2.1  Panes（窗格）  90\n6.2.2  Environments（环境）  90\n6.2.3  State（状态）  91\n6.3  安装Visdom  91\n6.4  可视化接口  91\n6.4.1  Python函数属性提取技巧  92\n6.4.2  vis.text  93\n6.4.3  vis.image  93\n6.4.4  vis.scatter  94\n6.4.5  vis.line  95\n6.4.6  vis.stem  97\n6.4.7  vis.heatmap  97\n6.4.8  vis.bar  99\n6.4.9  vis.histogram  101\n6.4.10  vis.boxplot  102\n6.4.11  vis.surf  103\n6.4.12  vis.contour  104\n6.4.13  vis.mesh  106\n6.4.14  vis.svg  107\n第二部分  实战部分\n第7章  卷积神经网络  110\n7.1  卷积层  112\n7.2  池化层  114\n7.3  经典的卷积神经网络  115\n7.3.1  LeNet-5神经网络结构  115\n7.3.2  ImageNet-2010网络结构  117\n7.3.3  VGGNet网络结构  122\n7.3.4  GoodLeNet网络结构  124\n7.3.5  ResNet网络结构  126\n7.4  卷积神经网络案例  129\n7.5  深度残差模型案例  138\n第8章  循环神经网络简介  145\n8.1  循环神经网络模型结构  146\n8.2  不同类型的RNN  147\n8.3  LSTM结构具体解析  151\n8.4  LSTM的变体  153\n8.5  循环神经网络实现  156\n8.5.1  循环神经网络案例  156\n8.5.2  双向RNN案例  160\n第9章  自编码模型  164\n第10章  对抗生成网络  172\n10.1  DCGAN原理  175\n10.2  GAN对抗生成网络实例  180\n第11章  Seq2seq自然语言处理  186\n11.1  Seq2seq自然语言处理简介  186\n11.2  Seq2seq自然语言处理案例  188\n第12章  利用PyTorch实现量化交易  204\n12.1  线性回归预测股价  205\n12.2  前馈神经网络预测股价  209\n12.3  递归神经网络预测股价  214","ebook_url":"https:\/\/read.douban.com\/ebook\/58642405\/","pages":"232","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29835784.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29835784.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29835784.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30290537\/","id":"30290537","publisher":"电子工业出版社","isbn10":"7121345641","isbn13":"9787121345647","title":"深度学习框架PyTorch快速开发与实战","url":"https:\/\/api.douban.com\/v2\/book\/30290537","alt_title":"","author_intro":"邢梦来，擅长量化分析理论，深入研究多空对比分析，对多空趋势平衡有独特的见解，形成一套多空对比体系。同时对对交易心理状况、人工智能与区块链技术也有较深的研究。\n王硕，资深软件工程师，具有9年的Java企业应用开发经验和4年的教育培训经验，曾主持多个B\/S项目开发，项目经验丰富，擅长Java EE（Struts2、Spring3、Hibernate3）项目开发、Python（程序GUI、数据分析、网络爬虫）项目开发，是极宽TOP开源团队核心成员，也是《PyQt5快速开发与实战》一书的作者之一。\n孙洋洋，《PyQt5快速开发与实战》一书的作者之一，擅长网络爬虫、机器学习、量化投资与程序GUI开发设计。有多年量化投资实盘操作经历，现就职于某期货公司做量化研究员。","summary":"深度学习已经成为人工智能炙手可热的技术，PyTorch是一个较新的、容易上手的深度学习开源框架，目前已得到广泛应用。《深度学习框架PyTorch快速开发与实战》从PyTorch框架结构出发，通过案例主要介绍了线性回归、逻辑回归、前馈神经网络、卷积神经网络、循环神经网络、自编码模型、以及生成对抗网络。《深度学习框架PyTorch快速开发与实战》作为深度学习的入门教材，省略了大量的数学模型推导，适合深度学习初学者，人工智能领域的从业者，以及深度学习感兴趣的人阅读。","ebook_price":"48.30","series":{"id":"41172","title":"博文视点AI系列"},"price":"69.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30681006\/","id":"30681006","publisher":"","isbn10":"7030571363","isbn13":"9787030571366","title":"基于深度学习的医学图像数据可视化分析与处理","url":"https:\/\/api.douban.com\/v2\/book\/30681006","alt_title":"","author_intro":"","summary":"","price":"87.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30664442\/","id":"30664442","publisher":"","isbn10":"9864342169","isbn13":"9789864342167","title":"TensorFlow+Keras 深度学习人工智能实务应用","url":"https:\/\/api.douban.com\/v2\/book\/30664442","alt_title":"","author_intro":"","summary":"","price":"273.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30674457\/","id":"30674457","publisher":"","isbn10":"7565128449","isbn13":"9787565128448","title":"《经济生活》的“三维”深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30674457","alt_title":"","author_intro":"","summary":"","price":"22.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[""],"pubdate":"","tags":[{"count":1,"name":"计算科学","title":"计算科学"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30764532\/","id":"30764532","publisher":"南开大学出版社","isbn10":"731005590X","isbn13":"9787310055906","title":"深度学习的探索之路","url":"https:\/\/api.douban.com\/v2\/book\/30764532","alt_title":"","author_intro":"","summary":"","price":"48元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30716367\/","id":"30716367","publisher":"","isbn10":"7544481727","isbn13":"9787544481724","title":"深度学习与智能治理：2018上海基础教育信息化发展蓝皮书","url":"https:\/\/api.douban.com\/v2\/book\/30716367","alt_title":"","author_intro":"","summary":"","price":"68.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30738648\/","id":"30738648","publisher":"","isbn10":"7568047202","isbn13":"9787568047203","title":"基于深度学习理论的纹身图像识别与检测研究","url":"https:\/\/api.douban.com\/v2\/book\/30738648","alt_title":"","author_intro":"","summary":"","price":"32.30元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30729074\/","id":"30729074","publisher":"","isbn10":"7121342863","isbn13":"9787121342868","title":"智能大数据与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30729074","alt_title":"","author_intro":"","summary":"","price":"56.40元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30728554\/","id":"30728554","publisher":"","isbn10":"7113244289","isbn13":"9787113244286","title":"深度学习：从入门到实战","url":"https:\/\/api.douban.com\/v2\/book\/30728554","alt_title":"","author_intro":"","summary":"","price":"59.20元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30685720\/","id":"30685720","publisher":"","isbn10":"7564175176","isbn13":"9787564175177","title":"深度学习基础（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/30685720","alt_title":"","author_intro":"","summary":"","price":"61.20元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30917130\/","id":"30917130","publisher":"","isbn10":"7553670561","isbn13":"9787553670560","title":"问题与任务促进科学深度学习\/课程与教学改革成果丛书·第1辑","url":"https:\/\/api.douban.com\/v2\/book\/30917130","alt_title":"","author_intro":"","summary":"","price":"30.90元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["（印）尼基尔·盖德卡尔  杜长营  苏辉 译"],"pubdate":"","tags":[{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"python","title":"python"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30769257\/","id":"30769257","publisher":"清华大学出版社","isbn10":"7302512876","isbn13":"9787302512875","title":"Python深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30769257","alt_title":"","author_intro":"","summary":"","price":"59元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["王晓华"],"pubdate":"","tags":[{"count":2,"name":"python","title":"python"},{"count":2,"name":"OpenCV","title":"OpenCV"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/111867626\/","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30771538\/","id":"30771538","publisher":"清华大学出版社","isbn10":"7302518424","isbn13":"9787302518426","title":"OpenCV+TensorFlow深度学习与计算机视觉实战","url":"https:\/\/api.douban.com\/v2\/book\/30771538","alt_title":"","author_intro":"","summary":"","ebook_price":"41.40","price":"69元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["刘鹏"],"pubdate":"","tags":[{"count":1,"name":"人工智能","title":"人工智能"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30821973\/","id":"30821973","publisher":"电子工业出版社","isbn10":"7121335212","isbn13":"9787121335211","title":"深度学习—高级大数据人才培养丛书","url":"https:\/\/api.douban.com\/v2\/book\/30821973","alt_title":"","author_intro":"","summary":"","price":"45元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["尤小平"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30823934\/","id":"30823934","publisher":"华东师范大学出版社","isbn10":"7567570025","isbn13":"9787567570023","title":"学历案与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30823934","alt_title":"","author_intro":"","summary":"","price":"36元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["何希平","刘波"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30818484\/","id":"30818484","publisher":"科学出版社","isbn10":"7030521048","isbn13":"9787030521040","title":"深度学习理论与实践","url":"https:\/\/api.douban.com\/v2\/book\/30818484","alt_title":"","author_intro":"","summary":"","price":"59元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["李春华"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"290","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/31818187\/","id":"31818187","publisher":"上海教育出版社","isbn10":"7544472795","isbn13":"9787544472791","title":"让深度学习真实发生——高效课堂的理论研究与实践探索(【按需印刷】)","url":"https:\/\/api.douban.com\/v2\/book\/31818187","alt_title":"","author_intro":"","summary":"","price":"35元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31879546.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s31879546.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s31879546.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31879546.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32989417\/","id":"32989417","publisher":"","isbn10":"9864768247","isbn13":"9789864768240","title":"Deep Learning深度學習基礎∣設計下一代人工智慧演算法","url":"https:\/\/api.douban.com\/v2\/book\/32989417","alt_title":"","author_intro":"","summary":"平装, 歐萊禮","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"学前教育","title":"学前教育"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33400787\/","id":"33400787","publisher":"","isbn10":"7518420562","isbn13":"9787518420568","title":"万千教育学前.小脑袋，大问题：促进幼儿深度学习的高水平提问","url":"https:\/\/api.douban.com\/v2\/book\/33400787","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["[韩]Phil Kim"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32345648.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32345648.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32345648.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32345648.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30662346\/","id":"30662346","publisher":"北京航空航天大学出版社","isbn10":"7512426666","isbn13":"9787512426665","title":"深度学习：基于Matlab的设计实例","url":"https:\/\/api.douban.com\/v2\/book\/30662346","alt_title":"","author_intro":"","summary":"","price":"59.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33477412\/","id":"33477412","publisher":"","isbn10":"7517075950","isbn13":"9787517075950","title":"深度学习——卷积神经网络算法原理与应用（普通高等教育新工科人才培养规划教材（大数据专业））","url":"https:\/\/api.douban.com\/v2\/book\/33477412","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32745038.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32745038.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32745038.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32745038.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33950362\/","id":"33950362","publisher":"","isbn10":"711162680X","isbn13":"9787111626800","title":"MXNet深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/33950362","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34465288\/","id":"34465288","publisher":"","isbn10":"7565128457","isbn13":"9787565128455","title":"《生活与哲学》的“三维”深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34465288","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["包子阳"],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32306632.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"196","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32306632.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32306632.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32306632.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33429295\/","id":"33429295","publisher":"电子工业出版社","isbn10":"7121362015","isbn13":"9787121362019","title":"神经网络与深度学习——基于TensorFlow框架和Python技术实现","url":"https:\/\/api.douban.com\/v2\/book\/33429295","alt_title":"","author_intro":"","summary":"","price":"49.8元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["[印] 纳温·库马尔·马纳西（Navin Kumar Manaswi）"],"pubdate":"","tags":[{"count":3,"name":"深度学习","title":"深度学习"},{"count":1,"name":"Tensorflow","title":"Tensorflow"},{"count":1,"name":"Keras","title":"Keras"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32302404.jpg","binding":"平装-胶订","translator":[],"catalog":"","pages":"168","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32302404.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32302404.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32302404.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33424186\/","id":"33424186","publisher":"机械工业出版社","isbn10":"7111622766","isbn13":"9787111622765","title":"Python深度学习实战：基于TensorFlow和Keras的聊天机器人以及人脸、物体和语音识别","url":"https:\/\/api.douban.com\/v2\/book\/33424186","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"69元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["张宁"],"pubdate":"2018-11-1","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32318018.jpg","binding":"平装","translator":[],"catalog":"","pages":"208","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32318018.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32318018.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32318018.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30753496\/","id":"30753496","publisher":"财经科学出版社","isbn10":"7514198202","isbn13":"9787514198201","title":"金融保险：深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30753496","alt_title":"","author_intro":"","summary":"","series":{"id":"47347","title":"央财金融科技书系"},"price":"68.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33379028\/","id":"33379028","publisher":"","isbn10":"7562283990","isbn13":"9787562283997","title":"智慧教室中基于APT教学的小学生深度学习研究\/智慧课堂与信息化教育研究丛书","url":"https:\/\/api.douban.com\/v2\/book\/33379028","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33444023\/","id":"33444023","publisher":"","isbn10":"7111624831","isbn13":"9787111624837","title":"深度学习实战","url":"https:\/\/api.douban.com\/v2\/book\/33444023","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/127313545\/","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33456778\/","id":"33456778","publisher":"","isbn10":"7302514267","isbn13":"9787302514268","title":"数据处理与深度学习","url":"https:\/\/api.douban.com\/v2\/book\/33456778","alt_title":"","author_intro":"","summary":"","ebook_price":"31.85","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32334212.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32334212.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32334212.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32334212.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33474862\/","id":"33474862","publisher":"","isbn10":"7115510091","isbn13":"9787115510099","title":"深度学习企业实战","url":"https:\/\/api.douban.com\/v2\/book\/33474862","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34777449\/","id":"34777449","publisher":"","isbn10":"7521603249","isbn13":"9787521603248","title":"深度学习：如何训练成一个很厉害的人","url":"https:\/\/api.douban.com\/v2\/book\/34777449","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"基于TensorFlow","author":["[日]中井悦司"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32271407.jpg","binding":"平装","translator":[],"catalog":"","pages":"241","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32271407.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32271407.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32271407.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33385185\/","id":"33385185","publisher":"人民邮电出版社","isbn10":"7115504822","isbn13":"9787115504821","title":"深度学习入门与实战 基于TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/33385185","alt_title":"","author_intro":"","summary":"","price":"69元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33449149.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33449149.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33449149.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33449149.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34783555\/","id":"34783555","publisher":"","isbn10":"7519451240","isbn13":"9787519451240","title":"基于移动端的英语词汇深度学习研究","url":"https:\/\/api.douban.com\/v2\/book\/34783555","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["程世东 编著"],"pubdate":"2019-8","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33448178.jpg","binding":"平装","translator":[],"catalog":"1 卷积神经网络与环境搭建 1\n1.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.2.1 卷积层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2.2 修正线性单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.2.3 池化层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.4 全连接层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n1.2.5 softmax 层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.2.6 LeNet-5 网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n1.3 准备开发环境 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.3.1 Anaconda 环境搭建 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.3.2 安装 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.3.3 FloydHub 使用介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n1.3.4 AWS 使用介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n1.4 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2 卷积神经网络实践：图像分类 27\n2.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.2 卷积神经网络项目实践：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . 27\n2.2.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.2.2 网络模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n2.2.3 训练网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n2.3 卷积神经网络项目实践：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . 41\n2.3.1 TensorFlow 2.0 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n2.3.2 CIFAR-100 分类网络的 TensorFlow 2.0 实现 . . . . . . . . . . . . . . . . . . 44\n2.4 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n3 彩票预测和生成古诗 61\n3.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n3.2 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n3.3 LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n3.4 嵌入矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.5 实现彩票预测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n3.5.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n3.5.2 构建神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n3.5.3 训练神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n3.5.4 分析网络训练情况 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n3.5.5 生成预测号码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n3.6 文本生成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n3.7 生成古诗：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n3.7.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n3.7.2 构建网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n3.7.3 开始训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n3.7.4 生成古诗 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n3.8 自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n3.8.1 序列到序列 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\n3.8.2 Transformer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n3.8.3 BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\n3.9 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\n4 个性化推荐系统 119\n4.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n4.2 MovieLens 1M 数据集分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n4.2.1 下载数据集 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n4.2.2 用户数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n4.2.3 电影数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\n4.2.4 评分数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n4.3 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n4.3.1 代码实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n4.3.2 加载数据并保存到本地 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n4.3.3 从本地读取数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n4.4 神经网络模型设计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n4.5 文本卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\n4.6 实现电影推荐：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n4.6.1 构建计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n4.6.2 训练网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n4.6.3 实现个性化推荐 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n4.7 实现电影推荐：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n4.7.1 构建模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n4.7.2 训练网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\n4.7.3 实现个性化推荐 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\n4.8 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\n5 广告点击率预估：Kaggle 实战 170\n5.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n5.2 下载数据集 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170\n5.3 数据字段的含义 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n5.4 点击率预估的实现思路 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n5.4.1 梯度提升决策树 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n5.4.2 因子分解机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\n5.4.3 场感知分解机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\n5.4.4 网络模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n5.5 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\n5.5.1 GBDT 的输入数据处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n5.5.2 FFM 的输入数据处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\n5.5.3 DNN 的输入数据处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\n5.5.4 数据预处理的实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\n5.6 训练 FFM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\n5.7 训练 GBDT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\n5.8 用 LightGBM 的输出生成 FM 数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n5.9 训练 FM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\n5.10 实现点击率预估：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . . . . . 218\n5.10.1 构建神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219\n5.10.2 训练网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n5.10.3 点击率预估 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n5.11 实现点击率预估：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . . . . . 237\n5.12 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n6 人脸识别 246\n6.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\n6.2 人脸检测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\n6.2.1 OpenCV 人脸检测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\n6.2.2 dlib 人脸检测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\n6.2.3 MTCNN 人脸检测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254\n6.3 提取人脸特征 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\n6.3.1 使用 FaceNet 提取人脸特征 . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\n6.3.2 使用 VGG 网络提取人脸特征 . . . . . . . . . . . . . . . . . . . . . . . . . . 265\n6.3.3 使用 dlib 提取人脸特征 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\n6.4 人脸特征的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\n6.5 从视频中找人的实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\n6.6 视频找人的案例实践 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\n6.7 人脸识别：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\n6.8 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\n7 AlphaZero \/ AlphaGo 实践：中国象棋 304\n7.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\n7.2 论文解析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\n7.2.1 蒙特卡罗树搜索算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\n7.2.2 神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\n7.2.3 AlphaZero 论文解析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\n7.3 实现中国象棋：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . . . . . . . 317\n7.3.1 中国象棋着法表示和 FEN 格式 . . . . . . . . . . . . . . . . . . . . . . . . . 317\n7.3.2 输入特征的设计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\n7.3.3 实现神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\n7.3.4 神经网络训练和预测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\n7.3.5 通过自我对弈训练神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\n7.3.6 自我对弈 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334\n7.3.7 实现蒙特卡罗树搜索：异步方式 . . . . . . . . . . . . . . . . . . . . . . . . 340\n7.3.8 训练和运行 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\n7.4 实现中国象棋：基于 TensorFlow 2.0，多 GPU 版 . . . . . . . . . . . . . . . . . . . 354\n7.5 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364\n8 汉字 OCR 365\n8.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\n8.2 分类网络实现汉字 OCR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\n8.2.1 图片矫正 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\n8.2.2 文本切割 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\n8.2.3 汉字分类网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\n8.3 端到端的汉字 OCR：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . . . . . 371\n8.3.1 CNN 设计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372\n8.3.2 双向 LSTM 设计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\n8.3.3 CTC 损失 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\n8.3.4 端到端汉字 OCR 的网络训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 388\n8.4 汉字 OCR：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395\n8.4.1 CNN 的实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395\n8.4.2 双向 LSTM 的实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396\n8.4.3 OCR 网络的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403\n8.5 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406\n9 强化学习：玩转 Flappy Bird 和超级马里奥 407\n9.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407\n9.2 DQN 算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407\n9.3 实现 DQN 玩 Flappy Bird：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . . . . . 412\n9.4 实现 DQN 玩 Flappy Bird：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . . . . . 417\n9.5 使用 OpenAI Baselines 玩超级马里奥 . . . . . . . . . . . . . . . . . . . . . . . . . . 424\n9.5.1 Gym . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424\n9.5.2 自定义 Gym 环境 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 426\n9.5.3 使用 Baselines 训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431\n9.5.4 使用训练好的智能体玩游戏 . . . . . . . . . . . . . . . . . . . . . . . . . . . 437\n9.5.5 开始训练马里奥游戏智能体 . . . . . . . . . . . . . . . . . . . . . . . . . . . 438\n9.6 具有好奇心的强化学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443\n9.7 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444\n10 生成对抗网络实践：人脸生成 445\n10.1 概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445\n10.2 GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446\n10.3 DCGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447\n10.3.1 生成器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 448\n10.3.2 判别器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449\n10.4 WGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449\n10.5 WGAN-GP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451\n10.5.1 WGAN-GP 算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451\n10.5.2 训练 WGAN-GP 生成人脸：基于 TensorFlow 1.x . . . . . . . . . . . . . . . . 452\n10.5.3 训练 WGAN-GP 生成人脸：基于 TensorFlow 2.0 . . . . . . . . . . . . . . . . 462\n10.6 PG-GAN 和 TL-GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469\n10.7 本章小结 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473","pages":"484","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33448178.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33448178.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33448178.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34782234\/","id":"34782234","publisher":"电子工业出版社","isbn10":"7121364999","isbn13":"9787121364990","title":"深度学习私房菜：跟着案例学TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/34782234","alt_title":"","author_intro":"","summary":"本书通过案例讲解如何使用TensorFlow 解决深度学习的实际任务，每章都包含TensorFlow 1.x和 2.0的代码实现。全书共分 10 章，主要讲解卷积神经网络、LSTM、Seq2Seq、Transformer、BERT、文本卷积、GBDT、FM、FFM、Dlib、MTCNN、VGG、AlphaGo\/AlphaZero、BiLSTM、DQN、Gym、GAN等技术，包含的项目有CIFAR-100 图像分类、彩票预测、古诗生成、推荐系统、广告点击率预测、人脸识别、中国象棋、汉字OCR、FlappyBird和超级马里奥、人脸生成。\n本书假设读者具有适当的 Python 编程基础和深度学习基础（比如梯度下降、反向传播等知识）。全书以案例的方式讲解涉及的知识，包括理论、算法和解决思路，适合相关专业的大学生或研究生，以及对深度学习感兴趣的读者参考阅读。","series":{"id":"41172","title":"博文视点AI系列"},"price":"128.00元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34791245\/","id":"34791245","publisher":"","isbn10":"7111632664","isbn13":"9787111632665","title":"神经网络与深度学习实战：Python+Keras+TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/34791245","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33438494.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33438494.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33438494.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33438494.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34648331\/","id":"34648331","publisher":"","isbn10":"7519119173","isbn13":"9787519119171","title":"深度学习教学改进丛书","url":"https:\/\/api.douban.com\/v2\/book\/34648331","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["[美] 乔希 • 帕特森","[美] 亚当 • 吉布森"],"pubdate":"2019-7","tags":[{"count":6,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"Bill","title":"Bill"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33442239.jpg","binding":"平装","translator":["郑明智"],"catalog":"前言　　xv\n第1章 机器学习回顾　　1\n第2章 神经网络基础与深度学习　　31\n第3章 深度网络基础　　60\n第4章 深度网络的主要架构　　85\n第5章 建立深度网络　　118\n第6章 深度网络调优　　176\n第7章 调优特定的深度网络架构　　217\n第8章 向量化　　237\n第9章 在Spark上使用深度学习和DL4J　　262\n附录A 人工智能是什么　　299\n附录B RL4J与强化学习　　307\n附录C 每个人都需要了解的数字　　325\n附录D 神经网络和反向传播：数学方法　　326\n附录E 使用ND4J API　　330\n附录F 使用DataVec　　341\n附录G 从源代码构建DL4J　　350\n附录H 设置DL4J项目　　352\n附录I 为DL4J项目设置GPU　　356\n附录J 解决DL4J安装上的问题　　359\n关于作者　　365\n关于封面　　365","pages":"388","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33442239.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33442239.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33442239.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34690881\/","id":"34690881","publisher":"人民邮电出版社","isbn10":"7115515425","isbn13":"9787115515421","title":"深度学习基础与实践","url":"https:\/\/api.douban.com\/v2\/book\/34690881","alt_title":"","author_intro":"Josh Patterson是Skymind\n公司副总裁，曾任Cloudera公司通用解决方案架构师、田纳西河流域管理局机器学习与分布式系统工程师。\nAdam Gibson\n是Skymind公司CTO，在帮助公司处理和解析大量实时数据方面经验丰富","summary":"本书是由两位技术出身的企业管理者编写的深度学习普及书。本书的前四章提供了足够的关于深度学习的理论知识，包括机器学习的基本概念、神经网络基础、从神经网络到深度网络的演化历程，以及主流的深度网络架构，为读者阅读本书剩余内容打下基础。后五章带领读者进行一系列深度学习的实践，包括建立深层网络、高级调优技术、各种数据类型的向量化和在Spark上运行深度学习工作流。","price":"119.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33461069.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33461069.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33461069.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33461069.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34799564\/","id":"34799564","publisher":"","isbn10":"7115509964","isbn13":"9787115509963","title":"深度学习原理与","url":"https:\/\/api.douban.com\/v2\/book\/34799564","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"电脑","title":"电脑"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34809459\/","id":"34809459","publisher":"","isbn10":"7301305818","isbn13":"9787301305812","title":"TensorFlow+PyTorch深度学习从算法到实战","url":"https:\/\/api.douban.com\/v2\/book\/34809459","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["李理"],"pubdate":"2019-7","tags":[{"count":1,"name":"akb","title":"akb"},{"count":1,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33305832.jpg","binding":"平装","translator":[],"catalog":"第 1 章 人工智能的基本概念 1\n1.1 人工智能的发展历史   1\n1.2 机器学习   4\n1.3 常见的监督学习模型     8\n1.4 衡量指标    16\n1.5 损失函数      17\n1.6 优化    18\n1.7 过拟合     20\n1.8 机器学习示例：线性回归    22\n第 2 章 神经网络   27\n2.1 手写数字识别问题    27\n2.2 单个神经元和多层神经网络   30\n2.3 用代码实战多层神经网络   33\n2.4 多层神经网络构建代码解析    33\n2.5 反向传播算法的推导     39\n2.6 代码实现反向传播算法    47\n2.7 为什么反向传播算法是一个高效的算法    50\n2.8 优化技巧     50\n第 3 章 卷积神经网络    59\n3.1 卷积神经网络简介     59\n3.2 局部感知域       59\n3.3 特征映射        62\n3.4 池化        63\n3.5 构建完整的卷积神经网络    65\n3.6 填充和步长        65\n3.7 CNN 识别 MNIST 手写数字     66\n3.8 CNN 模型识别 CIFAR¬10 图像    71\n3.9 使用残差网络识别 MNIST 图像      92\n第 4 章 循环神经网络    101\n4.1 基本概念      101\n4.2 RNN 的扩展     102\n4.3 Word Embedding 简介    103\n4.4 姓名分类       104\n4.5 RNN 生成莎士比亚风格句子    114\n4.6 机器翻译       123\n4.7 汉语—英语翻译的批量训练     146\n第 5 章 生成对抗网络     156\n5.1 为什么研究生成模型     156\n5.2 生成模型的原理以及 GAN 与其他生成模型的区别     159\n5.3 GAN 的原理      165\n5.4 深度卷积生成对抗网络     168\n5.5 反卷积        168\n5.6 DCGAN 实战        175\n第 6 章 TensorFlow      196\n6.1 TensorFlow 简介         196\n6.2 Opitimizer        219\n6.3 数据的处理和输入        226\n6.4 常见网络结构        250\n6.5 RNN 在 TensorFlow 中的实现      258\n6.6 TensorBoard        276\n6.7 高层 API        281\n6.8 调试         309\n6.9 TensorFlow Serving        316\n第 7 章 PyTorch     343\n7.1 基础知识       343\n7.2 PyTorch 神经网络简介     350\n7.3 训练一个分类器        354\n7.4 使用 NumPy 实现三层神经网络     363\n7.5 使用 Tensor 实现三层神经网络      364\n7.6 使用 autograd 实现三层神经网络     365\n7.7 使用自定义的 ReLU 函数      367\n7.8 和 TensorFlow 的对比     369\n7.9 使用 nn 模块实现三层神经网络     370\n7.10 使用 optim 包         372\n7.11 自定义 nn 模块        373\n7.12 流程控制和参数共享     374\n7.13 迁移学习示例         375\n7.14 数据的加载和预处理       382\n第 8 章 Keras    393\n8.1 Keras 简介         393\n8.2 Hello World        393\n8.3 Sequential API        395\n8.4 多分类       398\n8.5 两分类         400\n8.6 1D 卷积进行序列分类     400\n8.7 多层 LSTM 序列分类     402\n8.8 有状态的 LSTM       404\n8.9 Functional API      405\n8.10 判断两个数字是否是同一个数字      410\n8.11 图片问答      411\n8.12 视频问答       413","pages":"424","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33305832.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33305832.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33305832.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34441837\/","id":"34441837","publisher":"电子工业出版社","isbn10":"7121365367","isbn13":"9787121365362","title":"深度学习理论与实战：基础篇","url":"https:\/\/api.douban.com\/v2\/book\/34441837","alt_title":"","author_intro":"李理，毕业于北京大学，研究方向为自然语言处理，有十多年自然语言处理和人工智能研发经验，先后在去哪儿网、百度和出门问问等企业工作，从事过分布式爬虫、搜索引擎、广告系统，主持研发过多款智能硬件的问答和对话系统。现在是环信人工智能研发中心的VP，负责环信中文语义分析开放平台和环信智能机器人的设计与研发。目前他致力于语音识别、自然语言处理等人工智能技术在企业中的推广和落地，以提高企业服务的水平和效率。","summary":"《深度学习理论与实战：基础篇》不仅包含人工智能、机器学习及深度学习的基础知识，如卷积神经网络、循环神经网络、生成对抗网络等，而且也囊括了学会使用 TensorFlow、PyTorch 和 Keras 这三个主流的深度学习框架的最小知识量；不仅有针对相关理论的深入解释，而且也有实用的技巧，包括常见的优化技巧、使用多 GPU 训练、调试程序及将模型上线到生产系统中。\n《深度学习理论与实战：基础篇》希望同时兼顾理论和实战，使读者既能深入理解理论知识，又能把理论知识用于实战，因此本书每介绍完一个模型都会介绍其实现，读者阅读完一个模型的介绍之后就可以运行、阅读和修改相关代码，从而可以更加深刻地理解理论知识。\n回顾人工智能几十年经历过的起起落落，希望对人工智能及深度学习感兴趣的读者通过本书的学习能够更加理性、更加全面地看待这个行业，理解人工智能尤其是深度学习的原理并应用，根据当前的技术现状合理地应用深度学习去改变人们的工作、生活和学习。","price":"109"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34450036\/","id":"34450036","publisher":"","isbn10":"7564183268","isbn13":"9787564183264","title":"TensorFlow深度学习 第2版（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/34450036","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["张宪超"],"pubdate":"2019-07-01","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33468548.jpg","binding":"","translator":[""],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33468548.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33468548.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33468548.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34811599\/","id":"34811599","publisher":"科学","isbn10":"7030598342","isbn13":"9787030598349","title":"深度学习(上)","url":"https:\/\/api.douban.com\/v2\/book\/34811599","alt_title":"","author_intro":"","summary":" 本书对所有主要的深度学习方法和最新研究趋势进行了深入探索。全书分为上下两卷，五个部分。上卷包括两个部分：第一部分是基础算法，包括机器学习基础算法、早期神经网络算法、深度学习的正则化方法和深度学习的优化方法；第二部分是判别式模型，包括卷积神经网络（CNN）、循环神经网络（RNN）、长短期记忆模型（LSTM）、注意力机制和记忆网络。下卷包括三个部分：第三部分是生\n成式模型，包括深度置信网络\/深度玻尔兹曼机、自编码器（AE）\/变分自编码器（VAE）、生成对抗网络（GAN）、像素级生成、深度聚类等；第四部分是前沿技术，讨论深度强化学习；第五部分是安全保障，包括深度学习的可解释性和对抗样本的攻击与防御。本书特别注重学术前沿，对包括胶囊网络在内的当前最新成果进行了细致的讨论。全书构建了一套明晰的深度学习体系，同时各章内容相对独立，并有辅助网站（http:\/\/deeplearningresource.com）在线提供大量论文、代码，数据集和彩图等学习资源供读者边实践边学习。\n本书适合人工智能相关领域的科研人员、工程师阅读，也可以作为人工智能、自动化和计算机等专业的研究生和高年级本科生的学习材料。\n","price":"168.00元"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["徐彬 著"],"pubdate":"2019-9","tags":[{"count":6,"name":"人工智能","title":"人工智能"},{"count":3,"name":"好书推荐","title":"好书推荐"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33471233.jpg","binding":"","translator":[],"catalog":"第 1章基础分类模型 1\n1.1深度学习简介 ............................ 2\n1.2目标问题：空间中的二分类 .................... 2\n1.3感知机模型 ............................. 3\n1.3.1感知机函数 ......................... 3\n1.3.2损失函数 .......................... 4\n1.3.3感知机学习算法 ....................... 6\n1.4算法实现 .............................. 8\n1.4.1环境搭建 .......................... 8\n1.4.2数据准备 .......................... 9\n1.4.3实现感知机算法 ....................... 11\n1.5小结 ................................. 13参考文献 ................................. 13\n第 2章第一个神经网络 14\n2.1目标问题：MNIST手写数字识别 ................. 15\n2.1.1数据集 ............................ 15\n2.1.2图像数据和图向量 ..................... 16\n2.2挑战：从二分类到多分类 ..................... 16\n2.3 Softmax方法 ............................ 19\n2.4正确分类的独热编码 ........................ 20\n2.5损失函数——交叉熵 ........................ 21\n2.6信息熵和交叉熵 ........................... 21\n2.6.1信息熵 ............................ 21\n2.6.2交叉熵 ............................ 22\n2.7第一个神经网络的学习算法 .................... 23\n2.8反向传播 .............................. 26\n2.9抽象泄漏 .............................. 27\n2.10算法实现 .............................. 28\n2.10.1数据准备 .......................... 28\n2.10.2实现第一个神经网络 .................... 33\n2.10.3实现 MINIST手写数字识别 ................ 36\n2.11小结 ................................. 37参考文献 ................................. 38\n第 3章多层全连接神经网络 39\n3.1第一个挑战：异或问题 ....................... 40\n3.2更深的神经网络——隐藏层 .................... 40\n3.3第二个挑战：参数拟合的两面性 .................. 42\n3.4过拟合与正则化 ........................... 44\n3.4.1欠拟合与过拟合 ....................... 44\n3.4.2正则化 ............................ 44\n3.4.3正则化的效果 ........................ 44\n3.5第三个挑战：非线性可分问题 ................... 45\n3.6激活函数 .............................. 45\n3.7算法和结构 ............................. 47\n3.8算法实现 .............................. 50\n3.8.1数据准备 .......................... 50\n3.8.2实现多层全连接神经网络 ................. 50\n3.8.3在数据集上验证模型 .................... 53\n3.9小结 ................................. 54参考文献 ................................. 54\n第 4章卷积神经网络（CNN） 55\n4.1挑战：参数量和训练成本 ..................... 56\n4.2卷积神经网络的结构 ........................ 56\n4.2.1卷积层 ............................ 57\n4.2.2池化层 ............................ 62\n4.2.3全连接层和 Softmax处理 ................. 63\n4.3卷积神经网络学习算法 ....................... 63\n4.3.1全连接层 .......................... 63\n4.3.2池化层反向传播 ....................... 64\n4.3.3卷积层反向传播 ....................... 65\n4.4算法实现 .............................. 68\n4.4.1数据准备 .......................... 68\n4.4.2卷积神经网络模型的原始实现 ............... 69\n4.5小结 ................................. 76参考文献 ................................. 78\n第 5章卷积神经网络——算法提速和优化 79\n5.1第一个挑战：卷积神经网络的运算效率 .............. 80\n5.2提速改进 .............................. 80\n5.2.1边缘填充提速 ........................ 82\n5.2.2池化层提速 ......................... 83\n5.2.3卷积层处理 ......................... 85\n5.3反向传播算法实现 ......................... 88\n5.3.1池化层反向传播 ....................... 88\n5.3.2卷积层反向传播 ....................... 89\n5.4第二个挑战：梯度下降的幅度和方向 ............... 91\n5.5递减学习率参数 ........................... 92\n5.6学习策略的优化方法 ........................ 92\n5.6.1动量方法 .......................... 93\n5.6.2 NAG方法 .......................... 93\n5.6.3 Adagrad方法 ........................ 94\n5.6.4 RMSprop方法 ....................... 95\n5.6.5 AdaDelta方法 ....................... 96\n5.6.6 Adam方法 ......................... 97\n5.6.7各种优化方法的比较 .................... 98\n目录\n5.7总体模型结构 ............................ 100\n5.8使用 CNN实现 MNIST手写数字识别验证 ........... 101\n5.9小结 ................................. 102参考文献 ................................. 103\n第 6章批量规范化（Batch Normalization） 104\n6.1挑战：深度神经网络不易训练 ................... 105\n6.2批量规范化方法的初衷 ....................... 105\n6.2.1数据集偏移 ......................... 106\n6.2.2输入分布偏移 ........................ 106\n6.2.3内部偏移 .......................... 107\n6.3批量规范化的算法 ......................... 107\n6.3.1训练时的前向计算 ..................... 107\n6.3.2规范化与标准化变量 .................... 108\n6.3.3推理预测时的前向计算 ................... 109\n6.3.4全连接层和卷积层的批量规范化处理 ........... 110\n6.4批量规范化的效果 ......................... 111\n6.4.1梯度传递问题 ........................ 111\n6.4.2饱和非线性激活问题 .................... 112\n6.4.3正则化效果 ......................... 113\n6.5批量规范化为何有效 ........................ 113\n6.6批量规范化的反向传播算法 .................... 114\n6.7算法实现 .............................. 115\n6.7.1训练时的前向传播 ..................... 116\n6.7.2反向传播 .......................... 117\n6.7.3推理预测 .......................... 118\n6.8调整学习率和总体结构 ....................... 119\n6.8.1模型结构 .......................... 119\n6.8.2卷积层批量规范化的实现 ................. 120\n6.8.3引入批量规范化后的递减学习率 .............. 121\n6.9在 MNIST数据集上验证结果 ................... 122\n6.10小结 ................................. 123\n参考文献 ................................. 123\n第 7章循环神经网络（Vanilla RNN） 125\n7.1第一个挑战：序列特征的捕捉 ................... 126\n7.2循环神经网络的结构 ........................ 126\n7.2.1单层 RNN.......................... 126\n7.2.2双向 RNN.......................... 128\n7.2.3多层 RNN.......................... 129\n7.3 RNN前向传播算法 ......................... 130\n7.4 RNN反向传播算法 ......................... 131\n7.4.1误差的反向传播 ....................... 131\n7.4.2激活函数的导函数和参数梯度 ............... 132\n7.5第二个挑战：循环神经网络的梯度传递问题 ........... 133\n7.6梯度裁剪 .............................. 134\n7.7算法实现 .............................. 135\n7.8目标问题：序列数据分析 ..................... 139\n7.8.1数据准备 .......................... 139\n7.8.2模型搭建 .......................... 144\n7.8.3验证结果 .......................... 145\n7.9小结 ................................. 147参考文献 ................................. 147\n第 8章长短时记忆网络（LSTM）——指数分析 149\n8.1目标问题：投资市场的指数分析 .................. 150\n8.2挑战：梯度弥散问题 ........................ 150\n8.3长短时记忆网络的结构 ....................... 150\n8.4 LSTM前向传播算法 ........................ 152\n8.5 LSTM反向传播算法 ........................ 153\n8.5.1误差反向传播 ........................ 154\n8.5.2激活函数的导函数和参数梯度 ............... 155\n8.6算法实现 .............................. 156\n8.6.1实现 LSTM单时间步的前向计算 ............. 156\n8.6.2实现 LSTM多层多时间步的前向计算 .......... 157\n8.6.3实现 LSTM单时间步的反向传播 ............. 159\n8.6.4实现 LSTM多层多时间步的反向传播 .......... 160\n8.7实现沪深 300指数分析 ....................... 161\n8.7.1数据准备 .......................... 162\n8.7.2模型构建 .......................... 166\n8.7.3分析结果 .......................... 167\n8.8小结 ................................. 168参考文献 ................................. 169\n第 9章双向门控循环单元（BiGRU）——情感分析 170\n9.1目标问题：情感分析 ........................ 171\n9.2第一个挑战：模型的运算效率 ................... 172\n9.3 GRU模型的结构 .......................... 172\n9.4 GRU前向传播算法 ......................... 173\n9.5 GRU前向传播表达式的其他写法 ................. 174\n9.6 GRU反向传播算法 ......................... 175\n9.7 GRU算法实现 ........................... 177\n9.7.1单时间步的前向计算 .................... 177\n9.7.2实现单时间步的反向传播 ................. 178\n9.8用 GRU模型进行情感分析 .................... 179\n9.8.1数据预处理 ......................... 180\n9.8.2构建情感分析模型 ..................... 181\n9.9首次验证 .............................. 182\n9.10第二个挑战：序列模型的过拟合 .................. 183\n9.11 Dropout正则化 ........................... 183\n9.11.1 Dropout前向传播算法 ................... 183\n9.11.2 Dropout反向传播算法 ................... 184\n9.11.3 Dropout Rate的选择 ................... 185\n9.12再次验证：GRU+Dropout..................... 186\n9.13第三个挑战：捕捉逆序信息 .................... 187\n9.14双向门控循环单元（BiGRU） ................... 187\n9.15第三次验证：BiGRU+Dropout .................. 188\n9.16小结 ................................. 189\n参考文献 ................................. 189\n附录 A向量和矩阵运算 191\n附录 B导数和微分 194\n附录 C向量和矩阵导数 195\n附录 D概率论和数理统计 201\n索引 205","pages":"224页","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33471233.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33471233.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33471233.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34815565\/","id":"34815565","publisher":"电子工业出版社","isbn10":"7121371715","isbn13":"9787121371714","title":"实战深度学习算法：零起点通关神经网络模型（基于Python和NumPy实现）","url":"https:\/\/api.douban.com\/v2\/book\/34815565","alt_title":"","author_intro":"徐彬\n重庆大学计算机科学系学士、BI挪威商学院硕士。曾任中国工商银行软件工程师、平安银行应用架构专家、银行间市场清算所创新衍生品及利率产品项目群负责人。研究方向包括信贷及清算风险管控、复杂项目群管理，机器学习在特定场景的应用。","summary":"深度学习是机器学习的重要分支。《实战深度学习算法：零起点通关神经网络模型（基于Python和NumPy实现）》系统地介绍了如何用Python和NumPy一步步地实现深度学习的基础模型，无须借助TensorFlow、PyTorch等深度学习框架，帮助读者更好地理解底层算法的脉络，进而进行模型的定制、优化和改进。全书由简到难地讲述感知机模型、多分类神经网络、深层全连接网络、卷积神经网络、批量规范化方法、循环神经网络、长短时记忆网络、双向结构的BiGRU模型等神经网络模型的必要算法推导、实现及其实例，读者可直接动手调试和观察整个训练过程，进一步理解模型及其算法原理。\n《实战深度学习算法：零起点通关神经网络模型（基于Python和NumPy实现）》适合没有深度学习基础，希望进入此领域的在校学生、研究者阅读，也适合有一定基础但不满足于“调包”和“调参”的工程师学习，还可供想要深入了解底层算法的研究人员参考阅读。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34819619\/","id":"34819619","publisher":"","isbn10":"703059956X","isbn13":"9787030599568","title":"深度学习（下）","url":"https:\/\/api.douban.com\/v2\/book\/34819619","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33494054.jpg","binding":"","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/122599857\/","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33494054.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33494054.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33494054.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34799068\/","id":"34799068","publisher":"","isbn10":"711162940X","isbn13":"9787111629405","title":"基于浏览器的深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34799068","alt_title":"","author_intro":"","summary":"","ebook_price":"40.00","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["李永会"],"pubdate":"2019-10","tags":[{"count":2,"name":"移动端","title":"移动端"},{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"DeepLearning","title":"DeepLearning"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33491446.jpg","binding":"","translator":[],"catalog":"第1章  初窥移动端深度学习技术的应用\t1\n1.1  本书示例代码简介\t1\n1.1.1  安装编译好的文件\t1\n1.1.2  在Demo App中应用神经网络技术\t2\n1.2  移动端主体检测和分类\t2\n1.3  在线上产品中以“云+端计算”的方式应用深度学习技术\t4\n1.4  在移动端应用深度学习技术的业界案例\t6\n1.4.1  植物花卉识别\t6\n1.4.2  奇妙的风格化效果\t7\n1.4.3  视频主体检测技术在App中的应用\t7\n1.5  在移动端应用深度学习技术的难点\t8\n1.5.1  在服务器端和移动端应用深度学习技术的难点对比\t8\n1.5.2  实现AR实时翻译功能\t9\n1.6  编译运行深度学习App\t12\n1.6.1  mobile-deep-learning项目环境简介\t12\n1.6.2  mobile-deep-learning项目整体代码结构\t13\n1.6.3  mobile-deep-learning通用环境依赖\t14\n1.7  在iOS平台上搭建深度学习框架\t15\n1.7.1  在iOS平台上搭建mobile-deep-learning项目\t15\n1.7.2  在OS X平台上编译mobile-deep-learning项目\t16\n1.7.3  iOS平台上mobile-deep-learning项目的Demo代码结构\t17\n1.8  在Android平台上搭建深度学习框架\t18\n1.8.1  Android平台上mobile-deep-learning项目的环境依赖\t18\n1.8.2  Android平台上mobile-deep-learning项目的Demo代码结构\t19\n1.8.3  用Paddle-Lite框架编译与开发Android应用\t20\n1.8.4  开发一个基于移动端深度学习框架的Android App\t22\n第2章  以几何方式理解线性代数基础知识\t32\n2.1  线性代数基础\t32\n2.1.1  标准平面直角坐标系\t32\n2.1.2  改变坐标系的基向量\t34\n2.2  向量的几何意义\t35\n2.2.1  向量的加减运算\t36\n2.2.2  向量的数乘运算\t37\n2.3  线性组合的几何意义\t38\n2.4  线性空间\t40\n2.5  矩阵和变换\t41\n2.6  矩阵乘法\t43\n2.7  行列式\t46\n2.8  矩阵的逆\t48\n2.9  秩\t49\n2.10  零空间\t50\n2.11  点积和叉积的几何表示与含义\t51\n2.11.1  点积的几何意义\t51\n2.11.2  叉积的几何意义\t52\n2.12  线性代数的特征概念\t53\n2.13  抽象向量空间\t54\n第3章  什么是机器学习和卷积神经网络\t56\n3.1  移动端机器学习的全过程\t56\n3.2  预测过程\t57\n3.3  数学表达\t59\n3.3.1  预测过程涉及的数学公式\t59\n3.3.2  训练过程涉及的数学公式\t60\n3.4  神经元和神经网络\t61\n3.4.1  神经元\t61\n3.4.2  神经网络\t63\n3.5  卷积神经网络\t63\n3.6  图像卷积效果\t65\n3.6.1  从全局了解视觉相关的神经网络\t65\n3.6.2  卷积核和矩阵乘法的关系\t66\n3.6.3  多通道卷积核的应用\t69\n3.7  卷积后的图片效果\t70\n3.8  卷积相关的两个重要概念：padding和stride\t75\n3.8.1  让卷积核“出界”：padding\t75\n3.8.2  让卷积核“跳跃”：stride\t75\n3.9  卷积后的降维操作：池化\t76\n3.10  卷积的重要性\t77\n第4章  移动端常见网络结构\t78\n4.1  早期的卷积神经网络\t78\n4.2  AlexNet网络结构\t79\n4.3  GoogLeNet网络结构\t79\n4.3.1  模型体积问题\t80\n4.3.2  计算量问题\t80\n4.4  尝试在App中运行GoogLeNet\t81\n4.4.1  将32位float参数转化为8位int参数以降低传输量\t82\n4.4.2  将CPU版本服务器端框架移植到移动端\t83\n4.4.3  应用在产品中的效果\t84\n4.5  轻量化模型SqueezeNet\t85\n4.5.1  SqueezeNet的优化策略\t85\n4.5.2  fire模块\t86\n4.5.3  SqueezeNet的全局\t86\n4.6  轻量高性能的MobileNet\t88\n4.6.1  什么是深度可分离卷积（Depthwise Separable Convolution）\t88\n4.6.2  MobileNet v1网络结构\t89\n4.6.3  MobileNet v2网络结构\t91\n4.7  移动端神经网络模型的优化方向\t92\n第5章  ARM CPU组成\t94\n5.1  现代计算机与ARM CPU架构的现状\t94\n5.1.1  冯•诺依曼计算机的基本结构\t94\n5.1.2  移动计算设备的分工\t96\n5.2  简单的CPU模型\t98\n5.2.1  取指过程\t98\n5.2.2  译码过程\t99\n5.2.3  执行过程\t100\n5.2.4  回写过程\t101\n5.2.5  细化分工：流水线技术\t102\n5.3  汇编指令初探\t102\n5.3.1  汇编语言程序的第一行\t102\n5.3.2  这些指令是什么\t105\n5.4  汇编指令概况\t106\n5.4.1  ARM CPU家族\t106\n5.4.2  ARMv7-A处理器架构\t107\n5.4.3  ARMv7汇编指令介绍\t109\n5.5  ARM指令集架构\t111\n5.6  ARM手机芯片的现状与格局\t113\n第6章  存储金字塔与ARM汇编\t115\n6.1  ARM CPU的完整结构\t115\n6.2  存储设备的金字塔结构\t117\n6.3  ARM芯片的缓存设计原理\t119\n6.3.1  缓存的基本理解\t119\n6.3.2  简单的缓存映射结构：直接映射\t121\n6.3.3  灵活高效的缓存结构：组相联映射\t123\n6.3.4  利用一个简单的公式优化访存性能\t125\n6.4  ARM汇编知识\t126\n6.4.1  ARM汇编数据类型和寄存器\t127\n6.4.2  ARM指令集\t130\n6.4.3  ARM汇编的内存操作\t131\n6.5  NEON汇编指令\t133\n6.5.1  NEON寄存器与指令类型\t134\n6.5.2  NEON存储操作指令\t135\n6.5.3  NEON通用数据操作指令\t137\n6.5.4  NEON通用算术操作指令\t138\n6.5.5  NEON乘法指令\t139\n6.5.6  运用NEON指令计算矩阵乘法\t140\n第7章  移动端CPU预测性能优化\t142\n7.1  工具及体积优化\t142\n7.1.1  工具使用\t143\n7.1.2  模型体积优化\t148\n7.1.3  深度学习库文件体积优化\t149\n7.2  CPU高性能通用优化\t150\n7.2.1  编译选项优化\t150\n7.2.2  内存性能和耗电量优化\t151\n7.2.3  循环展开\t153\n7.2.4  并行优化与流水线重排\t154\n7.3  卷积性能优化方式\t157\n7.3.1  滑窗卷积和GEMM性能对比\t157\n7.3.2  基于Winograd算法进行卷积性能优化\t160\n7.3.3  快速傅里叶变换\t162\n7.3.4  卷积计算基本优化\t163\n7.4  开发问题与经验总结\t164\n第8章  移动端GPU编程及深度学习框架落地实践\t166\n8.1  异构计算编程框架OpenCL\t166\n8.1.1  开发移动端GPU应用程序\t167\n8.1.2  OpenCL中的一些概念\t168\n8.2  移动端视觉搜索研发\t169\n8.2.1  初次探索移动端AI能力\t170\n8.2.2  取消拍照按钮，提升视觉搜索体验\t171\n8.2.3  使用深度学习技术提速视觉搜索\t172\n8.2.4  通过AI工程技术提升视觉搜索体验\t174\n8.3  解决历史问题：研发Paddle-Lite框架\t176\n8.3.1  体积压缩\t178\n8.3.2  工程结构编码前重新设计\t178\n8.3.3  视觉搜索的高级形态：实时视频流式搜索\t184","pages":"204","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33491446.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33491446.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33491446.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34844817\/","id":"34844817","publisher":"电子工业出版社","isbn10":"7121371820","isbn13":"9787121371820","title":"移动深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34844817","alt_title":"","author_intro":"李永会\n百度App移动研发部资深工程师。2015年起在百度从事图像搜索和语音搜索客户端研发工作，主持了多个重要创新项目，包括百度Lens、实时翻译等。同时负责开源移动端深度学习框架Paddle-Lite的开发，长期从事移动端AI高性能计算优化工作，在多种软硬件平台上高性能运行深度学习技术。在工作之余有读史、书法等爱好。","summary":"《移动深度学习》由浅入深地介绍了如何将深度学习技术应用到移动端运算领域，书中尽量避免罗列公式，尝试用浅显的语言和几何图形去解释相关内容。本书第1章展示了在移动端应用深度学习技术的Demo，帮助读者建立直观的认识；第2章至第4章讲述了如何在移动端项目中应用深度学习技术；第5章至第8章的难度略大，主要讲述如何深入地调整框架，适配并定制自己的框架。\n《移动深度学习》适合移动端研发工程师阅读，也适合所有对移动端运算领域感兴趣的朋友阅读","series":{"id":"41172","title":"博文视点AI系列"},"price":"75"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34826028\/","id":"34826028","publisher":"","isbn10":"7553971014","isbn13":"9787553971018","title":"思维训练·初中数学深度学习九年级上册","url":"https:\/\/api.douban.com\/v2\/book\/34826028","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34825726\/","id":"34825726","publisher":"","isbn10":"7553970999","isbn13":"9787553970998","title":"思维训练·初中数学深度学习七年级上册","url":"https:\/\/api.douban.com\/v2\/book\/34825726","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34868611\/","id":"34868611","publisher":"","isbn10":"7517076450","isbn13":"9787517076452","title":"Keras深度学习","url":"https:\/\/api.douban.com\/v2\/book\/34868611","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33502663.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33502663.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33502663.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33502663.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34860481\/","id":"34860481","publisher":"","isbn10":"7512430396","isbn13":"9787512430396","title":"深度学习商业应用开发指南","url":"https:\/\/api.douban.com\/v2\/book\/34860481","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34871693\/","id":"34871693","publisher":"","isbn10":"7560653502","isbn13":"9787560653501","title":"遥感影像深度学习智能解译与识别","url":"https:\/\/api.douban.com\/v2\/book\/34871693","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["刘衍琦","詹福宇 等"],"pubdate":"2019-10","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33509210.jpg","binding":"平装","translator":[],"catalog":"第1章  基于直方图优化的图像去雾技术\t1\n1.1  案例背景\t1\n1.2  理论基础\t1\n1.2.1  空域图像增强\t1\n1.2.2  直方图均衡化\t2\n1.3  程序实现\t3\n1.3.1  设计GUI界面\t4\n1.3.2  全局直方图处理\t4\n1.3.3  局部直方图处理\t6\n1.3.4  Retinex增强处理\t8\n1.4  延伸阅读\t12\n第2章  基于形态学的权重自适应图像去噪\t13\n2.1  案例背景\t13\n2.2  理论基础\t14\n2.2.1  图像去噪的方法\t14\n2.2.2  数学形态学的原理\t15\n2.2.3  权重自适应的多结构形态学去噪\t15\n2.3  程序实现\t16\n2.4  延伸阅读\t22\n第3章  基于多尺度形态学提取眼前节组织\t24\n3.1  案例背景\t24\n3.2  理论基础\t25\n3.3  程序实现\t28\n3.3.1  多尺度结构设计\t28\n3.3.2  多尺度边缘提取\t29\n3.3.3  多尺度边缘融合\t31\n3.4  延伸阅读\t33\n第4章  基于Hough变化的答题卡识别\t34\n4.1  案例背景\t34\n4.2  理论基础\t34\n4.2.1  图像二值化\t35\n4.2.2  倾斜校正\t35\n4.2.3  图像分割\t38\n4.3  程序实现\t40\n4.3.1  图像灰度化\t40\n4.3.2  灰度图像二值化\t41\n4.3.3  图像平滑滤波\t41\n4.3.4  图像矫正\t41\n4.3.5  完整性核查\t42\n4.4  延伸阅读\t51\n第5章  基于阈值分割的车牌定位识别\t53\n5.1  案例背景\t53\n5.2  理论基础\t53\n5.2.1  车牌图像处理\t54\n5.2.2  车牌定位原理\t58\n5.2.3  车牌字符处理\t58\n5.2.4  车牌字符识别\t60\n5.3  程序实现\t62\n5.4  延伸阅读\t69\n第6章  基于分水岭分割进行肺癌诊断\t71\n6.1  案例背景\t71\n6.2  理论基础\t71\n6.2.1  模拟浸水的过程\t72\n6.2.2  模拟降水的过程\t72\n6.2.3  过度分割问题\t72\n6.2.4  标记分水岭分割算法\t72\n6.3  程序实现\t73\n6.4  延伸阅读\t77\n第7章  基于主成分分析的人脸二维码识别\t79\n7.1  案例背景\t79\n7.2  理论基础\t79\n7.2.1  QR二维码简介\t80\n7.2.2  QR二维码的编码和译码流程\t82\n7.2.3  主成分分析方法\t84\n7.3  程序实现\t85\n7.3.1  人脸建库\t85\n7.3.2  人脸识别\t87\n7.3.3  人脸二维码\t87\n7.4  延伸阅读\t92\n第8章  基于知识库的手写体数字识别\t94\n8.1  案例背景\t94\n8.2  理论基础\t94\n8.2.1  算法流程\t94\n8.2.2  特征提取\t95\n8.2.3  模式识别\t96\n8.3  程序实现\t97\n8.3.1  图像处理\t97\n8.3.2  特征提取\t98\n8.3.3  模式识别\t101\n8.4  延伸阅读\t102\n8.4.1  识别器选择\t102\n8.4.2  特征库改善\t102\n第9章  基于特征匹配的英文印刷字符识别\t103\n9.1  案例背景\t103\n9.2  理论基础\t104\n9.2.1  图像预处理\t104\n9.2.2  图像识别技术\t105\n9.3  程序实现\t106\n9.3.1  界面设计\t106\n9.3.2  回调识别\t111\n9.4  延伸阅读\t112\n第10章  基于不变矩的数字验证码识别\t113\n10.1  案例背景\t113\n10.2  理论基础\t114\n10.3  程序实现\t114\n10.3.1  设计GUI界面\t114\n10.3.2  载入验证码图像\t115\n10.3.3  验证码图像去噪\t116\n10.3.4  验证码数字定位\t118\n10.3.5  验证码归一化\t120\n10.3.6  验证码数字识别\t121\n10.3.7  手动确认并入库\t124\n10.3.8  重新生成模板库\t125\n10.4  延伸阅读\t128\n第11章  基于小波技术进行图像融合\t129\n11.1  案例背景\t129\n11.2  理论基础\t130\n11.3  程序实现\t132\n11.3.1  设计GUI界面\t132\n11.3.2  图像载入\t133\n11.3.3  小波融合\t135\n11.4  延伸阅读\t137\n第12章  基于块匹配的全景图像拼接\t138\n12.1  案例背景\t138\n12.2  理论基础\t138\n12.2.1  图像匹配\t139\n12.2.2  图像融合\t141\n12.3  程序实现\t142\n12.3.1  设计GUI界面\t142\n12.3.2  载入图片\t143\n12.3.3  图像匹配\t144\n12.3.4  图像拼接\t148\n12.4  延伸阅读\t153\n第13章  基于霍夫曼图像编码的图像压缩和重建\t155\n13.1  案例背景\t155\n13.2  理论基础\t155\n13.2.1  霍夫曼编码的步骤\t156\n13.2.2  霍夫曼编码的特点\t157\n13.3  程序实现\t158\n13.3.1  设计GUI界面\t158\n13.3.2  压缩和重建\t159\n13.3.3  效果对比\t164\n13.4  延伸阅读\t167\n第14章  基于主成分分析的图像压缩和重建\t168\n14.1  案例背景\t168\n14.2  理论基础\t168\n14.2.1  主成分降维分析原理\t168\n14.2.2  由得分矩阵重建样本\t169\n14.2.3  主成分分析数据压缩比\t170\n14.2.4  基于主成分分析的图像压缩\t170\n14.3  程序实现\t171\n14.3.1  主成分分析的源代码\t171\n14.3.2  图像数组和样本矩阵之间的转换\t172\n14.3.3  基于主成分分析的图像压缩\t173\n14.4  延伸阅读\t176\n第15章  基于小波的图像压缩技术\t177\n15.1  案例背景\t177\n15.2  理论基础\t178\n15.3  程序实现\t180\n15.4  延伸阅读\t188\n第16章  基于融合特征的以图搜图技术\t189\n16.1  案例背景\t189\n16.2  理论基础\t189\n16.3  程序实现\t191\n16.3.1  图像预处理\t191\n16.3.2  计算特征\t191\n16.3.3  图像检索\t194\n16.3.4  结果分析\t194\n16.4  延伸阅读\t196\n第17章  基于Harris的角点特征检测\t198\n17.1  案例背景\t198\n17.2  理论基础\t199\n17.2.1  Harris的基本原理\t199\n17.2.2  Harris算法的流程\t201\n17.2.3  Harris角点的性质\t201\n17.3  程序实现\t202\n17.3.1  Harris算法的代码\t202\n17.3.2  角点检测实例\t204\n17.4  延伸阅读\t205\n第18章  基于GUI搭建通用视频处理工具\t206\n18.1  案例背景\t206\n18.2  理论基础\t206\n18.3  程序实现\t208\n18.3.1  设计GUI界面\t208\n18.3.2  实现GUI界面\t209\n18.4  延伸阅读\t220\n第19章  基于语音识别的信号灯图像\n模拟控制技术\t221\n19.1  案例背景\t221\n19.2  理论基础\t221\n19.3  程序实现\t223\n19.4  延伸阅读\t232\n第20章  基于帧间差法进行视频目标检测\t234\n20.1  案例背景\t234\n20.2  理论基础\t234\n20.2.1  帧间差分法\t235\n20.2.2  背景差分法\t236\n20.2.3  光流法\t236\n20.3  程序实现\t237\n20.4  延伸阅读\t24\n第21章  路面裂缝检测系统设计\t247\n21.1  案例背景\t247\n21.2  理论基础\t247\n21.2.1  图像灰度化\t248\n21.2.2  图像滤波\t250\n21.2.3  图像增强\t252\n21.2.4  图像二值化\t253\n21.3  程序实现\t255\n21.4  延伸阅读\t267\n第22章  基于K-means聚类算法的图像分割\t268\n22.1  案例背景\t268\n22.2  理论基础\t268\n22.2.1  K-means聚类算法的原理\t268\n22.2.2  K-means聚类算法的要点\t269\n22.2.3  K-means聚类算法的缺点\t270\n22.2.4  基于K-means聚类算法进行图像分割\t270\n22.3  程序实现\t271\n22.3.1  样本间的距离\t271\n22.3.2  提取特征向量\t272\n22.3.3  图像聚类分割\t273\n22.4  延伸阅读\t275\n第23章  基于光流场的车流量计数应用\t276\n23.1  案例背景\t276\n23.2  理论基础\t276\n23.2.1  基于光流法检测运动的原理\t276\n23.2.2  光流场的主要计算方法\t277\n23.2.3  梯度光流场约束方程\t278\n23.2.4  Horn-Schunck光流算法\t280\n23.3  程序实现\t281\n23.3.1  计算视觉系统工具箱简介\t281\n23.3.2  基于光流法检测汽车运动\t282\n23.4  延伸阅读\t287\n第24章  基于Simulink进行图像和视频处理\t289\n24.1  案例背景\t289\n24.2  模块介绍\t289\n24.2.1  分析和增强模块库（Analysis和Enhancement）\t290\n24.2.2  转化模块库（Conversions）\t291\n24.2.3  滤波模块库（Filtering）\t292\n24.2.4  几何变换模块库（Geometric Transformations）\t292\n24.2.5  形态学操作模块库（Morphological Operations）\t292\n24.2.6  输入模块库（Sources）\t293\n24.2.7  输出模块库（Sinks）\t293\n24.2.8  统计模块库（Statistics）\t294\n24.2.9  文本和图形模块库（Text 和 Graphic）\t295\n24.2.10  变换模块库（Transforms）\t295\n24.2.11  其他工具模块库（Utilities）\t295\n24.3  仿真案例\t296\n24.3.1  搭建组织模型\t296\n24.3.2  仿真执行模型\t298\n24.3.3  自动生成报告\t299\n24.4  延伸阅读\t302\n第25章  基于小波变换的数字水印技术\t304\n25.1  案例背景\t304\n25.2  理论基础\t304\n25.2.1  数字水印技术的原理\t305\n25.2.2  典型的数字水印算法\t307\n25.2.3  数字水印攻击和评价\t309\n25.2.4  基于小波的水印技术\t310\n25.3  程序实现\t312\n25.3.1  准备载体和水印图像\t312\n25.3.2  小波数字水印的嵌入\t313\n25.3.3  小波数字水印的提取\t317\n25.3.4  小波水印的攻击试验\t319\n25.4  延伸阅读\t323\n第26章  基于最小误差法的胸片分割技术\t325\n26.1  案例背景\t325\n26.2  理论基础\t325\n26.2.1  图像增强\t326\n26.2.2  区域选择\t326\n26.2.3  形态学滤波\t327\n26.2.4  基于最小误差法进行胸片分割\t328\n26.3  程序实现\t329\n26.3.1  设计GUI界面\t329\n26.3.2  图像预处理\t330\n26.3.3  基于最小误差法进行图像分割\t333\n26.3.4  形态学后处理\t335\n26.4  延伸阅读\t338\n第27章  基于区域生长的肝脏影像分割系统\t339\n27.1  案例背景\t339\n27.2  理论基础\t340\n27.2.1  阈值分割\t340\n27.2.2  区域生长\t340\n27.2.3  基于阈值预分割的区域生长\t341\n27.3  程序实现\t342\n27.4  延伸阅读\t346\n第28章  基于计算机视觉的自动驾驶应用\t347\n28.1  案例背景\t347\n28.2  理论基础\t348\n28.2.1  环境感知\t348\n28.2.2  行为决策\t348\n28.2.3  路径规划\t349\n28.2.4  运动控制\t349\n28.3  程序实现\t349\n28.3.1  传感器数据载入\t349\n28.3.2  追踪器创建\t351\n28.3.3  碰撞预警\t353\n28.4  延伸阅读\t358\n第29章  基于深度学习的汽车目标检测\t359\n29.1  案例背景\t359\n29.2  理论基础\t360\n29.2.1  基本架构\t360\n29.2.2  卷积层\t360\n29.2.3  池化层\t362\n29.3  程序实现\t362\n29.3.1  加载数据\t362\n29.3.2  构建CNN\t364\n29.3.3  训练CNN\t365\n29.3.4  评估训练效果\t367\n29.4  延伸阅读\t368\n第30章  基于深度学习的视觉场景\n识别\t370\n30.1  案例背景\t370\n30.2  理论基础\t371\n30.3  程序实现\t371\n30.3.1  环境配置\t372\n30.3.2  数据集制作\t373\n30.3.3  网络训练\t375\n30.3.4  网络测试\t381\n30.4  延伸阅读\t383\n第31章  深度学习综合应用\t385\n31.1  应用背景\t385\n31.2  理论基础\t387\n31.2.1  分类识别\t387\n31.2.2  目标检测\t391\n31.3  案例实现1：基于CNN的数字识别\t 395\n31.3.1  自定义CNN\t397\n31.3.2  AlexNet\t399\n31.3.3  基于MATLAB进行实验设计\t405\n31.3.4  基于TensorFlow进行实验设计\t413\n31.3.5  实验小结\t418\n31.4  案例实现2：基于CNN的物体识别\t418\n31.4.1  CIFAR-10数据集\t418\n31.4.2  VggNet\t421\n31.4.3  ResNet\t422\n31.4.4  实验设计\t424\n31.4.5  实验小结\t432\n31.5  案例实现3：基于CNN的图像矫正\t\t432\n31.5.1  倾斜数据集\t432\n31.5.2  自定义CNN回归网络\t434\n31.5.3  AlexNet回归网络\t436\n31.5.4  实验设计\t437\n31.5.5  实验小结\t445\n31.6  案例实现4：基于LSTM的时间序列分析\t445\n31.6.1  厄尔尼诺南方涛动指数数据\t446\n31.6.2  样条拟合分析\t446\n31.6.3  基于MATLAB进行LSTM分析\t448\n31.6.4  基于Keras进行LSTM分析\t451\n31.6.5  实验小结\t455\n31.7  案例实现5：基于深度学习的以图搜图技术\t455\n31.7.1  人脸的深度特征\t455\n31.7.2  AlexNet的特征\t460\n31.7.3  GoogleNet的特征\t461\n31.7.4  深度特征融合计算\t462\n31.7.5  实验设计\t462\n31.7.6  实验小结\t46731.8  案例实现6：基于YOLO的交通目标检测应用\t467\n31.8.1  车辆目标的YOLO检测\t468\n31.8.2  交通标志的YOLO检测\t475\n31.9  延伸阅读\t481","pages":"496","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33509210.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33509210.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33509210.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34872153\/","id":"34872153","publisher":"","isbn10":"7121374838","isbn13":"9787121374838","title":"计算机视觉与深度学习实战：以MATLAB、Python为工具","url":"https:\/\/api.douban.com\/v2\/book\/34872153","alt_title":"","author_intro":"刘衍琦，机器学习算法专家及视觉AI课程讲师，擅长视觉智能分析、多源异构数据采集和挖掘等工程化应用，并长期从事视觉大数据工程相关工作，涉及互联网海量图像、声纹、视频检索，以及OCR图文检索、手绘草图智能识别、特殊通道数据分析等应用的算法架构与研发，对图文识别、大规模以图搜图、数据感知和采集等进行过深入研究，并结合行业背景推动了一系列工程化应用。曾主编和参与编写多本书籍。\n詹福宇，博士，资深飞行控制算法专家，毕业于西北工业大学航空学院飞行器设计专业。拥有近10年仿真控制开发经验，熟悉Simulink基于模型设计的流程，曾主编和参与编写多本书籍。\n王德建，档案管理副研究馆员，毕业于西安建筑科技大学系统工程专业，从事档案数字化、智能化分类、OCR图文检索、图像智能识别相关工作。\n陈峰蔚，熟悉机器学习、深度学习及计算机视觉在智能交通、智能驾驶领域的应用，长期从事汽车品牌识别、车型细粒度分类、目标检测与分割方面的相关工作，精通MATLAB、Python编程及TensorFlow深度学习框架，参与了多项专利的设计与开发。\n蒋献文，资深专业医事放射师，毕业于中国医药大学医学院临床医学研究所。擅长医学图像处理技术、放射线射影技术及手术房计算机断层与血管摄影技术，在临床放射技术学与图像处理方面进行过深入研究并发表了相关医学论文。\n周华英，新能源汽车高级工程师，毕业于北京交通大学交通运输规划与管理专业。长期进行纯电动及混合动力汽车系统建模与控制、汽车动力系统与控制、电动汽车能量管理和控制优化等研究，曾主编和参与编写多本书籍。","summary":"《计算机视觉与深度学习实战：以MATLAB、Python为工具》详细讲解了36个计算机视觉与深度学习实战案例（含可运行程序），涉及雾霾去噪、答题卡自动阅卷、肺部图像分割、小波数字水印、图像检索、人脸二维码识别、车牌定位及识别、霍夫曼图像压缩、手写数字识别、英文字符文本识别、眼前节组织提取、全景图像拼接、小波图像融合、基于语音识别的音频信号模拟灯控、路面裂缝检测识别、视频运动估计追踪、Simulink图像处理、胸片及肝脏分割、基于深度学习的汽车目标检测、基于计算机视觉的自动驾驶应用、基于深度学习的视觉场景识别、基于深度特征的以图搜画、基于CNN的字符识别、基于CNN的物体识别、基于CNN的图像矫正、基于LSTM的时间序列分析、基于深度学习的以图搜图技术、基于YOLO的智能交通目标检测等多项重要技术及应用，涵盖了数字图像处理中几乎所有的基本模块，并延伸到了深度学习理论及其应用方面。工欲善其事，必先利其器，本书对每个数字图像处理的知识点都提供了丰富、生动的案例素材，并以MATLAB、Python为工具详细讲解了实验的核心程序。通过对这些程序的阅读、理解和仿真运行，读者可以更加深刻地理解图像处理的内容，并且更加熟练地掌握计算机视觉及深度学习在不同实际领域中的用法。\n《计算机视觉与深度学习实战：以MATLAB、Python为工具》以案例为基础，结构布局紧凑，内容深入浅出，实验简捷高效，适合计算机、信号通信和自动化等相关专业的教师、本科生、研究生，以及广大从事数字图像处理的工程研发人员阅读参考。","series":{"id":"41172","title":"博文视点AI系列"},"price":"109"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["曾芃壹"],"pubdate":"2019-10-10","tags":[{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33501032.jpg","binding":"平装","translator":[],"catalog":"前言\t阅读\n第一部分　基础篇\n第1章　准备工作\n第2章　Tensor基础\n第3章　深度学习基础\t阅读\n第二部分　实战篇\n第4章　迁移学习\n第5章　序列转序列模型\n第6章　生成对抗网络\n第7章　深度强化学习\n第8章　风格迁移\n第三部分　高级篇\n第9章　PyTorch扩展\n第10章　PyTorch模型迁移\n第11章　PyTorch可视化\n第12章　PyTorch的并行计算","pages":"233","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33501032.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33501032.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33501032.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34858119\/","id":"34858119","publisher":"人民邮电出版社","isbn10":"7115519196","isbn13":"9787115519191","title":"PyTorch深度学习入门","url":"https:\/\/api.douban.com\/v2\/book\/34858119","alt_title":"","author_intro":"曾芃壹，现为中山大学数据科学与计算机学院在读硕士，主要研究兴趣有深度学习、语音识别、推荐系统、自动犯罪侦查等。熟悉 C、C++、Java、Python 等多种程序设计语言，Flask 建站技术以及 PyTorch、TensorFlow 深度学习框架。","summary":"本书用浅显易懂的语言，图文并貌地讲解了深度学习的基础知识，从如何挑选硬件到神经网络的初步搭建，再到实现图片识别、文本翻译、强化学习、生成对抗网络等多个目前最流行的深度学习应用。书中基于目前流行的PyTorch框架，运用Python语言实现了各种深度学习的应用程序，让理论和实践紧密结合。","series":{"id":"13000","title":"图灵原创"},"price":"59.00 元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34885846\/","id":"34885846","publisher":"","isbn10":"7313218885","isbn13":"9787313218889","title":"高中思想政治深度学习手册：中国特色社会主义（必修1 统编教材版）","url":"https:\/\/api.douban.com\/v2\/book\/34885846","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"V2著作问世，带你跨越颠覆性新版。从1到2快人一步，从0到2一步到位","author":["赵英俊"],"pubdate":"2019-12","tags":[{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33524287.jpg","binding":"","translator":[],"catalog":"目录\n第1章  Python基础编程入门\t1\n1.1  Python的历史\t1\n1.1.1  Python版本的演进\t1\n1.1.2  Python的工程应用情况\t2\n1.2  Python的基本数据类型\t2\n1.3  Python数据处理工具之Pandas\t6\n1.3.1  数据读取和存储\t7\n1.3.2  数据查看和选取\t8\n1.3.3  数据处理\t11\n1.4  Python图像处理工具之PIL\t14\n1.4.1  PIL简介\t14\n1.4.2  PIL接口详解\t14\n1.4.3  PIL图像处理实践\t18\n第2章  TensorFlow 2.0快速入门\t21\n2.1  TensorFlow 2.0简介\t21\n2.2  TensorFlow 2.0环境搭建\t22\n2.2.1  CPU环境搭建\t22\n2.2.2  基于Docker的GPU环境搭建\t23\n2.3  TensorFlow 2.0基础知识\t25\n2.3.1  TensorFlow 2.0 Eager模式简介\t25\n2.3.2  TensorFlow 2.0 AutoGraph简介\t26\n2.3.3  TensorFlow 2.0低阶API基础编程\t26\n2.4  TensorFlow 2.0高阶API（tf.keras）\t32\n2.4.1  tf.keras高阶API概览\t32\n2.4.2  tf.keras高阶API编程\t34\n第3章  基于CNN的图像识别应用编程实践\t36\n3.1  CNN相关基础理论\t36\n3.1.1  卷积神经网络概述\t36\n3.1.2  卷积神经网络结构\t36\n3.1.3  卷积神经网络三大核心概念\t38\n3.2  TensorFlow 2.0 API详解\t38\n3.2.1  tf.keras.Sequential\t39\n3.2.2  tf.keras.layers.Conv2D\t41\n3.2.3  tf.keras.layers.MaxPool2D\t42\n3.2.4  tf.keras.layers.Flatten与tf.keras.layer.Dense\t42\n3.2.5  tf.keras.layers.Dropout\t43\n3.2.6  tf.keras.optimizers.Adam\t43\n3.3  项目工程结构设计\t44\n3.4  项目实现代码详解\t44\n3.4.1  工具类实现\t45\n3.4.2  cnnModel实现\t46\n3.4.3  执行器实现\t48\n3.4.4  Web应用实现\t52\n第4章  基于Seq2Seq的中文聊天机器人编程实践\t55\n4.1  NLP基础理论知识\t55\n4.1.1  语言模型\t55\n4.1.2  循环神经网络\t57\n4.1.3  Seq2Seq模型\t59\n4.2  TensorFlow 2.0 API详解\t61\n4.2.1  tf.keras.preprocessing.text.Tokenizer\t61\n4.2.2  tf.keras.preprocessing.sequence.pad_sequences\t62\n4.2.3  tf.data.Dataset.from_tensor_slices\t63\n4.2.4  tf.keras.layers.Embedding\t63\n4.2.5  tf.keras.layers.GRU\t63\n4.2.6  tf.keras.layers.Dense\t65\n4.2.7  tf.expand_dims\t65\n4.2.8  tf.keras.optimizers.Adam\t65\n4.2.9  tf.keras.losses.SparseCategoricalCrossentropy\t66\n4.2.10  tf.math.logical_not\t66\n4.2.11  tf.concat\t66\n4.2.12  tf.bitcast\t67\n4.3  项目工程结构设计\t67\n4.4  项目实现代码详解\t68\n4.4.1  工具类实现\t68\n4.4.2  data_util实现\t69\n4.4.3  seq2seqModel实现\t71\n4.4.4  执行器实现\t77\n4.4.5  Web应用实现\t83\n第5章  基于CycleGAN的图像风格迁移应用编程实践\t85\n5.1  GAN基础理论\t85\n5.1.1  GAN的基本思想\t85\n5.1.2  GAN的基本工作机制\t86\n5.1.3  GAN的常见变种及应用场景\t86\n5.2  CycleGAN的算法原理\t88\n5.3  TensorFlow 2.0 API详解\t88\n5.3.1  tf.keras.Sequential\t88\n5.3.2  tf.keras.Input\t91\n5.3.3  tf.keras.layers.BatchNormalization\t91\n5.3.4  tf.keras.layers.Dropout\t92\n5.3.5  tf.keras.layers.Concatenate\t93\n5.3.6  tf.keras.layers.LeakyReLU\t93\n5.3.7  tf.keras.layers.UpSampling2D\t93\n5.3.8  tf.keras.layers.Conv2D\t93\n5.3.9  tf.optimizers.Adam\t94\n5.4  项目工程结构设计\t95\n5.5  项目实现代码详解\t96\n5.5.1  工具类实现\t96\n5.5.2  CycleganModel实现\t100\n5.5.3  执行器实现\t105\n5.5.4  Web应用实现\t109\n第6章  基于Transformer的文本情感分析编程实践\t111\n6.1  Transformer相关理论知识\t111\n6.1.1  Transformer基本结构\t111\n6.1.2  注意力机制\t112\n6.1.3  位置编码\t116\n6.2  TensorFlow 2.0 API详解\t117\n6.2.1  tf.keras.preprocessing.text.Tokenizer\t117\n6.2.2  tf.keras.preprocessing.sequence.pad_sequences\t118\n6.2.3  tf.data.Dataset.from_tensor_slices\t118\n6.2.4  tf.keras.layers.Embedding\t118\n6.2.5  tf.keras.layers.Dense\t119\n6.2.6  tf.keras.optimizers.Adam\t119\n6.2.7  tf.optimizers.schedules.LearningRateSchedule\t120\n6.2.8  tf.keras.layers.Conv1D\t120\n6.2.9  tf.nn.moments\t121\n6.3  项目工程结构设计\t121\n6.4  项目实现代码详解\t122\n6.4.1  工具类实现\t122\n6.4.2  data_util实现\t124\n6.4.3  textClassiferMode实现\t128\n6.4.4  执行器实现\t138\n6.4.5  Web应用实现\t142\n第7章  基于TensorFlow Serving的模型部署实践\t144\n7.1  TensorFlow Serving框架简介\t144\n7.1.1  Servable\t145\n7.1.2  Source\t145\n7.1.3  Loader\t145\n7.1.4  Manager\t145\n7.2  TensorFlow Serving环境搭建\t146\n7.2.1  基于Docker搭建TensorFlow Serving环境\t146\n7.2.2  基于Ubuntu 16.04搭建TensorFlow Serving环境\t146\n7.3  API详解\t147\n7.3.1  tf.keras.models.load_model\t147\n7.3.2  tf.keras.experimental.export_saved_model\t147\n7.3.3  tf.keras.backend.set_learning_phase\t148\n7.4  项目工程结构设计\t148\n7.5  项目实现代码详解\t149\n7.5.1  工具类实现\t149\n7.5.2  模型文件导出模块实现\t150\n7.5.3  模型文件部署模块实现\t150\n7.5.4  Web应用模块实现\t152","pages":"168","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33524287.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33524287.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33524287.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34894614\/","id":"34894614","publisher":"电子工业出版社","isbn10":"7121376466","isbn13":"9787121376467","title":"走向TensorFlow 2.0：深度学习应用编程快速入门","url":"https:\/\/api.douban.com\/v2\/book\/34894614","alt_title":"","author_intro":"赵英俊\n阿里云人工智能领域MVP，目前在阿里云从事产业、工业智能方向的解决方案架构师工作，基于数据智能、人工智能等技术和产品解决传统产业、工业的痛点和难点问题。现个人维护一个优秀的开源NLP项目——基于Seq2Seq的中文智能聊天机器人，目前GitHub stars超过1100。","summary":"编辑推荐\n√ TensorFlow 2.0与上一版对比，可以视为一个完全不同的深度学习框架，必须重学。\n√ 面向应用落地，涵盖图像识别|对话机器人|生成网络图片风格迁移|文本情感分析等。\n√ 本书实战样例丰富，从TensorFlow模型训练到生产环境部署，全程剖析AI系统开发。\n√ 通俗易懂地讲述人工智能从基本原理到知识结构再到工业应用，非常适合突击入门。\n内容提要\n《走向TensorFlow 2.0：深度学习应用编程快速入门》是TensorFlow 2.0编程实践的入门类书籍，目的是在TensorFlow 2.0正式版发布之际能够帮助大家快速了解其核心特性及基本编程技巧。本书通过5个常用的人工智能编程案例，帮助大家掌握如何在工作中使用TensorFlow 2.0进行应用开发。\n《走向TensorFlow 2.0：深度学习应用编程快速入门》内容覆盖了Python和TensorFlow基础入门、自然语言处理和CV领域的实践案例、模型的服务化部署，希望在基于TensorFlow 2.0的人工智能编程上能够助你一臂之力。\n精彩节摘\n推荐序\nAlphaGo以“Master”（大师）作为ID，横空出世，在中国乌镇围棋峰会上，它与世界围棋冠军柯洁对战，在围棋领域，击败人类精英。\n继而，AlphaGo Zero，从空白状态起步，在无任何人类输入的条件下，能够迅速自学围棋，并以100∶0的战绩击败人类“前辈”。\n机器学习，在尝试以人类经验图谱进行学习时，短短数年，就在围棋领域，击败了拥有几千年沉淀的人类顶尖高手。\n如果说这是机器的力量，那么AlphaGo Zero在尝试不以人类的经验图谱进行自我深度学习时，产生了另一个质的飞跃，这，就是机器学习的力量。\n机器学习作为人工智能的一种类型，可以让软件根据大量的数据来对未来的情况进行阐述或预判。这项技术，可以通过人类经验学习和自我深度学习，帮助人类在各个领域取得突破性进展。如今，领先的科技巨头无不在机器学习方面予以极大投入。Google、苹果、微软、阿里巴巴、百度，无不深度参与，期望成为机器学习技术的铺路者、领路者、践行者。\n未来是什么样子的，没人说得清，但是未来在一步步来临的路上，必然有机器学习技术的铺垫。\n2011年，“谷歌大脑”开始开展面向科学研究和工程应用的大规模深度学习。TensorFlow是Google第二代机器学习系统。如今，Google将此系统开源，并将此系统的参数公布给业界工程师、学者和大量拥有编程能力的技术人员，正是为了让全世界的人都能够从机器学习与人工智能中获益。\nTensorFlow社区，是机器学习领域内最活跃和友善的社区之一。社区的好处，在于学习的路上，有很多人同行，你的任何问题和疑惑，在社区中都能得到相当不错的答案。如果你想了解和学习机器学习，那么TensorFlow是一个相当不错的选择。如果你想学习TensorFlow，那么这本书会让你以最低难度领略机器学习的奥秘。\n我可以代表这样一类人，作为多年的技术工作者，在工作中和机器学习也有一些接触，对机器学习有比较浓厚的兴趣。拿到这本书，相见恨晚，翻阅着，用电脑作为武器，按照书中所示，比画着，一招一式中，不觉间就进入了机器学习的奇妙世界。这也使我通过学习机器如何进行自我深度学习，让自己从另一个角度进行思考，得到收获。\n英俊的这本书，书如其名，内容英朗俊秀，深入浅出，浅显易懂，思在天地，行在山野。\n推荐读者群体：期望入门机器学习的学生、技术工作者及其身边的人。如果你恰好是其中一类人，又读到了这里，这本书请不要错过，因为你阅读的书中项目可能会比Android系统更加深远地影响着世界！\n阿里巴巴菜鸟网络技术专家  薛巍\n中国，杭州\n2019年9月\n媒体评论\n本书探讨了开源机器学习软件库TensorFlow 2.0的诸多应用实践，内容涵盖各种热门的应用场景，包括图像识别、自然语言对话机器人、基于生成网络的图片风格迁移、文本情感分析等。该书是为“应用落地”而编写的，每章均附有大量的代码和注释，帮助读者更快地入门和实现应用落地。本书前两章分别介绍了Python的用法和TensorFlow的基础，在最后一章又探讨了如何将TensorFlow所训练的模型部署到生产环境中。本书对有志于在相关领域进行研究并快速产出原型的技术人员具有很高的参考价值。\n寿黎但\n浙江大学计算机学院教授\n深度学习在工业领域逐步得到应用，尤其是其与物联网的结合，在智能家居、智慧城市、智慧交通、智慧医疗、智慧教育、智慧工业等多种行业场景中具有广阔的发展空间。而在这一发展过程中，培养合格的人工智能与物联网结合方向的研发人才，实现人工智能技术在工业应用领域的技术落地和实际应用，是人工智能领域教育培训的一个重要方向。本书详细介绍了深度学习基本原理和基于TensorFlow 2.0的编程实践入门，可以为人工智能领域的入门读者提供非常好的实践导引。\n董亚波\n浙江大学计算机学院副教授，人工智能研究所副所长\n在与本书作者的项目合作中，借助其丰富的TensorFlow开发经验，使得项目得以顺利进行。有幸能够看到本书样章，书中内容短小精悍，有大量实战样例。读者阅读本书后，能够快速走进以TensorFlow 2.0为基础的AI系统开发领域。\n牟磊育\n中国地震局地球物理研究所 地震数据质量人工智能检测项目负责人\n这一波人工智能浪潮与以往我们所讨论的人工智能最大的不同，就是其已经迅速在工业领域进行应用。互联网+人工智能+大数据的时代正在到来，新一代人工智能正加速推进经济向智能化跃升。因此，投资界非常看好目前人工智能在IOT、5G等方向的应用前景。本书作者以深厚的专业知识和多年的实践经验，由浅入深，用生动语言讲述了人工智能的基本原理、知识结构、工业应用。相信此书能够为人工智能爱好者，以及在此领域开展技术研究的读者提供一个通俗易懂的入门导引，帮助读者更快捷地进入人工智能应用领域。\n詹家芳\n原德国林德工程（杭州）有限公司总经理，留美硕士\n前言\n坦白地说，在我的技术生涯规划中还未想过要在30岁生日之前出一本技术书。在30岁这一年里，我感觉有280天以上是每天工作超过12小时的，每天我积极处理工作上的事情以求在事业上取得成就、学习自己欠缺的技术以求提升能力、输出自己学到的知识以期帮助更多的人；在30岁这一年里，我第一次体会到颈椎病带来的痛苦，也将一直引以为傲的视力熬成了近视。之所以如此逼自己，大概是因为自己的不自信和痴痴的责任心在作祟。\n创作初衷\n最开始筹划这本书的时候，也只是想将自己在小象学院的课程内容整理成书（课程内容是关于TensorFlow 1.x的），但是当看到TensorFlow 2.0发布计划公布之后，我又觉得写一本关于TensorFlow 1.x的书是没有意义的，并且会浪费读者的时间和精力。因此，我彻底推翻书稿原来规划的内容，重新调整所有的知识点，所有的实践案例都用TensorFlow 2.0进行重新编程，从而导致交稿日期一拖再拖。说到这里，我要特别感谢电子工业出版社的张春雨老师，他一直在推动、鼓励甚至督促我，使我跌跌撞撞、写写停停完成了初稿、提升稿、提交稿。在本书写作过程中，江郎才尽和被掏空的感觉对我来说是最大的煎熬。我一直是一个喜欢分享知识和观点的人，但是这种成体系的、持续的、面向大众的分享和输出让我对自己的要求不断提高，总是担心如果写错了会误人子弟。这不是一个轻松的过程，尤其是在创业的初期，我首先要做的是全力以赴、出色地完成产品和技术工作，然后用本来就不多的休息时间来完成技术的提升和本书的编写。从一个追求技术深度的技术人员的视角来看，本书不能令我百分百满意，但是万事总要迈出第一步，希望这本书能够为读者带来一定的参考和学习价值。\n内容结构\n本书在内容规划上分3个部分，共7章，具体如下。\n第1部分：编程基础入门，包括Python基础编程入门和TensorFlow 2.0快速入门知识。\n\t第1章　Python基础编程入门：本章阐述了Python的历史、基本数据类型、数据处理工具Pandas、图像处理工具PIL等，基本覆盖了在后续章节中要用到的Python编程知识和工具。\n\t第2章　TensorFlow 2.0快速入门：本章从快速上手的角度，通过TensorFlow 2.0的简介、环境搭建、基础知识、高级API编程等内容详细讲解了TensorFlow 2.0编程所需的知识和技巧。\n第2部分：TensorFlow 2.0编程实践，讲解了4个编程案例，分别为基于CNN的图像识别应用、基于Seq2Seq的中文聊天机器人、基于CycleGAN的图片风格迁移应用、基于Transformer的文本情感分析。\n\t第3章　基于CNN的图像识别应用编程实践：本章介绍了基于CNN实现对CFAIR-10图像数据的训练以及在线图像分类预测，包括CNN基础理论知识、编程中用到的TensorFlow 2.0 API详解、项目工程结构设计、项目实现代码详解等。\n\t第4章　基于Seq2Seq的中文聊天机器人编程实践：本章介绍了基于Seq2Seq实现对“小黄鸡”对话数据集的训练以及在线中文聊天，包括自然语言模型、RNN（循环神经网络）、Seq2Seq模型、编程中用到的TensorFlow 2.0 API详解、项目工程结构设计、项目实现代码详解等。\n\t第5章　基于CycleGAN的图片风格迁移应用编程实践：本章介绍了基于CycleGAN实现对Apple2Orange数据集的训练以及图像在线风格迁移，包括GAN基础理论知识、CycleGAN算法原理、编程中用到的TensorFlow 2.0 API详解、项目工程结构设计、项目实现代码详解等。\n\t第6章　基于Transformer的文本情感分析编程实践：本章介绍了基于Transformer的变形结构实现对IMDB评价数据集的训练以及在线对文本的情感分析和预测，包括Transformer基本结构、注意力机制、位置编码、编程中用到的TensorFlow 2.0 API详解、项目工程结构设计、项目实现代码详解等。\n第3部分：TensorFlow 2.0模型服务化部署，采用TensorFlow Serving实现对完成训练的模型进行生产环境的服务化部署。\n\t第7章　基于TensorFlow Serving的模型部署实践：本章介绍了基于TensorFlow Serving框架实现对基于CNN的图像分类模型的服务化部署，包括TensorFlow Serving框架简介、TensorFlow Serving环境搭建、编程中用到的TensorFlow 2.0 API详解、项目工程结构设计、项目实现代码详解等。\n致谢\n最后，衷心感谢我的妻子包佳楠，感谢她一直以来的鼓励，以及一丝不苟地校正书稿中的语法错误和错别字，每次当我想要放弃的时候，她总是用几句不轻不重的话语让我重新回到本书的编写中来。","series":{"id":"41172","title":"博文视点AI系列"},"price":"55.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34825986\/","id":"34825986","publisher":"","isbn10":"7553971006","isbn13":"9787553971001","title":"思维训练·初中数学深度学习八年级上册","url":"https:\/\/api.douban.com\/v2\/book\/34825986","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34837626\/","id":"34837626","publisher":"","isbn10":"7115505853","isbn13":"9787115505859","title":"深度学习案例精粹","url":"https:\/\/api.douban.com\/v2\/book\/34837626","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["张若非","付强","高斌","张耿豪","叶挺"],"pubdate":"2019-9","tags":[{"count":5,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33477440.jpg","binding":"平装","translator":[],"catalog":"第1 章\n神经网络发展史 \/ 1\n1.1 神经网络的早期雏形 \/ 3\n1.1.1 联结主义和Hebb 学习规则 \/ 4\n1.1.2 Oja 学习规则及主分量分析 \/ 5\n1.1.3 早期的神经元模型 \/ 5\n1.2 现代神经网络 \/ 6\n1.2.1 反向传播算法 \/ 6\n1.2.2 神经网络的通用函数近似性 \/ 8\n1.2.3 深度的必要性 \/ 9\n1.3 深度学习发展历史中的重要神经网络 \/ 10\n1.3.1 深度神经网络的兴起 \/ 10\n1.3.2 自组织特征映射 \/ 10\n1.3.3 霍普菲尔德神经网络 \/ 11\n1.3.4 玻尔兹曼机及受限玻尔兹曼机 \/ 12\n1.3.5 深度信念网 \/ 14\n1.3.6 其他深度神经网络 \/ 15\n1.4 本章小结 \/ 15\n参考文献 \/ 16\n第2 章\n深度学习开源框架 \/ 17\n2.1 主流的深度学习开源框架 \/ 18\n2.2 简单神经网络模型在不同框架上的实现对比 \/ 29\n2.3 本章小结 \/ 44\n参考文献 \/ 45\n第3 章\n多层感知机在自然语言处理方面的应用 \/ 46\n3.1 词和文本模型的发展历程 \/ 47\n3.2 Word2Vec 模型：基于上下文的分布式表达 \/ 49\n3.2.1 Skip-Gram 算法的训练流程 \/ 50\n3.2.2 Skip-Gram 算法的网络结构 \/ 53\n3.2.3 代价函数 \/ 54\n3.3 应用TensorFlow 实现Word2Vec 模型 \/ 58\n3.3.1 定义计算图：训练语料库预处理 \/ 60\n3.3.2 模型计算图的实现 \/ 63\n3.4 Word2Vec 模型的局限及改进 \/ 66\n3.5 本章小结 \/ 67\n参考文献 \/ 68\n第4 章\n卷积神经网络在图像分类中的应用 \/ 69\n4.1 图像识别和图像分类的发展 \/ 72\n4.2 AlexNet \/ 73\n4.2.1 网络模型结构 \/ 74\n4.2.2 AlexNet 的具体改进 \/ 79\n4.2.3 代价函数 \/ 83\n4.3 应用TensorFlow 实现AlexNet \/ 83\n4.3.1 读取训练图像集 \/ 83\n4.3.2 模型计算图的实现 \/ 84\n4.4 本章小结 \/ 85\n参考文献 \/ 86\n第5 章\n递归神经网络 \/ 87\n5.1 递归神经网络应用背景介绍 \/ 88\n5.2 递归神经网络模型介绍 \/ 89\n5.2.1 递归神经网络模型结构 \/ 89\n5.2.2 双向递归神经网络 \/ 90\n5.2.3 长短期记忆模型 \/ 91\n5.3 递归神经网络展望 \/ 94\n5.4 本章小结 \/ 95\n参考文献 \/ 95\n第6 章\nDeepIntent 模型在信息检索领域的应用 \/ 96\n6.1 信息检索在搜索广告中的应用发展 \/ 97\n6.2 含有注意力机制的RNN 模型 \/ 99\n6.2.1 网络模型结构 \/ 100\n6.2.2 代价函数 \/ 104\n6.3 应用TensorFlow 实现DeepIntent 模型 \/ 107\n6.3.1 定义计算图 \/ 107\n6.3.2 定义代价函数及优化算法 \/ 114\n6.3.3 执行计算图进行训练 \/ 118\n6.4 本章小结 \/ 119\n参考文献 \/ 120\n第7 章\n图像识别及在广告搜索方面的应用 \/ 121\n7.1 视觉搜索 \/ 122\n7.2 方法和系统 \/ 124\n7.2.1 图像DNN 编码器 \/ 124\n7.2.2 利用Rich-CDSSM 降低维度 \/ 125\n7.2.3 快速最近邻搜索系统 \/ 127\n7.2.4 精密层 \/ 127\n7.2.5 端到端服务系统 \/ 128\n7.3 评测 \/ 129\n7.4 用于演示的Visual Shopping Assistant 应用程序 \/ 131\n7.5 相关工作 \/ 132\n7.6 本章小结 \/ 133\n第8 章\nSeq2Seq 模型在聊天机器人中的应用 \/ 134\n8.1 Seq2Seq 模型应用背景 \/ 135\n8.2 Seq2Seq 模型的应用方法 \/ 136\n8.3 含有注意力机制的多层Seq2Seq 模型 \/ 137\n8.3.1 词嵌入层 \/ 137\n8.3.2 可变深度LSTM 递归层 \/ 138\n8.3.3 注意力机制层 \/ 139\n8.3.4 投影层 \/ 139\n8.3.5 损失函数（loss function）和端到端训练 \/ 140\n8.4 信息导向的自适应序列采样 \/ 142\n8.5 多轮项目推荐 \/ 143\n8.6 熵作为信心的度量 \/ 143\n8.6.1 直观的定义和讨论 \/ 143\n8.6.2 序列后验估计的不确定性 \/ 145\n8.6.3 信息导向的抽样：最大化预期信息增益的原则 \/ 145\n8.6.4 Seq2Seq 模型的3 个应用程序 \/ 146\n8.6.5 应用程序1：查询理解和重写 \/ 147\n8.6.6 应用程序2：相关性评分 \/ 152\n8.6.7 应用程序3：聊天机器人 \/ 156\n8.7 本章小结 \/ 160\n参考文献 \/ 160\n第9 章\nword2vec 的改进：fastText 模型 \/ 162\n9.1 fastText 模型的原理 \/ 163\n9.1.1 回顾Skip-Gram 算法 \/ 163\n9.1.2 subword 模型 \/ 164\n9.1.3 subword 形态 \/ 167\n9.1.4 分层softmax \/ 168\n9.1.5 fastText 的模型架构 \/ 170\n9.1.6 fastText 算法实现 \/ 171\n9.2 应用场景：搜索广告中的查询词关键词匹配问题 \/ 172\n9.3 本章小结 \/ 173\n参考文献 \/ 174\n第10 章\n生成对抗网络 \/ 175\n10.1 生成对抗网络的原理 \/ 176\n10.1.1 GAN 的基本模型 \/ 176\n10.1.2 GAN 优化目标的原理 \/ 178\n10.1.3 GAN 的训练 \/ 179\n10.1.4 GAN 的扩展模型 \/ 180\n10.2 应用场景：搜索广告中由查询词直接生成关键词 \/ 182\n10.2.1 生成模型的构建 \/ 182\n10.2.2 判别模型的构建 \/ 184\n10.2.3 条件生成对抗网络的构建 \/ 185\n10.3 本章小结 \/ 186\n参考文献 \/ 187\n第11 章\n深度强化学习 \/ 188\n11.1 深度强化学习的原理 \/ 189\n11.1.1 强化学习的基本概念 \/ 189\n11.1.2 马尔可夫决策过程 \/ 191\n11.1.3 价值函数和贝尔曼方程 \/ 192\n11.1.4 策略迭代和值迭代 \/ 194\n11.1.5 Q-Learning \/ 196\n11.1.6 深度Q 网络 \/ 198\n11.1.7 策略梯度 \/ 201\n11.1.8 动作评价网络 \/ 202\n11.2 应用场景：基于深度强化学习的推荐系统 \/ 203\n11.3 本章小结 \/ 206\n参考文献 \/ 206\n第12 章\n工程实践和线上优化 \/ 208\n12.1 Seq2Seq 模型介绍 \/ 209\n12.2 LSTM 优化分析 \/ 211\n12.2.1 优化一：指数运算的近似展开 \/ 214\n12.2.2 优化二：矩阵运算的执行速度优化 \/ 218\n12.2.3 优化三：多线程并行处理 \/ 224\n12.3 优化应用实例：RapidScorer 算法对GBDT 的加速 \/ 227\n12.3.1 背景介绍 \/ 228\n12.3.2 RapidScorer 数据结构设计 \/ 231\n12.3.3 RapidScorer 矢量化 \/ 233\n12.3.4 RapidScorer 实验结果 \/ 237\n12.4 本章小结 \/ 238\n参考文献 \/ 239\n第13 章\n深度学习的下一个浪潮 \/ 240\n13.1 深度学习的探索方向展望 \/ 241\n13.1.1 设计更好的生成模型 \/ 241\n13.1.2 深度强化学习的发展 \/ 241\n13.1.3 半监督学习与深度学习 \/ 242\n13.1.4 深度学习自身的学习 \/ 242\n13.1.5 迁移学习与深度学习的结合 \/ 242\n13.1.6 用于推理的深度学习 \/ 243\n13.1.7 深度学习工具的标准化 \/ 243\n13.2 深度学习的应用场景展望 \/ 243\n13.2.1 医疗健康领域 \/ 243\n13.2.2 安全隐私领域 \/ 248\n13.2.3 城市治理领域 \/ 249\n13.2.4 艺术创作领域 \/ 250\n13.2.5 金融保险领域 \/ 252\n13.2.6 无人服务领域 \/ 254\n13.3 本章小结 \/ 257\n参考文献 \/ 258","pages":"276","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33477440.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33477440.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33477440.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34825680\/","id":"34825680","publisher":"电子工业出版社","isbn10":"712137126X","isbn13":"9787121371264","title":"深度学习模型及应用详解","url":"https:\/\/api.douban.com\/v2\/book\/34825680","alt_title":"","author_intro":"张若非\n美国纽约州立大学计算机科学博士。微软（美国）人工智能与研究院高级研究总监，全球合伙人，负责微软在线广告平台机器学习模型、算法及系统的研究和建设。研究领域包括机器学习、数据挖掘、自然语言处理、计算机视觉和多媒体信息检索。在这些领域的一流学术期刊和顶级学术会议发表论文50余篇，获得美国发明专利12项。美国国家自然科学基金会（NSF）智能系统评审委员会委员，IEEE和ACM高级会员。\n付强\n博士毕业于清华大学电子工程系，现任微软（美国）搜索广告部资深应用科学家，主要从事机器学习、深度学习、信息检索、自然语言理解、图像处理等方面的算法研究及其在搜索广告产品中的应用。此前曾任微软亚洲研究院研究员，研究将机器学习算法用于云计算平台的系统建模、性能优化，以及故障自动诊断。在机器学习、数据挖掘、计算机系统等领域的国际顶级会议及期刊上共发表论文30余篇，持有4项美国专利。\n高斌\n博士毕业于北京大学数学科学学院，现任微软（美国）搜索广告部资深机器学习科学家，此前曾担任微软亚洲研究院机器学习研究组主管研究员。主要从事机器学习、信息检索、数据挖掘和计算广告等领域的研究和开发。在国际顶级期刊和会议上发表相关论文40余篇，并持有30余项美国专利。主持研发的十余项创新技术已经被应用于必应搜索引擎、必应搜索广告及微软小冰等产品中。\n张耿豪\n博士毕业于美国加州大学伯克利分校，现任微软（美国）搜索广告部资深应用科学家。主要专注于机器学习、自然语言处理、信息检索、人机界面等领域，并且在微软负责必应搜索广告业务及多项延伸的应用与研究，例如聊天机器人、以图搜图等。在国际顶级期刊和会议上发表相关论文20余篇，并持有3项美国专利。\n叶挺\n硕士毕业于北京大学软件工程研究所，现任微软（美国）搜索广告部工程师，主要从事深度学习算法的性能优化和分布式实现，成功将多个深度学习模型应用于必应的广告服务中。在计算机会议KDD、ASE发表论文3篇，并取得发明专利3项。","summary":"《深度学习模型及应用详解》作者都是微软人工智能及研究院的研究人员和应用科学家，具有深厚的机器学习背景，在一线针对产品需求和支持的场景进行了大量的深度学习模型及算法的研究和开发，在模型设计、训练、评估、部署、推理优化等模型开发全生命周期积累了丰富的经验。\n《深度学习模型及应用详解》分为4 部分，共13 章。其中第1 部分（第1、2 章）简要介绍了深度学习的现状、概念和实现工具。第2 部分（第3～5 章）以具体的实际应用展示基于深度学习技术进行工程实践和开发的流程和技巧。第3 部分（第6～12 章）介绍了学术界和工业界最新的高阶深度学习模型的实现和应用。第4 部分（第13章）介绍了深度学习领域的一些前沿研究方向，并对深度学习的未来发展进行展望。\n《深度学习模型及应用详解》面向的读者是希望学习和运用深度学习模型到具体应用场景的企业工程师、科研院所的学生和科研人员。读者学习本书的目的是了解深度学习模型和算法基础后，快速部署到自己的工作领域，并取得落地成果。","series":{"id":"41172","title":"博文视点AI系列"},"price":"89"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[""],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33480253.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33480253.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33480253.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33480253.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34828729\/","id":"34828729","publisher":"中南大学出版社有限责任公司","isbn10":"7548722184","isbn13":"9787548722182","title":"MOOC时期“深度学习”教育场域建构研究","url":"https:\/\/api.douban.com\/v2\/book\/34828729","alt_title":"","author_intro":"","summary":"","price":"35元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34913486\/","id":"34913486","publisher":"","isbn10":"731322057X","isbn13":"9787313220578","title":"高中思想政治深度学习手册：经济与社会（必修2 统编教材版）","url":"https:\/\/api.douban.com\/v2\/book\/34913486","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["【美】Ahmed Sherif","【美】Amrith Ravindra"],"pubdate":"2020-1","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33547264.jpg","binding":"平装","translator":["黄友良"],"catalog":"1   为深度学习开发设置Spark  1\n介绍  1\n下载Ubuntu桌面映像  2\n在macOS中使用VMWare Fusion安装和配置Ubuntu  3\n在Windows中使用Oracle VirtualBox安装和配置Ubuntu  8\n为谷歌云平台安装和配置Ubuntu桌面端  11\n在Ubuntu桌面端安装和配置Spark  23\n集成Jupyter Notebook与Spark  29\n启动和配置Spark集群  33\n停止Spark集群  34\n2   在Spark中创建神经网络  36\n介绍  36\n在PySpark中创建数据帧  37\n在PySpark数据帧中操作列  41\n将PySpark数据帧转换为数组  42\n在散点图中将数组可视化  46\n设置输入神经网络的权重和偏差  49\n规范化神经网络的输入数据  52\n验证数组以获得最佳的神经网络性能  55\n使用sigmoid设置激活函数  57\n创建sigmoid导数  60\n计算神经网络中的代价函数  62\n根据身高值和体重值预测性别  66\n预测分数并进行可视化  69\n3   卷积神经网络的难点  72\n介绍  72\n难点1：导入MNIST图像  73\n难点2：可视化MNIST图像  77\n难点3：将MNIST图像导出为文件  80\n难点4：增加MNIST图像  82\n难点5：利用备用资源训练图像  86\n难点6：为卷积神经网络优先考虑高级库  88\n4   循环神经网络的难点  94\n介绍  94\n前馈网络简介  95\n循环神经网络的顺序工作  103\n难点1：梯度消失问题  108\n难点2：梯度爆炸问题  111\n长短期记忆单元的顺序工作  114\n5   用Spark机器学习预测消防部门呼叫  119\n介绍  119\n下载旧金山消防局呼叫数据集  119\n识别逻辑回归模型的目标变量  123\n为逻辑回归模型准备特征变量  130\n应用逻辑回归模型  137\n评估逻辑回归模型的准确度  142\n6   在生成网络中使用LSTM  145\n介绍  145\n下载将用作输入文本的小说\/书籍  145\n准备和清理数据  151\n标记句子  156\n训练和保存LSTM模型  158\n使用模型生成类似的文本  163\n7   使用TF-IDF进行自然语言处理  171\n介绍  171\n下载治疗机器人会话文本数据集  172\n分析治疗机器人会话数据集  176\n数据集单词计数可视化  178\n计算文本的情感分析  180\n从文本中删除停用词  184\n训练TF-IDF模型  188\n评估TF-IDF模型性能  192\n比较模型性能和基线分数  194\n8   使用XGBoost进行房地产价值预测  196\n下载金斯县房屋销售数据集  196\n执行探索性分析和可视化  199\n绘制价格与其他特征之间的相关性  210\n预测房价  223\n9   使用长短期记忆单元预测苹果公司股票市场价格  229\n下载苹果公司的股票市场数据  229\n探索和可视化苹果公司的股票市场数据  233\n准备用于提升模型性能的股票市场数据  238\n构建长短期记忆单元模型  246\n评估长短期记忆单元模型  249\n10   使用深度卷积网络进行人脸识别  252\n介绍  252\n下载MIT-CBCL数据集并将其加载到内存中  252\n绘制并可视化目录中的图像  257\n图像预处理  262\n模型构建、训练和分析  269\n11   使用Word2Vec创建和可视化单词向量  277\n介绍  277\n获取数据  277\n导入必要的库  281\n准备数据  284\n构建和训练模型  288\n进一步可视化  293\n进一步分析  300\n12   使用Keras创建电影推荐引擎  304\n介绍  304\n下载MovieLens数据集  305\n操作和合并MovieLens数据集  312\n探索MovieLens数据集  318\n为深度学习流水线准备数据集  322\n应用Keras深度学习模型  327\n评估推荐引擎的准确度  331\n13   使用TensorFlow在Spark中进行图像分类  333\n介绍  333\n下载梅西和罗纳尔多各30张图像  334\n使用深度学习包安装PySpark  339\n将图像加载到PySpark数据帧  341\n理解迁移学习  344\n创建用于图像分类训练的流水线  346\n评估模型性能  348\n微调模型参数  350","pages":"372","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33547264.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33547264.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33547264.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34930393\/","id":"34930393","publisher":"电子工业出版社","isbn10":"7121378825","isbn13":"9787121378829","title":"Spark 深度学习指南","url":"https:\/\/api.douban.com\/v2\/book\/34930393","alt_title":"","author_intro":"关于作者\nAhmed Sherif是一名数据科学家，自2005年以来一直从事各种各样的数据研究工作。他从2013年开始使用BI解决方案并慢慢转向数据科学。2016年，他从西北大学获得了预测分析硕士学位，在那里他研究使用Python和R语言进行机器学习和预测建模的科学与应用。最近，他一直使用Azure在云端开发机器学习和深度学习解决方案。2016年，他出版了他的第一本书《实用商业智能》。他目前是微软公司的数据和人工智能技术解决方案专家。\n“首先，我要感谢我的妻子Ameena和我的三个可爱的孩子Safiya、Hamza和Layla，感谢他们给我力量和支持来完成这本书。没有他们的爱与支持，我恐怕无法完成本书。我还要感谢我的合著者Amrith，感谢他给予我写这本书的决心和为本书付出的努力。”\nAmrith Ravindra是一位机器学习爱好者，拥有电气与工业工程学位。在攻读硕士学位期间，他深入地研究了机器学习问题，加深了自己对数据科学的热爱程度。工程专业的研究生课程给他提供了数学背景，使他开始了机器学习领域的职业生涯。他在坦帕市举行的当地数据科学聚会上遇到了Ahmed Sherif。他们决定合作写一本关于他们最喜欢的机器学习算法的书。他希望这本书能够帮助他实现成为数据科学家并积极为机器学习做出贡献的最终目标。\n“首先，我要感谢Ahmed给我这个机会和他一起工作。对我来说，写这本书比读大学本身更好。接下来，我要感谢我的爸爸、妈妈和姐姐，他们一直给我动力，给我成功的动力。最后，我要感谢我的朋友们，没有他们的指教，我永远不会像这样快速地成长。”\n关于审稿人\nMichal Malohlava是Sparkling Water的创始人。他是一位极客、开发者，同时也是一位拥有10年软件开发经验的Java、Linux编程语言爱好者。他于2012年在布拉格查理大学获得博士学位，并在普渡大学完成博士后工作。他参与了用于高级大数据数学与计算的H2O平台的开发，并将其整合到Spark引擎中，以名为Sparkling Water的项目发布。\nAdnan Masood博士是人工智能和机器学习研究员、软件架构师和微软数据平台最有价值专家。他目前在UST Global公司担任人工智能和机器学习首席架构师，在那里他与斯坦福人工智能实验室和麻省理工学院人工智能实验室合作构建企业解决方案。作为斯坦福大学的访问学者、亚马逊编程语言畅销书Functional Programming with F#的作者，他最近在丹佛市女性技术会议上发表的演讲强调了STEM（科学、技术、工业、数学）和技术领域多样化的重要性。该演讲被新闻媒体广为传播。","summary":"Spark是专为大规模数据处理而设计的快速通用的计算引擎，经过近几年的飞速发展，现已被广泛应用于各个领域。本书通过通俗易懂的语言和简单明了的操作，系统地讲解了构建Spark深度学习系统的方法、流程、标准和规范等相关内容，并提供了相应的示例与解析。\n《Spark 深度学习指南》适合作为高等院校计算机相关专业的参考资料，也适合大数据技术和机器学习技术的初学者阅读，还适合所有对大数据技术和机器学习技术有所了解并想将该技术应用于本职工作的读者阅读。","price":"109"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"CV","title":"CV"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34917990\/","id":"34917990","publisher":"","isbn10":"7111641744","isbn13":"9787111641742","title":"深度学习之PyTorch物体检测实战","url":"https:\/\/api.douban.com\/v2\/book\/34917990","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34922483\/","id":"34922483","publisher":"","isbn10":"7121375338","isbn13":"9787121375330","title":"课堂透视：STEM深度学习中学生创意和问题的获得","url":"https:\/\/api.douban.com\/v2\/book\/34922483","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34924094\/","id":"34924094","publisher":"","isbn10":"7513597758","isbn13":"9787513597753","title":"世界语言与文化深度学习指南","url":"https:\/\/api.douban.com\/v2\/book\/34924094","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["于祥"],"pubdate":"2019-12","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33531838.jpg","binding":"平装","translator":[],"catalog":"第　1章 飞桨PaddlePaddle简介\n与AI　Studio的使用　1\n1.1　飞桨PaddlePaddle简介　1\n1.2　飞桨PaddlePaddle的工具组件　2\n1.2.1　PaddleHub—简明易用的\n预训练模型管理框架　2\n1.2.2　PARL—基于飞桨PaddlePaddle\n的深度强化学习框架　3\n1.2.3　AutoDL Design—让深度学习\n来设计深度学习　4\n1.2.4　VisualDL—深度学习可视化\n工具库　5\n1.2.5　模型转换工具X2Paddle　5\n1.3　飞桨PaddlePaddle在百度内部\n支持的案例　6\n1.4　飞桨PaddlePaddle与TensorFlow的\n对比　7\n1.5　AI Studio简介　8\n1.6　在AI Studio中创建项目　9\n1.6.1　用户界面简介　9\n1.6.2　创建并运行一个项目　10\n1.7　AI Studio单机项目概述　11\n1.7.1　页面概览　11\n1.7.2　复制项目　12\n1.7.3　VisualDL工具的使用　13\n1.8　Notebook环境使用说明　14\n1.8.1　Notebook页面概览　14\n1.8.2　操作区　14\n1.8.3　Notebook内容编辑区　15\n1.8.4　侧边栏　21\n1.8.5　工具栏　23\n1.9　AI Studio集群项目　23\n1.9.1　集群项目说明　23\n1.9.2　创建集群项目　24\n1.9.3　页面概览　25\n1.9.4　代码编辑界面　25\n1.9.5　文件管理和数据集区域　26\n1.9.6　文件预览编辑和提交任务\n区域　27\n1.9.7　PaddlePaddle集群训练说明　27\n1.9.8　数据集与输出文件路径说明　28\n1.9.9　提交任务　29\n1.9.10　历史任务　29\n1.9.11　预安装包说明　30\n1.10　在线部署及预测　31\n1.10.1　功能说明　31\n1.10.2　通过训练任务生成模型文件　32\n1.10.3　创建一个在线服务　34\n1.10.4　测试沙盒服务　39\n1.10.5　部署在线服务　40\n1.10.6　调用在线服务　41\n1.11　NumPy常规操作及使用　42\n第　2章 PaddlePaddle Fluid的环境\n搭建与安装　50\n2.1　在Linux系统中安装\nPaddlePaddle　50\n2.1.1　租用百度BCC云服务器　50\n2.1.2　安装前的准备工作　56\n2.1.3　通过pip安装PaddlePaddle　58\n2.1.4　在Docker中安装\nPaddlePaddle　59\n2.2　在Windows系统中安装\nPaddlePaddle　64\n2.2.1　Windows GPU驱动环境安装　64\n2.2.2　下载并安装CUDA　65\n2.2.3　安装cuDNN　68\n2.2.4　安装PaddlePaddle　69\n2.3　在macOS系统中安装\nPaddlePaddle　69\n2.3.1　安装Python 3　69\n2.3.2　安装PaddlePaddle　71\n第3章　PaddlePaddle深度学习入门—\n在MNIST上进行手写\n数字识别　72\n3.1　引言　72\n3.2　模型概览　73\n3.2.1　Softmax回归模型　73\n3.2.2　多层感知器　74\n3.2.3　卷积神经网络　75\n3.3　数据介绍　78\n3.4　PaddlePaddle的程序配置过程　79\n3.4.1　程序说明　79\n3.4.2　配置inference_program　79\n3.4.3　配置train_program　81\n3.4.4　配置optimizer_program　82\n3.4.5　配置数据集reader　82\n3.5　构建训练过程　83\n3.5.1　事件处理程序配置　83\n3.5.2　开始训练　84\n3.6　应用模型　86\n3.6.1　生成待预测的输入数据　87\n3.6.2　Inference创建及预测　87\n3.6.3　预测结果　87\n3.7　小结　88\n第4章　PaddlePaddle设计思想与\n核心技术　89\n4.1　编译时与运行时的概念　89\n4.2　Fluid内部执行流程　90\n4.3　Program设计简介　91\n4.4　Block简介　92\n4.5　Block和Program的设计细节　93\n4.6　框架执行器设计思想　94\n4.6.1　代码示例　95\n4.6.2　创建框架执行器　95\n4.6.3　运行框架执行器　96\n4.7　示例　96\n4.7.1　定义Program　96\n4.7.2　创建框架执行器　98\n4.7.3　运行框架执行器　99\n4.8　LoD Tensor数据结构解读　99\n4.8.1　LoD索引　100\n4.8.2　LoD Tensor在PaddlePaddle\n中的表示方法　101\n4.8.3　LoD Tensor的API　103\n4.8.4　LoD Tensor的使用示例　105\n4.9　动态图机制——DyGraph　107\n4.9.1　动态图设置和基本用法　108\n4.9.2　基于DyGraph构建网络　109\n4.9.3　使用DyGraph训练模型　110\n4.9.4　模型参数的保存　115\n4.9.5　模型评估　116\n4.9.6　编写兼容的模型　118\n第5章　独孤九剑—经典图像分类\n网络实现　119\n5.1　图像分类网络现状　119\n5.2　VGG16图像分类任务　123\n5.2.1　定义网络结构　124\n5.2.2　定义推理程序　127\n5.2.3　定义训练程序　127\n5.2.4　实例化训练对象　128\n5.2.5　读取数据　128\n5.2.6　编写事件处理程序并\n启动训练　129\n5.2.7　执行模型预测　130\n5.3　模块化设计GoogleNet　135\n5.4　Alexnet模型实现　142\n5.5　Resnet模型实现　146\n5.6　MobileNet V2模型实现　149\n5.7　ShuffleNet V2模型实现　154\n第6章　“天网”系统基础—\n目标检测　159\n6.1　目标检测简介　160\n6.2　对R-CNN系列算法的探索历史　161\n6.2.1　R-CNN算法：目标检测\n开山之作　161\n6.2.2　SPP网络　164\n6.2.3　Fast R-CNN　166\n6.2.4　Faster R-CNN　167\n6.3　单步目标检测算法　177\n6.3.1　统一检测算法YOLO　178\n6.3.2　SSD基本原理　181\n6.3.3　SSD在训练时的匹配策略　185\n6.3.4　使用PaddlePaddle实现\nSSD网络　186\n6.4　PyramidBox　203\n6.4.1　提出PyramidBox方法的\n背景　204\n6.4.2　PyramidBox网络结构　205\n6.4.3　PyramidBox的创新点　208\n6.4.4　PyramidBox的PaddlePaddle\n官方实现　210\n第7章　“天网”系统进阶—像素级\n物体分割　221\n7.1　物体分割简介　221\n7.2　语义分割与实例分割的关系　222\n7.3　语义分割　222\n7.3.1　语义分割的任务描述　223\n7.3.2　全卷积网络　224\n7.3.3　ParseNet　229\n7.3.4　u-net　229\n7.3.5　v-net　231\n7.3.6　u-net变体网络　231\n7.3.7　PSPNet　233\n7.3.8　ICNet　234\n7.3.9　DeepLab v3 　241\n7.4　实例分割　249\n7.4.1　实例分割概述　249\n7.4.2　Mask R-CNN　250\n第8章　从零开始了解NLP\n技术—word2vec　263\n8.1　初识NLP　263\n8.2　词向量简介　265\n8.3　如何得到词向量模型　268\n8.4　词向量模型概览　269\n8.4.1　语言模型　269\n8.4.2　N-Gram模型　269\n8.4.3　CBOW模型　270\n8.4.4　Skip-Gram　271\n8.4.5　词ID　271\n8.5　通过PaddlePaddle训练\nCBOW模型　273\n8.5.1　CBOW模型训练过程　273\n8.5.2　数据预处理　274\n8.5.3　编程实现　274\n8.5.4　模型应用　278\n8.6　小结　280\n第9章　feed流最懂你—\n个性化推荐　282\n9.1　引言　282\n9.2　推荐网络模型设计　283\n9.2.1　YouTube的深度神经网络\n个性化推荐系统　284\n9.2.2　融合推荐模型　286\n9.3　电影推荐实验　290\n9.3.1　数据介绍与下载　290\n9.3.2　模型配置说明　292\n9.3.3　训练模型　295\n9.3.4　应用模型　298\n9.4　小结　299\n第　10章 让机器读懂你的心—\n情感分析技术　300\n10.1　情感分析及其作用　300\n10.2　模型设计　303\n10.3　情感分析实验　308\n第　11章 NLP技术深入理解—\n语义角色标注　315\n11.1　引言　315\n11.2　模型概览　317\n11.2.1　栈式循环神经网络　317\n11.2.2　双向循环神经单元　318\n11.2.3　条件随机场　319\n11.2.4　深度双向LSTM SRL模型　320\n11.3　使用PaddlePaddle实现SRL\n任务　322\n11.3.1　数据预处理　322\n11.3.2　进行PaddlePaddle实验　324\n11.4　小结　331\n第　12章 NLP技术的应用—\n机器翻译　332\n12.1　引言　332\n12.2　效果展示　333\n12.3　模型概览　333\n12.3.1　时间步展开的双向循环\n神经网络　333\n12.3.2　编码器-解码器框架　334\n12.3.3　柱搜索算法　337\n12.4　机器翻译实战　337\n12.4.1　数据预处理　337\n12.4.2　模型配置　338\n12.4.3　训练模型　342\n12.4.4　应用模型　343\n第　13章 PaddlePaddle移动端及嵌入式\n框架—Paddle-Mobile　345\n13.1　Paddle-Mobile简介　345\n13.2　Paddle-Mobile优化与适配　346\n13.2.1　包压缩　346\n13.2.2　工程结构编码前重新设计　347\n13.3　移动端主体识别和分类　350\n13.3.1　完全在云端的神经网络\n技术应用　352\n13.3.2　移动端业界案例　353\n13.3.3　在移动端应用深度学习\n技术的难点　355\n13.3.4　AR实时翻译问题的\n解决方案　356\n13.4　编译与开发Paddle-Mobile\n平台库　359\n13.5　开发一个基于移动端深度学习\n框架的Android　APP　360\n13.6　Paddle-Mobile设计思想　368\n第　14章 百度开源高速推理引擎——\nAnakin　374\n14.1　Anakin架构与性能　375\n14.2　Anakin的特性　379\n14.2.1　支持众多异构平台　379\n14.2.2　高性能　379\n14.2.3　汇编级的kernel优化　382\n14.2.4　Anakin值得一提的\n技术亮点　382\n14.3　Anakin的使用方法　384\n14.3.1　Anakin的工作原理　384\n14.3.2　Anakin v2.0 API　385\n14.4　示例程序　393\n附录A　TensorFlow与PaddlePaddle Fluid\n接口中常用层对照表　394\n附录B　Caffe与PaddlePaddle Fluid\n接口中常用层对照表　401","pages":"402","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33531838.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33531838.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33531838.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34899258\/","id":"34899258","publisher":"人民邮电出版社","isbn10":"7115519641","isbn13":"9787115519641","title":"深度学习与飞桨PaddlePaddle Fluid实战","url":"https:\/\/api.douban.com\/v2\/book\/34899258","alt_title":"","author_intro":"于祥\n百度PaddlePaddle技术运营。2015年开始研究神经网络技术，早期从事基于深度学习的身份认证技术研发，曾负责上海智慧城市项目和华润集团项目的算法支持，曾获得ACM-ICPC与CCCC-GPLT银奖。","summary":"飞桨PaddlePaddle是百度推出的深度学习框架，不仅支撑了百度公司的很多业务和应用，而且随着其开源过程的推进，在其他行业得到普及和应用。\n本书基于2019年7月4日发布的飞桨PaddlePaddle Fluid 1.5版本（后续版本会兼容旧版本），以真实案例介绍如何应用飞桨PaddlePaddle解决主流的深度学习问题。\n本书适合对人工智能感兴趣的学生、从事机器学习相关工作的读者阅读，尤其适合想要通过飞桨PaddlePaddle掌握深度学习应用技术的研究者和从业者参考。\n本书包括以下内容：\n● 飞桨PaddlePaddle 的核心设计思想；\n● PaddlePaddle在MNIST上进行手写数字识别；\n● 图像分类网络实现案例；\n● “天网”中目标检测和像素级物体分割的实现；\n● NLP技术应用案例 ：word2vec、情感分析、语义角色标注及机器翻译；\n● Paddle-Mobile与Anakin框架等高级主题；\n● 飞桨PaddlePaddle与TensorFlow、Caffe框架的常用层对比。","series":{"id":"43598","title":"深度学习系列"},"price":"99.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34907365\/","id":"34907365","publisher":"","isbn10":"7547845266","isbn13":"9787547845264","title":"深度学习与医学大数据","url":"https:\/\/api.douban.com\/v2\/book\/34907365","alt_title":"","author_intro":"","summary":"","price":""}]}
3	{"count":92,"start":200,"total":292,"books":[{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34916245\/","id":"34916245","publisher":"","isbn10":"7301308485","isbn13":"9787301308486","title":"TensorFlow深度学习实战大全","url":"https:\/\/api.douban.com\/v2\/book\/34916245","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["[美]安德鲁·特拉斯克(Andrew W. Trask)"],"pubdate":"2020-1","tags":[],"origin_title":"Gorkking Deep Learning","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33549246.jpg","binding":"平装","translator":["王晓雷","严烈"],"catalog":"目录\n\n第1章  深度学习简介：为什么应该学习深度学习   1\n1.1　欢迎阅读《深度学习图解》   1\n1.2　为什么要学习深度学习   2\n1.3　这很难学吗?   3\n1.4　为什么要阅读本书   3\n1.5　准备工作   4\n1.6　你可能需要掌握一部分Python知识   5\n1.7　本章小结   6\n第2章  基本概念：机器该如何学习？   7\n2.1　什么是深度学习?   7\n2.2　什么是机器学习？   8\n2.3　监督机器学习   9\n2.4　无监督机器学习   10\n2.5　参数学习和非参数学习   10\n2.6　监督参数学习   11\n2.7　无监督参数学习   13\n2.8　非参数学习   14\n2.9　本章小结   15\n第3章  神经网络预测导论：前向传播   17\n3.1　什么是预测   17\n3.2　能够进行预测的简单神经网络   19\n3.3　什么是神经网络?   20\n3.4　这个神经网络做了什么?   21\n3.5　使用多个输入进行预测   23\n3.6　多个输入：这个神经网络做了什么?   24\n3.7　多个输入：完整的可运行代码   29\n3.8　预测多个输出   30\n3.9　使用多个输入和输出进行预测   32\n3.10　多输入多输出神经网络的工作原理   33\n3.11　用预测结果进一步预测   35\n3.12　NumPy快速入门   37\n3.13　本章小结   40\n第4章  神经网络学习导论：梯度下降   41\n4.1　预测、比较和学习   41\n4.2　什么是比较   42\n4.3　学习   42\n4.4　比较：你的神经网络是否做出了好的预测？   43\n4.5　为什么需要测量误差？   44\n4.6　最简单的神经学习形式是什么？   45\n4.7　冷热学习   46\n4.8　冷热学习的特点   47\n4.9　基于误差调节权重   48\n4.10　梯度下降的一次迭代   50\n4.11　学习就是减少误差   52\n4.12　回顾学习的步骤   54\n4.13　权重增量到底是什么?   55\n4.14　狭隘的观点   57\n4.15　插着小棍的盒子   58\n4.16　导数：两种方式   59\n4.17　你真正需要知道的   60\n4.18　你不需要知道的   60\n4.19　如何使用导数来学习   61\n4.20　看起来熟悉吗?   62\n4.21　破坏梯度下降   63\n4.22　过度修正的可视化   64\n4.23　发散   65\n4.24　引入α   66\n4.25　在代码中实现α   66\n4.26　记忆背诵   67\n第5章  通用梯度下降：一次学习多个权重   69\n5.1　多输入梯度下降学习   69\n5.2　多输入梯度下降详解   71\n5.3　回顾学习的步骤   75\n5.4　单项权重冻结：它有什么作用?   77\n5.5　具有多个输出的梯度下降学习   79\n5.6　具有多个输入和输出的梯度下降   81\n5.7　这些权重学到了什么?   83\n5.8　权重可视化   85\n5.9　点积(加权和)可视化   86\n5.10　本章小结   87\n第6章  建立你的第一个深度神经网络：反向传播   89\n6.1　交通信号灯问题   89\n6.2　准备数据   91\n6.3　矩阵和矩阵关系   92\n6.4　使用Python创建矩阵   95\n6.5　建立神经网络   96\n6.6　学习整个数据集   97\n6.7　完全、批量和随机梯度下降   97\n6.8　神经网络对相关性的学习   98\n6.9　向上与向下的压力   99\n6.10　边界情况：过拟合   101\n6.11　边界情况：压力冲突   101\n6.12　学习间接相关性   103\n6.13　创建关联   104\n6.14　堆叠神经网络：回顾   105\n6.15　反向传播：远程错误归因   106\n6.16　反向传播：为什么有效?   107\n6.17　线性与非线性   107\n6.18　为什么神经网络仍然不起作用   109\n6.19　选择性相关的秘密   110\n6.20　快速冲刺   111\n6.21　你的第一个深度神经网络   111\n6.22　反向传播的代码   112\n6.23　反向传播的一次迭代   114\n6.24　整合代码   116\n6.25　为什么深度网络这么重要?   117\n第7章  如何描绘神经网络：在脑海里，在白纸上   119\n7.1　到了简化的时候了   119\n7.2　关联抽象   120\n7.3　旧的可视化方法过于复杂   121\n7.4　简化版可视化   122\n7.5　进一步简化   123\n7.6　观察神经网络是如何进行预测的   124\n7.7　用字母而不是图片来进行可视化   125\n7.8　连接变量   126\n7.9　信息整合   127\n7.10　可视化工具的重要性   127\n第8章  学习信号，忽略噪声：正则化和批处理介绍   129\n8.1　用在MNIST上的三层网络   129\n8.2　好吧，这很简单   131\n8.3　记忆与泛化   132\n8.4　神经网络中的过拟合   133\n8.5　过拟合从何而来   134\n8.6　最简单的正则化：提前停止   135\n8.7　行业标准正则化：dropout   136\n8.8　为什么dropout有效：整合是有效的   137\n8.9　dropout的代码   137\n8.10　在MNIST数据集上对dropout进行测试   139\n8.11　批量梯度下降   140\n8.12　本章小结   143\n第9章  概率和非线性建模：激活函数   145\n9.1　什么是激活函数?   145\n9.2　标准隐藏层激活函数   148\n9.3　标准输出层激活函数   149\n9.4　核心问题：输入具有\n相似性   151\n9.5　计算softmax   152\n9.6　激活函数使用说明   153\n9.7　将增量与斜率相乘   156\n9.8　将输出转换为斜率(导数)   157\n9.9　升级MNIST网络   157\n第10章  卷积神经网络概论：关于边与角的神经学习   161\n10.1　在多个位置复用权重   161\n10.2　卷积层   162\n10.3　基于NumPy的简单实现   164\n10.4　本章小结   167\n第11章  能够理解自然语言的神经网络：国王-男人+女人=？   169\n11.1　理解语言究竟是指什么?   170\n11.2　自然语言处理(NLP)   170\n11.3　监督NLP学习   171\n11.4　IMDB电影评论数据集   172\n11.5　在输入数据中提取单词相关性   173\n11.6　对影评进行预测   174\n11.7　引入嵌入层   175\n11.8　解释输出   177\n11.9　神经网络结构   178\n11.10　单词嵌入表达的对比   180\n11.11　神经元是什么意思?   181\n11.12　完形填空   182\n11.13　损失函数的意义   183\n11.14　国王-男人+女人~=女王   186\n11.15　单词类比   187\n11.16　本章小结   188\n第12章  像莎士比亚一样写作的神经网络：变长数据的递归层   189\n12.1　任意长度的挑战   189\n12.2　做比较真的重要吗？   190\n12.3　平均词向量的神奇力量   191\n12.4　信息是如何存储在这些向量嵌入中的？   192\n12.5　神经网络是如何使用嵌入的？   193\n12.6　词袋向量的局限   194\n12.7　用单位向量求词嵌入之和   195\n12.8　不改变任何东西的矩阵   196\n12.9　学习转移矩阵   197\n12.10　学习创建有用的句子向量   198\n12.11　Python下的前向传播   199\n12.12　如何反向传播？   200\n12.13　让我们训练它！   201\n12.14　进行设置   201\n12.15　任意长度的前向传播   202\n12.16　任意长度的反向传播   203\n12.17　任意长度的权重更新   204\n12.18　运行代码，并分析输出   205\n12.19　本章小结   207\n第13章  介绍自动优化：搭建深度学习框架   209\n13.1　深度学习框架是什么？   209\n13.2　张量介绍   210\n13.3　自动梯度计算(autograd)介绍   211\n13.4　快速检查   213\n13.5　多次使用的张量   214\n13.6　升级autograd以支持多次使用的张量   215\n13.7　加法的反向传播如何工作？   217\n13.8　增加取负值操作的支持   218\n13.9　添加更多函数的支持   219\n13.10　使用autograd训练神经网络   222\n13.11　增加自动优化   224\n13.12　添加神经元层类型的支持   225\n13.13　包含神经元层的神经元层   226\n13.14　损失函数层   227\n13.15　如何学习一个框架   228\n13.16　非线性层   228\n13.17　嵌入层   230\n13.18　将下标操作添加到\nautograd   231\n13.19　再看嵌入层   232\n13.20　交叉熵层   233\n13.21　递归神经网络层   235\n13.22　本章小结   238\n第14章  像莎士比亚一样写作：长短期记忆网络   239\n14.1　字符语言建模   239\n14.2　截断式反向传播的必要性   240\n14.3　截断式反向传播   241\n14.4　输出样例   244\n14.5　梯度消失与梯度激增   245\n14.6　RNN反向传播的小例子   246\n14.7　长短期记忆(LSTM)元胞   247\n14.8　关于LSTM门限的直观理解   248\n14.9　长短期记忆层   249\n14.10　升级字符语言模型   250\n14.11　训练LSTM字符语言模型   251\n14.12　调优LSTM字符语言模型   252\n14.13　本章小结   253\n第15章  在看不见的数据上做深度学习：联邦学习导论   255\n15.1　深度学习的隐私问题   255\n15.2　联邦学习   256\n15.3　学习检测垃圾邮件   257\n15.4　让我们把它联邦化   259\n15.5　深入联邦学习   260\n15.6　安全聚合   261\n15.7　同态加密   262\n15.8　同态加密联邦学习   263\n15.9　本章小结   264\n第16章  往哪里去：简要指引   265\n","pages":"292","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33549246.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33549246.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33549246.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34932968\/","id":"34932968","publisher":"清华大学出版社","isbn10":"7302540993","isbn13":"9787302540991","title":"深度学习图解","url":"https:\/\/api.douban.com\/v2\/book\/34932968","alt_title":"Gorkking Deep Learning","author_intro":"Andrew W. Trask是Digital Reasoning公司机器学习实验室的创始成员，该实验室致力于自然语言处理、图像识别和音频转录的深度学习研究。几个月内，Andrew和他的伙伴们就在情绪分类和词性标注方面发表了超过业界最佳方案的结果。\n他训练了世界上最大的人工神经网络，拥有超过1600亿个参数，实验结果发表在ICML(International Conference on Machine Learning)上，还有一部分结果发表在Journal of Machine Learning(JML)上。他在Digital Reasoning公司担任文本处理和音频分析的产品经理，负责仿真认知计算平台的架构设计，深度学习是这一平台的核心能力。","summary":"《深度学习图解》指导你从最基础的每一行代码开始搭建深度学习网络！经验丰富的深度学习专家Andrew W. Trask以有趣的图解方式为你揭开深度学习的神秘面纱，使你可亲身体会训练神经网络的每个细节。只需要使用Python语言及其最基本的数学库NumPy，就可以训练出自己的神经网络，借助它观察并理解图像、将文字翻译成不同的语言，甚至像莎士比亚一样写作！当你完成这一切后，就为成为精通深度学习框架的专家做好了充分准备！\n主要内容：\n• 深度学习的基础科学原理\n• 自行设计和训练神经网络\n• 隐私保护的知识，包括联邦学习\n• 帮助你继续深度学习之旅的建议","price":"99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34932805\/","id":"34932805","publisher":"","isbn10":"7115524254","isbn13":"9787115524256","title":"深度学习实战手册 R语言版","url":"https:\/\/api.douban.com\/v2\/book\/34932805","alt_title":"","author_intro":"","summary":"","series":{"id":"43598","title":"深度学习系列"},"price":""},{"rating":{"max":10,"numRaters":128,"average":"9.1","min":0},"subtitle":"跟好萊塢編劇教父學習角色說話的藝術，在已說、未說、不可說之間，強化故事的深度、角色的厚度、風格的魅力","author":["Robert McKee"],"pubdate":"2017-12-7","tags":[{"count":154,"name":"写作","title":"写作"},{"count":116,"name":"编剧","title":"编剧"},{"count":78,"name":"剧本写作","title":"剧本写作"},{"count":73,"name":"编剧理论","title":"编剧理论"},{"count":73,"name":"电影","title":"电影"},{"count":67,"name":"罗伯特·麦基","title":"罗伯特·麦基"},{"count":43,"name":"港台版","title":"港台版"},{"count":39,"name":"編劇","title":"編劇"}],"origin_title":"Dialogue: The Art of Verbal Action for Page, Stage, and Screen","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29637942.jpg","binding":"平装","translator":["周蔚"],"catalog":"自序：對白禮讚\n引言：作家的導航系統\n第一部：對白的奧妙\n01對白的完整定義\n戲劇對白\n敘述對白\n對白與講故事的幾類主要媒介\n舞台上的對白\n銀幕上的對白\n書頁上的對白\n間接對白\n02對白的三種功能\n講解\n角色刻劃\n行動\n03表達（一）：內容\n已說（the said）\n未說（the unsaid）\n不可說（the unsayable）\n行動相對於活動\n文本相對於潛文本\n04表達（二）：形式\n衝突叢集\n劇場的對白\n電影中的對白\n電視上的對白\n05表達（三）：技巧\n語言比喻\n周邊語言\n混搭手法\n台詞句式\n精簡\n停頓\n沉默\n第二部：診斷你的對白\n導論：對白的六大任務\n06可信度上的瑕疵\n可信度\n內容空洞\n情緒過激\n知道太多\n洞悉太深\n藉口偽裝成動機\n情節劇\n07語言上的瑕疵\n陳腔濫調\n找無正主\n舖張賣弄\n枯燥無味\n．具體優於抽象\n．熟悉優於奇異\n．短優於長\n．直言優於曲筆\n．主動優於被動\n．長話短說優於長篇大論\n．自道優於學舌\n．刪除枝節\n08內容上的瑕疵\n淺白露骨\n自言自語的謬論\n角力對白\n09結構上的瑕疵\n嘮叨重覆\n七零八落的台詞\n歪歪扭扭的場景\n四分五裂的場景\n覆述的陷阱\n第三部：如何寫作對白\n10角色專屬的對白\n兩大創造力\n辭彙與角色塑造的關係\n創造的極限法則\n慣用語和角色塑造的關係\n角色專屬原則\n文化和角色塑造的關係\n11四則案例研究\n舞台劇《凱撒大帝》\n小說《視線之外》\n電視情境喜劇《超級製作人》\n電影《杯酒人生》（台譯《尋找新方向》）\n第四部：如何設計對白\n12劇情／場景／對白\n觸發事件\n故事情節的價值\n欲求叢集\n對立力量\n行動的骨幹\n故事推展\n轉捩點\n場景推展\n節拍\n行為的五道步驟\n七則作品研究\n13平衡式衝突：電視影集《黑道家族》\n14喜趣式衝突：情境喜劇《歡樂一家親》\n．喜劇對白的技巧\n15非對稱衝突：舞台劇《太陽底下的葡萄》\n16間接衝突：小說《大亨小傳》\n．轉捩點／場景高潮\n17反身式衝突：小說《艾瑟姑娘》與《純真寶庫》\n．「自我」介紹\n．反身式衝突\n18極簡衝突：電影《愛情不用翻譯》\n．引論：文本和潛文本間的天平\n19練功祕笈\n．傾聽\n．關鍵問題\n．後話\n原書注解\n名詞對照\n","pages":"320","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29637942.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29637942.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29637942.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27600590\/","id":"27600590","publisher":"漫遊者文化","isbn10":"9864892258","isbn13":"9789864892259","title":"對白的解剖","url":"https:\/\/api.douban.com\/v2\/book\/27600590","alt_title":"Dialogue: The Art of Verbal Action for Page, Stage, and Screen","author_intro":"羅伯特．麥基 Robert McKee\n1941年生，傅爾布萊特學者（Fulbright Scholar），縱橫全球、炙手可熱的敘事藝術講師。過去三十年指導過無數編劇、小說家、劇作家、詩人、紀錄片工作者、製作人、導演；總計教出六十位奧斯卡獎項得主、二百位奧斯卡獎項提名人、二百位艾美獎獎項得主、一千位艾美獎獎項提名，一百位美國作家工會獎項得主，五十位美國導演工會獎項得主。\n1997年出版的《故事的解剖》（STORY）至今長踞各國暢銷榜，有「編劇聖經」之稱。2017年榮獲Final Draft編劇專業獎項Screenwriters Choice Awards之終身成就獎。英國《衛報》讚譽為「亞里斯多德之後最有影響力的故事理論家」。\n1941年生，好萊塢知名劇作教學大師。1981年受美國南加大之邀，開設「STORY講座」，同時在好萊塢製作電視節目。1997年出版的《故事的解剖》（STORY）至今長踞各國暢銷榜，有「編劇聖經」之稱。《2017年榮獲Final Draft編劇專業獎項Screenwriters Choice Awards之終身成就獎。英國《衛報》讚譽為「亞理斯多德後最有影響力的故事理論家」。","summary":"史上第一本！\n電影、電視、舞台劇、小說\n對白寫作的創意指南\n◆\n對白，不光是說話。\n對白就是行動（action）\n\n●以《故事的解剖》暢銷世界20年，好萊塢編劇教父最新力作\n●英國《衛報》讚譽為「亞理斯多德後最有影響力的故事理論家」\n●2017年榮獲Final Draft編劇專業獎項Screenwriters Choice Awards之終身成就獎\n角色只要開口講話，都是在以話語作演出，是一種行動；\n角色每一次「透過講話」而呈現的行動，都應該將場戲往下一拍（beat）推進。\n對白有多重要？\n不論戲劇的製作再怎麼豪華、小說的描寫再怎麼生動、電影的鏡頭再怎麼絢麗，\n角色一開口講話，就決定了在故事底層湧動的糾葛、嘲諷和內蘊。\n沒有意味深長的對白，事件就少了深度，角色就沒有厚度，故事也就塌陷下去。\n對白撐起了故事。\n▉檢驗你的對白 Part 1\n對白要發揮效力，必須滿足以下六大任務。你寫的對白做到了嗎？\n1. 角色只要開口講話，就有內在行動。\n2. 每一拍的行動（反應）都會強化該場戲，以轉捩點為軸心，不斷蓄積劇情的能量。\n3. 台詞裡的陳述和影射，都具有講解角色或故事背景的功能。\n4. 每一角色各有其語言格調。\n5. 一拍、一拍往前流洩的氣勢牢牢抓住觀眾（讀者），讓他們被敘述的浪頭帶著走，渾然忘了時間。\n6. 對白的語言聽在觀眾（讀者）耳裡、放在演出的背景中都恰如其份，也符合角色的性格，讓觀眾（讀者）深陷在故事的邏輯與世界中，信以為真。\n寫好對白沒有公式\n卻有一套「吸引力法則」：\n打造內容層次的「冰山」\n＋ 探索形式的極限 ＋ 令觀者「通靈」的表達技巧\n\n對白的內容應該具有三種層次，決定你的人物厚度：\n●已說：角色選擇講給人聽的心思和感情。（露出海平面的冰山）\n●未說：角色內心只對自己說的心思和感情。（海平面下若隱若現的冰層）\n●不可說：潛意識裡的驅動和欲求，角色說不出口，連對自己悄悄私語也做不到，因為這是沉默無聲、覺察不到的。（海面下深不可知的龐大冰層）\n\n形式不會限制創作，反而會激發表達力：\n●電影、電視、舞台、小說四大媒介形式，對白應有什麼不同？\n電影劇本是影像重於聲音，舞台劇是聲音重於影像；電視劇介於劇場和電影之間，要求聲音、影像二者間的平衡；小說則是靠腦力，走的是迂迴的路線，必須取道讀者的心智。\n●不論哪一種媒介形式，對白都必須具備三種基本功能：\n1. 講解：指明故事的背景、歷史、角色等，供觀眾（讀者）在某個當下吸收消化，以便跟上情節與入戲。【同場加映】「以講解為彈藥」：《星際大戰：帝國大反擊》在劇情最高潮處，黑武士引爆了「路克是他兒子」這顆炸彈，震撼了全世界觀眾，觸發對續集的熱切期待。\n2. 角色塑造：從表相、真相這兩面來設計角色，創造出人物的本性，從而勾起觀眾（讀者）的興趣、賦予角色個性，最後取信於觀眾（讀者）。\n3. 行動：對白所展現的「口語行動」、角色在台詞背後所做之事，必須符合角色的性格，才能說服、打動觀眾（讀者）。\n高明的作者都懂得將「講解」化整為零，一點一點地釋放，只在觀眾（讀者）必須知道也想要知道的最適當時機透露訊息，半刻也不會提早，而且只給最少量，緊緊抓住觀眾（讀者）的好奇心、對角色的同理心，再加上深入人性的角色刻劃、有潛文本可以挖掘的口語行動，你的故事已經立於不敗之地。\n懂得運用表達技巧的好對白，能讓觀眾（讀者）有如會通靈一般，\n將未形諸言語的角色內心與觀眾（讀者）內心串連起來：\n●鑽研遣辭用字，打造獨創的對白：運用各種文學比喻手法，精煉出漂亮的台詞、具可信度的對白，又能帶出引申意涵，跟角色沒說出來、不能說出來的潛文本共鳴共振。\n●掌握各種台詞句式的優缺點，適時變化運用：包括將核心字詞往後推的懸疑句（戲劇性最大），或是核心字詞在前、像滾雪球一樣漸次推展的累進句（最自然，接近口語對話），或是把重點放在句子中間的平衡句，甚至同時並用不同句式的混合句——有意識地決定重點字詞的位置，牽動觀眾（讀者）的心。\n●善用周邊語言：諸如臉部表情、手勢、姿態、語速、音量、節奏、音調等，甚至角色站位的距離，都可以用來強化對白的意義和感覺。\n●非必要的句子就刪去：意味深長又精簡，才是好對白。\n●掌握停頓的機鋒：對白中的所有停頓都要付出代價，因此一定要有效果才停頓。\n●沉默無語也是一種語言：這是最極致的精簡。用說的不如用演的。\n用戲劇來說故事，重點不在於作者如何遣辭用字，而是作者進入角色後，讓角色在人生路上掙扎前行時如何遣辭用字。舉凡句法、措辭、步調等語言的組成單位，都是對白的生命線，但最能清楚勾勒角色生命與個性的，就屬角色選用的字詞（已說與未說），因為它們才能直指角色的內心，並引導觀眾（讀者）深入解讀潛文本（不可說）。\n▉檢驗你的對白 Part 2\n以下的對白寫作方法，你用過哪幾種？\n1. 用角色之間的閒聊，向觀眾（讀者）交代故事的設定或背景。\n2. 把角色設定的功課做到最足，不只個性、經歷與身份，也包括其內心所有創傷、弱點、潛意識活動，並透過對白展露無疑，讓角色充滿人性色彩。\n3. 常見用語和說法，是現實生活中確實在使用的語言，可以增添對白的真實況味，也可以讓觀眾（讀者）馬上理解，避免造成誤解。\n4. 婉轉迂迴的對白不只展現作者的程度和用心，也可以讓觀眾（讀者）細細品味。\n5. 把潛文本化為文本，以免觀眾（讀者）遺漏任何角色心裡流轉的念頭、情感波動。\n6. 讓兩個角色針鋒相對，把問題直接攤開來說個清楚，將情緒推到最高，製造出戲劇的張力與高潮。\n7. 現實中說話就是會囉唆，重複也可以是強調。寫實主義的對白不該回避真實的說話方式。\n8. 對白應該盡早破題、說出重點，以免觀眾失去耐性、出戲，甚至猜出角色後面要說的話。\n\n這樣的對白寫作，你知道有可能犯了諸如「內容空洞」、「陳腔濫調」、「淺白露骨」、「時機不對」等各式各樣常見的毛病，分別具有可信度、語言、內容、結構上的瑕疵嗎？\n角色，終究要在自身裡尋找，\n對白，要往自己的想像挖掘。\n\n培養創意寫作所需的兩種創造力：講故事的才氣 + 文學表現的才氣\n1. 講故事的才氣在於能將日常生活轉化為有深意、感動人的事情與角色，繼而將作品的內部構想（出了什麼事、被誰遇上了）雕琢為人生的比喻。\n2. 文學的才氣在於將日常生活的言語，轉化成為意味深長的對白。\n\n寫出角色專屬的對白\n◆頂尖作家怎麼運用「冰山技巧」？\n推展故事情節時，將大量內容劃歸為不說出來的心思、感覺、欲求、活動，壓進場景的潛文本，不見天日；開始說故事時，便以其為本創作台詞，作為角色行為的冰山一角。\n◆為什麼信手拈來的對白反而不好？什麼是「創作的極限法則」？\n技巧愈難，招式就愈漂亮。信手拈來一揮而就，寫出來的角色個個聽起來都像同一個模子印出來的。有束縛、紀律、限制，激發出來的創意才教人驚艷。搜索枯腸，就是要將想像力從極限挖出來的意象清晰立體地勾畫出來。\n全書結構\n第一部：對白的奧妙\n大幅擴張對白的定義，擴增更多的寫法，並深入剖析角色在說故事的四大媒介中開口說話的功能、內容、形式、技巧。\n第二部：診斷你的對白\n一一點名對白最常見的毛病，從無法說服觀眾，到陳腔濫調、鋪張賣弄、枯燥無味、意義模糊、嘮叨反覆、提示失準等，一一挖掘出病灶再開立藥方，並引用眾多小說、戲劇、電影、電視劇作品為範例，闡述琢磨對白的種種技巧。\n第三部：如何寫作對白\n檢視作家如何踢進「臨門一腳」：找到最適當的字眼，為角色寫出恰如其份的對白。角色說話應該各有其句法、節奏和聲調，以及最重要的用字等特點，某一角色嘴裡吐出來的話，非這角色講不出來。寫對白最理想的境界是每個角色活脫有如長了腳的字典，收錄這個角色專用的字詞。\n第四部：如何設計對白\n先討論故事的組成和場景的設計，以及它們如何決定角色說出怎樣的台詞。再以六部作品為例，深入探討以下兩大決定對白效力的原則：一、對白在一來一往間製造出「行動／反應」，進而推動場景發展；二、「行動」雖是從「說話」這種外在行為表現出來，角色行動的泉源卻是由潛文本悄無聲息流洩出來。","price":"450元新台币"},{"rating":{"max":10,"numRaters":45,"average":"6.0","min":0},"subtitle":"从数据获取到深度学习","author":["朱洁"],"pubdate":"2016-10","tags":[{"count":38,"name":"大数据","title":"大数据"},{"count":10,"name":"深度学习","title":"深度学习"},{"count":7,"name":"计算机","title":"计算机"},{"count":6,"name":"架构","title":"架构"},{"count":6,"name":"数据平台","title":"数据平台"},{"count":6,"name":"数据分析","title":"数据分析"},{"count":4,"name":"软件开发","title":"软件开发"},{"count":4,"name":"数据挖掘","title":"数据挖掘"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29120064.jpg","binding":"平装","translator":[],"catalog":"第一部分  大数据的本质\n第1章  大数据是什么\t2\n1.1  大数据导论\t2\n1.1.1  大数据简史\t2\n1.1.2  大数据现状\t3\n1.1.3  大数据与BI\t3\n1.2  企业数据资产\t4\n1.3  大数据挑战\t5\n1.3.1  成本挑战\t6\n1.3.2  实时性挑战\t6\n1.3.3  安全挑战\t6\n1.4  小结\t6\n第2章  运营商大数据架构\t7\n2.1  架构驱动的因素\t7\n2.2  大数据平台架构\t7\n2.3  平台发展趋势\t8\n2.4  小结\t8\n第3章  运营商大数据业务\t9\n3.1  运营商常见的大数据业务\t9\n3.1.1  SQM（运维质量管理）\t9\n3.1.2  CSE（客户体验提升）\t9\n3.1.3  MSS（市场运维支撑）\t10\n3.1.4  DMP（数据管理平台）\t10\n3.2  小结\t11\n第二部分  大数据技术\n第4章  数据获取\t14\n4.1  数据分类\t14\n4.2  数据获取组件\t14\n4.3  探针\t15\n4.3.1  探针原理\t15\n4.3.2  探针的关键能力\t16\n4.4  网页采集\t26\n4.4.1  网络爬虫\t26\n4.4.2  简单爬虫Python代码示例\t32\n4.5  日志收集\t33\n4.5.1  Flume\t33\n4.5.2  其他日志收集组件\t47\n4.6  数据分发中间件\t47\n4.6.1  数据分发中间件的作用\t47\n4.6.2  Kafka架构和原理\t47\n4.7  小结\t82\n第5章  流处理\t83\n5.1  算子\t83\n5.2  流的概念\t83\n5.3  流的应用场景\t84\n5.3.1  金融领域\t84\n5.3.2  电信领域\t85\n5.4  业界两种典型的流引擎\t85\n5.4.1  Storm\t85\n5.4.2  Spark Streaming\t89\n5.4.3  融合框架\t102\n5.5  CEP\t108\n5.5.1  CEP是什么\t108\n5.5.2  CEP的架构\t109\n5.5.3  Esper\t110\n5.6  实时结合机器学习\t110\n5.6.1  Eagle的特点\t111\n5.6.2  Eagle概览\t111\n5.7  小结\t116\n第6章  交互式分析\t117\n6.1  交互式分析的概念\t117\n6.2  MPP DB技术\t118\n6.2.1  MPP的概念\t118\n6.2.2  典型的MPP数据库\t121\n6.2.3  MPP DB调优实战\t131\n6.2.4  MPP DB适用场景\t162\n6.3  SQL on Hadoop\t163\n6.3.1  Hive\t163\n6.3.2  Phoenix\t165\n6.3.3  Impala\t166\n6.4  大数据仓库\t167\n6.4.1  数据仓库的概念\t167\n6.4.2  OLTP\/OLAP对比\t168\n6.4.3  大数据场景下的同与不同\t168\n6.4.4  查询引擎\t169\n6.4.5  存储引擎\t170\n6.5  小结\t171\n第7章  批处理技术\t172\n7.1  批处理技术的概念\t172\n7.2  MPP DB技术\t172\n7.3  MapReduce编程框架\t173\n7.3.1  MapReduce起源\t173\n7.3.2  MapReduce原理\t173\n7.3.3  Shuffle\t174\n7.3.4  性能差的主要原因\t177\n7.4  Spark架构和原理\t177\n7.4.1  Spark的起源和特点\t177\n7.4.2  Spark的核心概念\t178\n7.5  BSP框架\t217\n7.5.1  什么是BSP模型\t217\n7.5.2  并行模型介绍\t218\n7.5.3  BSP模型基本原理\t220\n7.5.4  BSP模型的特点\t222\n7.5.5  BSP模型的评价\t222\n7.5.6  BSP与MapReduce对比\t222\n7.5.7  BSP模型的实现\t223\n7.5.8  Apache Hama简介\t223\n7.6  批处理关键技术\t227\n7.6.1  CodeGen\t227\n7.6.2  CPU亲和技术\t228\n7.7  小结\t229\n第8章  机器学习和数据挖掘\t230\n8.1  机器学习和数据挖掘的联系与区别\t230\n8.2  典型的数据挖掘和机器学习过程\t231\n8.3  机器学习概览\t232\n8.3.1  学习方式\t232\n8.3.2  算法类似性\t233\n8.4  机器学习&数据挖掘应用案例\t235\n8.4.1  尿布和啤酒的故事\t235\n8.4.2  决策树用于电信领域故障快速定位\t236\n8.4.3  图像识别领域\t236\n8.4.4  自然语言识别\t238\n8.5  交互式分析\t239\n8.6  深度学习\t240\n8.6.1  深度学习概述\t240\n8.6.2  机器学习的背景\t241\n8.6.3  人脑视觉机理\t242\n8.6.4  关于特征\t244\n8.6.5  需要有多少个特征\t245\n8.6.6  深度学习的基本思想\t246\n8.6.7  浅层学习和深度学习\t246\n8.6.8  深度学习与神经网络\t247\n8.6.9  深度学习的训练过程\t248\n8.6.10  深度学习的框架\t248\n8.6.11  深度学习与GPU\t255\n8.6.12  深度学习小结与展望\t256\n8.7  小结\t257\n第9章  资源管理\t258\n9.1  资源管理的基本概念\t258\n9.1.1  资源调度的目标和价值\t258\n9.1.2  资源调度的使用限制及难点\t258\n9.2  Hadoop领域的资源调度框架\t259\n9.2.1  YARN\t259\n9.2.2  Borg\t260\n9.2.3  Omega\t262\n9.2.4  本节小结\t263\n9.3  资源分配算法\t263\n9.3.1  算法的作用\t263\n9.3.2  几种调度算法分析\t263\n9.4  数据中心统一资源调度\t271\n9.4.1  Mesos+Marathon架构和原理\t271\n9.4.2  Mesos+Marathon小结\t283\n9.5  多租户技术\t284\n9.5.1  多租户概念\t284\n9.5.2  多租户方案\t284\n9.6  基于应用描述的智能调度\t287\n9.7  Apache Mesos架构和原理\t288\n9.7.1  Apache Mesos背景\t288\n9.7.2  Apache Mesos总体架构\t288\n9.7.3  Apache Mesos工作原理\t290\n9.7.4  Apache Mesos关键技术\t295\n9.7.5  Mesos与YARN比较\t304\n9.8  小结\t305\n第10章  存储是基础\t306\n10.1  分久必合，合久必分\t306\n10.2  存储硬件的发展\t306\n10.2.1  机械硬盘的工作原理\t306\n10.2.2  SSD的原理\t307\n10.2.3  3DXPoint\t309\n10.2.4  硬件发展小结\t309\n10.3  存储关键指标\t309\n10.4  RAID技术\t309\n10.5  存储接口\t310\n10.5.1  文件接口\t311\n10.5.2  裸设备\t311\n10.5.3  对象接口\t312\n10.5.4  块接口\t316\n10.5.5  融合是趋势\t328\n10.6  存储加速技术\t328\n10.6.1  数据组织技术\t328\n10.6.2  缓存技术\t335\n10.7  小结\t336\n第11章  大数据云化\t337\n11.1  云计算定义\t337\n11.2  应用上云\t337\n11.2.1  Cloud Native概念\t338\n11.2.2  微服务架构\t338\n11.2.3  Docker配合微服务架构\t342\n11.2.4  应用上云小结\t348\n11.3  大数据上云\t348\n11.3.1  大数据云服务的两种模式\t348\n11.3.2  集群模式AWSEMR\t349\n11.3.3  服务模式Azure Data Lake Analytics\t352\n11.4  小结\t354\n第三部分  大数据文化\n第12章  大数据技术开发文化\t356\n12.1  开源文化\t356\n12.2  DevOps理念\t356\n12.2.1  Development和Operations的组合\t357\n12.2.2  对应用程序发布的影响\t357\n12.2.3  遇到的问题\t358\n12.2.4  协调人\t358\n12.2.5  成功的关键\t359\n12.3  速度远比你想的重要\t359\n12.4  小结\t361","pages":"372","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29120064.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29120064.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29120064.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26902173\/","id":"26902173","publisher":"电子工业出版社","isbn10":"7121300001","isbn13":"9787121300004","title":"大数据架构详解","url":"https:\/\/api.douban.com\/v2\/book\/26902173","alt_title":"","author_intro":"朱洁,2008年加入华为，具有8年大数据研发管理经验，现任华为大数据服务首席规划师。专注于大数据服务平台建设、规划和实践应用，同时参与多项企业级大数据项目解决方案的规划、设计和实施工作，在深化大数据行业落地方面有诸多实践经验，对解读大数据垂直行业的技术创新与开发有诸多独到的见解和心得。\n罗华霖,2002年加入华为，华为大数据首席规划师，主导完成华为大数据平台DataSight和华为电信大数据解决方案SmartCare技术规划和架构设计，支持电信运营商数字化战略转型，完成浙江移动、上海联通、沙特STC等200+电信大数据解决方案项目落地。曾任华为软交换首席设计师，华为大型电信大数据解决方案SmartCare首席架构师。","summary":"《大数据架构详解：从数据获取到深度学习》从架构、业务、技术三个维度深入浅出地介绍了大数据处理领域端到端的知识。主要内容包括三部分：第一部分从数据的产生、采集、计算、存储、消费端到端的角度介绍大数据技术的起源、发展、关键技术点和未来趋势，结合生动的业界最新产品，以及学术界最新的研究方向和成果，让深奥的技术浅显易懂；第二部分从业务和技术角度介绍实际案例，让读者理解大数据的用途及技术的本质；第三部分介绍大数据技术不是孤立的，讲解如何与前沿的云技术、深度学习、机器学习等相结合。\n《大数据架构详解：从数据获取到深度学习》内容深入浅出，技术结合实践，从实践中理解架构和技术的本质，适合大数据技术领域的从业人员如架构师、工程师、产品经理等，以及准备学习相关领域知识的学生和老师阅读。","price":"69"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"一种强大的可扩展的人工智能和深度学习技术","author":["达伦.库克"],"pubdate":"2018-7-1","tags":[{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"机器学习","title":"机器学习"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":1,"name":"H2O","title":"H2O"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29896474.jpg","binding":"平装","translator":[],"catalog":"译者序\n原书前言\n第 1章 安装和快速启动 1\n1.1 安装准备 1\n1.1.1 安装 R 1\n1.1.2 安装 Python 2\n1.1.3 隐私保护 2\n1.1.4 安装 Java 2\n1.2 利用 R（CRAN）安装 H2O 3\n1.3 利用 Python（pip）安装 H2O 4\n1.4 diyi个学习示例 5\n1.4.1 利用 Python进行训练和预测 8\n1.4.2 利用 R进行训练和预测 10\n1.4.3 性能与预测 12\n1.4.4 运气不佳 13\n1.5 Flow 13\n1.5.1 数据 14\n1.5.2 模型 16\n1.5.3 预测 17\n1.5.4 Flow中的其他注意事项 18\n1.6 小结 18\n第2章 数据导入\/数据导出19\n2.1 存储空间要求 19\n2.2 数据准备 20\n2.3 数据导入到 H2O 21\n2.3.1 加载 csv文件 21\n2.3.2 加载其他格式文件 23\n2.3.3 从 R中直接加载 23\n2.3.4 从 Python中直接加载 25\n2.4 数据操作 26\n2.4.1 懒操作、命名和删除 26\n2.4.2 数据汇总 27\n2.4.3 列操作 28\n2.4.4 行聚合 29\n2.4.5 索引 30\n2.4.6 H2O中的数据拆分 31\n2.4.7 行和列 35\n2.5 数据从 H2O中导出 38\n2.5.1 导出数据帧 38\n2.5.2 POJO 39\n2.5.3 模型文件 40\n2.5.4 保存所有模型 40\n2.6 小结 41\n第３章 数据集 42\n3.1 数据集：建筑节能 42\n3.1.1 设置和加载 43\n3.1.2 数据列 44\n3.1.3 拆分数据 45\n3.1.4 观察 46\n3.1.5 关于数据集 50\n3.2 数据集：手写体 50\n3.2.1 设置和加载 51\n3.2.2 观察 52\n3.2.3 帮助建模 54\n3.2.4 关于数据集 55 5.4 建筑节能：默认的随机森林 91\n3.3 数据集：足球比分 56\n3.3.1 相关性 59\n3.3.2 缺失数据.更多列 62\n3.3.3 如何训练和测试？ 63\n3.3.4 设置和加载 63\n3.3.5 其他第三方 64\n3.3.6 缺失数据（再次） 67\n3.3.7 设置和加载（再次） 67\n3.3.8 关于数据集 70\n3.4 小结 70\n第 4章 常用模型参数 71\n4.1 支持测度 71\n4.1.1 回归指数 72\n4.1.2 分类指数 72\n4.1.3 二项式分类 73\n4.2 要素 75\n4.3 努力 76\n4.4 评分和验证 76\n4.5 提前终止 77\n4.6 检查点 79\n4.7 交叉验证（又名 k-folds） 81\n4.8 数据加权 82\n4.9 抽样、归纳 84\n4.10 回归 85\n4.11 输出控制 87\n4.12 小结 87\n第5章 随机森林88\n5.1 决策树 88\n5.2 随机森林 89\n5.3 参数 89 5.5 网格搜索 93\n5.5.1 笛卡尔 94\n5.5.2 随机离散 96\n5.5.3 高层策略 98\n5.6 建筑节能：改进的随机森林 99\n5.7 MNIST：默认的随机森林 101\n5.8 MNIST：改进的随机森林 102\n5.8.1 增强数据 105\n5.9 足球比赛：默认的随机森林 106\n5.10 足球比赛：改进的随机森林 108\n5.11 小结 110\n第 6章 梯度推进机 \/\/ 111\n6.1 推进 \/\/ 111\n6.2 好处、坏处和…神秘之处 \/\/ 112\n6.3 参数 \/\/ 113\n6.4 建筑节能：默认 GBM \/\/ 114\n6.5 建筑节能：改进 GBM \/\/ 115\n6.6 MNIST：默认 GBM \/\/ 119\n6.7 MNIST：改进 GBM \/\/ 120\n6.8 足球比赛：默认 GBM \/\/ 122\n6.9 足球比赛：改进 GBM \/\/ 123\n6.10 小结 \/\/ 125\n第 7章 线性模型 \/\/ 126\n7.1 GLM参数 \/\/ 126\n7.2 建筑节能：默认 GLM \/\/ 130\n7.3 建筑节能：改进 GLM \/\/ 132\n7.4 MNIST：默认 GLM \/\/ 136\n7.5 MNIST：改进 GLM \/\/ 137\n7.6 足球比赛：默认 GLM \/\/ 139\n7.7 足球比赛：改进 GLM \/\/ 141\n7.8 小结 \/\/ 142\n第 8章 深度学习（神经网络）\/\/ 143\n8.1 什么是神经网络？ \/\/ 143\n8.1.1 数值与分类 \/\/ 145\n8.1.2 神经网络层 \/\/ 146\n8.1.3 激活函数 \/\/ 147\n8.2 参数 \/\/ 148\n8.2.1 深度学习正则化 \/\/ 148\n8.2.2 深度学习评分 \/\/ 149\n8.3 建筑节能：默认的深度学习 \/\/ 152\n8.4 建筑节能：改进的深度学习 \/\/ 153\n8.5 MNIST：默认的深度学习 \/\/ 157\n8.6 MNIST：改进的深度学习 \/\/ 159\n8.7 足球比赛：默认的深度学习 \/\/ 163\n8.8 足球比赛：改进的深度学习 \/\/ 164\n8.9 小结 \/\/ 168\n8.10 附录：更多的深度学习参数 \/\/ 169\n第 9章 无监督学习 \/\/ 171\n9.1 k均值聚类 \/\/ 172\n9.2 深度学习自动编码器 \/\/ 174\n9.2.1 层叠自动编码器 \/\/ 177\n9.3 主成分分析 \/\/ 178\n9.4 GLRM \/\/ 179\n9.5 缺失数据 \/\/ 180\n9.5.1 GLRM \/\/ 183\n9.5.2 失去 R \/\/ 183\n9.6 小结 \/\/ 187\n第 10章 其他内容 \/\/ 188\n10.1 重要且需要分析的内容 \/\/ 188\n10.2 安装zui新版本的 H2O \/\/ 188\n10.2.1 由源代码构建 \/\/ 189\n10.3 命令行运行 \/\/ 189\n10.4 聚类 \/\/ 189\n10.4.1 EC2 \/\/ 190\n10.4.2 其他云提供商 \/\/ 191\n10.4.3 Hadoop \/\/ 191\n10.5 Spark\/Sparkling Water \/\/ 191\n10.6 朴素贝叶斯 \/\/ 192\n10.7 集成 \/\/ 192\n10.7.1 层叠： h2o.ensemble \/\/ 193\n10.7.2 分类集成 \/\/ 195\n10.8 小结 \/\/ 195\n第 11章 后记：一切运行良好！ \/\/ 196\n11.1 建筑节能结果 \/\/ 196\n11.2 MNIST结果 \/\/ 197\n11.3 足球比赛结果 \/\/ 199\n11.4 究竟有多差？ \/\/ 200\n11.4.1 越多越好 \/\/ 201\n11.4.2 仍渴望更多 \/\/ 202\n11.4.3 困难排除 \/\/ 202\n11.4.4 自动编码器 \/\/ 203\n11.4.5 卷积和收缩 \/\/ 204\n11.4.6 集成 \/\/ 205\n11.4.7 这就是可能zui差的情况. \/\/ 206\n11.5 小结 \/\/ 206","pages":"206","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29896474.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29896474.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29896474.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30352509\/","id":"30352509","publisher":"机械工业出版社","isbn10":"7111600517","isbn13":"9787111600510","title":"基于H2O的机器学习实用方法","url":"https:\/\/api.douban.com\/v2\/book\/30352509","alt_title":"","author_intro":"","summary":"《基于H2O的机器学习实用方法：一种强大的可扩展的人工智能和深度学习技术》主要介绍了H2O的基本概念和应用。全书共11章，首先介绍了H2O在R和Python下的安装和启动、数据导入\/导出和操作以及本书所用的三种不同示例数据集和常用的模型参数。然后分别介绍了随机森林、梯度推进机、线性模型、深度学习和无监督式学习等算法在三种不同数据集中的应用，分析对比了默认算法和改进算法的性能。另外，还讨论了相关其他内容。","series":{"id":"45479","title":"深度学习系列"},"price":"69"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"跨越边界的深度学习","author":["[美]弗朗西斯·克鲁尼"],"pubdate":"2014-11","tags":[{"count":1,"name":"杂文","title":"杂文"},{"count":1,"name":"宗教","title":"宗教"}],"origin_title":"Comparative Theology: Deep Learning Across Religious Borders","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28318254.jpg","binding":"平装","translator":["聂建松 等"],"catalog":"总序\n致中国读者\n献给我的那些学生\n前言与致谢\n第一部分 出发点\n第一章 宗教多样性和比较神学\n我们身边的多样性\n我们内部的多样性\n比较神学作为对21世纪宗教多样性的一种回应\n比较神学与相关学科的区别\n比较神学与学术的宗教研究\n比较神学与跨宗教对话\n比较神学和诸宗教神学（Theology of Religions）\n基于自我经历的比较神学\n本书的局限性\n前瞻\n第二章 过去的几代人：比较神学的一些前辈\n比较神学与基督教跨宗教思考的悠久历史\n在印度的西方耶稣会学者\n作为一门学科的比较神学（1699至今）\n对传教学术和旧有的比较神学的温和批判\n时代的结束\n第三章 当今的比较神学\n大卫·特雷西\n奇斯·沃德\n南乐山\n对雷蒙·潘尼卡的评述\n詹姆斯·弗雷德里克\n新方向\n从理论（回）到实践\n第二部分 比较地去做神学\n第四章 从理论到实践\n（比较）宗教阅读的实践\n理智的阅读\n作为一种宗教实践的注释\n跨宗教的评注\n为其他的阅读者以及他们的阅读方式留出空间\n必要的精英选择\n第五章 进入具体：对印度教的一种基督教研究\n专注的重要性\n这一特殊的比较神学的（自我）说明\n绘制地图，标记领域：概论印度教\n进入具体：弥漫差，吠檀多，室利·毗湿奴派\n欣赏相似之处\n作为一种实际和恰当的关注方式的神一位论印度教\n作为印度学一门学科的神学\n印度教和其他传统中的比较神学\n我的比较神学，汲取自印度教神学\n第六章 “学会观察”：比较的实践和神学视野的拓展\n2003年，在美国天主教神学学会的全体报告\n走近一位女神\n提毗的美丽，提毗的愉悦\n重新发现玛利亚\n通过穆斯林的角度，看玛利亚和她的儿子耶稣\n索琼纳·特鲁思的解放的上帝\n众人在基督之中，但仍旧是自身\n天职\n“学会观察”之后\n第三部分 比较的成果\n第七章 比较之后的神学\n比较神学以及更为宏大的神学工作\n比较神学家的多重责任\n比较神学里暗含的一些神学假设\n具体的比较神学学习\n神的形象与我们有福的命运\n那罗延对于基督教徒的意义\n与女神相遇\n比较神学与虔信的强化\n小范围内的神学\n第八章 “为我们而在的神”\n“为我们而在的神”：一篇文章\n一段经文、一条线索\n印度教徒对这段经文的理解\n让经文变得生动\n经文和更广的语境\n关于“如何观看神”以及“神希望如何被观看”的一段题外话\n关注个人第一身份：对依纳爵观点的思考和我本来的身份\n依纳爵必须提及的内容\n对于《灵性操练》中，关于想象力的集中与清空的几种现代观点\n多重宗教归属，与人有关也与神有关\n作为比较神学内容的“为我们而在的神”\n第九章 比较的作者，比较的读者\n转变的比较神学家\n作为边缘人的比较神学家\n比较神学家的新团体\n读者的任务和机遇\n超越本书\n后记","pages":"191","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28318254.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28318254.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28318254.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25841850\/","id":"25841850","publisher":"宗教文化出版社","isbn10":"7802548101","isbn13":"9787802548107","title":"比较神学","url":"https:\/\/api.douban.com\/v2\/book\/25841850","alt_title":"Comparative Theology: Deep Learning Across Religious Borders","author_intro":"弗朗西斯·克鲁尼，哈佛大学教授及世界宗教研究中心主任。主要研究领域为宗教对话、比较申雪、印度教梵文和泰米尔文传统神学评注等，其所倡导的比较申雪推动宗教对话的方法在国际上独树一帜。作品有《超越比较：萨勒的圣法兰西斯和室利·吠檀多·提希伽对神的顺从之爱》、《真理、道路、生命：对室利·毗湿奴派神三圣颂的基督教评注》。2010年6月，当选英国社会科学院（British Academy）成员。","summary":"《比较神学——跨越边界的深度学习》一书的作者弗朗西斯·克鲁尼以其亲身经验，为我们提供了一个全新的“以比较促对话、以对话促互鉴”的新视野，表明了基督教思想发展之中的一种新的可能性。它为宗教对话提供了一种全新的理解方式——尊重彼此的独立性的同时，以对方的视野反观自身，从中得出有益于自身的思想。作者言辞恳切，思想深邃，充分体现了梵蒂冈二、欠会议叉寸于宗教对话的影响，实为不可多得的一本好书。\n本书介绍了一种新的比较研究与宗教间对话的模式，即比较神学。这种模式基于作者自身的传统，由此而出发进入到另外一个传统之中，从那个传统反观自身，并再次回归到自身传统之中加以深化和发展。这种方法不要求消解自身的传统，而是通过对异传统的深度学习，来丰富和深化自身。此种方法不同于以往的比较研究，它不追求宏大的解释，也不希望从前提中获得预想的答案。此书对基督教圣母与印度教女神、基督教与印度教灵修等方面进行了一些具体的比较，用实例来证明比较神学的特殊性和实用性，并对比较神学的未来进行了前瞻。","series":{"id":"35822","title":"比较经学丛书"},"price":"30.00元"},{"rating":{"max":10,"numRaters":54,"average":"8.1","min":0},"subtitle":"原理与实践","author":["陈仲铭","何   明"],"pubdate":"2019-4","tags":[{"count":23,"name":"强化学习","title":"强化学习"},{"count":15,"name":"人工智能","title":"人工智能"},{"count":12,"name":"机器学习","title":"机器学习"},{"count":6,"name":"推荐好书","title":"推荐好书"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31469915.jpg","binding":"平装","translator":[],"catalog":"第一篇 初探强化学习\n--第1章 强化学习绪论\n--第2章 数学基础及环境\n第二篇 求解强化学习\n--第3章 动态规划法\n--第4章 蒙特卡洛法\n--第5章 时间差分法\n第三篇 求解强化学习进阶\n--第6章 值函数近似法\n--第7章 策略梯度法\n--第8章 整合学习与规划\n第四章 深度强化学习\n--第9章 深度强化学习\n--第10章 深度Q网络\n--第11章 深度强化学习算法框架\n--第12章 从围棋AlphaGo到AlphaGo Zero","pages":"380","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s31469915.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s31469915.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31469915.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32568833\/","id":"32568833","publisher":"","isbn10":"7115505322","isbn13":"9787115505323","title":"深度强化学习","url":"https:\/\/api.douban.com\/v2\/book\/32568833","alt_title":"","author_intro":"陈仲铭：西安电子科技大学硕士。主要研究方向为强化学习与深度学习、数据挖掘、图像算法及其应用。曾参与激光点云三维扫描、个性化推荐系统、多传感器融合系统等大型项目，期间多次获国家级创新项目奖，并在国内外发表多篇相关论文。此外，作为技术顾问为 多家科研和企业机构提供关于数学建模、深度学习等咨询和培训。著有《深度学习原理与实践》一书。\n何明：重庆大学学士，中国科学技术大学博士，曾于美国北卡夏洛特分校访学交流，目前为上海交通大学电子科学与技术方向博士后研究人员、OPPO研究院人工智能算法研究员。主要研究方向为深度强化学习、数据挖掘与知识发现、机器学习方法及其应用，侧重于移动端用户行为分析与建模。在TIP、TWEB、DASFAA、IEEE Access等重要学术会议和期刊共发表论文10余篇，并获得过数据挖掘领域国际会议KSEM2018的最佳论文奖。","summary":"本书构建了一个完整的深度强化学习理论和实践体系：从马尔科夫决策过程开始，根据价值函数、策略函数求解贝尔曼方程，到利用深度学习模拟价值网络和策略网络。书中详细介绍了深度强化学习相关最新算法，如Rainbow、APE-X算法等，并阐述了相关算法的具体实现方式和代表性应用（如AlphaGo）。此外，本书还深度剖析了强化学习各算法之间的联系，有助于读者举一反三。\n本书分为4个部分：初探强化学习、求解强化学习、求解强化学习进阶和深度强化学习。涉及基础理论到深度强化学习算法框架的各方面内容，反映了深度强化学习领域过去的发展历程和最新的研究进展，有助于读者发现该领域中新的研究问题和方向。\n本书适用于计算机视觉、计算机自然语言的相关从业人员，以及对人工智能、机器学习和深度学习感兴趣的人员，还可作为高等院校计算机等相关专业本科生及研究生的参考用书。","price":""},{"rating":{"max":10,"numRaters":13,"average":"7.7","min":0},"subtitle":"深度学习系统构建详解","author":[],"pubdate":"2018-6","tags":[{"count":6,"name":"机器学习","title":"机器学习"},{"count":4,"name":"tensorflow","title":"tensorflow"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"对对对","title":"对对对"},{"count":1,"name":"以色列","title":"以色列"},{"count":1,"name":"2018","title":"2018"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29935128.jpg","binding":"平装","translator":["朱小虎","李紫辉"],"catalog":"前言1\n第1章 引言5\n1.1 走入深度学习5\n1.2 TensorFlow：名字中的含义8\n1.3 高层次概览9\n1.4 本章总结11\n第2章 随之“流”动：启动与运行TensorFlow12\n2.1 安装TensorFlow12\n2.2 Hello World14\n2.3 MNIST16\n2.4 softmax回归17\n2.5 本章总结24\n第3章 理解TensorFlow基础知识25\n3.1 计算图25\n3.2 图、会话和提取数据26\n3.3 流动的张量32\n3.4 变量、占位符和简单的优化41\n3.5 本章总结52\n第4章 卷积神经网络53\n4.1 卷积神经网络简介53\n4.2 MNIST：第二轮55\n4.3 CIFAR1063\n4.4 本章总结71\n第5章 文本I：文本及序列的处理，以及TensorBoard可视化72\n5.1 序列数据的重要性72\n5.2 循环神经网络简介73\n5.3 处理RNN的文本序列87\n5.4 本章总结97\n第6章 文本II：词向量、高级RNN和词嵌入可视化99\n6.1 词嵌入介绍99\n6.2 word2vec101\n6.3 预训练词嵌入，高级RNN110\n6.4 本章总结116\n第7章 TensorFlow抽象与简化117\n7.1 本章概述117\n7.2 contrib.learn121\n7.3 TFLearn136\n7.4 本章总结156\n第8章 队列、线程和数据读取158\n8.1 输入管道158\n8.2 TFRecord159\n8.3 队列162\n8.4 完全多线程的输入管道168\n8.5 本章总结172\n第9章 分布式 TensorFlow173\n9.1 分布式计算173\n9.2 TensorFlow 元素175\n9.3 分布式示例180\n9.4 本章总结187\n第10章 用TensorFlow导出和提供服务模型188\n10.1 保存和导出模型188\n10.2 TensorFlow Serving简介199\n10.3 本章总结209\n附录A 模型构建和使用TensorFlow Serving的建议210","pages":"227","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29935128.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29935128.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29935128.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30285667\/","id":"30285667","publisher":"机械工业出版社","isbn10":"711160072X","isbn13":"9787111600725","title":"TensorFlow学习指南","url":"https:\/\/api.douban.com\/v2\/book\/30285667","alt_title":"","author_intro":"Tom Hope 是一位应用机器学习研究者和数据科学家，在学术界和工业界拥有广泛的背景。他领导了跨领域的数据科学和深度学习的研发团队。\nYehezkel S. Resheff 是机器学习和数据挖掘领域的应用研究人员。在读博士期间，他的工作主要围绕开发机器学习和深度学习方法来分析可穿戴设备和物联网的数据。他在英特尔和Microsoft公司领导了深度学习的研发工作。\nItay Lieder 是机器学习和计算神经科学领域的应用研究人员。在研究生学习期间，他开发了用于模拟低级知觉的计算方法。他曾在大型跨国公司工作，在文本分析、Web挖掘领域从事深度学习研发。","summary":"本书主要介绍如何使用 TensorFlow 框架进行深度学习系统的构建。从基础知识入手，将使用TensorFlow 的各种方式贯穿于整本书的讲解之中，并结合实际的深度学习任务展示终深度学习系统的效果。本书涉及卷积神经网络、循环神经网络等核心的技术，并介绍了用于图像数据和文本序列数据的模型。在后半部分，本书介绍了更加高级的使用 TensorFlow 的技巧，并给出了分布式深度学习系统在TensorFlow 下的构建过程以及如何将训练后的模型导出和部署的方法。通过学习本书，你将能够使用 TensorFlow 完成从简单到高级应用系统构建的技术。\n本书适合计算机相关专业的学生、软件工程师、深度学习开发者、架构师、CTO 等技术人员阅读。","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"用Python進行深度學習的基礎理論實作","author":["[日]斎藤康毅"],"pubdate":"2017-8","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"Python","title":"Python"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29617731.jpg","binding":"平装","translator":["吳嘉芳"],"catalog":"第一章 Python入門\n第二章 感知器\n第三章 神經網路\n第四章 神經網路的學習\n第五章 誤差反向傳播法\n第六章 與學習有關的技巧\n第七章 卷積神經網路\n第八章 深度學習\n附錄A Softmax-with-Loss層的計算圖\n參考文獻","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29617731.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29617731.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29617731.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27280063\/","id":"27280063","publisher":"歐萊禮","isbn10":"9864764845","isbn13":"9789864764846","title":"Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/27280063","alt_title":"","author_intro":"斎藤康毅\n1984年生於長崎縣對馬，畢業於東京工業大學工學院，東京大學研究所學際情報學府學士課程修畢。現在於企業內從事與電腦視覺、機器學習有關的研究開發工作。1984年生於長崎縣對馬，畢業於東京工業大學工學院，東京大學研究所學際情報學府學士課程修畢。現在於企業內從事與電腦視覺、機器學習有關的研究開發工作。","summary":"不走捷徑，幫助您真正搞懂「深度學習」的真義\n這是一本與「深度學習」有關的書籍。從入門開始說明，一步一步帶領你瞭解深度學習必須具備的知識。本書可以幫助您了解：深度學習究竟是什麼？有何特色？根據何種原理來運作？\n從零開始，由實做中學習\n本書的目標是，盡量避免使用不瞭解內容的「黑盒子」，以基礎的知識為起點，以容易上手的Python撰寫程式，從動手實作的過程中，一步步深入瞭解深度學習。若以車用書籍來比喻這本書的話，這本書並不屬於汽車駕訓教材，而是希望能夠幫助您瞭解車子的原理，而非教您開車的方法。為了瞭解汽車的結構，必須試著打開車子的引擎蓋，將每個零件都拿起來觀察、操作看看。然後盡量用簡單的形狀，篩選出車子的核心部分，就像組合迷你模型般，製作出這台車子。本書的目標，就是透過製作車子的過程，讓你感受到自己實際可以製作出車子，進而熟悉與車子的相關技術。\n本書特色：\n．利用最少的外部函式庫，使用Python，從零開始實際執行深度學習的程式。\n．說明Python 的用法，讓Python 的初學者也能理解。\n．實際執行Python 的原始碼，同時提供讀者手邊可以進行實驗的學習環境。\n．從簡單的機器學習問題開始，到最後執行精密辨識影像的系統。\n．以淺顯易懂的方式說明深度學習與神經網路理論。\n．針對看似複雜的技術，如誤差反向傳播與卷積運算等，利用實際操作方式說明，幫助理解。\n．介紹在執行深度學習時，有幫助且實用的技巧，包括決定學習率的方法、權重的預設值等。\n．說明Batch Normalization、Dropout、Adam 等最近的趨勢與操作。\n．為什麼深度學習很優秀，為什麼加深層數，就能提高辨識準確度，為什麼隱藏層很重要，仔細說明這些「為什麼」。\n．介紹自動運作、產生影像、強化學習等深度學習的應用範例。","price":"TWD580"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"一个深度学习框架的初步实现","author":["李伟"],"pubdate":"2018-11-1","tags":[{"count":14,"name":"C++","title":"C++"},{"count":7,"name":"深度学习","title":"深度学习"},{"count":4,"name":"计算机","title":"计算机"},{"count":4,"name":"元编程","title":"元编程"},{"count":3,"name":"计算机科学","title":"计算机科学"},{"count":2,"name":"游戏","title":"游戏"},{"count":2,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29939243.jpg","binding":"平装","translator":[],"catalog":"第一部分　元编程基础技术\n第1章 基本技巧　3\n1.1　元函数与type_traits　3\n1.1.1　元函数介绍　3\n1.1.2　类型元函数　4\n1.1.3　各式各样的元函数　6\n1.1.4　type_traits　7\n1.1.5　元函数与宏　7\n1.1.6　本书中元函数的命名方式　8\n1.2　模板型模板参数与容器模板　8\n1.2.1　模板作为元函数的输入　9\n1.2.2　模板作为元函数的输出　9\n1.2.3　容器模板　10\n1.3　顺序、分支与循环代码的编写　12\n1.3.1　顺序执行的代码　12\n1.3.2　分支执行的代码　13\n1.3.3　循环执行的代码　19\n1.3.4　小心：实例化爆炸与编译崩溃　21\n1.3.5　分支选择与短路逻辑　23\n1.4　奇特的递归模板式　24\n1.5　小结　25\n1.6　练习　26\n第2章 异类词典与policy模板　28\n2.1　具名参数简介　28\n2.2　异类词典　30\n2.2.1　模块的使用方式　30\n2.2.2　键的表示　32\n2.2.3　异类词典的实现　34\n2.2.4　VarTypeDict的性能简析　41\n2.2.5　用std::tuple作为缓存　41\n2.3　policy模板　42\n2.3.1　policy介绍　42\n2.3.2　定义policy与policy对象（模板）　45\n2.3.3　使用policy　47\n2.3.4　背景知识：支配与虚继承　49\n2.3.5　policy对象与policy支配结构　50\n2.3.6　policy选择元函数　52\n2.3.7　使用宏简化policy对象的声明　57\n2.4　小结　58\n2.5　练习　58\n第二部分 深度学习框架\n第3章　深度学习概述　63\n3.1　深度学习简介　63\n3.1.1　从机器学习到深度学习　64\n3.1.2　各式各样的人工神经网络　65\n3.1.3　深度学习系统的组织与训练　68\n3.2　本书所实现的框架：MetaNN　70\n3.2.1　从矩阵计算工具到深度学习框架　70\n3.2.2　MetaNN介绍　71\n3.2.3　本书将要讨论的内容　72\n3.2.4　本书不会涉及的主题　75\n3.3　小结　75\n第4章　类型体系与基本数据类型　76\n4.1　类型体系　77\n4.1.1　类型体系介绍　77\n4.1.2　迭代器分类体系　78\n4.1.3　将标签作为模板参数　80\n4.1.4　MetaNN的类型体系　81\n4.1.5　与类型体系相关的元函数　82\n4.2　设计理念　84\n4.2.1　支持不同的计算设备与计算单元　84\n4.2.2　存储空间的分配与维护　85\n4.2.3　浅拷贝与写操作检测　88\n4.2.4　底层接口扩展　89\n4.2.5　类型转换与求值　91\n4.2.6　数据接口规范　92\n4.3　标量　92\n4.3.1　类模板的声明　93\n4.3.2　基于CPU的特化版本　94\n4.3.3　标量的主体类型　95\n4.4　矩阵　96\n4.4.1　Matrix类模板　96\n4.4.2　特殊矩阵：平凡矩阵、全零矩阵与独热向量　101\n4.4.3　引入新的矩阵类　104\n4.5　列表　105\n4.5.1　Batch模板　105\n4.5.2　Array模板　108\n4.5.3　重复与Duplicate模板　113\n4.6　小结　116\n4.7　练习　116\n第5章　运算与表达式模板　119\n5.1　表达式模板简介　119\n5.2　MetaNN运算模板的设计思想　122\n5.2.1　Add模板的问题　122\n5.2.2　运算模板的行为分析　122\n5.3　运算分类　124\n5.4　辅助模板　125\n5.4.1　辅助类模板OperElementType_\/OperDeviceType_　125\n5.4.2　辅助类模板OperXXX_　126\n5.4.3　辅助类模板OperCateCal　126\n5.4.4　辅助类模板OperOrganizer　128\n5.4.5　辅助类模板OperSeq　130\n5.5　运算模板的框架　131\n5.5.1　运算模板的类别标签　131\n5.5.2　UnaryOp的定义　132\n5.6　运算实现示例　133\n5.6.1　Sigmoid运算　133\n5.6.2　Add运算　136\n5.6.3　转置运算　139\n5.6.4　折叠运算　141\n5.7　MetaNN已支持的运算列表　141\n5.7.1　一元运算　141\n5.7.2　二元运算　142\n5.7.3　三元运算　144\n5.8　运算的折衷与局限性　144\n5.8.1　运算的折衷　144\n5.8.2　运算的局限性　145\n5.9　小结　146\n5.10　练习　146\n第6章　基本层　148\n6.1　层的设计理念　148\n6.1.1　层的介绍　148\n6.1.2　层对象的构造　150\n6.1.3　参数矩阵的初始化与加载　151\n6.1.4　正向传播　152\n6.1.5　存储中间结果　154\n6.1.6　反向传播　154\n6.1.7　参数矩阵的更新　155\n6.1.8　参数矩阵的获取　155\n6.1.9　层的中性检测　156\n6.2　层的辅助逻辑　156\n6.2.1　初始化模块　156\n6.2.2　DynamicData类模板　161\n6.2.3　层的常用policy对象　166\n6.2.4　InjectPolicy元函数　168\n6.2.5　通用I\/O结构　168\n6.2.6　通用操作函数　169\n6.3　层的具体实现　170\n6.3.1　AddLayer　170\n6.3.2　ElementMulLayer　172\n6.3.3　BiasLayer　176\n6.4　MetaNN已实现的基本层　181\n6.5　小结　183\n6.6　练习　184\n第7章　复合层与循环层　185\n7.1　复合层的接口与设计理念　186\n7.1.1　基本结构　186\n7.1.2　结构描述语法　187\n7.1.3　policy的继承关系　188\n7.1.4　policy的修正　189\n7.1.5　复合层的构造函数　190\n7.1.6　一个完整的复合层构造示例　190\n7.2　policy继承与修正逻辑的实现　191\n7.2.1　policy继承逻辑的实现　191\n7.2.2　policy修正逻辑的实现　194\n7.3　ComposeTopology的实现　195\n7.3.1　功能介绍　195\n7.3.2　拓扑排序算法介绍　195\n7.3.3　ComposeTopology包含的主要步骤　196\n7.3.4　结构描述子句与其划分　196\n7.3.5　结构合法性检查　198\n7.3.6　拓扑排序的实现　200\n7.3.7　子层实例化元函数　203\n7.4　ComposeKernel的实现　207\n7.4.1　类模板的声明　208\n7.4.2　子层对象管理　208\n7.4.3　参数获取、梯度收集与中性检测　211\n7.4.4　参数初始化与加载　212\n7.4.5　正向传播　214\n7.4.6　反向传播　221\n7.5　复合层实现示例　221\n7.6　循环层　222\n7.6.1　GruStep　222\n7.6.2　构建RecurrentLayer类模板　224\n7.6.3　RecurrentLayer的使用　230\n7.7　小结　230\n7.8　练习　230\n第8章　求值与优化　233\n8.1　MetaNN的求值模型　234\n8.1.1　运算的层次结构　234\n8.1.2　求值子系统的模块划分　235\n8.2　基本求值逻辑　242\n8.2.1　主体类型的求值接口　242\n8.2.2　非主体基本数据类型的求值　243\n8.2.3　运算模板的求值　245\n8.2.4　DyanmicData与求值　248\n8.3　求值过程的优化　249\n8.3.1　避免重复计算　249\n8.3.2　同类计算合并　250\n8.3.3　多运算协同优化　251\n8.4　小结　258\n8.5　练习　259\n后记—方家休见笑，吾道本艰难　260","pages":"268","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29939243.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29939243.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29939243.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30394402\/","id":"30394402","publisher":"人民邮电出版社","isbn10":"7115491704","isbn13":"9787115491701","title":"C++模板元编程实战","url":"https:\/\/api.douban.com\/v2\/book\/30394402","alt_title":"","author_intro":"李伟，2011年毕业于清华大学，曾经在百度自然语言处理部担任深度学习机器翻译系统线上预测部分的开发与维护，目前供职于微软亚洲工程院。主要研究方向为C++，拥有10余年相关开发经验，对C++模板元编程与编译期计算有着浓厚的兴趣。喜欢尝试新的技术，业余爱好是编程与阅读。","summary":"《C++模板元编程实战：一个深度学习框架的初步实现》以一个深度学习框架的初步实现为例，讨论如何在一个相对较大的项目中深入应用元编程，为系统性能优化提供更多的可能。\n《C++模板元编程实战：一个深度学习框架的初步实现》分为8章，前两章讨论了一些元编程与编译期计算的基本技术，后面6章则讨论了元编程在深度学习框架中的实际应用，涉及富类型与标签体系、表达式模板、复杂元函数的编写等多个主题，详尽地展示了如何将面向对象与元编程相结合以构造复杂系统。\n《C++模板元编程实战：一个深度学习框架的初步实现》适合具有一定C++基础的读者阅读。对主流深度学习框架的内核有一定了解的读者，也可以参考本书，对比使用元编程与编译期计算所实现的深度学习框架与主流的（主要基于面向对象所构造的）深度学习框架之间的差异。","price":"69"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30724110\/","id":"30724110","publisher":"","isbn10":"7564752610","isbn13":"9787564752613","title":"当代机器深度学习方法与应用研究","url":"https:\/\/api.douban.com\/v2\/book\/30724110","alt_title":"","author_intro":"","summary":"","price":"41.40元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["尤舒亚·本吉奥 (Yoshua Bengio)"],"pubdate":"2017-7-1","tags":[{"count":7,"name":"人工智能","title":"人工智能"},{"count":3,"name":"深度学习","title":"深度学习"},{"count":3,"name":"机器学习","title":"机器学习"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"阳志平","title":"阳志平"},{"count":1,"name":"无来源","title":"无来源"},{"count":1,"name":"想读的书","title":"想读的书"},{"count":1,"name":"2.6人工智能X","title":"2.6人工智能X"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29570393.jpg","binding":"平装","translator":[],"catalog":"","pages":"117","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29570393.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29570393.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29570393.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27163075\/","id":"27163075","publisher":"机械工业出版社","isbn10":"7111569350","isbn13":"9787111569350","title":"人工智能中的深度结构学习","url":"https:\/\/api.douban.com\/v2\/book\/27163075","alt_title":"","author_intro":"","summary":"","series":{"id":"45476","title":"大数据丛书"},"price":"CNY 35.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"向运营商学习如何深度开发客户","author":["李永志","吴佩兰","李灿伟"],"pubdate":"2014-1-1","tags":[{"count":2,"name":"职场","title":"职场"},{"count":1,"name":"维系","title":"维系"},{"count":1,"name":"学习","title":"学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27234985.jpg","binding":"平装","translator":[],"catalog":"第一篇 形势篇\nChapter01 市场形势:通信市场风云变幻\n活在尖刀上的运营商／／005\n主动出击未必好／／007\n客户质态问题是运营商面对的最大问题／／008\n有效控制客户流失／／010\nChapter02 深化认识:全方位、多角度探讨维系工作\n客户维系的定义及价值／／014\n客户维系的有效分类／／019\n维系面临的五个阻碍／／021\n维系的三个认识误区／／024\n影响维系效果的五种关系／／027\n传统维系模式VS新型维系模式／／031\n第二篇 建设篇\nChapter03 队伍建设:打造金牌维系队伍\n维系队伍培训机制／／040\n劳动竞赛机制／／048\n团队评价机制／／050\n团队授权机制／／054\n岗位资格认证／／056\n团队文化塑造／／058\nChapter04 规范建设:团队一体化建设的必备功课\n岗位职责规范／／062\n赠礼规范／／065\n新客户回访规范／／066\n工作号码管理规范／／067\n流失预警回访规范／／068\nChapter05 系统建设:属于存量客户的系统\n系统的主要特性／／073\n系统宜精简／／075\n如何应用现有系统推进客户维系工作／／076\n第三篇 保障篇\nChapter06 客户管理:有效提升客户质态\n准确收集和整理客户资料／／082\n对客户分层维系／／084\n提升客户忠诚度／／094\n提高客户满意度／／098\n客户满意度和忠诚度之间的关系／／100\nChapter07 流失分析:了解客户离网的真实原因\n精确洞察，识别客户行为／／104\n如何定义客户流失／／108\n客户流失的两种类型／／110\n判断客户流失的指标／／112\n深入了解客户流失原因／／122\n理性看待流失／／127\nChapter08 预警机制:以客户生命周期为基础\n寻找客户流失规律／／131\n探索客户生命周期／／133\n客户生命周期的不同阶段／／134\n生命周期不同阶段客户与企业的关系／／138\n生命周期不同阶段的关键时刻／／139\nChapter09 渠道协同:搭建最好的业务桥梁\n渠道协同的定义和意义／／144\n不同的渠道承担的维系内容有所差异／／145\n维系渠道与实体渠道、社会渠道协同的主要方式／／147\n如何做好渠道协同／／148\nChapter10 考核管控:保障维系过程的正常化\n质态管控／／152\n指标管控／／159\n过程管控／／165\n派单管控／／170\n第四篇 实战篇\nChapter11 到期续约:把握有所为、有所不为的心态\n到期续约概念／／178\n续约实施过程／／179\n到期续约心态／／183\n考量到期续约的关键因素／／184\nChapter12 实战宝典:常规维系实战12招\n招式1　预存提升法／／188\n招式2　关怀捆绑法／／190\n招式3　套餐迁移法／／192\n招式4　网龄服务法／／193\n招式5　购机盛会法／／196\n招式6　积分兑换法／／199\n招式7　主动关怀法／／202\n招式8　体验感知法／／203\n招式9　信用服务法／／203\n招式10　俱乐部活动法／／204\n招式11　品牌宣传法／／206\n招式12　专属服务法／／206\nChapter13 校园维系:破局后重建维系体系\n从校园营销看校园客户质态／／210\n校园客户的流失原因／／212\n校园维系体系建设要点／／213\nChapter14 PWV模型:定向维系，激活沉默客户\n沉默客户管理的基本概念／／219\n客户沉默的真实原因／／219\n激活沉默客户\"PWV\"实战模型／／220","pages":"240","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27234985.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27234985.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27234985.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25843208\/","id":"25843208","publisher":"北京大学出版社","isbn10":"7301235100","isbn13":"9787301235102","title":"最受欢迎的客户维系课","url":"https:\/\/api.douban.com\/v2\/book\/25843208","alt_title":"","author_intro":"李永志:管理中国电信3000人的客户服务团队、集团级内训师;吴佩兰:管理中国电信1000多人的VIP客户维系服务团队、集团级内训师;李灿伟:中国电信省公司VIP团队主管、集团级内训师。","summary":"研究发现，客户流失率降低5%，企业利润就能增加25%～85%。那么如何才能降低客户流失？答案非客户维系莫属！因此，当众多企业还在为争夺客户而厮杀时，通信运营商已脱身而出，筹划如何维系已有客户了。\n本书由中国电信三位集团级内训师集十几年的教学实践和理论研究而成，作者综合了中国电信维系4亿存量客户的管理实践，对客户维系系统进行了战略层的总结和战术层的方法细化，引领企业实现高绩效的客户关系管理。\n可以说，本书不仅是运营商的必备指南，也是其他企业进行客户管理的关键指导书。","price":"49.00"},{"rating":{"max":10,"numRaters":462,"average":"9.2","min":0},"subtitle":"Adaptive Computation and Machine Learning series","author":["Ian Goodfellow","Yoshua Bengio","Aaron Courville"],"pubdate":"2016-11-11","tags":[{"count":466,"name":"深度学习","title":"深度学习"},{"count":342,"name":"机器学习","title":"机器学习"},{"count":300,"name":"DeepLearning","title":"DeepLearning"},{"count":277,"name":"人工智能","title":"人工智能"},{"count":155,"name":"AI","title":"AI"},{"count":145,"name":"MachineLearning","title":"MachineLearning"},{"count":124,"name":"计算机","title":"计算机"},{"count":97,"name":"计算机科学","title":"计算机科学"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29133163.jpg","binding":"Hardcover","translator":[],"catalog":"Acknowledgments xv\nNotation xix\n1 Introduction 1\n1.1 Who Should Read This Book?  8\n1.2 Historical Trend sin Deep Learning 12\nI Applied Math and Machine Learning Basics 27\n2 Linear Algebra 29\n2.1 Scalars, Vectors, Matrices and Tensors 29\n2.2 Multiplying Matricesand Vectors 32\n2.3 Identity and Inverse Matrices 34\n2.4 Linear Dependence and Span 35\n2.5 Norms 36\n2.6 Special Kinds of Matrices and Vectors 38\n2.7 Eigendecomposition  39\n2.8 Singular Value Decomposition  42\n2.9 The Moore-Penrose Pseudoinverse 43\n2.10 The Trace Operator 44\n2.11 The Determinant 45\n2.12 Example: Principal Components Analysis 45\n3 Probability and Information Theory 51\n3.1 Why Probability?  52\n3.2 Random Variables 54\n3.3 Probability Distributions  54\n3.4 Marginal Probability  56\n3.5 ConditionalProbability 57\n3.6 The Chain Rule of Conditional Probabilities 57\n3.7 Independence and Conditional Independence 58\n3.8 Expectation, Varianceand Covariance 58\n3.9 Common Probability Distributions 60\n3.10 UsefulPropertiesofCommonFunctions 65\n3.11 Bayes’Rule 68\n3.12 Technical Details of Continuous Variables 68\n3.13 Information Theory  70\n3.14 Structured Probabilistic Models 74\n4 Numerical Computation 77\n4.1 Overflow and Underflow 77\n4.2 Poor Conditioning 79\n4.3 Gradient-Based Optimization 79\n4.4 Constrained Optimization 89\n4.5 Example: Linear Least Squares 92\n5 Machine Learning Basics 95\n5.1 Learning Algorithms 96\n5.2 Capacity, Overfitting and Underfitting 107\n5.3 Hyperparameters and Validation Sets 117\n5.4 Estimators, Bias and Variance 119\n5.5 Maximum Likelihood Estimation 128\n5.6 BayesianStatistics132\n5.7 Supervised Learning Algorithms 136\n5.8 Unsupervised Learning Algorithms142\n5.9 StochasticGradientDescent 147\n5.10 Building a Machine Learning Algorithm 149\n5.11 Challenges Motivating Deep Learning 151\nII Deep Networks: Modern Practices 161\n6 Deep Feedforward Networks 163\n6.1 Example:Learning XOR 166\n6.2 Gradient-Based Learning 171\n6.3\tHidden Units 185\n6.4\tArchitecture Design 191\n6.5\tBack-Propagation and Other Dierentiation Algorithms 197\n6.6\tHistorical Notes 217\n7 Regularization for Deep Learning\t221\n7.1 Parameter Norm Penalties 223\n7.2 Norm Penalties as Constrained Optimization 230\n7.3 Regularization and Under-Constrained Problems 232\n7.4 Dataset Augmentation 233\n7.5 Noise Robustness 235\n7.6 Semi-Supervised Learning236\n7.7 Multitask Learning 237\n7.8 Early Stopping 239\n7.9 Parameter Tying and Parameter Sharing 246\n7.10 Sparse Representations 247\n7.11 Bagging and Other Ensemble Methods 249\n7.12 Dropout 251\n7.13 Adversarial Training261\n7.14 Tangent Distance, Tangent Prop and Manifold Tangent Classiffer 263\n8 Optimization for Training DeepModels 267\n8.1 How Learning Differs from Pure Optimization 268\n8.2 Challenges in Neural Network Optimization 275\n8.3 Basic Algorithms 286\n8.4 Parameter Initialization Strategies 292\n8.5 Algorithms with Adaptive Learning Rates 298\n8.6 Approximate Second-Order Methods 302\n8.7 Optimization Strategies and Meta-Algorithms 309\n9 Convolutional Networks 321\n9.1 The Convolution Operation 322\n9.2 Motivation  324\n9.3 Pooling 330\n9.4 Convolution and Pooling as an Infinitely Strong Prior 334\n9.5 Variants of the Basic Convolution Function 337\n9.6 Structured Outputs 347\n9.7 Data Types 348\n9.8 Efficient Convolution Algorithms 350\n9.9 Random or Unsupervised Features 351\n9.10 The Neuroscientific Basis for Convolutional Networks  353\n9.11 Convolutional Networks and the History of Deep Learning 359\n10 Sequence Modeling: Recurrent and Recursive Nets 363\n10.1 Unfolding Computational Graphs 365\n10.2 Recurrent Neural Networks 368\n10.3 Bidirectional RNNs 383\n10.4 Encoder-Decoder Sequence-to-Sequence Architectures 385\n10.5 Deep Recurrent Networks 387\n10.6 Recursive Neural Networks 388\n10.7 The Challenge of Long-Term Dependencies 390\n10.8 Echo State Networks 392\n10.9 Leaky Units and Other Strategies for Multiple Time Scales 395\n10.10 The Long Short-Term Memory and Other Gated RNNs 397\n10.11 Optimization for Long-Term Dependencies 401\n10.12 Explicit Memory 405\n11 Practical Methodology 409\n11.1 Performance Metrics 410\n11.2 DefaultBaselineModels 413\n11.3 Determining Whether to Gather More Data 414\n11.4 Selecting Hyperparameters 415\n11.5 Debugging Strategies 424\n11.6 Example: Multi-Digit Number Recognition 428\n12 Applications 431\n12.1 Large-Scale Deep Learning 431\n12.2 Computer Vision.440\n12.3 Speech Recognition 446\n12.4 Natural Language Processing 448\n12.5 Other Applications 465\nIII Deep Learning Research 475\n13 Linear Factor Models 479\n13.1 Probabilistic PCA and Factor Analysis 480\n13.2 Independent Component Analysis (ICA) 481\n13.3 Slow Feature Analysis.484\n13.4 Sparse Coding 486\n13.5 Manifold Interpretation of PCA 489\n14 Autoencoders 493\n14.1 Undercomplete Autoencoders 494\n14.2 Regularized Autoencoders 495\n14.3 Representational Power, Layer Size and Depth 499\n14.4 Stochastic Encodersand Decoders 500\n14.5 Denoising Autoencoders501\n14.6 Learning Manifolds with Autoencoders 506\n14.7 Contractive Autoencoders 510\n14.8 Predictive Sparse Decomposition 514\n14.9 Applications of Autoencoders515\n15 Representation Learning 517\n15.1 Greedy Layer-Wise Unsupervised Pretraining 519\n15.2 Transfer Learning and Domain Adaptation 526\n15.3 Semi-Supervised Disentangling of Causal Factors 532\n15.4 Distributed Representation 536\n15.5 Exponential Gains from Depth 543\n15.6 Providing Clues to Discover Underlying Causes 544\n16 Structured Probabilistic Models for Deep Learning 549\n16.1 The Challenge of Unstructured Modeling 550\n16.2 Using Graphs to Describe Model Structure 554\n16.3 Sampling from Graphical Models 570\n16.4 Advantages of Structured Modeling 572\n16.5 Learning about Dependencies 572\n16.6 Inferenceand Approximate Inference 573\n16.7 The Deep Learning Approach to Structured Probabilistic Models 575\n17 Monte Carlo Methods 581\n17.1 Sampling and Monte Carlo Methods 581\n17.2 Importance Sampling 583\n17.3 Markov Chain Monte Carlo Methods 586\n17.4 Gibbs Sampling 590\n17.5 The Challenge of Mixing between Separated Modes 591\n18 Confronting the Partition Function 597\n18.1 The Log-Likelihood Gradient 598\n18.2 Stochastic Maximum Likelihood and Contrastive Divergence 599\n18.3 Pseudolikelihood 607\n18.4 Score Matching and Ratio Matching 609\n18.5 DenoisingScore Matching 611\n18.6 Noise-Contrastive Estimation 612\n18.7 Estimatingthe Partition Function 614\n19 Approximate Inference 623\n19.1 Inferenceas Optimization 624\n19.2 Expectation Maximization 626\n19.3 MAP Inferenceand Sparse Coding 627\n19.4 Variational Inferenceand Learning 629\n19.5 Learned Approximate Inference 642\n20 Deep Generative Models 645\n20.1 Boltzmann Machines 645\n20.2 Restricted Boltzmann Machines 647\n20.3 Deep Belief Networks 651\n20.4 Deep Boltzmann Machines 654\n20.5 Boltzmann Machines for Real-Valued Data 667\n20.6 Convolutional Boltzmann Machines 673\n20.7 Boltzmann Machines for Structured or Sequential Outputs 675\n20.8 Other Boltzmann Machines.677\n20.9 Back-Propagation through Random Operations 678\n20.10 Directed Generative Nets  682\n20.11 Drawing Samples from Autoencoders 701\n20.12 Generative Stochastic Networks 704\n20.13 Other Generation Schemes 706\n20.14 Evaluating Generative Models 707\n20.15 Conclusion 710\nBibliography 711\nIndex 767","pages":"800","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29133163.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29133163.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29133163.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26883982\/","id":"26883982","publisher":"The MIT Press","isbn10":"0262035618","isbn13":"9780262035613","title":"Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26883982","alt_title":"","author_intro":"Ian Goodfellow is Research Scientist at OpenAI. Yoshua Bengio is Professor of Computer Science at the Université de Montréal. Aaron Courville is Assistant Professor of Computer Science at the Université de Montréal.","summary":"\"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.\" -- Elon Musk, co-chair of OpenAI; co-founder and CEO of Tesla and SpaceX\nDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning.\nThe text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models.\nDeep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.","series":{"id":"43694","title":"Adaptive Computation and Machine Learning"},"price":"USD 72.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"从设计的角度学习色彩","author":["刘源 编"],"pubdate":"2010-10","tags":[{"count":1,"name":"学设计从它开始","title":"学设计从它开始"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s9061679.jpg","binding":"","translator":[],"catalog":"","pages":"217","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s9061679.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s9061679.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s9061679.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5377539\/","id":"5377539","publisher":"","isbn10":"7109149455","isbn13":"9787109149458","title":"从设计的角度学习色彩","url":"https:\/\/api.douban.com\/v2\/book\/5377539","alt_title":"","author_intro":"","summary":"《从设计的角度学习色彩》主要内容包括：以科学的态度分析设计教育的绘画教学，以包容的思想理解设计的本质需求，以开放的姿态进行教学实践尝试，是当今设计教育教学改革的当务之急，也是社会发展的时代要求。","price":"55.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["谢群松 编"],"pubdate":"2002-6","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s5846744.jpg","binding":"","translator":[],"catalog":"\n      ","pages":"250","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s5846744.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s5846744.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s5846744.jpg"},"alt":"https:\/\/book.douban.com\/subject\/1602603\/","id":"1602603","publisher":"工商出版社","isbn10":"7800127001","isbn13":"9787800127007","title":"行政事业单位会计决算报告制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/1602603","alt_title":"","author_intro":"","summary":"本书运用基本的财政、财务和会计理论，结合我国行政事业单位会计决算报告编制、军核和汇总上报的工作的现状，根据行政事业单位会计决算制度本身内在的逻辑结构，对该制度的法规条文逐条进行了阐述和解释。","price":"18.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["严军兴"],"pubdate":"2004-5","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s9893150.jpg","binding":"平装","translator":[],"catalog":"\n      ","pages":"272","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s9893150.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s9893150.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s9893150.jpg"},"alt":"https:\/\/book.douban.com\/subject\/1255444\/","id":"1255444","publisher":"中共党史出版社","isbn10":"7801990285","isbn13":"9787801990280","title":"中国法律救助制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/1255444","alt_title":"","author_intro":"","summary":"\n      ","price":"18.0"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["最高人民检察院政治部编写组"],"pubdate":"2006年","tags":[{"count":1,"name":"社会主义法治理念","title":"社会主义法治理念"},{"count":1,"name":"最高人民检察院","title":"最高人民检察院"},{"count":1,"name":"学习材料","title":"学习材料"},{"count":1,"name":"中国特色社会主义检察制度","title":"中国特色社会主义检察制度"},{"count":1,"name":"中国检察出版社","title":"中国检察出版社"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4421399.jpg","binding":"","translator":[],"catalog":"","pages":"209","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s4421399.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s4421399.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4421399.jpg"},"alt":"https:\/\/book.douban.com\/subject\/2104522\/","id":"2104522","publisher":"中国检察出版社","isbn10":"7801855795","isbn13":"9787801855794","title":"中国特色社会主义检察制度学习材料","url":"https:\/\/api.douban.com\/v2\/book\/2104522","alt_title":"","author_intro":"","summary":"社会主义法治理念教育辅助读本","price":"10.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["《国家公务员培训教材系列》编写组 编"],"pubdate":"2011-7","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6851060.jpg","binding":"","translator":[],"catalog":"","pages":"246","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s6851060.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s6851060.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6851060.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6737252\/","id":"6737252","publisher":"","isbn10":"7503545208","isbn13":"9787503545207","title":"国家公务员基本制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/6737252","alt_title":"","author_intro":"","summary":"《国家公务员基本制度学习读本》根据公务员培训要求，围绕《公务员法》和相关的法律法规，特别是结合公务员制度运行过程中的实践，全面系统阐述了公务员制度的基本理论、基本概念、基本内容，包括公务员制度的起源和演变、国内外公务员制度比较分析，特别是就公务员权利义务、基本条件、录用考试要求、考核奖惩、任免升降、纪律、行政处分、培训交流、行为规范、工资保险福利、辞职辞退、申诉控告、退休、法律责任、素质与能力建设等，做了简明、系统的阐述，同时对公务员制度实际运行过程中出现的具体问题，进行分析和解答。《国家公务员基本制度学习读本》由国家行政学院、中央党校公共管理专家集体编写，内容准确、系统，比较好结合了公务员制度运行实践，适合作为公务员培训教材。\n公务员必须掌握公务员基本制度，这是做一个合格、称职公务员的基本要求。","price":"36.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/3942959\/","id":"3942959","publisher":"","isbn10":"7304013281","isbn13":"9787304013288","title":"当代中国政治制度学习指导","url":"https:\/\/api.douban.com\/v2\/book\/3942959","alt_title":"","author_intro":"","summary":"","price":"7.90元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["吴茂贵","郁明敏","朱凤元","张粤磊"],"pubdate":"2018-2","tags":[{"count":7,"name":"Spark","title":"Spark"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29730980.jpg","binding":"平装","translator":[],"catalog":"前言\n第1章　了解机器学习 1\n1.1　机器学习的定义 1\n1.2　大数据与机器学习 2\n1.3　机器学习、人工智能及深度学习 2\n1.4　机器学习的基本任务 3\n1.5　如何选择合适算法 4\n1.6　Spark在机器学习方面的优势 5\n1.7　小结 5\n第2章　构建Spark机器学习系统 6\n2.1　机器学习系统架构 6\n2.2　启动集群 7\n2.3　加载数据 9\n2.4　探索数据 10\n2.4.1　数据统计信息 10\n2.4.2　数据质量分析 11\n2.4.3　数据特征分析 12\n2.4.4　数据的可视化 17\n2.5　数据预处理 19\n2.5.1　数据清理 20\n2.5.2　数据变换 21\n2.5.3　数据集成 22\n2.5.4　数据归约 23\n2.6　构建模型 25\n2.7　模型评估 26\n2.8　组装 30\n2.9　模型选择或调优 30\n2.9.1　交叉验证 31\n2.9.2　训练–验证切分 32\n2.10　保存模型 32\n2.11　小结 33\n第3章　ML Pipeline原理与实战 34\n3.1　Pipeline简介 34\n3.2　DataFrame 35\n3.3　Pipeline组件 36\n3.4　Pipeline原理 37\n3.5　Pipeline实例 38\n3.5.1　使用Estimator、Transformer和Param的实例 38\n3.5.2　ML使用Pipeline的实例 40\n3.6　小结 41\n第4章　特征提取、转换和选择 42\n4.1　特征提取 42\n4.1.1　词频—逆向文件\n频率（TF-IDF） 42\n4.1.2　Word2Vec 43\n4.1.3　计数向量器 44\n4.2　特征转换 45\n4.2.1　分词器 45\n4.2.2　移除停用词 46\n4.2.3　n-gram 47\n4.2.4　二值化 48\n4.2.5　主成分分析 48\n4.2.6　多项式展开 50\n4.2.7　离散余弦变换 50\n4.2.8　字符串—索引变换 51\n4.2.9　 索引—字符串变换 53\n4.2.10　独热编码 54\n4.2.11　向量—索引变换 57\n4.2.12　交互式 58\n4.2.13　正则化 59\n4.2.14　规范化 60\n4.2.15　最大值—最小值缩放 60\n4.2.16　最大值—绝对值缩放 61\n4.2.17　离散化重组 62\n4.2.18　元素乘积 63\n4.2.19　SQL转换器 64\n4.2.20　向量汇编 65\n4.2.21　分位数离散化 66\n4.3　特征选择 67\n4.3.1　向量机 67\n4.3.2　R公式 69\n4.3.3　卡方特征选择 70\n4.4　小结 71\n第5章　模型选择和优化 72\n5.1　模型选择 72\n5.2　交叉验证 73\n5.3　训练验证拆分法 75\n5.4　自定义模型选择 76\n5.5　小结 78\n第6章　Spark MLlib基础 79\n6.1　Spark MLlib简介 80\n6.2　Spark MLlib架构 81\n6.3　数据类型 82\n6.4　基础统计 84\n6.4.1　摘要统计 84\n6.4.2　相关性 84\n6.4.3　假设检验 85\n6.4.4　随机数据生成 85\n6.5　RDD、Dataframe和Dataset 86\n6.5.1　RDD 86\n6.5.2　DatasetDataFrame 87\n6.5.3　相互转换 88\n6.6　小结 89\n第7章　构建Spark ML推荐模型 90\n7.1　推荐模型简介 91\n7.2　数据加载 92\n7.3　数据探索 94\n7.4　训练模型 94\n7.5　组装 95\n7.6　评估模型 96\n7.7　模型优化 96\n7.8　小结 98\n第8章　构建Spark ML分类模型 99\n8.1　分类模型简介 99\n8.1.1　线性模型 100\n8.1.2　决策树模型 101\n8.1.3　朴素贝叶斯模型 102\n8.2　数据加载 102\n8.3　数据探索 103\n8.4　数据预处理 104\n8.5　组装 109\n8.6　模型优化 110\n8.7　小结 113\n第9章　构建Spark ML回归模型 114\n9.1　回归模型简介 115\n9.2　数据加载 115\n9.3　探索特征分布 117\n9.4　数据预处理 120\n9.4.1　特征选择 121\n9.4.2　特征转换 121\n9.5　组装 122\n9.6　模型优化 124\n9.7　小结 126\n第10章　构建Spark ML聚类模型 127\n10.1　K-means模型简介 128\n10.2　数据加载 129\n10.3　探索特征的相关性 129\n10.4　数据预处理 131\n10.5　组装 132\n10.6　模型优化 134\n10.7　小结 136\n第11章　PySpark 决策树模型 137\n11.1　PySpark 简介 138\n11.2　决策树简介 139\n11.3　数据加载 140\n11.3.1　原数据集初探 140\n11.3.2　PySpark的启动 142\n11.3.3　基本函数 142\n11.4　数据探索 143\n11.5　数据预处理 143\n11.6　创建决策树模型 145\n11.7　训练模型进行预测 146\n11.8　模型优化 149\n11.8.1　特征值的优化 149\n11.8.2　交叉验证和网格参数 152\n11.9　脚本方式运行 154\n11.9.1　在脚本中添加配置信息 154\n11.9.2　运行脚本程序 154\n11.10　小结 154\n第12章　SparkR朴素贝叶斯模型 155\n12.1　SparkR简介 156\n12.2　获取数据 157\n12.2.1　SparkDataFrame数据结构\n说明 157\n12.2.2　创建SparkDataFrame 157\n12.2.3　SparkDataFrame的常用操作 160\n12.3　朴素贝叶斯分类器 162\n12.3.1　数据探查 162\n12.3.2　对原始数据集进行转换 163\n12.3.3　查看不同船舱的生还率差异 163\n12.3.4　转换成SparkDataFrame格式的数据 165\n12.3.5　模型概要 165\n12.3.6　预测 165\n12.3.7　评估模型 166\n12.4　小结 167\n第13章　使用Spark Streaming构建在线学习模型 168\n13.1　Spark Streaming简介 168\n13.1.1　Spark Streaming常用术语 169\n13.1.2　Spark Streaming处理流程 169\n13.2　Dstream操作","pages":"233","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29730980.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29730980.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29730980.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30185941\/","id":"30185941","publisher":"机械工业出版社","isbn10":"7111589955","isbn13":"9787111589952","title":"深度实践spark机器学习","url":"https:\/\/api.douban.com\/v2\/book\/30185941","alt_title":"","author_intro":"吴茂贵\n资深BI和大数据专家，在BI、数据挖掘与分析、数据仓库、机器学习等领域有超过20年的工作经验，在Spark机器学习、TensorFlow深度学习领域有大量的实践经验。\n郁明敏\n对大数据、机器学习有一定的研究，擅长Python、Hadoop、Spark等技术，曾或得“江苏省TI杯大学生电子竞技大赛”二等奖和全国大学生数学建模大赛二等奖。","summary":"本书系统讲解了Spark机器学习的技术、原理、组建、算法，以及构建Spark机器学习系统的方法、流程、标准和规范。此外，还介绍了Spark的深度学习框架TensorFlowOnSpark，以及如何借助它实现卷积神经网络和循环神经网络。","price":"69.00元"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":3,"name":"强化学习","title":"强化学习"},{"count":3,"name":"Python","title":"Python"},{"count":2,"name":"人工智能","title":"人工智能"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33523041.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s33523041.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s33523041.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s33523041.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30710611\/","id":"30710611","publisher":"","isbn10":"7111612884","isbn13":"9787111612889","title":"Python强化学习实战：应用OpenAI Gym和TensorFlow精通强化学习和深度强化学习","url":"https:\/\/api.douban.com\/v2\/book\/30710611","alt_title":"","author_intro":"","summary":"","series":{"id":"45479","title":"深度学习系列"},"price":"54.50元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["岳彩申 编"],"pubdate":"2004-8","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6496121.jpg","binding":"","translator":[],"catalog":"","pages":"443","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s6496121.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s6496121.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6496121.jpg"},"alt":"https:\/\/book.douban.com\/subject\/1696799\/","id":"1696799","publisher":"四川人民","isbn10":"7220067852","isbn13":"9787220067853","title":"WTO法律制度学习指导","url":"https:\/\/api.douban.com\/v2\/book\/1696799","alt_title":"","author_intro":"","summary":"《WTO法律制度学习指导》为了帮助学生更好地理解与掌握WTO法律制度的框架与主要内容，专门编写了《WTO法律制度学习指导》。该书包括四个部分，即：第一部分为各章学习要点与内容提要，简要指出各章学习的重点与难点；第二部分为各章练习题，题型包括名词解释、单项选择、多项选择、判断题、简述（答）题及论述题，通过做这些练习题，可以使学生更准确与熟练地掌握本课程的内容；第三部分为各章练习题的参考答案；第四部分为法律文件汇编。这些法律文件既是WTO最主要的法律文件，也是学习WTO法律制度必需的文件。\n《WTO法律制度学习指导》编写人员：袁林、李云捷、沈立平、陈文波、王玉学、樊栋、朱识义、宋臻、唐泽兵、张琼莹。\n由于编写时间与编者的水平有限，可能有不当或错误之处，欢迎批评指正。","price":"20.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["中华人民共和国教"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/1650743\/","id":"1650743","publisher":"高等教育","isbn10":"7040100681","isbn13":"9787040100686","title":"教师资格制度学习宣传提纲","url":"https:\/\/api.douban.com\/v2\/book\/1650743","alt_title":"","author_intro":"","summary":"","price":"4.6"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["张一名"],"pubdate":"2009-11","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6290823.jpg","binding":"","translator":[],"catalog":"","pages":"278","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s6290823.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s6290823.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s6290823.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5904000\/","id":"5904000","publisher":"","isbn10":"7562147752","isbn13":"9787562147756","title":"社会保障制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/5904000","alt_title":"","author_intro":"","summary":"《社会保障制度学习读本》涵盖了社会保障体系的养老保险、医疗保险、失业保险、工伤保险、生育保险、社会救助与社会福利等主要内容，对广大干部群众在工作中把握政策、指导实践、解决具体问题有实用价值。为了贯彻中央精神，配合广大干部学习社会保障制度知识，编者编写了这本《社会保障制度学习读本》。","price":"24.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["刘源 编"],"pubdate":"2009-4","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26014255.jpg","binding":"","translator":[],"catalog":"","pages":"242","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s26014255.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s26014255.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26014255.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4916784\/","id":"4916784","publisher":"","isbn10":"7109141470","isbn13":"9787109141476","title":"从设计的角度学习素描","url":"https:\/\/api.douban.com\/v2\/book\/4916784","alt_title":"","author_intro":"","summary":"《从设计的角度学习素描》主要内容包括：以科学的态度分析设计教育的绘画教学，以包容的思想理解设计的本质需求，以开放的姿态进行教学实践尝试，是当今设计教育教学改革的当务之急，也是社会发展的时代要求。","price":"45.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30531248\/","id":"30531248","publisher":"","isbn10":"755980716X","isbn13":"9787559807168","title":"车尔尼钢琴手指灵巧练习曲 作品740 适合8-10级程度学习","url":"https:\/\/api.douban.com\/v2\/book\/30531248","alt_title":"","author_intro":"","summary":"","price":"25.30"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["申浩"],"pubdate":"2018-06-01","tags":[{"count":1,"name":"钢琴","title":"钢琴"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29812758.jpg","binding":"","translator":[""],"catalog":"","pages":"38","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29812758.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29812758.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29812758.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30267435\/","id":"30267435","publisher":"广西师大","isbn10":"7559807186","isbn13":"9787559807182","title":"布格缪勒钢琴进阶练习曲25首(适合3-5级程度学习)","url":"https:\/\/api.douban.com\/v2\/book\/30267435","alt_title":"","author_intro":"","summary":" 布格缪勒著申浩编注的《布格缪勒钢琴进阶练习曲25首(适合3-5级程度学习)》为德国作曲家布格缪勒为儿童创作的25首钢琴练习曲汇编，也是布格缪勒最负盛名的练习曲作品。这些作品对事物和情感的细腻描绘非常精彩，意境准确到位，在琴童心目中受欢迎的程度明显要高于车尔尼和哈农等几乎以纯技术训练为目标的练习曲。其中的《坦诉》《阿拉伯风格曲》《叙事曲》等都是琴童耳熟能详的音乐。\n","price":"22.0"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30677027\/","id":"30677027","publisher":"","isbn10":"7559807151","isbn13":"9787559807151","title":"车尔尼钢琴快速练习曲 作品299 适合6-8级程度学习","url":"https:\/\/api.douban.com\/v2\/book\/30677027","alt_title":"","author_intro":"","summary":"","price":"15.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30728278\/","id":"30728278","publisher":"","isbn10":"7512372639","isbn13":"9787512372634","title":"电网建设通用制度学习辅导","url":"https:\/\/api.douban.com\/v2\/book\/30728278","alt_title":"","author_intro":"","summary":"","price":"50.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["本书编委会"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30814844\/","id":"30814844","publisher":"法律出版社","isbn10":"7519710467","isbn13":"9787519710460","title":"(S)宪法宣誓制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/30814844","alt_title":"","author_intro":"","summary":"","price":"49.8元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["环境保护部环境应急指挥领导小组办公室　编"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30794327\/","id":"30794327","publisher":"中国环境出版社","isbn10":"7511123759","isbn13":"9787511123756","title":"突发环境事件应急管理制度学习读本","url":"https:\/\/api.douban.com\/v2\/book\/30794327","alt_title":"","author_intro":"","summary":"","price":"39元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["周染云","刘素刚　著"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30801417\/","id":"30801417","publisher":"人民军医出版社","isbn10":"7509188954","isbn13":"9787509188958","title":"护理核心制度学习与考核","url":"https:\/\/api.douban.com\/v2\/book\/30801417","alt_title":"","author_intro":"","summary":"","price":"35元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33408292\/","id":"33408292","publisher":"","isbn10":"7517406566","isbn13":"9787517406563","title":"破除形式主义官僚主义法规制度学习手册","url":"https:\/\/api.douban.com\/v2\/book\/33408292","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34691483\/","id":"34691483","publisher":"","isbn10":"7559817947","isbn13":"9787559817945","title":"什密特钢琴五指练习曲：作品16 适合3-6级程度学习","url":"https:\/\/api.douban.com\/v2\/book\/34691483","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":186,"average":"9.4","min":0},"subtitle":"","author":["Michael Nielsen"],"pubdate":"2016-1","tags":[{"count":146,"name":"深度学习","title":"深度学习"},{"count":131,"name":"神经网络","title":"神经网络"},{"count":121,"name":"机器学习","title":"机器学习"},{"count":75,"name":"DeepLearning","title":"DeepLearning"},{"count":49,"name":"人工智能","title":"人工智能"},{"count":42,"name":"deep_learning","title":"deep_learning"},{"count":41,"name":"计算机","title":"计算机"},{"count":33,"name":"数据科学","title":"数据科学"}],"origin_title":"Michael Nielsen","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28855545.jpg","binding":"online","translator":[],"catalog":"Neural Networks and Deep Learning\nWhat this book is about\nOn the exercises and problems\nUsing neural nets to recognize handwritten digits\nHow the backpropagation algorithm works\nImproving the way neural networks learn\nA visual proof that neural nets can compute any function\nWhy are deep neural networks hard to train?\nDeep learning\nAppendix: Is there a simple algorithm for intelligence?\nAcknowledgements\nFrequently Asked Questions","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28855545.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28855545.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28855545.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26727997\/","id":"26727997","publisher":"","isbn10":"0780354192","isbn13":"9780780354197","title":"Neural Networks and Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26727997","alt_title":"Michael Nielsen","author_intro":"","summary":"http:\/\/neuralnetworksanddeeplearning.com\/","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"免费答疑+课程精讲+冲刺+最后预测押题","author":["全国会计专业技术资格统一考试命题研究组 编"],"pubdate":"2011-11","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s8492470.jpg","binding":"","translator":[],"catalog":"","pages":"124","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s8492470.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s8492470.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s8492470.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10426289\/","id":"10426289","publisher":"","isbn10":"7515400714","isbn13":"9787515400716","title":"中级财务管理深度预测试卷及历年真题-购正版图书.送200元网校学习卡.抵扣相关费用","url":"https:\/\/api.douban.com\/v2\/book\/10426289","alt_title":"","author_intro":"","summary":"《全国会计专业技术资格统一考试辅导丛书•高分必过系列•深度预测试卷历年真题:中级财务管理(2012)》含5套深度预测试卷和2套真题，每道题都有详细的答案解析，便于考生准确掌握自己的不足，及时查漏补缺，顺利过关！万经几载的检验，考试过关最重要的保证！历经考生实战验收，碰到似曾相识的考题时，请将喜兑埋在心底！","price":"20.00元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Hong Song Lin"],"pubdate":"2018-5-1","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29934345.jpg","binding":"平装","translator":[],"catalog":"","pages":"333","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29934345.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29934345.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29934345.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30283425\/","id":"30283425","publisher":"机械工业出版社","isbn10":"7111595998","isbn13":"9787111595991","title":"机器学习技术与实战:医学大数据深度应用","url":"https:\/\/api.douban.com\/v2\/book\/30283425","alt_title":"","author_intro":"","summary":"","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"89"},{"rating":{"max":10,"numRaters":140,"average":"8.7","min":0},"subtitle":"学校未教过的超简易入门技巧","author":["[日] 神永正博"],"pubdate":"2018-7","tags":[{"count":217,"name":"数学","title":"数学"},{"count":163,"name":"微积分","title":"微积分"},{"count":101,"name":"科普","title":"科普"},{"count":56,"name":"入门书","title":"入门书"},{"count":34,"name":"计算科学","title":"计算科学"},{"count":32,"name":"日本","title":"日本"},{"count":29,"name":"简单微积分","title":"简单微积分"},{"count":20,"name":"深度学习","title":"深度学习"}],"origin_title":"「超」入門 微分積分","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29816436.jpg","binding":"平装","translator":["李慧慧"],"catalog":"第 1章 积分是什么 1\n积分的存在意义 2\n积分应用的基础 2\n所有图形都与长方形相通 5\n近似的方法 8\n和变为了积分 13\n何为“接近精确值” 18\n两个思想实验 20\n椭圆的面积 20\n地球的体积 25\n切口的秘密 32\n卡瓦列利原理 32\n三分之一的原理 37\n圆锥的体积 45\n球的体积 48\n球的表面积 54\n感觉和逻辑 59\n初中入学考试中的积分 59\n像小学生那样求圆环体体积 67\n把甜甜圈变成蛇的方法 69\n帕普斯-古尔丁定理 73\n第 2章 微分是什么 77\n微分存在的意义 78\n分析钻石的价格 78\n“亮出指数”的理由 86\n乘积的微分公式 94\n从未知到已知 97\n商的微分公式 100\n再次扩展幂函数的微分公式 102\n丰富多彩的函数世界 105\n山峰和山谷 105\n了解切线 109\n根据单调性表画函数图像 113\n最大值和最小值、极大值和极小值 117\n手绘函数图像的意义 119\n存在休息平台的函数 121\n有预谋地使用微分 128\n理想的冰激凌蛋卷筒 128\n“忽略”与“不可忽略”的界线 138\n第3章 探寻微积分的可能性 141\n1800年后的真相 142\n反军队式学习法 142\n伟大的发现会成为未来的常识 144\n基本定理的使用方法 152\n填坑 160\n自然常数从何而来 160\n无限接近于精确的值 164\n关键在于根号 166\n转换思路能行得通吗 169\n指数函数出现了 175\n让关系更清晰 178\n唯一一个微分后不会发生变化的函数 181\n弯曲也没问题 184\n测量曲线的长度 184\n简洁的悬链线公式 187\n验证项链的长度 194\n微积分的真身 199\n微分的可能性 199\n微分相关的冒险 202\n近似和忽略 205\n后记 207\n尾注 209","pages":"213","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29816436.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29816436.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29816436.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30271424\/","id":"30271424","publisher":"人民邮电出版社","isbn10":"7115485070","isbn13":"9787115485076","title":"简单微积分","url":"https:\/\/api.douban.com\/v2\/book\/30271424","alt_title":"「超」入門 微分積分","author_intro":"神永正博（Kunihiko Kodaira）\n1967年出生于东京，理学博士，日本东北学院大学教授。曾在京都大学研究生院理学研究所（数学方向）进行博士后期课程学习。主要研究方向为解析学（作为量子力学基础方程式的薛定谔方程）以及密码理论。主要著作有《看穿谎言的统计学》《数学思考法》，另外审阅翻译的著作有《漫画统计学入门》等。","summary":"本书为微积分入门科普读物，书中以微积分的“思考方法”为核心，以生活例子通俗讲解了微积分的基本原理、公式推导以及实际应用意义，解答了微积分初学者遭遇的常见困惑。本书讲解循序渐进、生动亲切，没有烦琐计算、干涩理论，是一本只需“轻松阅读”便可以理解微积分原理的入门书。\n日本人气“微积分入门”读本\n无须背诵公式、烦琐计算\n仅用“阅读”理解微积分原理\n丰富图解 亲切解说\n传授日本微积分入门的“巧妙思路”\n微积分的本质在于方法。简单说，如果抓住思考的“要领”，那么就能轻而易举地理解复杂算式。相反，如果不能掌握思考要领，直接从计算技术入手的话，微积分的学习便如同咀嚼沙子一般变成了苦涩的修行。\n——神永正博","series":{"id":"4087","title":"图灵新知"},"price":"49"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"免费答疑+课程精讲+冲刺+最后预测押题","author":["全国会计专业技术资格统一考试命题研究组"],"pubdate":"2011-11","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8492468.jpg","binding":"","translator":[],"catalog":"","pages":"108","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s8492468.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s8492468.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8492468.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10426288\/","id":"10426288","publisher":"","isbn10":"7515400684","isbn13":"9787515400686","title":"初级经济法基础深度预测试卷及历年真题-购正版图书.送200元网校学习卡.抵扣相关费用","url":"https:\/\/api.douban.com\/v2\/book\/10426288","alt_title":"","author_intro":"","summary":"初级经济法基础：深度预测试卷及历年真题，ISBN：9787515400686，作者：全国会计专业技术资格统一考试命题研究组 编","price":"20.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"免费答疑+课程精讲+冲刺+最后预测押题","author":["全国会计专业技术资格统一考试命题研究组"],"pubdate":"2011-11","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s8492474.jpg","binding":"","translator":[],"catalog":"","pages":"116","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s8492474.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s8492474.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s8492474.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10413725\/","id":"10413725","publisher":"","isbn10":"7515400692","isbn13":"9787515400693","title":"初级会计实务深度预测试卷及历年真题-购正版图书.送200元网校学习卡.抵扣相关费用","url":"https:\/\/api.douban.com\/v2\/book\/10413725","alt_title":"","author_intro":"","summary":"初级会计实务：深度预测试卷及历年真题，ISBN：9787515400693，作者：全国会计专业技术资格统一考试命题研究组 编","price":"20.00元"},{"rating":{"max":10,"numRaters":26,"average":"7.2","min":0},"subtitle":"激发全部身心、活力、创造力和启发式学习的指南","author":["美］约瑟夫·克奈尔（Joseph Bharat Cornell）"],"pubdate":"2019-7","tags":[{"count":10,"name":"自然教育","title":"自然教育"},{"count":8,"name":"教育","title":"教育"},{"count":5,"name":"成长","title":"成长"},{"count":4,"name":"亲子","title":"亲子"},{"count":3,"name":"自然游戏","title":"自然游戏"},{"count":3,"name":"自然","title":"自然"},{"count":3,"name":"育儿","title":"育儿"},{"count":3,"name":"家庭教育","title":"家庭教育"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33313388.jpg","binding":"平装","translator":["李佳陵","肖志欣"],"catalog":"国际赞誉\n中方赞誉\n中文版推荐序\n英文版推荐序\n自序\n游戏：“结伴静走”\n第1章   万物都爱玩\n第2章   游戏与生俱来，是学习不可或缺的一部分\n第3章   体验到学习的快乐至关重要\n第4章   游戏让我们能量满满\n游戏：“邂逅一棵树”|“倾听声音”\n第5章   游戏让我们彼此联结\n游戏：“探索大地之心”\n第6章   游戏激活我们的全部存在\n游戏：“打造一棵树”|“观想树”\n第7章   创造力是游戏的核心\n第8章   创造力的秘密：感同身受\n游戏：“我是一座高山”\n第9章   游戏释放创造天性\n第 10 章   正念游戏\n游戏：“扩大能量圈”\n第 11 章   游戏适合每个人\n游戏：“有多近？”| 沉静冥想\n第 12 章   在自然中感受全然的生命力\n游戏：“地球之窗”\n第 13 章   从一般游戏到深度游戏\n心流学习法\n心流学习法的 4 个阶段\n游戏：“自然历程”|“伪装步道”\n第 14 章   如何玩得更深入 ?\n促进深度游戏的五种有效方法\n游戏：“我能看见”|“微观之旅”\n第 15 章   四个深度自然游戏\n1. 照相机\n2. 声音地图\n3. 与自然谈心\n4. 藏头诗\n附录\n引注出处\n图片来源\n约瑟夫·克奈尔及全球共享自然活动","pages":"176","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33313388.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33313388.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33313388.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34452005\/","id":"34452005","publisher":"湖南教育出版社 | 青豆书坊","isbn10":"7553968587","isbn13":"9787553968582","title":"深度自然游戏","url":"https:\/\/api.douban.com\/v2\/book\/34452005","alt_title":"","author_intro":"【约瑟夫·克奈尔（Joseph Bharat Cornell）】\n被誉为世界自然教育之父，当代著名自然教育家、作家，全球共享自然协会创办人。\n他的第一本著作“在世界各地点燃了自然教育的革命之火”，以20种语言出版，荣登美国1890 年以来出版的15部“帮助儿童、家庭与自然联结”的著作之一。\n美国国家公园管理局将约瑟夫独创的户外学习法“心流学习法”，与蒙台梭利、加德纳、杜威和皮亚杰等人的理论一起，并列为世界五大学习理论。\n日本教育部已经批准将共享自然的游戏用于基础科学课程中。\n约瑟夫将他的整个生命深深地与自然融为一体，著有《与孩子共享自然》《共享自然的喜悦》《倾听自然》《探索大地之心》《学做自然的孩子》《来自天地的感动》和《共享自然》等一系列自然教育和生命教育书籍，并在1979年组织、成立了“全球共享自然协会”，与世界各地更多的人分享交流他的自然哲学和教育方法。相关书籍、讲座和活动影响了数百万人。","summary":"本本书是自然教育之父约瑟夫·克奈尔的最新力作，浓缩了他40年自然实践活动的精华，也是其理论依据所在。\n书中系统梳理了每个深具吸引力的自然游戏背后的核心理念，阐述了从一般游戏晋升到深度游戏，运用“心流学习法”的操作关键，为广大父母、早期儿童教育者以及广大教师提供了自然教育、自我疗愈与觉醒以及启发性学习的范例。\n本书中总结分享了促进深度自然游戏的五种有效方法，并从40年积累的自然游戏活动中，精选出18个好玩有趣、简单易行的深度自然游戏：\n遇见一棵树\n观想树\n地球之窗\n自然历程\n我能看见\n照相机\n声音地图\n与自然谈心\n藏头诗\n沉静冥想\n……","price":"42.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"免费答疑+课程精讲+冲刺+最后预测押题","author":["全国会计专业技术资格统一考试命题研究组 编"],"pubdate":"2011-11","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8492469.jpg","binding":"","translator":[],"catalog":"","pages":"124","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s8492469.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s8492469.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8492469.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10426290\/","id":"10426290","publisher":"","isbn10":"7515400722","isbn13":"9787515400723","title":"中国经济法深度预测试卷及历年真题-购正版图书.送200元网校学习卡.抵扣相关费用","url":"https:\/\/api.douban.com\/v2\/book\/10426290","alt_title":"","author_intro":"","summary":"《全国会计专业技术资格统一考试辅导丛书•高分必过系列•深度预测试卷历年真题:中级经济法(2012)》含5套深度预测试卷和2套真题，每道题都有详细的答案解析，便于考生准确掌握自己的不足，及时查漏补缺，顺利过关！万经几载的检验，考试过关最重要的保证！历经考生实战验收，碰到似曾相识的考题时，请将喜兑埋在心底！","price":"20.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"免费答疑+课程精讲+冲刺+最后预测押题","author":["全国会计专业技术资格统一考试命题研究组"],"pubdate":"2011-11","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8862437.jpg","binding":"","translator":[],"catalog":"","pages":"124","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s8862437.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s8862437.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8862437.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10413726\/","id":"10413726","publisher":"","isbn10":"7515400706","isbn13":"9787515400709","title":"中级会计实务深度预测试卷及历年真题-购正版图书.送200元网校学习卡.抵扣相关费用","url":"https:\/\/api.douban.com\/v2\/book\/10413726","alt_title":"","author_intro":"","summary":"中级会计实务：深度预测试卷及历年真题，ISBN：9787515400709，作者：全国会计专业技术资格统一考试命题研究组 编","price":"20.00元"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["彭伟"],"pubdate":"2018-5-1","tags":[{"count":3,"name":"深度学习","title":"深度学习"},{"count":2,"name":"强化学习","title":"强化学习"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"【考虑】","title":"【考虑】"},{"count":1,"name":"DL","title":"DL"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29787478.jpg","binding":"平装","translator":[],"catalog":"第1章  深度强化学习概览\n1.1  什么是深度强化学习？\n1.1.1  俯瞰强化学习\n1.1.2  来一杯深度学习\n1.1.3  Hello，深度强化学习\n1.2  深度强化学习的学习策略\n1.3  本书的内容概要\n参考文献\n第2章  强化学习基础\n2.1  真相--经典的隐马尔科夫模型（HMM）\n2.1.1  HMM引例\n2.1.2  模型理解与推导\n2.1.3  隐马尔科夫应用举例\n2.2  逢考必过—马尔科夫决策过程（MDP）\n2.2.1  MDP生活化引例\n2.2.2  MDP模型\n2.2.3  MDP模型引例\n2.2.4  模型理解\n2.2.5  探索与利用\n2.2.6  值函数和动作值函数\n2.2.7  基于动态规划的强化问题求解\n2.3  糟糕，考试不给题库—无模型强化学习\n2.3.1  蒙特卡洛算法\n2.3.2  时序差分算法\n2.3.3  异步强化学习算法\n2.4  学霸来了--强化学习之模仿学习\n2.4.1  模仿学习（Imitation Learning）\n2.4.2  逆强化学习\n本章总结\n参考\n第3章  深度学习基础\n3.1 深度学习简史\n3.1.1  神经网络发展史\n3.1.2  深度学习的分类\n3.1.3  深度学习的应用\n3.1.4  深度学习存在的问题\n3.2 深度学习基础概念\n3.2.1  深度学习总体感知\n3.2.2  神经网络的基本组成\n3.2.3  深度学习训练\n3.2.4  梯度下降法\n3.2.5  反向传播算法（BP）\n3.3 数据预处理\n3.3.1  主成分分析（PCA）\n3.3.2  独立成分分析（ICA）\n3.3.3  数据白化处理\n3.4  深度学习硬件基础\n3.4.1  深度学习硬件基础\n3.4.2  GPU简介\n3.4.3  CUDA编程\n本章总结\n参考\n第4章  功能神经网络层\n4.1  激活函数单元\n4.2  池化层Pooling layer\n4.3  参数开关Dropout\n4.4  批量归一化层（Batch normalization layer）\n4.5  全连接层\n4.6  卷积神经网络\n4.7  全卷积神经网络\n4.8  循环（递归）神经网络（RNN）\n4.9  深度学习的\n本章总结\n参考\n第5章  卷积神经网络（CNN）\n5.1   卷积神经网络 CNN 基础\n5.1.1  卷积神经网络的历史\n5.1.2  卷积神经网络的核心\n5.2  卷积神经网络 CNN 结构\n5.2.1  深度卷积神经网络CNN\n5.2.2  深度卷积神经网络CNN可视化\n5.3  经典卷积神经网络架构分析\n5.3.1  一切的开始--LeNet\n5.3.2  王者回归--AlexNet\n5.3.3  起飞的时候--VGG\n5.3.4  致敬经典GoogLeNet\n5.3.5  没有最深只有更深--ResNet\n5.4   对抗网络\n5.4.1  对抗网络（GAN）\n5.4.2  WGAN\n5.5  RCNN\n5.6  CNN的应用实例\n本章总结\n参考\n第6章  循环神经网络（RNN）\n6.1 RNN概览\n6.2  长期依赖（Long-Term Dependencies）问题\n6.3  LSTM 的变体\n本章总结\n参考\n第7章：如何写自己的CNN—C语言实现深度学习\n7.1  如何写自己的CMake文件\n7.2  如何写自己神经网络\n7.2.1  激活函数\n7.2.2  池化函数\n7.2.3  全连接层\n7.3  卷积神经网络\n7.3.1  CNN网络的构建\n7.3.2  CNN前向传播\n7.3.3  CNN的反向传播\n7.4  文件解析\n本章总结\n第8章  深度强化学习\n8.1  初识深度强化学习\n8.1.1  深度强化学习概览\n8.1.2  记忆回放（Memory-Replay）机制\n8.1.3  蒙特卡罗搜索树\n8.2  深度强化学习（DRL）中的值函数算法\n8.2.1  DRL中值函数的作用\n8.2.2  DRL中值函数理论推导\n8.3  深度强化学习中的策略梯度（Policy Gradient）\n8.3.1  策略梯度的作用和优势\n8.3.2  策略梯度的理论推导\n8.3.3  REINFORCE算法\n8.3.4  策略梯度的优化算法\n8.3.5  策略子－评判算法（Actor-Critic）\n8.4  深度强化学习网络结构\n参考\n第9章 深度强化学习算法框架\n9.1  深度Q学习\n9.2  双Q学习\n9.3  异步深度强化学习\n9.4  异步优越性策略子-评价算法\n9.5  DDPG 算法：\n9.6  值迭代网络\n本章总结\n参考\n第10章  深度强化学习应用实例\n10.1  Flappy Bird 应用\n10.2  Play Pong 应用\n10.3  深度地形-自适应应用（Deep Terrain-adaptive应用）\n10.4  AlphaGo  254\n10.4.1  独立算法的研究部分\n10.4.2  AlphaGo算法\n本章总结\n参考\n附录： 常用的深度学习框架\nF.1. 谷歌TensorFlow\nF.1.1  TensorFlow 简介\nF.1.2  TensorFlow 基础\nF.2  轻量级MXNet\nF.2.1  MXnet介绍\nF.2.2  MXnet基础\nF.3  来至UCLA 的Caffe\nF.3.1  Caffe 简介\nF3.2  Caffe基础\nF.4  悠久的 Theano\nF.4.1  Theano简介\nF.4.2  Theano基础\nF.5 30s  入门的Keras\n参考","pages":"360","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29787478.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29787478.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29787478.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30242422\/","id":"30242422","publisher":"水利水电出版社","isbn10":"7517062387","isbn13":"9787517062387","title":"揭秘深度强化学习","url":"https:\/\/api.douban.com\/v2\/book\/30242422","alt_title":"","author_intro":"","summary":"深度强化学习（Deep Reinforcement Learning，DRL）是深度学习算法和强化学习算法的巧妙结合，它是一种新兴的通用人工智能算法技术，也是机器学习的前沿技术，DRL 算法潜力无限，AlphaGo 是目前该算法*成功的使用案例。DRL 算法以马尔科夫决策过程为基础，是在深度学习强大的非线性函数的拟合能力下构成的一种增强算法。深度强化学习算法主要包括基于动态规划（DP）的算法以及基于策略优化的算法，本书的目的就是要把这两种主要的算法（及设计技巧）讲解清楚，使算法研究人员能够熟练地掌握。\n《揭秘深度强化学习人工智能机器学习技术丛书》共10 章，首先以AlphaGo 在围棋大战的伟大事迹开始，引起对人工智能发展和现状的介绍，进而介绍深度强化学习的基本知识。然后分别介绍了强化学习（重点介绍蒙特卡洛算法和时序差分算法）和深度学习的基础知识、功能神经网络层、卷积神经网络（CNN）、循环神经网络（RNN），以及深度强化学习的理论基础和当前主流的算法框架。*后介绍了深度强化学习在不同领域的几个应用实例。引例、基础知识和实例相结合，方便读者理解和学习。\n《揭秘深度强化学习 人工智能机器学习技术丛书》内容丰富，讲解全面、语言描述通俗易懂，是深度强化学习算法入门的*选择。本书适合计算机专业本科相关学生、人工智能领域的研究人员以及所有对机器学习和人工智能算法感兴趣的人员。","price":"89.80元"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["娄华英"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29801119.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29801119.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29801119.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29801119.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30256317\/","id":"30256317","publisher":"","isbn10":"7567576120","isbn13":"9787567576124","title":"跨界学习--学校课程变革的新取向\/学校课程深度变革丛书","url":"https:\/\/api.douban.com\/v2\/book\/30256317","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30500240\/","id":"30500240","publisher":"","isbn10":"7303226958","isbn13":"9787303226955","title":"自主深度探究·合作多元探究:“三人行”课程下的儿童学习与发展","url":"https:\/\/api.douban.com\/v2\/book\/30500240","alt_title":"","author_intro":"","summary":"","price":"52.70"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30855860\/","id":"30855860","publisher":"","isbn10":"7567569817","isbn13":"9787567569812","title":"课程群：学习的深度聚焦","url":"https:\/\/api.douban.com\/v2\/book\/30855860","alt_title":"","author_intro":"","summary":"","price":"33.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30696865\/","id":"30696865","publisher":"","isbn10":"7564359242","isbn13":"9787564359249","title":"外国学习者汉语词汇深度习得研究","url":"https:\/\/api.douban.com\/v2\/book\/30696865","alt_title":"","author_intro":"","summary":"","price":"58.40元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"水利水电工程管理与实务","author":["建造师教材辅导编写组　编著"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"172","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/31831112\/","id":"31831112","publisher":"北京理工大学出版社","isbn10":"7564098716","isbn13":"9787564098711","title":"2015年全国一级建造师执业资格考试   水利水电工程管理与实务 历年真题+押题模拟二合一试卷（历年真题专家详解  命题规律深度剖析 押题模拟举一反三  快速提升备考效果 学习光盘标准题库  随机组卷智能评分）","url":"https:\/\/api.douban.com\/v2\/book\/31831112","alt_title":"","author_intro":"","summary":"","price":"25.2元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32261218.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32261218.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32261218.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32261218.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33372383\/","id":"33372383","publisher":"","isbn10":"9866264335","isbn13":"9789866264337","title":"策略管理:簡明學習．深度思考","url":"https:\/\/api.douban.com\/v2\/book\/33372383","alt_title":"","author_intro":"","summary":"页面: 497, 平装, 前程文化(前程企業管理有限公司)","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"想读的书","title":"想读的书"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34434877\/","id":"34434877","publisher":"","isbn10":"7564183217","isbn13":"9787564183219","title":"深度强化学习实践（影印版 英文版）","url":"https:\/\/api.douban.com\/v2\/book\/34434877","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["建造师教材辅导编写组　编著"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32293339.jpg","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32293339.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32293339.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32293339.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33411686\/","id":"33411686","publisher":"北京理工大学出版社","isbn10":"7564098740","isbn13":"9787564098742","title":"2015年全国一级建造师执业资格考试建设工程经济历年真题+押题模拟二合一试卷（历年真题专家详解  命题规律深度剖析 押题模拟举一反三  快速提升备考效果 学习光盘标准题库  随机组卷智能评分）","url":"https:\/\/api.douban.com\/v2\/book\/33411686","alt_title":"","author_intro":"","summary":"","price":"25.2元"},{"rating":{"max":10,"numRaters":145,"average":"9.4","min":0},"subtitle":"","author":["Francois Chollet"],"pubdate":"2017-10-31","tags":[{"count":172,"name":"深度学习","title":"深度学习"},{"count":164,"name":"Python","title":"Python"},{"count":107,"name":"机器学习","title":"机器学习"},{"count":70,"name":"人工智能","title":"人工智能"},{"count":59,"name":"Keras","title":"Keras"},{"count":53,"name":"DeepLearning","title":"DeepLearning"},{"count":43,"name":"计算机","title":"计算机"},{"count":38,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29444148.jpg","binding":"Paperback","translator":[],"catalog":"PART 1 - FUNDAMENTALS OF DEEP LEARNING\n1.What is deep learning?\n2.Before we begin: the mathematical building blocks of neural networks\n3.Getting started with neural networks\n4.Fundamentals of machine learning\nPART 2 - DEEP LEARNING IN PRACTICE\n5.Deep learning for computer vision\n6.Deep learning for text and sequences\n7.Advanced deep-learning best practices\n8.Generative deep learning\n9.Conclusions\nappendix A - Installing Keras and its dependencies on Ubuntu\nappendix B - Running Jupyter notebooks on an EC2 GPU instance","pages":"350","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29444148.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29444148.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29444148.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27038207\/","id":"27038207","publisher":"Manning Publications","isbn10":"1617294438","isbn13":"9781617294433","title":"Deep Learning with Python","url":"https:\/\/api.douban.com\/v2\/book\/27038207","alt_title":"","author_intro":"François Chollet works on deep learning at Google in Mountain View, CA. He is the creator of the Keras deep-learning library, as well as a contributor to the TensorFlow machine-learning framework. He also does deep-learning research, with a focus on computer vision and the application of machine learning to formal reasoning. His papers have been published at major conferences in the field, including the Conference on Computer Vision and Pattern Recognition (CVPR), the Conference and Workshop on Neural Information Processing Systems (NIPS), the International Conference on Learning Representations (ICLR), and others.","summary":"Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher François Chollet, this book builds your understanding through intuitive explanations and practical examples. You'll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you finish, you'll have the knowledge and hands-on skills to apply deep learning in your own projects.","price":"USD 49.99"},{"rating":{"max":10,"numRaters":123,"average":"8.4","min":0},"subtitle":"","author":["美团算法团队"],"pubdate":"2018-8-1","tags":[{"count":199,"name":"机器学习","title":"机器学习"},{"count":64,"name":"AI","title":"AI"},{"count":45,"name":"计算机","title":"计算机"},{"count":42,"name":"深度学习","title":"深度学习"},{"count":41,"name":"美团","title":"美团"},{"count":28,"name":"计算机科学","title":"计算机科学"},{"count":23,"name":"算法_机器学习","title":"算法_机器学习"},{"count":20,"name":"算法","title":"算法"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29841559.jpg","binding":"平装","translator":[],"catalog":"第一部分 通用流程\n第　1章 问题建模　2\n1.1　评估指标　3\n1.1.1　分类指标　4\n1.1.2　回归指标　7\n1.1.3　排序指标　9\n1.2　样本选择　10\n1.2.1　数据去噪　11\n1.2.2　采样　12\n1.2.3　原型选择和训练集选择　13\n1.3　交叉验证　14\n1.3.1　留出法　14\n1.3.2　K折交叉验证　15\n1.3.3　自助法　16\n参考文献　17\n第　2章 特征工程　18\n2.1　特征提取　18\n2.1.1　探索性数据分析　19\n2.1.2　数值特征　20\n2.1.3　类别特征　22\n2.1.4　时间特征　24\n2.1.5　空间特征　25\n2.1.6　文本特征　25\n2.2　特征选择　27\n2.2.1　过滤方法　28\n2.2.2　封装方法　31\n2.2.3　嵌入方法　31\n2.2.4　小结　32\n2.2.5　工具介绍　33\n参考文献　33\n第3章　常用模型　35\n3.1　逻辑回归　35\n3.1.1　逻辑回归原理　35\n3.1.2　逻辑回归应用　38\n3.2　场感知因子分解机　39\n3.2.1　因子分解机原理　39\n3.2.2　场感知因子分解机原理　40\n3.2.3　场感知因子分解机的应用　41\n3.3　梯度提升树　42\n3.3.1　梯度提升树原理　42\n3.3.2　梯度提升树的应用　44\n参考文献　44\n第4章　模型融合　45\n4.1　理论分析　46\n4.1.1　融合收益　46\n4.1.2　模型误差 分歧分解　46\n4.1.3　模型多样性度量　48\n4.1.4　多样性增强　49\n4.2　融合方法　50\n4.2.1　平均法　50\n4.2.2　投票法　52\n4.2.3　Bagging　54\n4.2.4　Stacking　55\n4.2.5　小结　56\n参考文献　57\n第二部分　数据挖掘\n第5章　用户画像　60\n5.1　什么是用户画像　60\n5.2　用户画像数据挖掘　63\n5.2.1　画像数据挖掘整体架构　63\n5.2.2　用户标识　65\n5.2.3　特征数据　67\n5.2.4　样本数据　68\n5.2.5　标签建模　69\n5.3　用户画像应用　83\n5.3.1　用户画像实时查询系统　83\n5.3.2　人群画像分析系统　87\n5.3.3　其他系统　90\n5.3.4　线上应用效果　91\n5.4　小结　91\n参考文献　91\n第6章　POI实体链接　92\n6.1　问题的背景与难点　92\n6.2　国内酒店POI实体链接解决方案　94\n6.2.1　酒店POI实体链接　94\n6.2.2　数据清洗　96\n6.2.3　特征生成　97\n6.2.4　模型选择与效果评估　100\n6.2.5　索引粒度的配置　101\n6.3　其他场景的策略调整　101\n6.4　小结　103\n第7章　评论挖掘　104\n7.1　评论挖掘的背景　104\n7.1.1　评论挖掘的粒度　105\n7.1.2　评论挖掘的维度　105\n7.1.3　评论挖掘的整合思考　106\n7.2　评论标签提取　106\n7.2.1　数据的获取及预处理　107\n7.2.2　无监督的标签提取方法　109\n7.2.3　基于深度学习的标签提取方法　111\n7.3　标签情感分析　113\n7.3.1　评论标签情感分析的特殊性　113\n7.3.2　基于深度学习的情感分析方法　115\n7.3.3　评论标签情感分析的后续优 化与思考　118\n7.4　评论挖掘的未来应用及实践　119\n7.5　小结　119\n参考文献　119\n第三部分　搜索和推荐\n第8章　O2O场景下的查询理解与 用户引导　122\n8.1　现代搜索引擎原理　123\n8.2　精确理解查询　124\n8.2.1　用户查询意图的定义与识别　125\n8.2.2　查询实体识别与结构化　129\n8.2.3　召回策略的变迁　130\n8.2.4　查询改写　131\n8.2.5　词权重与相关性计算　134\n8.2.6　类目相关性与人工标注　135\n8.2.7　查询理解小结　136\n8.3　引导用户完成搜索　137\n8.3.1　用户引导的产品定义与衡量 标准　137\n8.3.2　搜索前的引导——查询词 推荐　140\n8.3.3　搜索中的引导——查询补全　143\n8.3.4　搜索后的引导——相关搜索　145\n8.3.5　效率提升与效果提升　145\n8.3.6　用户引导小结　149\n8.4　小结　149\n参考文献　150\n第9章　O2O场景下排序的特点　152\n9.1　系统概述　154\n9.2　在线排序服务　154\n9.3　多层正交A\/B测试　155\n9.4　特征获取　155\n9.5　离线调研系统　156\n9.6　特征工程　156\n9.7　排序模型　157\n9.8　场景化排序　160\n9.9　小结　165\n第　10章 推荐在O2O场景的应用　166\n10.1　典型的O2O推荐场景　166\n10.2　O2O推荐场景特点　167\n10.2.1　O2O场景的地理位置因素　168\n10.2.2　O2O场景的用户历史行为　168\n10.2.3　O2O场景的实时推荐　169\n10.3　美团推荐实践——推荐框架　169\n10.4　美团推荐实践——推荐召回　170\n10.4.1　基于协同过滤的召回　171\n10.4.2　基于位置的召回　171\n10.4.3　基于搜索查询的召回　172\n10.4.4　基于图的召回　172\n10.4.5　基于实时用户行为的召回　172\n10.4.6　替补策略　172\n10.5　美团推荐实践——推荐排序　173\n10.5.1　排序特征　173\n10.5.2　排序样本　174\n10.5.3　排序模型　175\n10.6　推荐评价指标　176\n参考文献　176\n第四部分　计算广告\n第　11章 O2O场景下的广告营销　178\n11.1　O2O场景下的广告业务特点　178\n11.2　商户、用户和平台三者利益平衡　180\n11.2.1　商户效果感知　180\n11.2.2　用户体验　181\n11.2.3　平台收益　182\n11.3　O2O广告机制设计　183\n11.3.1　广告位设定　183\n11.3.2　广告召回机制　183\n11.3.3　广告排序机制　184\n11.4　O2O推送广告　187\n11.5　O2O广告系统工具　190\n11.5.1　面向开发人员的系统工具　190\n11.5.2　面向广告主和运营人员的 工具　192\n11.6　小结　194\n参考文献　194\n第　12章 用户偏好和损失建模　196\n12.1　如何定义用户偏好　196\n12.1.1　什么是用户偏好　196\n12.1.2　如何衡量用户偏好　196\n12.1.3　对不同POI 的偏好　197\n12.1.4　用户对 POI 偏好的衡量　197\n12.2　广告价值与偏好损失的兑换　198\n12.2.1　优化目标　199\n12.2.2　模型建模　199\n12.3　Pairwise 模型学习　201\n12.3.1　GBRank　202\n12.3.2　RankNet　204\n参考文献　205\n第五部分　深度学习\n第　13章 深度学习概述　208\n13.1　深度学习技术发展历程　209\n13.2　深度学习基础结构　211\n13.3　深度学习研究热点　216\n13.3.1　基于深度学习的生成式模型　216\n13.3.2　深度强化学习　218\n参考文献　219\n第　14章 深度学习在文本领域的应用　220\n14.1　基于深度学习的文本匹配　221\n14.2　基于深度学习的排序模型　231\n14.2.1　排序模型简介　231\n14.2.2　深度学习排序模型的演进　232\n14.2.3　美团的深度学习排序模型 尝试　235\n14.3　小结　237\n参考文献　237\n第　15章 深度学习在计算机视觉中的 应用　238\n15.1　基于深度学习的OCR　238\n15.1.1　OCR技术发展历程　239\n15.1.2　基于深度学习的文字检测　244\n15.1.3　基于序列学习的文字识别　248\n15.1.4　小结　251\n15.2　基于深度学习的图像智能审核　251\n15.2.1　基于深度学习的水印检测　252\n15.2.2　明星脸识别　254\n15.2.3　色情图片检测　257\n15.2.4　场景分类　257\n15.3　基于深度学习的图像质量排序　259\n15.3.1　图像美学质量评价　260\n15.3.2　面向点击预测的图像质量 评价　260\n15.4　小结　263\n参考文献　264\n第六部分　算法工程\n第　16章 大规模机器学习　268\n16.1　并行计算编程技术　268\n16.1.1　向量化　269\n16.1.2　多核并行OpenMP　270\n16.1.3　GPU编程　272\n16.1.4　多机并行MPI　273\n16.1.5　并行编程技术小结　276\n16.2　并行计算模型　276\n16.2.1　BSP　277\n16.2.2　SSP　279\n16.2.3　ASP　280\n16.2.4　参数服务器　281\n16.3　并行计算案例　284\n16.3.1　XGBoost并行库Rabit　284\n16.3.2　MXNet并行库PS-Lite　286\n16.4　美团并行计算机器学习平台　287\n参考文献　289\n第　17章 特征工程和实验平台　290\n17.1　特征平台　290\n17.1.1　特征生产　290\n17.1.2　特征上线　293\n17.1.3　在线特征监控　301\n17.2　实验管理平台　302\n17.2.1　实验平台概述　302\n17.2.2　美团实验平台——Gemini　304","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29841559.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29841559.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29841559.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30243136\/","id":"30243136","publisher":"人民邮电出版社","isbn10":"7115484635","isbn13":"9787115484635","title":"美团机器学习实践","url":"https:\/\/api.douban.com\/v2\/book\/30243136","alt_title":"","author_intro":"美团算法团队由数百名优秀算法工程师组成，负责构建美团这个生活服务互联网大平台的“大脑”，涵盖搜索、推荐、广告、风控、机器学习、计算机视觉、语音、自然语言处理、智能调度、机器人和无人配送等多个技术方向，在帮助美团数亿活跃用户改善用户体验的同时，也帮助餐饮、酒店、婚庆、丽人、亲子等200多个行业的数百万商户提升运营效率。我们致力于通过算法和人工智能技术，帮大家吃得更好，活得更好。","summary":"人工智能技术正以一种超快的速度深刻地改变着我们的生活，引导了第四次工业革命。美团作为国内O2O领域领 先的服务平台，结合自身的业务场景和数据，积极进行了人工智能领域的应用探索。在美团的搜索、推荐、计算广告、风控、图像处理等领域，相关的人工智能技术得到广泛的应用。本书包括通用流程、数据挖掘、搜索和推荐、计算广告、深度学习以及算法工程6大部分内容，全面介绍了美团在多个重要方面对机器学习的应用。\n本书非常适合有一定机器学习基础的工程技术人员和在校大学生学习和阅读。通过本书，有经验的算法工程师可以了解美团在这方面的做法，在校大学生可以学习机器学习算法如何在具体的业务场景中落地。","series":{"id":"13000","title":"图灵原创"},"price":"79.00元"},{"rating":{"max":10,"numRaters":15,"average":"8.5","min":0},"subtitle":"","author":["[意] 罗伯托·巴蒂蒂","[意] 毛罗·布鲁纳托"],"pubdate":"2018-5","tags":[{"count":70,"name":"机器学习","title":"机器学习"},{"count":22,"name":"人工智能","title":"人工智能"},{"count":14,"name":"优化","title":"优化"},{"count":13,"name":"深度学习","title":"深度学习"},{"count":12,"name":"计算机","title":"计算机"},{"count":8,"name":"python","title":"python"},{"count":4,"name":"CS","title":"CS"},{"count":3,"name":"编程","title":"编程"}],"origin_title":"The LION Way : Learning plus Intelligent Optimization","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29784984.jpg","binding":"平装","translator":["王彧弋"],"catalog":"第1章 引言 1\n1.1 学习与智能优化：燎原之火 1\n1.2 寻找黄金和寻找伴侣 3\n1.3 需要的只是数据 5\n1.4 超越传统的商业智能 5\n1.5 LION方法的实施 6\n1.6 “动手”的方法 6\n第2章 懒惰学习：最近邻方法 9\n第3章 学习需要方法 14\n3.1 从已标记的案例中学习：最小化和泛化 16\n3.2 学习、验证、测试 18\n3.3 不同类型的误差 21\n第一部分 监督学习\n第4章 线性模型 26\n4.1 线性回归 27\n4.2 处理非线性函数关系的技巧 28\n4.3 用于分类的线性模型 29\n4.4 大脑是如何工作的 30\n4.5 线性模型为何普遍，为何成功 31\n4.6 最小化平方误差和 32\n4.7 数值不稳定性和岭回归 34\n第5章 广义线性最小二乘法 37\n5.1 拟合的优劣和卡方分布 38\n5.2 最小二乘法与最大似然估计 42\n5.2.1 假设检验 42\n5.2.2 交叉验证 44\n5.3 置信度的自助法 44\n第6章 规则、决策树和森林 50\n6.1 构造决策树 52\n6.2 民主与决策森林 56\n第7章 特征排序及选择 59\n7.1 特征选择：情境 60\n7.2 相关系数 62\n7.3 相关比 63\n7.4 卡方检验拒绝统计独立性 64\n7.5 熵和互信息 64\n第8章 特定非线性模型 67\n8.1 logistic 回归 67\n8.2 局部加权回归 69\n8.3 用LASSO来缩小系数和选择输入值 72\n第9章 神经网络：多层感知器 76\n9.1 多层感知器 78\n9.2 通过反向传播法学习 80\n9.2.1 批量和bold driver反向传播法 81\n9.2.2 在线或随机反向传播 82\n9.2.3 训练多层感知器的高级优化 83\n第10章 深度和卷积网络 84\n10.1 深度神经网络 85\n10.1.1 自动编码器 86\n10.1.2 随机噪声、屏蔽和课程 88\n10.2 局部感受野和卷积网络 89\n第11章 统计学习理论和支持向量机 94\n11.1 经验风险最小化 96\n11.1.1 线性可分问题 98\n11.1.2 不可分问题 100\n11.1.3 非线性假设 100\n11.1.4 用于回归的支持向量 101\n第12章 最小二乘法和健壮内核机器 103\n12.1 最小二乘支持向量机分类器 104\n12.2 健壮加权最小二乘支持向量机 106\n12.3 通过修剪恢复稀疏 107\n12.4 算法改进：调谐QP、原始版本、无补偿 108\n第13章 机器学习中的民主 110\n13.1 堆叠和融合 111\n13.2 实例操作带来的多样性：装袋法和提升法 113\n13.3 特征操作带来的多样性 114\n13.4 输出值操作带来的多样性：纠错码 115\n13.5 训练阶段随机性带来的多样性 115\n13.6 加性logistic回归 115\n13.7 民主有助于准确率－拒绝的折中 118\n第14章 递归神经网络和储备池计算 121\n14.1 递归神经网络 122\n14.2 能量极小化霍普菲尔德网络 124\n14.3 递归神经网络和时序反向传播 126\n14.4 递归神经网络储备池学习 127\n14.5 超限学习机 128\n第二部分 无监督学习和聚类\n第15章 自顶向下的聚类：K均值 132\n15.1 无监督学习的方法 134\n15.2 聚类：表示与度量 135\n15.3 硬聚类或软聚类的K均值方法 137\n第16章 自底向上（凝聚）聚类 142\n16.1 合并标准以及树状图 142\n16.2 适应点的分布距离：马氏距离 144\n16.3 附录：聚类的可视化 146\n第17章 自组织映射 149\n17.1 将实体映射到原型的人工皮层 150\n17.2 使用成熟的自组织映射进行分类 153\n第18章 通过线性变换降维（投影） 155\n18.1 线性投影 156\n18.2 主成分分析 158\n18.3 加权主成分分析：结合坐标和关系 160\n18.4 通过比值优化进行线性判别 161\n18.5 费希尔线性判别分析 163\n第19章 通过非线性映射可视化图与网络 165\n19.1 最小应力可视化 166\n19.2 一维情况：谱图绘制 168\n19.3 复杂图形分布标准 170\n第20章 半监督学习 174\n20.1 用部分无监督数据进行学习 175\n20.1.1 低密度区域中的分离 177\n20.1.2 基于图的算法 177\n20.1.3 学习度量 179\n20.1.4 集成约束和度量学习 179\n第三部分 优化：力量之源\n第21章 自动改进的局部方法 184\n21.1 优化和学习 185\n21.2 基于导数技术的一维情况 186\n21.2.1 导数可以由割线近似 190\n21.2.2 一维最小化 191\n21.3 求解高维模型（二次正定型） 191\n21.3.1 梯度与最速下降法 194\n21.3.2 共轭梯度法 196\n21.4 高维中的非线性优化 196\n21.4.1 通过线性查找的全局收敛 197\n21.4.2 解决不定黑塞矩阵 198\n21.4.3 与模型信赖域方法的关系 199\n21.4.4 割线法 200\n21.4.5 缩小差距：二阶方法与线性复杂度 201\n21.5 不涉及导数的技术：反馈仿射振荡器 202\n21.5.1 RAS：抽样区域的适应性 203\n21.5.2 为健壮性和多样化所做的重复 205\n第22章 局部搜索和反馈搜索优化 211\n22.1 基于扰动的局部搜索 212\n22.2 反馈搜索优化：搜索时学习 215\n22.3 基于禁忌的反馈搜索优化 217\n第23章 合作反馈搜索优化 222\n23.1 局部搜索过程的智能协作 223\n23.2 CoRSO：一个政治上的类比 224\n23.3 CoRSO的例子：RSO与RAS合作 226\n第24章 多目标反馈搜索优化 232\n24.1 多目标优化和帕累托最优 233\n24.2 脑－计算机优化：循环中的用户 235\n第四部分 应用精选\n第25章 文本和网页挖掘 240\n25.1 网页信息检索与组织 241\n25.1.1 爬虫 241\n25.1.2 索引 242\n25.2 信息检索与排名 244\n25.2.1 从文档到向量：向量－空间模型 245\n25.2.2 相关反馈 247\n25.2.3 更复杂的相似性度量 248\n25.3 使用超链接来进行网页排名 250\n25.4 确定中心和权威：HITS 254\n25.5 聚类 256\n第26章 协同过滤和推荐 257\n26.1 通过相似用户结合评分 258\n26.2 基于矩阵分解的模型 260\n参考文献 263\n索引 269","pages":"272","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29784984.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29784984.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29784984.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30239753\/","id":"30239753","publisher":"人民邮电出版社","isbn10":"711548029X","isbn13":"9787115480293","title":"机器学习与优化","url":"https:\/\/api.douban.com\/v2\/book\/30239753","alt_title":"The LION Way : Learning plus Intelligent Optimization","author_intro":"【作者简介】\n罗伯托·巴蒂蒂（Roberto Battiti）\n人工智能领域先驱，IEEE会士。因在无功搜索优化（RSO）方向做出了开创性的工作而名震学界。 目前为意大利特伦托大学教授，同时担任特伦托大学机器学习与智能优化实验室（LION lab）主任。\n毛罗·布鲁纳托（Mauro Brunato）\n意大利特伦托大学助理教授，LION研究团队成员。\n【译者简介】\n王彧弋\n博士，现于瑞士苏黎世联邦理工学院从事研究工作，主要研究方向为理论计算机科学与机器学习。","summary":"本书是机器学习实战领域的一本佳作，从机器学习的基本概念讲起，旨在将初学者引入机器学习的大门，并走上实践的道路。本书通过讲解机器学习中的监督学习和无监督学习，并结合特征选择和排序、聚类方法、文本和网页挖掘等热点问题，论证了“优化是力量之源”这一观点，为机器学习在企业中的应用提供了切实可行的操作建议。","price":"89.00元"},{"rating":{"max":10,"numRaters":20,"average":"8.2","min":0},"subtitle":"","author":["Andrew Trask"],"pubdate":"2017-3-31","tags":[{"count":31,"name":"深度学习","title":"深度学习"},{"count":24,"name":"人工智能","title":"人工智能"},{"count":13,"name":"机器学习","title":"机器学习"},{"count":11,"name":"计算机","title":"计算机"},{"count":6,"name":"计算机科学","title":"计算机科学"},{"count":6,"name":"Python","title":"Python"},{"count":4,"name":"软件开发","title":"软件开发"},{"count":4,"name":"原版","title":"原版"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29083357.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"325","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29083357.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29083357.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29083357.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26887949\/","id":"26887949","publisher":"Manning Publications","isbn10":"1617293709","isbn13":"9781617293702","title":"Grokking Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26887949","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":23,"average":"9.0","min":0},"subtitle":"从图灵机到人工智能","author":["周志明"],"pubdate":"2018-1-1","tags":[{"count":28,"name":"人工智能","title":"人工智能"},{"count":8,"name":"深度学习","title":"深度学习"},{"count":4,"name":"计算机科学","title":"计算机科学"},{"count":4,"name":"科普","title":"科普"},{"count":1,"name":"神经网络","title":"神经网络"},{"count":1,"name":"数学","title":"数学"},{"count":1,"name":"技术史","title":"技术史"},{"count":1,"name":"心理","title":"心理"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29923729.jpg","binding":"平装","translator":[],"catalog":"前言\n致谢\n第一部分　以智慧创造智慧\n第1章　洪荒年代 \/ 2\n1.1 概述 \/ 2\n1.2 引言：信息革命 \/ 3\n1.3 图灵机，计算的基石 \/ 5\n1.4 人工智能的萌芽 \/ 10\n1.5 图灵测试：何谓智能？ \/ 12\n1.6 智能与人类的界限 \/ 16\n1.7 机器能思考吗？ \/ 17\n1.8 机器拟人心 \/ 21\n1.9 机器拟人脑 \/ 24\n1.10 机器拟人身 \/ 27\n1.11 本章小结 \/ 28\n第2章　迈向人工智能 \/ 30\n2.1 概述 \/ 30\n2.2 引言：不经意间改变世界 \/ 31\n2.3 达特茅斯会议 \/ 35\n2.4 有学术就有江湖 \/ 41\n2.5 有江湖就有传奇 \/ 48\n2.6 人工智能早期成果 \/ 54\n2.7 本章小结 \/ 63\n第二部分　学派争鸣\n第3章　符号主义学派 \/ 66\n3.1 概述 \/ 66\n3.2 引言：五分钟逻辑学 \/ 68\n3.3 描述已知，推理未知 \/ 73\n3.4 知识！知识！知识！ \/ 87\n3.5 从演绎到归纳 \/ 96\n3.6 符号主义的现状和未来 \/ 101\n3.7 本章小结 \/ 103\n第4章　连接主义学派 \/ 105\n4.1 概述 \/ 105\n4.2 引言：命运 \/ 106\n4.3 大脑模型 \/ 108\n4.4 崛起的明星 \/ 114\n4.5 陨落的流星 \/ 118\n4.6 感知机 \/ 121\n4.7 凛冬将至 \/ 129\n4.8 人工智能的繁荣与寒冬 \/ 137\n4.9 本章小结 \/ 141\n第5章　行为主义学派 \/ 143\n5.1 概述 \/ 143\n5.2 引言：昔日神童 \/ 145\n5.3 自动机对抗自动机 \/ 147\n5.4 从“控制论”说起 \/ 151\n5.5 机械因果观和行为主义 \/ 154\n5.6 自复制机和进化主义 \/ 157\n5.7 机器人学 \/ 161\n5.8 本章小结 \/ 170\n第三部分　第三波高潮\n第6章　机器学习概览 \/ 172\n6.1 概述 \/ 172\n6.2 什么是机器学习 \/ 174\n6.3 机器学习的意义 \/ 177\n6.4 机器学习解决的问题 \/ 179\n6.5 进行机器学习：实战模型训练 \/ 185\n6.6 评估验证 \/ 233\n6.7 本章小结 \/ 242\n第7章　深度学习时代 \/ 244\n7.1 概述 \/ 244\n7.2 引言：深度学习教父 \/ 245\n7.3 逆反之心 \/ 247\n7.4 复兴之路 \/ 249\n7.5 深度学习时代 \/ 263\n7.6 深度神经网络 \/ 290\n7.7 从实验室到企业 \/ 309\n7.8 挑战与反思 \/ 317\n7.9 本章小结 \/ 322\n第四部分　人机共生\n第8章　与机器共生 \/ 326\n8.1 概述 \/ 326\n8.2 引言：天才还是白痴 \/ 327\n8.3 与机器竞技 \/ 329\n8.4 与机器共舞 \/ 360\n8.5 本章小结 \/ 368\n附录　人工智能历史大事记 \/ 370","pages":"413","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29923729.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29923729.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29923729.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30379536\/","id":"30379536","publisher":"机械工业出版社","isbn10":"7111610490","isbn13":"9787111610496","title":"智慧的疆界","url":"https:\/\/api.douban.com\/v2\/book\/30379536","alt_title":"","author_intro":"周志明，Java技术、机器学习和企业级开发技术专家，现任远光软件研究院院长，人工智能博士在读，著有畅销书本书。\n开源技术的积极倡导者和推动者，对计算机科学和相关的多个领域都有深刻的见解，尤其是人工智能、Java技术和敏捷开发等领域。曾受邀在InfoQ和IBMDeveloperWorks等网站撰写技术专栏。\n著作颇丰，著有《深入理解Java虚拟机》《深入理解OSGi》，翻译了《Java虚拟机规范》等著作。其中《深入理解Java虚拟机》第1版出版于2011年，已经出至第2版，累计印刷超过30次，不仅销量好，而且口碑更好，是中文计算机图书领域公认的、难得一见的佳作。","summary":"这是一部对人工智能充满敬畏之心的匠心之作，由《深入理解Java虚拟机》作者耗时一年完成，它将带你从奠基人物、历史事件、学术理论、研究成果、技术应用等5个维度全面读懂人工智能。\n本书以时间为主线，用专业的知识、通俗的语言、巧妙的内容组织方式，详细讲解了人工智能这个学科的全貌、能解决什么问题、面临怎样的困难、尝试过哪些努力、取得过多少成绩、未来将向何方发展，尽可能消除人工智能的神秘感，把阳春白雪的人工智能从科学的殿堂推向公众面前。","price":"56.9"},{"rating":{"max":10,"numRaters":13,"average":"8.7","min":0},"subtitle":"Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow, 2nd Edition","author":["Sebastian Raschka","Vahid Mirjalili"],"pubdate":"2017-9-6","tags":[{"count":18,"name":"机器学习","title":"机器学习"},{"count":16,"name":"Python","title":"Python"},{"count":3,"name":"TML","title":"TML"},{"count":2,"name":"ML\/DL","title":"ML\/DL"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"数据分析","title":"数据分析"},{"count":1,"name":"工具书","title":"工具书"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29511031.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"501","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29511031.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29511031.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29511031.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27107214\/","id":"27107214","publisher":"Packt Publishing - ebooks Account","isbn10":"1787125939","isbn13":"9781787125933","title":"Python Machine Learning","url":"https:\/\/api.douban.com\/v2\/book\/27107214","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":220,"average":"7.2","min":0},"subtitle":"","author":["黄文坚","唐源"],"pubdate":"2017-2-1","tags":[{"count":149,"name":"TensorFlow","title":"TensorFlow"},{"count":124,"name":"深度学习","title":"深度学习"},{"count":118,"name":"机器学习","title":"机器学习"},{"count":51,"name":"人工智能","title":"人工智能"},{"count":36,"name":"计算机","title":"计算机"},{"count":34,"name":"技术","title":"技术"},{"count":28,"name":"编程","title":"编程"},{"count":17,"name":"深度学习，人工智能，强化学习，深入浅出，通俗易懂","title":"深度学习，人工智能，强化学习，深入浅出，通俗易懂"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29343414.jpg","binding":"平装","translator":[],"catalog":"1 TensorFlow基础 1\n1.1 TensorFlow概要 1\n1.2 TensorFlow编程模型简介 4\n2 TensorFlow和其他深度学习框架的对比 18\n2.1 主流深度学习框架对比 18\n2.2 各深度学习框架简介 20\n3 TensorFlow第一步 39\n3.1 TensorFlow的编译及安装 39\n3.2 TensorFlow实现SoftmaxRegression识别手写数字 46\n4 TensorFlow实现自编码器及多层感知机 55\n4.1 自编码器简介 55\n4.2 TensorFlow实现自编码器 59\n4.3 多层感知机简介 66\n4.4 TensorFlow实现多层感知机 70\n5 TensorFlow实现卷积神经网络 74\n5.1 卷积神经网络简介 74\n5.2 TensorFlow实现简单的卷积网络 80\n5.3 TensorFlow实现进阶的卷积网络 83\n6 TensorFlow实现经典卷积神经网络 95\n6.1 TensorFlow实现AlexNet 97\n6.2 TensorFlow实现VGGNet 108\n6.3 TensorFlow实现GoogleInceptionNet 119\n6.4 TensorFlow实现ResNet 143\n6.5 卷积神经网络发展趋势 156\n7 TensorFlow实现循环神经网络及Word2Vec 159\n7.1 TensorFlow实现Word2Vec 159\n7.2 TensorFlow实现基于LSTM的语言模型 173\n7.3 TensorFlow实现BidirectionalLSTMClassifier 188\n8 TensorFlow实现深度强化学习 195\n8.1 深度强化学习简介 195\n8.2 TensorFlow实现策略网络 201\n8.3 TensorFlow实现估值网络 213\n9 TensorBoard、多GPU并行及分布式并行 233\n9.1 TensorBoard 233\n9.2 多GPU并行 243\n9.3 分布式并行 249\n10 TF.Learn从入门到精通 259\n10.1 分布式Estimator 259\n10.2 深度学习Estimator 267\n10.3 机器学习Estimator 272\n10.4 DataFrame 278\n10.5 监督器Monitors 279\n11 TF.Contrib的其他组件 283\n11.1 统计分布 283\n11.2 Layer模块 285\n11.3 性能分析器tfprof 293\n参考文献 297","pages":"316","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29343414.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29343414.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29343414.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26974266\/","id":"26974266","publisher":"电子工业出版社","isbn10":"7121309122","isbn13":"9787121309120","title":"TensorFlow实战","url":"https:\/\/api.douban.com\/v2\/book\/26974266","alt_title":"","author_intro":"黄文坚，PPmoney大数据算法总监，负责集团的风控、理财、互联网证券等业务的数据挖掘工作。Google TensorFlow Contributor。前明略数据技术合伙人，领导了对诸多大型银行、保险公司、基金的数据挖掘项目，包括建立金融风控模型、新闻舆情分析、保险复购预测等。曾就职于阿里巴巴搜索引擎算法团队，负责天猫个性化搜索系统。曾参加阿里巴巴大数据推荐算法大赛，于7000多支队伍中获得前10名。本科、研究生就读于香港科技大学，曾在会议和期刊SIGMOBILE MobiCom、IEEE Transactions on Image Processing发表论文，研究成果获美国计算机协会移动计算大会（MobiCom）移动应用技术冠军，并获得两项美国专利和一项中国专利。\n唐源，目前在芝加哥的Uptake公司带领团队建立用于多个物联网领域的数据科学引擎进行条件和健康监控，也建立了公司的预测模型引擎，现在被用于航空、能源等大型机械领域。一直活跃在开源软件社区，是TensorFlow和DMLC的成员，是TensorFlow、XGBoost、MXNet等软件的committer，TF.Learn、ggfortify等软件的作者，以及caret、pandas等软件的贡献者。曾获得谷歌Open Source Peer Bonus，以及多项高校和企业编程竞赛的奖项。在美国宾州州立大学获得荣誉数学学位，曾在本科学习期间成为创业公司DataNovo的核心创始成员，研究专利数据挖掘、无关键字现有技术搜索、策略推荐等。","summary":"Google近日发布了TensorFlow 1.0候选版，这个稳定版将是深度学习框架发展中的里程碑的一步。自TensorFlow于2015年底正式开源，距今已有一年多，这期间TensorFlow不断给人以惊喜，推出了分布式版本，服务框架TensorFlow Serving，可视化工具TensorFlow，上层封装TF.Learn，其他语言（Go、Java、Rust、Haskell）的绑定、Windows的支持、JIT编译器XLA、动态计算图框架Fold，以及数不胜数的经典模型在TensorFlow上的实现（Inception Net、SyntaxNet等）。在这一年多时间，TensorFlow已从初入深度学习框架大战的新星，成为了几近垄断的行业事实标准。\n《TensorFlow实战》希望用简单易懂的语言带领大家探索TensorFlow（基于1.0版本API）。在《TensorFlow实战》中我们讲述了TensorFlow的基础原理，TF和其他框架的异同。并用具体的代码完整地实现了各种类型的深度神经网络：AutoEncoder、MLP、CNN（AlexNet，VGGNet，Inception Net，ResNet）、Word2Vec、RNN（LSTM，Bi-RNN）、Deep Reinforcement Learning(Policy Network、Value Network)。此外，《TensorFlow实战》还讲解了TensorBoard、多GPU并行、分布式并行、TF.Learn和其他TF.Contrib组件。《TensorFlow实战》希望能帮读者快速入门TensorFlow和深度学习，在工业界或者研究中快速地将想法落地为可实践的模型。","series":{"id":"41172","title":"博文视点AI系列"},"price":"79"},{"rating":{"max":10,"numRaters":34,"average":"8.7","min":0},"subtitle":"","author":["Yoshua Bengio"],"pubdate":"","tags":[{"count":51,"name":"深度学习","title":"深度学习"},{"count":41,"name":"机器学习","title":"机器学习"},{"count":21,"name":"人工智能","title":"人工智能"},{"count":16,"name":"神经网络","title":"神经网络"},{"count":13,"name":"AI","title":"AI"},{"count":12,"name":"计算机","title":"计算机"},{"count":6,"name":"计算机科学","title":"计算机科学"},{"count":6,"name":"programming","title":"programming"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s21095441.jpg","binding":"散装","translator":[],"catalog":"","pages":"136","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s21095441.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s21095441.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s21095441.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6346890\/","id":"6346890","publisher":"","isbn10":"1601982941","isbn13":"9781601982940","title":"Learning Deep Architectures for AI","url":"https:\/\/api.douban.com\/v2\/book\/6346890","alt_title":"","author_intro":"","summary":"Theoretical results suggest that in order to learn the kind of complicated\nfunctions that can represent high-level abstractions (e.g., in\nvision, language, and other AI-level tasks), one may need deep architectures.\nDeep architectures are composed of multiple levels of non-linear\noperations, such as in neural nets with many hidden layers or in complicated\npropositional formulae re-using many sub-formulae. Searching\nthe parameter space of deep architectures is a difficult task, but learning\nalgorithms such as those for Deep Belief Networks have recently been\nproposed to tackle this problem with notable success, beating the stateof-\nthe-art in certain areas. This monograph discusses the motivations\nand principles regarding learning algorithms for deep architectures, in\nparticular those exploiting as building blocks unsupervised learning of\nsingle-layer models such as Restricted Boltzmann Machines, used to\nconstruct deeper models such as Deep Belief Networks.","price":"695.00 元"},{"rating":{"max":10,"numRaters":22,"average":"9.6","min":0},"subtitle":"","author":[],"pubdate":"2010-11","tags":[{"count":67,"name":"学习方法","title":"学习方法"},{"count":55,"name":"学习","title":"学习"},{"count":34,"name":"教育","title":"教育"},{"count":29,"name":"学习科学","title":"学习科学"},{"count":24,"name":"方法论","title":"方法论"},{"count":22,"name":"心理学-学习理论","title":"心理学-学习理论"},{"count":21,"name":"深度学习","title":"深度学习"},{"count":10,"name":"致用类","title":"致用类"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6258906.jpg","binding":"","translator":["杭零"],"catalog":"绪论\n第1部分学习问题研究概述\n第1章 学习的模型\n1．直接传递模型\n2．行为主义模型\n3．建构主义模型\n4．各模型的贡献与局限\n第2章 学习的变构模型\n1．变构模型的功能性结构\n2．学习者的概念在学习过程中的地位\n3．变构模型的维度\n4．学习，一个布满悖论的过程\n第Ⅱ部分关于学习者的概念及其转化的研究\n第3章 学习者的概念\n1．“学习者的概念”之教学释义\n2．获知学习者的概念的方法论\n3．如何查明学习者的概念：几个例子\n第4章 转化学习者的概念\n1．学习者的概念的各种运用：“概念志\n2．研究学习者的概念转化的方法论\n3．关于学习者的概念转化研究的例子\n第5章 知识炼制的变构过程\n1．解构\n2．理解知识\n3．认知干扰\n4．炼制的过程\n第6章 为学习创建教学环境\n1．变构学习：以“光合作用”概念的学习为例\n2．相关参数系统\n3．变构教学策略\n4．各参数间的必要调节\n结语\n1．矛盾的管理\n2．有待开展的研究","pages":"219","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s6258906.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s6258906.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6258906.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5388442\/","id":"5388442","publisher":"教育科学出版社","isbn10":"7504152412","isbn13":"9787504152411","title":"变构模型-学习研究的新路径","url":"https:\/\/api.douban.com\/v2\/book\/5388442","alt_title":"","author_intro":"","summary":"《变构模型:学习研究的新路径》内容简介：针对当前我国读者对学习与教育问题的关注，尤其是关于课堂教学热点问题的讨论，中外学者联手奉献了基于多年探索的研究成果。20世纪80年代后期，瑞士日内瓦大学安德烈·焦尔当提出了学习的变构模型，对欧洲以及北美洲和南美洲许多国家的学校、媒介及学习型企业的变革与发展产生了重要影响。《变构模型:学习研究的新路径》系统展现了变构模型对复杂学习机理的揭示，深刻剖析了“学习者的概念”的内涵和教学意义，并大量例示了促发根本性学习的研究及实践的方法和策略。细读《变构模型:学习研究的新路径》，在与作者的对话中思索我们所关切的学习与教育问题并寻找答案，或许可以经历一回独特的认识论体验。","price":"30.00元"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"A Practitioner's Approach","author":["Josh Patterson","Adam Gibson"],"pubdate":"2017-3-25","tags":[{"count":33,"name":"机器学习","title":"机器学习"},{"count":28,"name":"深度学习","title":"深度学习"},{"count":15,"name":"DeepLearning","title":"DeepLearning"},{"count":7,"name":"数据挖掘","title":"数据挖掘"},{"count":4,"name":"AI","title":"AI"},{"count":3,"name":"计算机","title":"计算机"},{"count":3,"name":"MachineLearning","title":"MachineLearning"},{"count":3,"name":"ML","title":"ML"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28061930.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"400","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28061930.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28061930.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28061930.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26379661\/","id":"26379661","publisher":"O'Reilly Media","isbn10":"1491914254","isbn13":"9781491914250","title":"Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26379661","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":37,"average":"6.4","min":0},"subtitle":"","author":["[美] 山姆·亚伯拉罕（Sam Abrahams）","[美] 丹尼亚尔·哈夫纳（Danijar Hafner）","[美] 埃里克·厄威特","[美] 阿里尔·斯卡尔皮内里"],"pubdate":"2017-5-1","tags":[{"count":34,"name":"TensorFlow","title":"TensorFlow"},{"count":24,"name":"深度学习","title":"深度学习"},{"count":11,"name":"人工智能","title":"人工智能"},{"count":9,"name":"计算机","title":"计算机"},{"count":8,"name":"机器学习","title":"机器学习"},{"count":6,"name":"编程","title":"编程"},{"count":6,"name":"ML","title":"ML"},{"count":3,"name":"计算机科学","title":"计算机科学"}],"origin_title":"TensorFlow for Machine Intelligence","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29437348.jpg","binding":"平装","translator":["段菲","陈澎"],"catalog":"译者序\n前言\n第一部分　开启TensorFlow之旅\n第1章　引言2\n1.1　无处不在的数据2\n1.2　深度学习2\n1.3　TensorFlow：一个现代的机器学习库3\n1.4　TensorFlow：技术概要3\n1.5　何为TensorFlow4\n1.5.1　解读来自官网的单句描述4\n1.5.2　单句描述未体现的内容6\n1.6　何时使用TensorFlow7\n1.7　TensorFlow的优势8\n1.8　使用TensorFlow所面临的挑战9\n1.9　高歌猛进9\n第2章　安装TensorFlow10\n2.1　选择安装环境10\n2.2　Jupyter Notebook与matplotlib12\n2.3　创建Virtualenv环境12\n2.4　TensorFlow的简易安装13\n2.5　源码构建及安装实例：在64位Ubuntu Linux上安装GPU版TensorFlow14\n2.5.1　安装依赖库14\n2.5.2　安装Bazel15\n2.5.3　安装CUDA软件（仅限NVIDIA GPU）16\n2.5.4　从源码构建和安装TensorFlow18\n2.6　安装Jupyter Notebook20\n2.7　安装matplotlib20\n2.8　测试TensorFlow、Jupyter Notebook及matplotlib21\n2.9　本章小结23\n第二部分　TensorFlow与机器学习基础\n第3章　TensorFlow基础26\n3.1　数据流图简介26\n3.1.1　数据流图基础26\n3.1.2　节点的依赖关系29\n3.2　在TensorFlow中定义数据流图33\n3.2.1　构建第一个TensorFlow数据流图33\n3.2.2　张量思维39\n3.2.3　张量的形状43\n3.2.4　TensorFlow的Operation44\n3.2.5　TensorFlow的Graph对象46\n3.2.6　TensorFlow Session48\n3.2.7　利用占位节点添加输入52\n3.2.8　Variable对象53\n3.3　通过名称作用域组织数据流图56\n3.4　练习：综合运用各种组件61\n3.4.1　构建数据流图63\n3.4.2　运行数据流图66\n3.5　本章小结71\n第4章　机器学习基础72\n4.1　有监督学习简介72\n4.2　保存训练检查点74\n4.3　线性回归76\n4.4　对数几率回归78\n4.5　softmax分类83\n4.6　多层神经网络85\n4.7　梯度下降法与误差反向传播算法88\n第三部分　用TensorFlow实现更高级的深度模型\n第5章　目标识别与分类96\n5.1　卷积神经网络97\n5.2　卷积100\n5.2.1　输入和卷积核100\n5.2.2　跨度102\n5.2.3　边界填充104\n5.2.4　数据格式104\n5.2.5　深入探讨卷积核105\n5.3　常见层107\n5.3.1　卷积层108\n5.3.2　激活函数108\n5.3.3　池化层111\n5.3.4　归一化113\n5.3.5　高级层114\n5.4　图像与TensorFlow116\n5.4.1　加载图像116\n5.4.2　图像格式117\n5.4.3　图像操作121\n5.4.4　颜色127\n5.5　CNN的实现129\n5.5.1　Stanford Dogs数据集129\n5.5.2　将图像转为TFRecord文件130\n5.5.3　加载图像133\n5.5.4　模型134\n5.5.5　训练136\n5.5.6　用TensorBoard调试滤波器137\n5.6　本章小结139\n第6章　循环神经网络与自然语言处理140\n6.1　循环神经网络简介140\n6.1.1　时序的世界140\n6.1.2　近似任意程序141\n6.1.3　随时间反向传播142\n6.1.4　序列的编码和解码143\n6.1.5　实现第一个循环神经网络145\n6.1.6　梯度消失与梯度爆炸145\n6.1.7　长短时记忆网络147\n6.1.8　RNN结构的变种148\n6.2　词向量嵌入149\n6.2.1　准备维基百科语料库151\n6.2.2　模型结构155\n6.2.3　噪声对比分类器156\n6.2.4　训练模型156\n6.3　序列分类157\n6.3.1　Imdb影评数据集158\n6.3.2　使用词向量嵌入159\n6.3.3　序列标注模型159\n6.3.4　来自最后相关活性值的softmax层161\n6.3.5　梯度裁剪162\n6.3.6　训练模型163\n6.4　序列标注164\n6.4.1　OCR数据集164\n6.4.2　时间步之间共享的soft-max层166\n6.4.3　训练模型169\n6.4.4　双向RNN171\n6.5　预测编码174\n6.5.1　字符级语言建模174\n6.5.2　ArXiv摘要API175\n6.5.3　数据预处理177\n6.5.4　预测编码模型178\n6.5.5　训练模型182\n6.5.6　生成相似序列185\n6.6　本章小结188\n第四部分　其他提示、技术与特性\n第7章　产品环境中模型的部署190\n7.1　搭建TensorFlow服务开发环境190\n7.1.1　Docker镜像190\n7.1.2　Bazel工作区191\n7.2　导出训练好的模型192\n7.3　定义服务器接口195\n7.4　实现推断服务器197\n7.5　客户端应用201\n7.6　产品准备203\n7.7　本章小结203\n第8章　辅助函数、代码结构和类204\n8.1　确保目录结构存在204\n8.2　下载函数204\n8.3　磁盘缓存修饰器205\n8.4　属性字典206\n8.5　惰性属性修饰器207\n8.6　覆盖数据流图修饰器209\n第9章　结语：其他资源212","pages":"212","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29437348.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29437348.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29437348.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27031750\/","id":"27031750","publisher":"机械工业出版社","isbn10":"7111563891","isbn13":"9787111563891","title":"面向机器智能的TensorFlow实践","url":"https:\/\/api.douban.com\/v2\/book\/27031750","alt_title":"TensorFlow for Machine Intelligence","author_intro":"山姆·亚伯拉罕：数据科学家、工程师，富有经验的TensorFlow贡献者。\n丹尼亚尔·哈夫纳：谷歌软件工程师\n埃里克·厄威特：高级软件工程师\n阿里尔·斯卡尔皮内里：团队负责人，高级Java开发者\n段菲，清华大学信号与信息处理专业博士，前三星电子中国研究院高级研究员，现为英特尔中国研究院高级研究员。研究方向是深度学习、计算机视觉、数据可视化。参与翻译过《机器学习》《机器学习实践：测试驱动的开发方法》《DirectX103D游戏编程深度探索》等多本图书。","summary":"本书是一本*佳的TensorFlow入门指南。几位作者都来自研发一线，他们用自己的宝贵经验，结合众多高质量的代码，生动讲解TensorFlow的底层原理，并从实践角度介绍如何将两种常见模型——深度卷积网络、循环神经网络应用到图像理解和自然语言处理的典型任务中。此外，还介绍了在模型部署和编程中可用的诸多实用技巧。\n全书分为四部分，共9章。第一部分（第1~2章）讨论TensorFlow的设计模式以及选择TensorFlow作为深度学习库的优势和面临的挑战，并给出详细的安装指南。第二部分（第3~4章）深入介绍TensorFlow API的基础知识和机器学习基础。第三部分（第5~6章）探讨如何用TensorFlow实现高级深度模型，涉及卷积神经网络（或CNN）模型和循环神经网络（或RNN）模型。第四部分（第7~8章）探讨TensorFlow API中*新推出的特性，包括如何准备用于部署的模型、一些有用的编程模式等。第9章给出一些进一步了解TensorFlow的学习资源。","series":{"id":"42106","title":"智能系统与技术丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":16,"average":"7.6","min":0},"subtitle":"Designing Next-Generation Artificial Intelligence Algorithms","author":["Nikhil Buduma"],"pubdate":"2015-11-25","tags":[{"count":26,"name":"机器学习","title":"机器学习"},{"count":18,"name":"DeepLearning","title":"DeepLearning"},{"count":15,"name":"深度学习","title":"深度学习"},{"count":12,"name":"人工智能","title":"人工智能"},{"count":6,"name":"数据挖掘","title":"数据挖掘"},{"count":5,"name":"TensorFlow","title":"TensorFlow"},{"count":5,"name":"CS","title":"CS"},{"count":5,"name":"Algorithm","title":"Algorithm"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29881668.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"150","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29881668.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29881668.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29881668.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26425877\/","id":"26425877","publisher":"O'Reilly Media","isbn10":"1491925612","isbn13":"9781491925614","title":"Fundamentals of Deep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26425877","alt_title":"","author_intro":"","summary":"","price":"GBP 34.99"},{"rating":{"max":10,"numRaters":10,"average":"9.1","min":0},"subtitle":"Tricks of the Trade","author":["Grégoire Montavon","Geneviève Orr","Klaus-Robert Müller"],"pubdate":"2013-11-6","tags":[{"count":16,"name":"DeepLearning","title":"DeepLearning"},{"count":15,"name":"神经网络","title":"神经网络"},{"count":15,"name":"机器学习","title":"机器学习"},{"count":10,"name":"NeuralNetwork","title":"NeuralNetwork"},{"count":5,"name":"深度学习","title":"深度学习"},{"count":4,"name":"计算机","title":"计算机"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"数据挖掘","title":"数据挖掘"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27026851.jpg","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27026851.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27026851.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27026851.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25711852\/","id":"25711852","publisher":"Springer","isbn10":"3642352898","isbn13":"9783642352898","title":"Neural Networks","url":"https:\/\/api.douban.com\/v2\/book\/25711852","alt_title":"","author_intro":"","summary":"The twenty last years have been marked by an increase in available data and computing power. In parallel to this trend, the focus of neural network research and the practice of training neural networks has undergone a number of important changes, for example, use of deep learning machines.\nThe second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers. These tricks can make a substantial difference (in terms of speed, ease of implementation, and accuracy) when it comes to putting algorithms to work on real problems.","price":"USD 131.00"},{"rating":{"max":10,"numRaters":30,"average":"7.0","min":0},"subtitle":"","author":["库姆斯 (Alexander T.Combs)"],"pubdate":"2017-5-1","tags":[{"count":38,"name":"机器学习","title":"机器学习"},{"count":23,"name":"Python","title":"Python"},{"count":13,"name":"人工智能","title":"人工智能"},{"count":10,"name":"python","title":"python"},{"count":8,"name":"数据科学","title":"数据科学"},{"count":6,"name":"计算机","title":"计算机"},{"count":6,"name":"深度学习","title":"深度学习"},{"count":5,"name":"ML","title":"ML"}],"origin_title":"Python Machine Learning Blueprints","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29479318.jpg","binding":"平装","translator":["黄申"],"catalog":"第1章Python机器学习的生态系统1\n1.1数据科学／机器学习的工作流程2\n1.1.1获取2\n1.1.2检查和探索2\n1.1.3清理和准备3\n1.1.4建模3\n1.1.5评估3\n1.1.6部署3\n1.2Python库和功能3\n1.2.1获取4\n1.2.2检查4\n1.2.3准备20\n1.2.4建模和评估26\n1.2.5部署34\n1.3设置机器学习的环境34\n1.4小结34\n第2章构建应用程序，发现低价的公寓35\n2.1获取公寓房源数据36\n使用import.io抓取房源数据36\n2.2检查和准备数据38\n2.2.1分析数据46\n2.2.2可视化数据50\n2.3对数据建模51\n2.3.1预测54\n2.3.2扩展模型57\n2.4小结57\n第3章构建应用程序，发现低价的机票58\n3.1获取机票价格数据59\n3.2使用高级的网络爬虫技术检索票价数据60\n3.3解析DOM以提取定价数据62\n通过聚类技术识别异常的票价66\n3.4使用IFTTT发送实时提醒75\n3.5整合在一起78\n3.6小结82\n第4章使用逻辑回归预测IPO市场83\n4.1IPO市场84\n4.1.1什么是IPO84\n4.1.2近期IPO市场表现84\n4.1.3基本的IPO策略93\n4.2特征工程94\n4.3二元分类103\n4.4特征的重要性108\n4.5小结111\n第5章创建自定义的新闻源112\n5.1使用Pocket应用程序，创建一个监督训练的集合112\n5.1.1安装Pocket的Chrome扩展程序113\n5.1.2使用PocketAPI来检索故事114\n5.2使用embed.lyAPI下载故事的内容119\n5.3自然语言处理基础120\n5.4支持向量机123\n5.5IFTTT与文章源、Google表单和电子邮件的集成125\n通过IFTTT设置新闻源和Google表单125\n5.6设置你的每日个性化新闻简报133\n5.7小结137\n第6章预测你的内容是否会广为流传138\n6.1关于病毒性，研究告诉我们了些什么139\n6.2获取分享的数量和内容140\n6.3探索传播性的特征149\n6.3.1探索图像数据149\n6.3.2探索标题152\n6.3.3探索故事的内容156\n6.4构建内容评分的预测模型157\n6.5小结162\n第7章使用机器学习预测股票市场163\n7.1市场分析的类型164\n7.2关于股票市场，研究告诉我们些什么165\n7.3如何开发一个交易策略166\n7.3.1延长我们的分析周期172\n7.3.2使用支持向量回归，构建我们的模型175\n7.3.3建模与动态时间扭曲182\n7.4小结186\n第8章建立图像相似度的引擎187\n8.1图像的机器学习188\n8.2处理图像189\n8.3查找相似的图像191\n8.4了解深度学习195\n8.5构建图像相似度的引擎198\n8.6小结206\n第9章打造聊天机器人207\n9.1图灵测试207\n9.2聊天机器人的历史208\n9.3聊天机器人的设计212\n9.4打造一个聊天机器人217\n9.5小结227\n第10章构建推荐引擎228\n10.1协同过滤229\n10.1.1基于用户的过滤230\n10.1.2基于项目的过滤233\n10.2基于内容的过滤236\n10.3混合系统237\n10.4构建推荐引擎238\n10.5小结251","pages":"251","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29479318.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29479318.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29479318.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27073447\/","id":"27073447","publisher":"人民邮电出版社","isbn10":"7115449066","isbn13":"9787115449061","title":"Python机器学习实践指南","url":"https:\/\/api.douban.com\/v2\/book\/27073447","alt_title":"Python Machine Learning Blueprints","author_intro":"Alexander T. Combs 是一位经验丰富的数据科学家、策略师和开发人员。他有金融数据抽取、自然语言处理和生成，以及定量和统计建模的背景。他目前是纽约沉浸式数据科学项目的一名全职资深讲师。","summary":"机器学习是近年来渐趋热门的一个领域，同时Python 语言经过一段时间的发展也已逐渐成为主流的编程语言之一。本书结合了机器学习和Python 语言两个热门的领域，通过利用两种核心的机器学习算法来将Python 语言在数据分析方面的优势发挥到极致。\n全书共有10 章。第1 章讲解了Python 机器学习的生态系统，剩余9 章介绍了众多与机器学习相关的算法，包括各类分类算法、数据可视化技术、推荐引擎等，主要包括机器学习在公寓、机票、IPO 市场、新闻源、内容推广、股票市场、图像、聊天机器人和推荐引擎等方面的应用。\n本书适合Python 程序员、数据分析人员、对算法感兴趣的读者、机器学习领域的从业人员及科研人员阅读。","price":"69"},{"rating":{"max":10,"numRaters":74,"average":"6.7","min":0},"subtitle":"","author":["刘少山","唐洁","吴双","李力耘"],"pubdate":"2017-5","tags":[{"count":59,"name":"无人驾驶","title":"无人驾驶"},{"count":29,"name":"人工智能","title":"人工智能"},{"count":14,"name":"机器学习","title":"机器学习"},{"count":11,"name":"深度学习","title":"深度学习"},{"count":8,"name":"强化学习","title":"强化学习"},{"count":7,"name":"自动驾驶","title":"自动驾驶"},{"count":5,"name":"科学","title":"科学"},{"count":5,"name":"机器人","title":"机器人"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29444407.jpg","binding":"平装","translator":[],"catalog":"1    无人车：正在开始的未来\t1\n1.1  正在走来的无人驾驶\t2\n1.2  自动驾驶的分级\t4\n1.3  无人驾驶系统简介\t7\n1.4  序幕刚启\t18\n1.5  参考资料\t18\n2    光学雷达在无人驾驶技术中的应用\t21\n2.1  无人驾驶技术简介\t21\n2.2  光学雷达基础知识\t22\n2.3  LiDAR在无人驾驶技术中的应用领域\t24\n2.4  LiDAR技术面临的挑战\t26\n2.5  展望未来\t28\n2.6  参考资料\t28\n3    GPS及惯性传感器在无人驾驶中的应用\t30\n3.1  无人驾驶定位技术\t30\n3.2  GPS简介\t31\n3.3  惯性传感器简介\t34\n3.4  GPS和惯性传感器的融合\t36\n3.5  结论\t37\n3.6  参考资料\t38\n4    基于计算机视觉的无人驾驶感知系统\t39\n4.1  无人驾驶的感知\t39\n4.3  计算机视觉能帮助无人车辆解决的问题\t42\n4.4  Optical Flow和立体视觉\t43\n4.5  物体的识别与追踪\t45\n4.6  视觉里程计算法\t47\n4.7  结论\t48\n4.8  参考资料\t49\n5    卷积神经网络在无人驾驶中的应用\t50\n5.1  CNN简介\t50\n5.2  无人驾驶双目3D感知\t51\n5.3  无人驾驶物体检测\t54\n5.4  结论\t59\n5.5  参考资料\t59\n6    增强学习在无人驾驶中的应用\t61\n6.1  增强学习的简介\t61\n6.2  增强学习算法\t63\n6.3  使用增强学习帮助决策\t68\n6.4  无人驾驶的决策介绍\t70\n6.5  参考资料\t74\n7    无人驾驶的规划与控制\t75\n7.1  规划与控制简介\t75\n7.2  路由寻径\t77\n7.3  行为决策\t84\n7.4  动作规划\t93\n7.5  反馈控制\t102\n7.6  无人车规划控制结语\t105\n7.7  参考资料\t106\n8    基于ROS的无人驾驶系统\t108\n8.1  无人驾驶：多种技术的集成\t108\n8.2  机器人操作系统（ROS）简介\t110\n8.3  系统可靠性\t115\n8.4  系统通信性能提升\t116\n8.5  系统资源管理与安全性\t117\n8.6  结论\t118\n8.7  参考资料\t118\n9    无人驾驶的硬件平台\t120\n9.1  无人驾驶：复杂系统\t120\n9.2  传感器平台\t121\n9.3  计算平台\t140\n9.4  控制平台\t150\n9.5  结论\t157\n9.6  参考资料\t158\n10    无人驾驶系统安全\t160\n10.1  针对无人驾驶的安全威胁\t160\n10.2  无人驾驶传感器的安全\t161\n10.3  无人驾驶操作系统的安全\t162\n10.4  无人驾驶控制系统的安全\t163\n10.5  车联网通信系统的安全性\t165\n10.6  安全模型校验方法\t168\n10.7  参考资料\t169\n11    基于Spark与ROS的分布式无人驾驶模拟平台\t171\n11.1  无人驾驶模拟技术\t171\n11.2  基于ROS的无人驾驶模拟器\t173\n11.3  基于Spark的分布式的模拟平台\t175\n11.4  结论\t178\n11.5  参考资料\t178\n12    无人驾驶中的高精地图\t180\n12.1  电子地图分类\t180\n12.2  高精地图的特点\t183\n12.3  高精地图的生产\t185\n12.4  无人驾驶场景中的应用\t188\n12.5  高精地图的现状与结论\t190\n12.6  参考资料\t191\n13    无人驾驶的未来\t192\n13.1  无人驾驶的商业前景\t192\n13.2  无人驾驶汽车面临的障碍\t194\n13.3  无人驾驶产业\t198\n13.4  全球化下的无人驾驶\t203\n13.5  无人驾驶发展对策\t205\n13.6  可预见的未来\t207\n13.7  参考资料\t208","pages":"220","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29444407.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29444407.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29444407.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27038410\/","id":"27038410","publisher":"电子工业出版社","isbn10":"7121313553","isbn13":"9787121313554","title":"第一本无人驾驶技术书","url":"https:\/\/api.douban.com\/v2\/book\/27038410","alt_title":"","author_intro":"刘少山，PerceptIn联合创始人。加州大学欧文分校计算机博士。现在PerceptIn主要专注于机器人的核心SLAM与深度学习技术，以及其在智能硬件上的实现。在创立PerceptIn之前，在百度美国研发中心主要专注于百度无人车系统架构与产品化、深度学习，以及异构计算平台的架构与开发。\n唐洁，华南理工大学计算机科学与工程学院副教授。唐洁博士现主要从事面向无人驾驶和机器人的大数据计算与存储平台、面向人工智能的计算体系架构、面向机器视觉的嵌入式系统研究。\n吴双，依图科技研究科学家，依图硅谷研究院负责人。原百度研究院硅谷人工智能实验室资深研究科学家，原百度美国研发中心高级架构师。美国南加州大学物理博士，加州大学洛杉矶分校博士后，研究方向包括计算机和生物视觉，互联网广告算法和语音识别，曾在NIPS等国际会议中发表文章。\n李力耘，百度美国研发中心无人驾驶高级架构师。本科毕业于清华大学电子工程系，后获得美国纽约大学计算机专业博士学位。加入百度后从事移动推荐、转换广告、图片变形、无人车决策规划等多个项目。目前在百度无人车部门负责无人车行为预测方向的系统架构及算法优化。拥有多项国际专利，其中已递交三十余项无人车决策预测相关专利申请。","summary":"无人驾驶是一个复杂的系统，涉及的技术点种类多且跨度大，入门者常常不知从何入手。《第一本无人驾驶技术书》首先宏观地呈现了无人驾驶的整体技术架构，概述了无人驾驶中涉及的各个技术点。在读者对无人驾驶技术有了宏观认识后，《第一本无人驾驶技术书》深入浅出地讲解了无人驾驶定位导航、感知、决策与控制等算法，深度学习在无人驾驶中的应用，无人驾驶系统软件和硬件平台，无人驾驶安全及无人驾驶云平台等多个主要技术点。《第一本无人驾驶技术书》的作者都是无人驾驶行业的从业者与研究人员，有着多年无人驾驶及人工智能技术的实战经验。\n《第一本无人驾驶技术书》从实用的角度出发，以期帮助对无人驾驶技术感兴趣的从业者与相关人士实现对无人驾驶行业的快速入门，以及对无人驾驶技术的深度理解与应用实践。","price":"59"},{"rating":{"max":10,"numRaters":32,"average":"8.0","min":0},"subtitle":"","author":["任柳江"],"pubdate":"2017-4","tags":[{"count":23,"name":"数据分析","title":"数据分析"},{"count":22,"name":"机器学习","title":"机器学习"},{"count":19,"name":"大数据","title":"大数据"},{"count":15,"name":"全栈","title":"全栈"},{"count":14,"name":"python","title":"python"},{"count":13,"name":"数据挖掘","title":"数据挖掘"},{"count":8,"name":"深度学习","title":"深度学习"},{"count":6,"name":"Linux","title":"Linux"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29402668.jpg","binding":"平装","translator":[],"catalog":"前言　自强不息，厚德载物 \/ XIX\n0x1　Linux，自由之光 \/ 001\n0x10　Linux，你是我的眼 \/ 001\n0x11　Linux 基础，从零开始 \/ 003\n01 Linux 之门 \/ 003\n02 文件操作 \/ 004\n03 权限管理 \/ 006\n04 软件安装 \/ 008\n05 实战经验 \/ 010\n0x12　Sed 与Grep，文本处理 \/ 010\n01 文本工具 \/ 010\n02 grep 的使用 \/ 011\n03 grep 家族 \/ 013\n04 sed 的使用 \/ 014\n05 综合案例 \/ 016\n0x13　数据工程，必备Shell \/ 018\n01 Shell 分析 \/ 018\n02 文件探索 \/ 019\n03 内容探索 \/ 020\n04 交差并补 \/ 020\n05 其他常用的命令 \/ 021\n06 批量操作 \/ 022\n07 结语 \/ 025\n0x14　Shell 快捷键，Emacs 之门 \/ 025\n01 提高效率 \/ 025\n02 光标移动 \/ 026\n03 文本编辑 \/ 027\n04 命令搜索 \/ 028\n05 Emacs 入门 \/ 029\n06 Emacs 思维 \/ 031\n0x15　缘起Linux，一入Mac 误终身 \/ 032\n01 开源生万物 \/ 032\n02 有钱就换Mac \/ 032\n03 程序员需求 \/ 033\n04 非程序员需求 \/ 034\n05 一入Mac 误终身 \/ 035\n0x16　大成就者，集群安装 \/ 036\n01 离线安装 \/ 036\n02 Host 与SSH 配置 \/ 037\n03 sudo 与JDK 环境 \/ 039\n04 准备Hadoop 包 \/ 040\n05 开启HTTP 与配置源 \/ 041\n06 安装ambari-server \/ 041\n07 后续服务安装 \/ 042\n08 结语 \/ 044\n0x2　Python，道法自然 \/ 045\n0x20　Python，灵犀一指 \/ 045\n0x21　Python 基础，兴趣为王 \/ 047\n01 第一语言 \/ 047\n02 数据结构 \/ 047\n03 文件读写 \/ 049\n04 使用模块 \/ 050\n05 函数式编程 \/ 052\n06 一道面试题 \/ 053\n07 兴趣驱动 \/ 055\n0x22　喜新厌旧，2 迁移3 \/ 056\n01 新旧交替 \/ 056\n02 基础变化 \/ 057\n03 编码问题 \/ 058\n04 其他变化 \/ 058\n05 2to3 脚本 \/ 060\n06 PySpark 配置 \/ 061\n07 喜新厌旧 \/ 062\n0x23　Anaconda，IPython \/ 062\n01 Anaconda \/ 062\n02 安装与配置 \/ 063\n03 pip 与源 \/ 064\n04 IPython 与Jupyter \/ 065\n05 结语 \/ 067\n0x24　美不胜收，Python 工具 \/ 067\n01 缘起 \/ 067\n02 调试与开发 \/ 068\n03 排版与格式化 \/ 070\n04 辅助工具 \/ 072\n05 实用推荐 \/ 074\n0x25　numpy 基础，线性代数 \/ 075\n01 numpy 的使用 \/ 075\n02 索引与切片 \/ 076\n03 变形与统计 \/ 078\n04 矩阵运算 \/ 080\n05 实用方法 \/ 083\n06 结语 \/ 085\n0x26　numpy 实战，PCA 降维 \/ 085\n01 PCA 介绍 \/ 085\n02 数据均值化 \/ 086\n03 协方差矩阵 \/ 087\n04 特征值与向量 \/ 088\n05 数据映射降维 \/ 089\n06 sklearn 实现 \/ 090\n0x3　大数据，其大无外 \/ 093\n0x30　太大数据，极生两仪 \/ 093\n0x31　神象住世，Hadoop \/ 095\n01 Hadoop \/ 095\n02 HDFS \/ 096\n03 角色与管理 \/ 097\n04 文件操作 \/ 098\n05 结语 \/ 100\n0x32　分治之美，MapReduce \/ 100\n01 map 与reduce 函数 \/ 100\n02 分而治之 \/ 102\n03 Hello,World \/ 103\n04 Streaming 接口 \/ 105\n0x33　Hive 基础，蜂巢与仓库 \/ 106\n01 引言 \/ 106\n02 Hive 接口 \/ 107\n03 分区建表 \/ 108\n04 分区机制 \/ 110\n05 数据导入\/ 导出 \/ 111\n06 Hive-QL \/ 112\n07 结语 \/ 114\n0x34　Hive 深入，实战经验 \/ 115\n01 排序与分布式 \/ 115\n02 多表插入与mapjoin \/ 116\n03 加载map-reduce 脚本 \/ 117\n04 使用第三方UDF \/ 119\n05 实战经验 \/ 120\n06 生成唯一ID \/ 121\n0x35　HBase 库，实时业务 \/ 122\n01 理论基础 \/ 122\n02 Shell 操作 \/ 123\n03 关联Hive 表 \/ 126\n04 数据导入 \/ 128\n05 实用经验 \/ 130\n0x36　SQL 与NoSQL，Sqoop 为媒 \/ 130\n01 SQL 与NOSQL \/ 130\n02 从MySQL 导入HDFS \/ 131\n03 增量导入 \/ 134\n04 映射到Hive \/ 135\n05 导入Hive 表 \/ 136\n06 从HDFS 导出到MySQL \/ 137\n07 从Hive 导出到MySQL \/ 138\n0x4　数据分析，见微知著 \/ 141\n0x40　大数据分析，鲁班为祖师 \/ 141\n0x41　SQL 技能，必备MySQL \/ 143\n01 SQL 工具 \/ 143\n02 基础操作 \/ 144\n03 查询套路 \/ 145\n04 join 查询 \/ 146\n05 union 与exists \/ 149\n06 实战经验 \/ 151\n0x42　快刀awk，斩乱数据 \/ 152\n01 快刀 \/ 152\n02 一二三要点 \/ 152\n03 一个示例 \/ 154\n04 应用与统计 \/ 154\n05 斩乱麻 \/ 156\n0x43　Pandas，数据之框 \/ 157\n01 数据为框 \/ 157\n02 加载数据 \/ 158\n03 行列索引 \/ 159\n04 行列操作 \/ 161\n05 合并聚合 \/ 163\n06 迭代数据 \/ 164\n07 结语 \/ 165\n0x44　Zeppelin，一统江湖 \/ 166\n01 心潮澎湃 \/ 166\n02 基本使用 \/ 168\n03 SQL 与可视化 \/ 169\n04 安装Zeppelin \/ 172\n05 配置Zeppelin \/ 173\n06 数据安全 \/ 174\n07 使用心得 \/ 176\n0x45　数据分组，聚合窗口 \/ 177\n01 MySQL 聚合 \/ 177\n02 Spark 聚合 \/ 178\n03 非聚合字段 \/ 179\n04 Hive 实现 \/ 180\n05 group_concat \/ 181\n06 Hive 窗口函数 \/ 183\n07 DataFrame 窗口 \/ 184\n08 结语 \/ 185\n0x46　全栈分析，六层内功 \/ 186\n01 引言 \/ 186\n02 MySQL 版本 \/ 186\n03 awk 版本 \/ 187\n04 Python 版本 \/ 188\n05 Hive 版本 \/ 189\n06 map-reduce 版本 \/ 190\n07 Spark 版本 \/ 190\n08 结语 \/ 191\n0x5　机器学习，人类失控 \/ 193\n0x50　机器学习，琅琊论断 \/ 193\n0x51　酸酸甜甜，Orange \/ 195\n01 可视化学习 \/ 195\n02 数据探索 \/ 196\n03 模型与评估 \/ 199\n04 组件介绍 \/ 200\n05 与Python 进行整合 \/ 202\n06 结语 \/ 204\n0x52　sklearn，机器学习 \/ 205\n01 sklearn 介绍 \/ 205\n02 数据预处理 \/ 206\n03 建模与预测 \/ 207\n04 模型评估 \/ 209\n05 模型持久化 \/ 210\n06 三个层次 \/ 210\n0x53　特征转换，量纲伸缩 \/ 211\n01 特征工程 \/ 211\n02 独热编码 \/ 212\n03 sklearn 示例 \/ 213\n04 标准化与归一化 \/ 215\n05 sklearn 与Spark 实现 \/ 216\n06 结语 \/ 219\n0x54　描述统计，基础指标 \/ 220\n01 描述性统计 \/ 220\n02 Pandas 实现 \/ 222\n03 方差与协方差 \/ 223\n04 Spark-RDD 实现 \/ 224\n05 DataFrame 实现 \/ 226\n06 Spark-SQL 实现 \/ 227\n07 结语 \/ 227\n0x55　模型评估，交叉验证 \/ 228\n01 测试与训练 \/ 228\n02 评价指标 \/ 229\n03 交叉验证 \/ 231\n04 验证数据 \/ 232\n05 OOB 数据 \/ 233\n0x56　文本特征，词袋模型 \/ 234\n01 自然语言 \/ 234\n02 中文分词 \/ 235\n03 词袋模型 \/ 236\n04 词频统计 \/ 237\n05 TF-IDF \/ 238\n06 结语 \/ 239\n0x6　算法预测，占天卜地 \/ 241\n0x60　命由己做，福自己求 \/ 241\n0x61　近朱者赤，相亲kNN \/ 243\n01 朴素的思想 \/ 243\n02 算法介绍 \/ 243\n03 分类与回归 \/ 244\n04 k 与半径 \/ 245\n05 优化计算 \/ 246\n06 实例应用 \/ 247\n0x62　物以类聚，Kmeans \/ 248\n01 算法描述 \/ 248\n02 建立模型 \/ 249\n03 理解模型 \/ 251\n04 距离与相似性 \/ 252\n05 降维与可视化 \/ 253\n06 无监督学习 \/ 255\n0x63　很傻很天真，朴素贝叶斯 \/ 257\n01 朴素思想 \/ 257\n02 概率公式 \/ 257\n03 三种实现 \/ 258\n04 sklearn 示例 \/ 260\n05 朴素却不傻 \/ 262\n0x64　菩提之树，决策姻缘 \/ 263\n01 缘起 \/ 263\n02 Orange 演示 \/ 264\n03 scikit-learn 模拟 \/ 266\n04 熵与基尼指数 \/ 267\n05 决策过程分析 \/ 268\n06 Spark 模拟 \/ 270\n07 结语 \/ 271\n0x65　随机之美，随机森林 \/ 271\n01 树与森林 \/ 271\n02 处处随机 \/ 273\n03 sklearn 示例 \/ 274\n04 MLlib 示例 \/ 275\n05 特点与应用 \/ 276\n0x66　自编码器，深度之门 \/ 277\n01 深度学习 \/ 277\n02 特征学习 \/ 278\n03 自动编码器 \/ 280\n04 Keras 代码 \/ 282\n05 抗噪编码器 \/ 283\n0x7　Spark，唯快不破 \/ 285\n0x70　人生苦短，快用Spark \/ 285\n0x71　PySpark 之门，强者联盟 \/ 287\n01 全栈框架 \/ 287\n02 环境搭建 \/ 288\n03 分布式部署 \/ 289\n04 示例分析 \/ 290\n05 两类算子 \/ 292\n06 map 与reduce \/ 293\n07 AMPLab 的野心 \/ 294\n0x72　RDD 算子，计算之魂 \/ 295\n01 算子之道 \/ 295\n02 获取数据 \/ 296\n03 过滤与排序 \/ 297\n04 聚合数据 \/ 298\n05 join 连接 \/ 299\n06 union 与zip \/ 300\n07 读写文件 \/ 301\n08 结语 \/ 303\n0x73　分布式SQL，蝶恋飞舞 \/ 304\n01 SQL 工具 \/ 304\n02 命令行CLI \/ 304\n03 读Hive 数据 \/ 305\n04 将结果写入Hive \/ 306\n05 读写MySQL 数据 \/ 307\n06 读写三种文件 \/ 308\n0x74　DataFrame，三角之恋 \/ 310\n01 DataFrame \/ 310\n02 生成数据框 \/ 311\n03 合并与join \/ 313\n04 select 操作 \/ 314\n05 SQL 操作 \/ 315\n06 自定义UDF \/ 316\n07 三角之恋 \/ 318\n0x75　神器之父，Scala 入世 \/ 319\n01 Spark 与Scala \/ 319\n02 Scala REPL \/ 320\n03 编译Scala \/ 321\n04 sbt 编译 \/ 322\n05 示例分析 \/ 323\n06 编译提交 \/ 325\n0x76　机器之心，ML 套路 \/ 326\n01 城市套路深 \/ 326\n02 算法与特征工程 \/ 327\n03 管道工作流 \/ 328\n04 OneHotEncoder 示例 \/ 329\n05 ML 回归实战 \/ 331\n06 特征处理与算法 \/ 332\n07 拟合与评估 \/ 334\n0x8　数据科学，全栈智慧 \/ 337\n0x80　才高八斗，共分天下 \/ 337\n0x81　自学数据，神蟒领舞 \/ 339\n01 机器学习 \/ 339\n02 语言领域 \/ 339\n03 Python 数据生态 \/ 340\n04 相关资料 \/ 341\n05 书籍推荐 \/ 342\n06 性感的职业 \/ 343\n0x82　数据科学，七大技能 \/ 343\n01 七大技能 \/ 343\n02 SQL 与NoSQL 技能 \/ 344\n03 Linux 工具集 \/ 344\n04 Python 或者R 语言生态 \/ 345\n05 Hadoop 与Spark 生态 \/ 345\n06 概率、统计与线性代数 \/ 346\n07 机器学习与深度学习 \/ 346\n08 业务及杂项 \/ 347\n09 结语 \/ 347\n0x83　大无所大，生态框架 \/ 348\n01 计算生态 \/ 348\n02 离线计算 \/ 348\n03 交互分析 \/ 349\n04 实时处理 \/ 350\n05 算法挖掘 \/ 351\n06 发行版本 \/ 352\n07 其他工具 \/ 353\n0x84　集体智慧，失控哲学 \/ 354\n01 数据是宝 \/ 354\n02 一分为二 \/ 355\n03 回归统一 \/ 356\n04 聚少成多 \/ 356\n05 你中有我 \/ 357\n06 从小看大 \/ 358\n07 大事化小 \/ 358\n08 少即是多 \/ 359\n0x85　一技之长，一生之用 \/ 359\n01 一技之长 \/ 359\n02 数据分析相关 \/ 360\n03 Python 相关 \/ 360\n04 Hadoop 相关 \/ 361\n05 Spark 相关 \/ 361\n06 模型相关 \/ 362\n07 算法相关 \/ 362\n08 一生之用 \/ 363\n0x86 知识作谱，数据为栈 \/ 363\n01 知识作谱 \/ 363\n02 理论基础 \/ 363\n03 Python\/R 编程 \/ 364\n04 分析与可视化 \/ 365\n05 大数据 \/ 365\n06 ETL 与特征工程 \/ 366\n07 机器学习与深度学习 \/ 366\n08 工具与库 \/ 367\n09 全栈为用 \/ 367","pages":"368","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29402668.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29402668.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29402668.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26998034\/","id":"26998034","publisher":"电子工业出版社","isbn10":"712130905X","isbn13":"9787121309052","title":"全栈数据之门","url":"https:\/\/api.douban.com\/v2\/book\/26998034","alt_title":"","author_intro":"","summary":"《全栈数据之门》以数据分析领域最热的Python语言为主要线索，介绍了数据分析库numpy、Pandas与机器学习库scikit-learn，使用了可视化环境Orange 3来理解算法的一些细节。对于机器学习，既有常用算法kNN与Kmeans的应用，决策树与随机森林的实战，还涉及常用特征工程与深度学习中的自动编程器。在大数据Hadoop与Hive环境的基础之上，使用Spark的ML\/MLlib库集成了前面的各部分内容，让分布式机器学习更容易。大量的工具与技能实战的介绍将各部分融合成一个全栈的数据科学内容。\n《全栈数据之门》不是从入门到精通地介绍某一种技术，可以把《全栈数据之门》当成一本技术文集，内容定位于数据科学的全栈基础入门，全部内容来自当前业界最实用的技能，有非常基础的，也有比较深入的，有些甚至需要深入领悟才能理解。\n《全栈数据之门》适用于任何想在数据领域有所作为的人，包括学生、爱好者、在职人员与科研工作者。无论想从事数据分析、数据工程、数据挖掘或者机器学习，或许都能在书中找到一些之前没有接触过的内容。","price":"79"},{"rating":{"max":10,"numRaters":82,"average":"5.5","min":0},"subtitle":"","author":["李嘉璇"],"pubdate":"2017-6-1","tags":[{"count":37,"name":"TensorFlow","title":"TensorFlow"},{"count":26,"name":"机器学习","title":"机器学习"},{"count":15,"name":"粗制滥造","title":"粗制滥造"},{"count":14,"name":"深度学习","title":"深度学习"},{"count":11,"name":"内容浅显","title":"内容浅显"},{"count":9,"name":"人工智能","title":"人工智能"},{"count":7,"name":"编程","title":"编程"},{"count":5,"name":"AI","title":"AI"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475322.jpg","binding":"平装","translator":[],"catalog":"第一篇　基础篇\n第1章　人工智能概述 2\n1.1　什么是人工智能 2\n1.2　什么是深度学习 5\n1.3　深度学习的入门方法 7\n1.4　什么是TensorFlow 11\n1.5　为什么要学TensorFlow 12\n1.5.1　TensorFlow的特性 14\n1.5.2　使用TensorFlow的公司 15\n1.5.3　TensorFlow的发展 16\n1.6　机器学习的相关赛事 16\n1.6.1　ImageNet的ILSVRC 17\n1.6.2　Kaggle 18\n1.6.3　天池大数据竞赛 19\n1.7　国内的人工智能公司 20\n1.8　小结 22\n第2章　TensorFlow环境的准备 23\n2.1　下载TensorFlow 1.1.0 23\n2.2　基于pip的安装 23\n2.2.1　Mac OS环境准备 24\n2.2.2　Ubuntu\/Linux环境准备 25\n2.2.3　Windows环境准备 25\n2.3　基于Java的安装 28\n2.4　从源代码安装 29\n2.5　依赖的其他模块 30\n2.5.1　numpy 30\n2.5.2　matplotlib 31\n2.5.3　jupyter 31\n2.5.4　scikit-image 32\n2.5.5　librosa 32\n2.5.6　nltk 32\n2.5.7　keras 33\n2.5.8　tflearn 33\n2.6　小结 33\n第3章　可视化TensorFlow 34\n3.1　PlayGround 34\n3.1.1　数据 35\n3.1.2　特征 36\n3.1.3　隐藏层 36\n3.1.4　输出 37\n3.2　TensorBoard 39\n3.2.1　SCALARS面板 40\n3.2.2　IMAGES面板 41\n3.2.3　AUDIO面板 42\n3.2.4　GRAPHS面板 42\n3.2.5　DISTRIBUTIONS面板 43\n3.2.6　HISTOGRAMS面板 43\n3.2.7　EMBEDDINGS面板 44\n3.3　可视化的例子 44\n3.3.1　降维分析 44\n3.3.2　嵌入投影仪 48\n3.4　小结 51\n第4章　TensorFlow基础知识 52\n4.1　系统架构 52\n4.2　设计理念 53\n4.3　编程模型 54\n4.3.1　边 56\n4.3.2　节点 57\n4.3.3　其他概念 57\n4.4　常用API 60\n4.4.1　图、操作和张量 60\n4.4.2　可视化 61\n4.5　变量作用域 62\n4.5.1　variable_scope示例 62\n4.5.2　name_scope示例 64\n4.6　批标准化 64\n4.6.1　方法 65\n4.6.2　优点 65\n4.6.3　示例 65\n4.7　神经元函数及优化方法 66\n4.7.1　激活函数 66\n4.7.2　卷积函数 69\n4.7.3　池化函数 72\n4.7.4　分类函数 73\n4.7.5　优化方法 74\n4.8　模型的存储与加载 79\n4.8.1　模型的存储与加载 79\n4.8.2　图的存储与加载 82\n4.9　队列和线程 82\n4.9.1　队列 82\n4.9.2　队列管理器 85\n4.9.3　线程和协调器 86\n4.10　加载数据 87\n4.10.1　预加载数据 87\n4.10.2　填充数据 87\n4.10.3　从文件读取数据 88\n4.11　实现一个自定义操作 92\n4.11.1　步骤 92\n4.11.2　最佳实践 93\n4.12　小结 101\n第5章　TensorFlow源代码解析 102\n5.1　TensorFlow的目录结构 102\n5.1.1　contirb 103\n5.1.2　core 104\n5.1.3　examples 105\n5.1.4　g3doc 105\n5.1.5　python 105\n5.1.6　tensorboard 105\n5.2　TensorFlow源代码的学习方法 106\n5.3　小结 108\n第6章　神经网络的发展及其TensorFlow实现 109\n6.1　卷积神经网络 109\n6.2　卷积神经网络发展 110\n6.2.1　网络加深 111\n6.2.2　增强卷积层的功能 115\n6.2.3　从分类任务到检测任务 120\n6.2.4　增加新的功能模块 121\n6.3　MNIST的AlexNet实现 121\n6.3.1　加载数据 121\n6.3.2　构建网络模型 122\n6.3.3　训练模型和评估模型 124\n6.4　循环神经网络 125\n6.5　循环神经网络发展 126\n6.5.1　增强隐藏层的功能 127\n6.5.2　双向化及加深网络 129\n6.6　TensorFlow Model Zoo 131\n6.7　其他研究进展 131\n6.7.1　强化学习 132\n6.7.2　深度森林 132\n6.7.3　深度学习与艺术 132\n6.8　小结 133\n第7章　TensorFlow的高级框架 134\n7.1　TFLearn 134\n7.1.1　加载数据 134\n7.1.2　构建网络模型 135\n7.1.3　训练模型 135\n7.2　Keras 135\n7.2.1　Keras的优点 136\n7.2.2　Keras的模型 136\n7.2.3　Keras的使用 137\n7.3　小结 141\n第二篇　实战篇\n第8章　第一个TensorFlow程序 144\n8.1　TensorFlow的运行方式 144\n8.1.1　生成及加载数据 144\n8.1.2　构建网络模型 145\n8.1.3　训练模型 145\n8.2　超参数的设定 146\n8.3　小结 147\n第9章　TensorFlow在MNIST中的应用 148\n9.1　MNIST数据集简介 148\n9.1.1　训练集的标记文件 148\n9.1.2　训练集的图片文件 149\n9.1.3　测试集的标记文件 149\n9.1.4　测试集的图片文件 150\n9.2　MNIST的分类问题 150\n9.2.1　加载数据 150\n9.2.2　构建回归模型 151\n9.2.3　训练模型 151\n9.2.4　评估模型 152\n9.3　训练过程的可视化 152\n9.4　MNIST的卷积神经网络 156\n9.4.1　加载数据 157\n9.4.2　构建模型 157\n9.4.3　训练模型和评估模型 159\n9.5　MNIST的循环神经网络 161\n9.5.1　加载数据 161\n9.5.2　构建模型 161\n9.5.3 训练数据及评估模型 163\n9.6　MNIST的无监督学习 164\n9.6.1　自编码网络 164\n9.6.2　TensorFlow的自编码网络实现 165\n9.7　小结 169\n第10章　人脸识别 170\n10.1　人脸识别简介 170\n10.2　人脸识别的技术流程 171\n10.2.1　人脸图像采集及检测 171\n10.2.2　人脸图像预处理 171\n10.2.3　人脸图像特征提取 171\n10.2.4　人脸图像匹配与识别 172\n10.3　人脸识别的分类 172\n10.3.1　人脸检测 172\n10.3.2　人脸关键点检测 173\n10.3.3　人脸验证 174\n10.3.4　人脸属性检测 174\n10.4　人脸检测 175\n10.4.1　LFW数据集 175\n10.4.2　数据预处理 175\n10.4.3　进行检测 176\n10.5　性别和年龄识别 178\n10.5.1　数据预处理 179\n10.5.2　构建模型 181\n10.5.3　训练模型 182\n10.5.4　验证模型 184\n10.6　小结 185\n第11章　自然语言处理 186\n11.1　模型的选择 186\n11.2　英文数字语音识别 187\n11.2.1　定义输入数据并预处理数据 188\n11.2.2　定义网络模型 188\n11.2.3　训练模型 188\n11.2.4　预测模型 189\n11.3　智能聊天机器人 189\n11.3.1　原理 190\n11.3.2　最佳实践 191\n11.4　小结 200\n第12章　图像与语音的结合 201\n12.1　看图说话模型 201\n12.1.1　原理 202\n12.1.2　最佳实践 203\n12.2　小结 205\n第13章　生成式对抗网络 206\n13.1　生成式对抗网络的原理 206\n13.2　生成式对抗网络的应用 207\n13.3　生成式对抗网络的实现 208\n13.4　生成式对抗网络的改进 214\n13.5　小结 214\n第三篇　提高篇\n第14章　分布式TensorFlow 216\n14.1　分布式原理 216\n14.1.1　单机多卡和分布式 216\n14.1.2　分布式部署方式 217\n14.2　分布式架构 218\n14.2.1　客户端、主节点和工作节点的关系 218\n14.2.2　客户端、主节点和工作节点的交互过程 220\n14.3　分布式模式 221\n14.3.1　数据并行 221\n14.3.2　同步更新和异步更新 222\n14.3.3　模型并行 224\n14.4　分布式API 225\n14.5　分布式训练代码框架 226\n14.6　分布式最佳实践 227\n14.7　小结 235\n第15章　TensorFlow线性代数编译框架XLA 236\n15.1　XLA的优势 236\n15.2　XLA的工作原理 237\n15.3　JIT编译方式 238\n15.3.1　打开JIT编译 238\n15.3.2　将操作符放在XLA设备上 238\n15.4　JIT编译在MNIST上的实现 239\n15.5　小结 240\n第16章　TensorFlow Debugger 241\n16.1　Debugger的使用示例 241\n16.2　远程调试方法 245\n16.3　小结 245\n第17章　TensorFlow和Kubernetes结合 246\n17.1　为什么需要Kubernetes 246\n17.2　分布式TensorFlow在Kubernetes中的运行 247\n17.2.1　部署及运行 247\n17.2.2　其他应用 253\n17.3　小结 254\n第18章　TensorFlowOnSpark 255\n18.1　TensorFlowOnSpark的架构 255\n18.2　TensorFlowOnSpark在MNIST上的实践 257\n18.3　小结 261\n第19章　TensorFlow移动端应用 262\n19.1　移动端应用原理 262\n19.1.1　量化 263\n19.1.2　优化矩阵乘法运算 266\n19.2　iOS系统实践 266\n19.2.1　环境准备 266\n19.2.2　编译演示程序并运行 267\n19.2.3　自定义模型的编译及运行 269\n19.3　Android系统实践 273\n19.3.1　环境准备 274\n19.3.2　编译演示程序并运行 275\n19.3.3　自定义模型的编译及运行 277\n19.4　树莓派实践 278\n19.5　小结 278\n第20章　TensorFlow的其他特性 279\n20.1　TensorFlow Serving 279\n20.2　TensorFlow Flod 280\n20.3　TensorFlow计算加速 281\n20.3.1　CPU加速 281\n20.3.2　TPU加速和FPGA加速 282\n20.4　小结 283\n第21章　机器学习的评测体系 284\n21.1　人脸识别的性能指标 284\n21.2　聊天机器人的性能指标 284\n21.3　机器翻译的评价方法 286\n21.3.1　BLEU 286\n21.3.2　METEOR 287\n21.4　常用的通用评价指标 287\n21.4.1　ROC和AUC 288\n21.4.2　AP和mAP 288\n21.5　小结 288\n附录A　公开数据集 289\n附录B　项目管理经验小谈 292","pages":"316","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29475322.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29475322.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475322.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27055214\/","id":"27055214","publisher":"人民邮电出版社","isbn10":"7115456135","isbn13":"9787115456137","title":"TensorFlow技术解析与实战","url":"https:\/\/api.douban.com\/v2\/book\/27055214","alt_title":"","author_intro":"李嘉璇，创建TensorFlow交流社区，活跃于国内各大技术社区，知乎编程问题回答者。致力于人工智能的研究，对深度学习框架的架构、源码分析及在不同领域的应用有浓厚兴趣。有过上百篇论文阅读和深度学习经验，处理图像、社交文本数据情感分析、数据挖掘经验，参与过基于深度学习的自动驾驶二维感知系统Hackathon竞赛，曾任职百度研发工程师。","summary":"TensorFlow 是谷歌公司开发的深度学习框架，也是目前深度学习的主流框架之一。本书从深度学习的基础讲起，深入TensorFlow框架原理、模型构建、源代码分析和网络实现等各个方面。全书分为基础篇、实战篇和提高篇三部分。基础篇讲解人工智能的入门知识，深度学习的方法，TensorFlow的基础原理、系统架构、设计理念、编程模型、常用API、批标准化、模型的存储与加载、队列与线程，实现一个自定义操作，并进行TensorFlow源代码解析，介绍卷积神经网络（CNN）和循环神经网络（RNN）的演化发展及其TensorFlow实现、TensorFlow的高级框架等知识；实战篇讲解如何用TensorFlow写一个神经网络程序并介绍TensorFlow实现各种网络（CNN、RNN和自编码网络等）并对MNIST数据集进行训练，讲解TensorFlow在人脸识别、自然语言处理、图像和语音的结合、生成式对抗网络等方面的应用；提高篇讲解TensorFlow的分布式原理、架构、模式、API，还会介绍TensorFlow XLA、TensorFlow Debugger、TensorFlow和Kubernetes结合、TensorFlowOnSpark、TensorFlow移动端应用，以及TensorFlow Serving、TensorFlow Fold和TensorFlow计算加速等其他特性。最后，附录中列出一些可供参考的公开数据集，并结合作者的项目经验介绍项目管理的一些建议。","price":"79.00元"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["Sam Abrahams","Danijar Hafner","Erik Erwitt"],"pubdate":"2016-11-10","tags":[{"count":16,"name":"机器学习","title":"机器学习"},{"count":12,"name":"tensorflow","title":"tensorflow"},{"count":6,"name":"深度学习","title":"深度学习"},{"count":5,"name":"Tensorflow","title":"Tensorflow"},{"count":3,"name":"计算机","title":"计算机"},{"count":3,"name":"大数据","title":"大数据"},{"count":2,"name":"神經網絡","title":"神經網絡"},{"count":1,"name":"機器學習","title":"機器學習"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29179612.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"298","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29179612.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29179612.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29179612.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26923648\/","id":"26923648","publisher":"Bleeding Edge Press","isbn10":"1939902452","isbn13":"9781939902450","title":"TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms","url":"https:\/\/api.douban.com\/v2\/book\/26923648","alt_title":"","author_intro":"","summary":"TensorFlow, a popular library for machine learning, embraces the innovation and community-engagement of open source, but has the support, guidance, and stability of a large corporation. Because of its multitude of strengths, TensorFlow is appropriate for individuals and businesses ranging from startups to companies as large as, well, Google. TensorFlow is currently being used for natural language processing, artificial intelligence, computer vision, and predictive analytics. TensorFlow, open  sourced to the public by Google in November 2015, was made to be flexible, efficient, extensible, and portable. Computers of any shape and size can run it, from smartphones all the way up to huge computing clusters.  This book is for anyone who knows a little machine learning (or not) and who has heard about TensorFlow, but found the documentation too daunting to approach. It introduces the TensorFlow framework and the underlying machine learning concepts that are important to harness machine intelligence. After reading this book, you should have a deep understanding of the core TensorFlow API.","price":"USD 29.99"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["Francois Chollet","J. J. Allaire"],"pubdate":"2018-3-30","tags":[{"count":14,"name":"R","title":"R"},{"count":7,"name":"机器学习","title":"机器学习"},{"count":6,"name":"深度学习","title":"深度学习"},{"count":3,"name":"Keras","title":"Keras"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"statistics","title":"statistics"},{"count":1,"name":"MachineLearning","title":"MachineLearning"},{"count":1,"name":"ML","title":"ML"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29625177.jpg","binding":"Paperback","translator":[],"catalog":"PART 1 - FUNDAMENTALS OF DEEP LEARNING\nWhat is deep learning?\nBefore we begin: the mathematical building blocks of neural networks\nGetting started with neural networks\nFundamentals of machine learning\nPART 2 - DEEP LEARNING IN PRACTICE\nDeep learning for computer vision\nDeep learning for text and sequences\nAdvanced deep-learning best practices\nGenerative deep learning\nConclusions","pages":"325","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29625177.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29625177.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29625177.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27594587\/","id":"27594587","publisher":"Manning Publications","isbn10":"161729554X","isbn13":"9781617295546","title":"Deep Learning with R","url":"https:\/\/api.douban.com\/v2\/book\/27594587","alt_title":"","author_intro":"François Chollet is a deep-learning researcher at Google and the author of the Keras library.\nJ.J. Allaire is the founder of RStudio and the author of the R interfaces to TensorFlow and Keras.","summary":"Deep Learning with R introduces the world of deep learning using the powerful Keras library and its R language interface. Initially written for Python as Deep Learning with Python by Keras creator and Google AI researcher François Chollet and adapted for R by RStudio founder J. J. Allaire, this book builds your understanding of deep learning through intuitive explanations and practical examples. You'll practice your new skills with R-based applications in computer vision, natural-language processing, and generative models.","price":"USD 49.99"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["Li Deng","Dong Yu"],"pubdate":"2014-6-12","tags":[{"count":7,"name":"深度学习","title":"深度学习"},{"count":7,"name":"机器学习","title":"机器学习"},{"count":4,"name":"计算机科学","title":"计算机科学"},{"count":3,"name":"自然语言处理","title":"自然语言处理"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":2,"name":"CS","title":"CS"},{"count":1,"name":"豆瓣","title":"豆瓣"},{"count":1,"name":"豆列","title":"豆列"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28033315.jpg","binding":"Paperback","translator":[],"catalog":"1. Introduction\n2. Some Historical Context of Deep Learning\n3. Three Classes of Deep Learning Networks\n4. Deep Autoencoders - Unsupervised Learning\n5. Pre-Trained Deep Neural Networks - A Hybrid\n6. Deep Stacking Networks and Variants - Supervised Learning\n7. Selected Applications in Speech and Audio Processing\n8. Selected Applications in Language Modeling and Natural Language Processing\n9. Selected Applications in Information Retrieval\n10. Selected Applications in Object Recognition and Computer Vision\n11. Selected Applications in Multimodal and Multi-task Learning\n12. Conclusion\nReferences","pages":"212","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28033315.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28033315.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28033315.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26350941\/","id":"26350941","publisher":"Now Publishers Inc","isbn10":"1601988141","isbn13":"9781601988140","title":"Deep Learning: Methods and Applications (Foundations and Trends(r) in Signal Processing)","url":"https:\/\/api.douban.com\/v2\/book\/26350941","alt_title":"","author_intro":"http:\/\/research.microsoft.com\/en-us\/people\/deng\/","summary":"This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.\nIn Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme.\nIn Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.","price":"USD 94.05"},{"rating":{"max":10,"numRaters":40,"average":"9.3","min":0},"subtitle":"","author":["张军平"],"pubdate":"2019-8-1","tags":[{"count":23,"name":"人工智能","title":"人工智能"},{"count":16,"name":"机器学习","title":"机器学习"},{"count":13,"name":"深度学习","title":"深度学习"},{"count":9,"name":"科普","title":"科普"},{"count":8,"name":"一名会唱歌的人工智能领域教授用心之作","title":"一名会唱歌的人工智能领域教授用心之作"},{"count":7,"name":"人工智能，科普","title":"人工智能，科普"},{"count":6,"name":"学习","title":"学习"},{"count":5,"name":"感知","title":"感知"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33439527.jpg","binding":"平装","translator":[],"catalog":"目录\n简单视觉错觉\/1\n1 视觉倒像 \/ 2\n2 颠倒的视界 \/ 7\n3 看不见的萨摩耶 \/ 13\n4 看得见的斑点狗 18\n5 火星人脸的阴影 \/ 23\n6 外国的月亮比较圆 \/ 32\n复杂视觉错觉\/39\n7 眼中的黎曼流形与距离错觉 \/ 40\n8 由粗到细、大范围优先的视觉 \/ 53\n9 抽象的颜色与高层认知 \/ 61\n10 自举的视觉与智能 \/ 70\n11 主观时间与运动错觉 79\n听觉、体感和语言\/89\n12 听觉错觉与语音、歌唱的智能分析 \/ 90\n13 视听错觉与无限音阶中的拓扑 \/ 101\n14 我思故我在？ \/ 114\n15 可塑与多义 \/ 122\n梦、顿悟与情感\/133\n16 庄周梦蝶与梦境学习 \/ 134\n17 灵光一闪与认知错觉 \/ 144\n18 情感与回忆错觉 \/ 153\n群体智能\/161\n19 群体的情感共鸣：AI 写歌，抓不住回忆 \/ 162\n20 群体智能与错觉 \/ 169\n总结\/181\n21 平衡：机器 vs 智能 \/ 182\n附录\/201\n附录一：深度学习，你就是那位 116 岁的长寿老奶奶！\/200\n附录二：童话（同化）世界的人工智能\/205\n参考文献 \/ 209\n图片来源 \/ 229","pages":"232","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33439527.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33439527.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33439527.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34667567\/","id":"34667567","publisher":"清华大学出版社","isbn10":"7302530424","isbn13":"9787302530428","title":"爱犯错的智能体","url":"https:\/\/api.douban.com\/v2\/book\/34667567","alt_title":"","author_intro":"张军平，复旦大学计算机科学技术学院，教授、博士生导师。主要研究方向是人工智能、机器学习、图像处理、生物认证及智能交通。曾于2007.9-2008.3年作为访问学者访问加州大学圣地亚哥分校，2014.8-2015.8年作为Research Associate受聘于宾夕法尼亚州立大学工作一年。曾主持3个国家自然科学基金、“863”项目和浦江人才计划项目。目前主持2018科技部重点专项“人-机器人智能融合技术”子课题和国家自然科学基金面上项目。中国自动化学会混合智能专业委员会副主任，中国计算机学会人工智能专业委员会委员，中国人工智能学会机器学习专业委员会常委。发表100余篇人工智能相关的高质量论文。包括IEEE TPAMI、TNNLS、ToC、TAC、TITS、TVCG等国际期刊和ICML、AAAI、ECCV等国际会议。","summary":"智能是什么？二十一世纪以来，人工智能有了飞速发展，在各行各业如互联网、安防、多媒体等都有了广泛且有效的应用。但这是否意味着人类就能制造超越人类自身的智能体呢？作者在科普性地介绍了人工智能前沿进展的同时，着重从犯错的角度，浅显易懂地剖析了智能体在视、听、语言等方面存在的各种错觉和犯错。并指出，理解我们很少关注的犯错，才有利于智能体的研究和发展。\n书中从分析生物人的感知功能谈起，以生动的例子介绍了人的视觉、听觉、触觉和体觉的解剖学知识及其基本原理。之后又进入人的感情世界，从人的情感、回忆、梦境，一直谈到灵感和错觉。在这个过程中，作者又适时讨论计算机在处理人的感知世界时会遇到的麻烦及处理原则，还不忘介绍一下讨论对象的数学背景。高斯、黎曼、莱布尼茨、庞加莱、爱因斯坦、图灵等大师级人物的名字频频出现。作者不费力地游弋于生命、计算机、数学、物理等几大学科之间，让读者经历一次目不暇接的跨学科科学旅游。再加上一个个有趣的故事，还有诗，画，歌，甚至还有乡愁！这样的科普，很新鲜、很解惑，又易于接受。","price":"55.00元"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"贝叶斯和优化方法","author":["Sergios Theodoridis"],"pubdate":"2017-4-1","tags":[{"count":19,"name":"机器学习","title":"机器学习"},{"count":9,"name":"贝叶斯","title":"贝叶斯"},{"count":6,"name":"人工智能","title":"人工智能"},{"count":5,"name":"计算机","title":"计算机"},{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"软件开发","title":"软件开发"},{"count":3,"name":"英文版","title":"英文版"},{"count":1,"name":"想读的书","title":"想读的书"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29482788.jpg","binding":"平装","translator":[],"catalog":"Contents\nPreface.iv\nAcknowledgments.vv\nNotation.vfivi\nCHAPTER 1 Introduction .1\n1.1 What Machine Learning is About1\n1.1.1 Classification.2\n1.1.2 Regression3\n1.2 Structure and a Road Map of the Book5\nReferences8\nCHAPTER 2 Probability and Stochastic Processes 9\n2.1 Introduction.10\n2.2 Probability and Random Variables.10\n2.2.1Probability11\n2.2.2Discrete Random Variables12\n2.2.3Continuous Random Variables14\n2.2.4Meanand Variance15\n2.2.5Transformation of Random Variables.17\n2.3 Examples of Distributions18\n2.3.1Discrete Variables18\n2.3.2Continuous Variables20\n2.4 Stochastic Processes29\n2.4.1First and Second Order Statistics.30\n2.4.2Stationarity and Ergodicity30\n2.4.3PowerSpectral Density33\n2.4.4Autoregressive Models38\n2.5 InformationTheory.41\n2.5.1Discrete Random Variables42\n2.5.2Continuous Random Variables45\n2.6 Stochastic Convergence48\nProblems49\nReferences51\nCHAPTER 3 Learning in Parametric Modeling: Basic Concepts and Directions 53\n3.1 Introduction.53\n3.2 Parameter Estimation: The Deterministic Point of View.54\n3.3 Linear Regression.57\n3.4 Classification60\n3.5 Biased Versus Unbiased Estimation.64\n3.5.1 Biased or Unbiased Estimation?65\n3.6 The Cramér-Rao Lower Bound67\n3.7 Suf?cient Statistic.70\n3.8 Regularization.72\n3.9 The Bias-Variance Dilemma.77\n3.9.1 Mean-Square Error Estimation77\n3.9.2 Bias-Variance Tradeoff78\n3.10 MaximumLikelihoodMethod.82\n3.10.1 Linear Regression: The Nonwhite Gaussian Noise Case84\n3.11 Bayesian Inference84\n3.11.1 The Maximum a Posteriori Probability Estimation Method.88\n3.12 Curse of Dimensionality89\n3.13 Validation.91\n3.14 Expected and Empirical Loss Functions.93\n3.15 Nonparametric Modeling and Estimation.95\nProblems.97\nReferences102\nCHAPTER4 Mean-quare Error Linear Estimation105\n4.1Introduction.105\n4.2Mean-Square Error Linear Estimation: The Normal Equations106\n4.2.1The Cost Function Surface107\n4.3A Geometric Viewpoint: Orthogonality Condition109\n4.4Extensionto Complex-Valued Variables111\n4.4.1Widely Linear Complex-Valued Estimation113\n4.4.2Optimizing with Respect to Complex-Valued Variables: Wirtinger Calculus116\n4.5Linear Filtering.118\n4.6MSE Linear Filtering: A Frequency Domain Point of View120\n4.7Some Typical Applications.124\n4.7.1Interference Cancellation124\n4.7.2System Identification125\n4.7.3Deconvolution: Channel Equalization126\n4.8Algorithmic Aspects: The Levinson and the Lattice-Ladder Algorithms132\n4.8.1The Lattice-Ladder Scheme.137\n4.9Mean-Square Error Estimation of Linear Models.140\n4.9.1The Gauss-Markov Theorem143\n4.9.2Constrained Linear Estimation:The Beamforming Case145\n4.10Time-Varying Statistics: Kalman Filtering148\nProblems.154\nReferences158\nCHAPTER 5 Stochastic Gradient Descent: The LMS Algorithm and its Family .161\n5.1 Introduction.162\n5.2 The Steepest Descent Method163\n5.3 Application to the Mean-Square Error Cost Function167\n5.3.1 The Complex-Valued Case175\n5.4 Stochastic Approximation177\n5.5 The Least-Mean-Squares Adaptive Algorithm179\n5.5.1 Convergence and Steady-State Performanceof the LMS in Stationary Environments.181\n5.5.2 Cumulative Loss Bounds186\n5.6 The Affine Projection Algorithm.188\n5.6.1 The Normalized LMS.193\n5.7 The Complex-Valued Case.194\n5.8 Relatives of the LMS.196\n5.9 Simulation Examples.199\n5.10 Adaptive Decision Feedback Equalization202\n5.11 The Linearly Constrained LMS204\n5.12 Tracking Performance of the LMS in Nonstationary Environments.206\n5.13 Distributed Learning:The Distributed LMS208\n5.13.1Cooperation Strategies.209\n5.13.2The Diffusion LMS211\n5.13.3 Convergence and Steady-State Performance: Some Highlights218\n5.13.4 Consensus-Based Distributed Schemes.220\n5.14 A Case Study:Target Localization222\n5.15 Some Concluding Remarks: Consensus Matrix.223\nProblems.224\nReferences227\nCHAPTER 6 The Least-Squares Family 233\n6.1 Introduction.234\n6.2 Least-Squares Linear Regression: A Geometric Perspective.234\n6.3 Statistical Properties of the LS Estimator236\n6.4","pages":"1050","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29482788.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29482788.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29482788.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27076976\/","id":"27076976","publisher":"机械工业出版社","isbn10":"7111565266","isbn13":"9787111565260","title":"机器学习:贝叶斯和优化方法(英文版)","url":"https:\/\/api.douban.com\/v2\/book\/27076976","alt_title":"","author_intro":"作者简介\nSergios Theodoridis 希腊雅典大学信息系教授。主要研究方向是自适应信号处理、通信与模式识别。他是欧洲并行结构及语言协会（PARLE-95）的主席和欧洲信号处理协会（EUSIPCO-98）的常务主席、《信号处理》杂志编委。\nKonstantinos Koutroumbas 1995年在希腊雅典大学获得博士学位。自2001年起任职于希腊雅典国家天文台空间应用研究院，是国际知名的专家。","summary":"本书对所有主要的机器学习方法和新研究趋势进行了深入探索，涵盖概率和确定性方法以及贝叶斯推断方法。其中，经典方法包括平均\/小二乘滤波、卡尔曼滤波、随机逼近和在线学习、贝叶斯分类、决策树、逻辑回归和提升方法等，新趋势包括稀疏、凸分析与优化、在线分布式算法、RKH空间学习、贝叶斯推断、图模型与隐马尔可夫模型、粒子滤波、深度学习、字典学习和潜变量建模等。全书构建了一套明晰的机器学习知识体系，各章内容相对独立，物理推理、数学建模和算法实现精准且细致，并辅以应用实例和习题。本书适合该领域的科研人员和工程师阅读，也适合学习模式识别、统计\/自适应信号处理和深度学习等课程的学生参考。","price":"269元"},{"rating":{"max":10,"numRaters":35,"average":"9.3","min":0},"subtitle":"","author":["Yoav Goldberg"],"pubdate":"2017-4-17","tags":[{"count":48,"name":"NLP","title":"NLP"},{"count":45,"name":"自然语言处理","title":"自然语言处理"},{"count":37,"name":"深度学习","title":"深度学习"},{"count":22,"name":"机器学习","title":"机器学习"},{"count":17,"name":"神经网络","title":"神经网络"},{"count":16,"name":"计算机","title":"计算机"},{"count":15,"name":"人工智能","title":"人工智能"},{"count":11,"name":"自然語言處理","title":"自然語言處理"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29437868.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"310","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29437868.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29437868.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29437868.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27032271\/","id":"27032271","publisher":"Morgan & Claypool Publishers","isbn10":"1627052984","isbn13":"9781627052986","title":"Neural Network Methods in Natural Language Processing","url":"https:\/\/api.douban.com\/v2\/book\/27032271","alt_title":"","author_intro":"","summary":"","price":"USD 74.95"},{"rating":{"max":10,"numRaters":21,"average":"7.7","min":0},"subtitle":"","author":["Antonio Gulli","Sujit Pal"],"pubdate":"2017-5-4","tags":[{"count":8,"name":"深度学习","title":"深度学习"},{"count":6,"name":"人工智能","title":"人工智能"},{"count":5,"name":"Python","title":"Python"},{"count":5,"name":"Keras","title":"Keras"},{"count":3,"name":"机器学习","title":"机器学习"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"MachineLearning","title":"MachineLearning"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29442546.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"322","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29442546.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29442546.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29442546.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27036791\/","id":"27036791","publisher":"Packt Publishing - ebooks Account","isbn10":"1787128423","isbn13":"9781787128422","title":"Deep Learning with Keras","url":"https:\/\/api.douban.com\/v2\/book\/27036791","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"Deep Learning with Generative Adversarial Networks","author":["Jakub Langr","Vladimir Bok"],"pubdate":"2019-10-8","tags":[{"count":8,"name":"GAN","title":"GAN"},{"count":3,"name":"AI","title":"AI"},{"count":2,"name":"计算机科学","title":"计算机科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"DeepLearning","title":"DeepLearning"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29881670.jpg","binding":"Paperback","translator":[],"catalog":"Table of Contents\nPART 1 - INTRODUCTION TO GANS AND GENERATIVE MODELING\nIntroduction to GANs\nIntro to generative modeling with autoencoders\nYour first GAN: Generating handwritten digits\nDeep Convolutional GAN\nPART 2 - ADVANCED TOPICS IN GANS\nTraining and common challenges: GANing for success\nProgressing with GANs\nSemi-Supervised GAN\nConditional GAN\nCycleGAN\nPART 3 - WHERE TO GO FROM HERE\nAdversarial examples\nPractical applications of GANs\nLooking ahead","pages":"240","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29881670.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29881670.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29881670.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30338539\/","id":"30338539","publisher":"Manning Publications","isbn10":"1617295566","isbn13":"9781617295560","title":"Gans in Action","url":"https:\/\/api.douban.com\/v2\/book\/30338539","alt_title":"","author_intro":"Jakub Langr is a Computer Vision Cofounder at Founders Factory (YEPIC.AI). Vladimir Bok is a Senior Product Manager overseeing machine learning infrastructure and research teams at a New York-based startup.","summary":"Summary\nGANs in Action teaches you how to build and train your own Generative Adversarial Networks, one of the most important innovations in deep learning. In this book, you'll learn how to start building your own simple adversarial system as you explore the foundation of GAN architecture: the generator and discriminator networks.\nPurchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.\nAbout the Technology\nGenerative Adversarial Networks, GANs, are an incredible AI technology capable of creating images, sound, and videos that are indistinguishable from the \"real thing.\" By pitting two neural networks against each other—one to generate fakes and one to spot them—GANs rapidly learn to produce photo-realistic faces and other media objects. With the potential to produce stunningly realistic animations or shocking deepfakes, GANs are a huge step forward in deep learning systems.\nAbout the Book\nGANs in Action teaches you to build and train your own Generative Adversarial Networks. You'll start by creating simple generator and discriminator networks that are the foundation of GAN architecture. Then, following numerous hands-on examples, you'll train GANs to generate high-resolution images, image-to-image translation, and targeted data generation. Along the way, you'll find pro tips for making your system smart, effective, and fast.\nWhat's inside\nBuilding your first GAN\nHandling the progressive growing of GANs\nPractical applications of GANs\nTroubleshooting your system\nAbout the Reader\nFor data professionals with intermediate Python skills, and the basics of deep learning-based image processing.","price":"USD 49.99"},{"rating":{"max":10,"numRaters":14,"average":"6.2","min":0},"subtitle":"","author":["【阿根廷】Rodolfo Bonnin"],"pubdate":"2017-11","tags":[{"count":6,"name":"机器学习","title":"机器学习"},{"count":2,"name":"TensorFlow","title":"TensorFlow"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"经典","title":"经典"},{"count":1,"name":"理工","title":"理工"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"异步社区","title":"异步社区"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29596594.jpg","binding":"","translator":["姚鹏鹏"],"catalog":"第1章　探索和转换数据 1\n1.1　TensorFlow的主要数据结构—\n张量 1\n1.1.1　张量的属性—阶、形状和\n类型 1\n1.1.2　创建新的张量 3\n1.1.3　动手工作—与TensorFlow\n交互 4\n1.2　处理计算工作流—TensorFlow\n的数据流图 5\n1.2.1　建立计算图 5\n1.2.2　数据供给 6\n1.2.3　变量 6\n1.2.4　保存数据流图 6\n1.3　运行我们的程序—会话 8\n1.4　基本张量方法 8\n1.4.1　简单矩阵运算 8\n1.4.2　序列 11\n1.4.3　张量形状变换 12\n1.4.4　数据流结构和结果可视化—\nTensorBoard 14\n1.5　从磁盘读取信息 18\n1.5.1　列表格式—CSV 18\n1.5.2　读取图像数据 19\n1.5.3　加载和处理图像 20\n1.5.4　读取标准TensorFlow格式 21\n1.6　小结 21\n第2章　聚类 22\n2.1　从数据中学习—无监督学习 22\n2.2　聚类的概念 22\n2.3　k均值 23\n2.3.1　k均值的机制 23\n2.3.2　算法迭代判据 23\n2.3.3　k均值算法拆解 24\n2.3.4　k均值的优缺点 25\n2.4　k最近邻 25\n2.4.1　k最近邻算法的机制 26\n2.4.2　k-nn的优点和缺点 26\n2.5　有用的库和使用示例 27\n2.5.1　matplotlib绘图库 27\n2.5.2　scikit-learn数据集模块 28\n2.5.3　人工数据集类型 28\n2.6　例1—对人工数据集的k均值\n聚类 29\n2.6.1　数据集描述和加载 29\n2.6.2　模型架构 30\n2.6.3　损失函数描述和优化循环 31\n2.6.4　停止条件 31\n2.6.5　结果描述 31\n2.6.6　每次迭代中的质心变化 32\n2.6.7　完整源代码 32\n2.6.8　k均值用于环状数据集 34\n2.7　例2—对人工数据集使用最近\n邻算法 36\n2.7.1　数据集生成 36\n2.7.2　模型结构 36\n2.7.3　损失函数描述 37\n2.7.4　停止条件 37\n2.7.5　结果描述 37\n2.7.6　完整源代码 37\n2.8　小结 39\n第3章　线性回归 40\n3.1　单变量线性模型方程 40\n3.2　选择损失函数 41\n3.3　最小化损失函数 42\n3.3.1　最小方差的全局最小值 42\n3.3.2　迭代方法：梯度下降 42\n3.4　示例部分 43\n3.4.1　TensorFlow中的优化方法—\n训练模块 43\n3.4.2　tf.train.Optimizer类 43\n3.4.3　其他Optimizer实例类型 44\n3.5　例1—单变量线性回归 44\n3.5.1　数据集描述 45\n3.5.2　模型结构 45\n3.5.3　损失函数描述和Optimizer 46\n3.5.4　停止条件 48\n3.5.5　结果描述 48\n3.5.6　完整源代码 49\n3.6　例2—多变量线性回归 51\n3.6.1　有用的库和方法 51\n3.6.2　Pandas库 51\n3.6.3　数据集描述 51\n3.6.4　模型结构 53\n3.6.5　损失函数和Optimizer 54\n3.6.6　停止条件 55\n3.6.7　结果描述 55\n3.6.8　完整源代码 56\n3.7　小结 57\n第4章　逻辑回归 58\n4.1　问题描述 58\n4.2　Logistic函数的逆函数—Logit\n函数 59\n4.2.1　伯努利分布 59\n4.2.2　联系函数 60\n4.2.3　Logit函数 60\n4.2.4　对数几率函数的逆函数—\nLogistic函数 60\n4.2.5　多类分类应用—Softmax\n回归 62\n4.3　例1—单变量逻辑回归 64\n4.3.1　有用的库和方法 64\n4.3.2　数据集描述和加载 65\n4.3.3　模型结构 67\n4.3.4　损失函数描述和优化器\n循环 67\n4.3.5　停止条件 68\n4.3.6　结果描述 68\n4.3.7　完整源代码 69\n4.3.8　图像化表示 71\n4.4　例2—基于skflow单变量逻辑\n回归 72\n4.4.1　有用的库和方法 72\n4.4.2　数据集描述 72\n4.4.3　模型结构 72\n4.4.4　结果描述 73\n4.4.5　完整源代码 74\n4.5　小结 74\n第5章　简单的前向神经网络 75\n5.1　基本概念 75\n5.1.1　人工神经元 75\n5.1.2　神经网络层 76\n5.1.3　有用的库和方法 78\n5.2　例1—非线性模拟数据\n回归 79\n5.2.1　数据集描述和加载 79\n5.2.2　数据集预处理 80\n5.2.3　模型结构—损失函数\n描述 80\n5.2.4　损失函数优化器 80\n5.2.5　准确度和收敛测试 80\n5.2.6　完整源代码 80\n5.2.7　结果描述 81\n5.3　例2—通过非线性回归，对\n汽车燃料效率建模 82\n5.3.1　数据集描述和加载 82\n5.3.2　数据预处理 83\n5.3.3　模型架构 83\n5.3.4　准确度测试 84\n5.3.5　结果描述 84\n5.3.6　完整源代码 84\n5.4　例3—多类分类：葡萄酒\n分类 86\n5.4.1　数据集描述和\n加载 86\n5.4.2　数据集预处理 86\n5.4.3　模型架构 87\n5.4.4　损失函数描述 87\n5.4.5　损失函数优化器 87\n5.4.6　收敛性测试 88\n5.4.7　结果描述 88\n5.4.8　完整源代码 88\n5.5　小结 89\n第6章　卷积神经网络 90\n6.1　卷积神经网络的起源 90\n6.1.1　卷积初探 90\n6.1.2　降采样操作—池化 95\n6.1.3　提高效率—dropout\n操作 98\n6.1.4　卷积类型层构建办法 99\n6.2　例1—MNIST数字分类 100\n6.2.1　数据集描述和加载 100\n6.2.2　数据预处理 102\n6.2.3　模型结构 102\n6.2.4　损失函数描述 103\n6.2.5　损失函数优化器 103\n6.2.6　准确性测试 103\n6.2.7　结果描述 103\n6.2.8　完整源代码 104\n6.3　例2—CIFAR10数据集的图像\n分类 106\n6.3.1　数据集描述和加载 107\n6.3.2　数据集预处理 107\n6.3.3　模型结构 108\n6.3.4　损失函数描述和\n优化器 108\n6.3.5　训练和准确性测试 108\n6.3.6　结果描述 108\n6.3.7　完整源代码 109\n6.4　小结 110\n第7章　循环神经网络和LSTM 111\n7.1　循环神经网络 111\n7.1.1　梯度爆炸和梯度消失 112\n7.1.2　LSTM神经网络 112\n7.1.3　其他RNN结构 116\n7.1.4　TensorFlow LSTM有用的类和\n方法 116\n7.2　例1—能量消耗、单变量时间序\n列数据预测 117\n7.2.1　数据集描述和加载 117\n7.2.2　数据预处理 118\n7.2.3　模型结构 119\n7.2.4　损失函数描述 121\n7.2.5　收敛检测 121\n7.2.6　结果描述 122\n7.2.7　完整源代码 122\n7.3　例2—创作巴赫风格的\n曲目 125\n7.3.1　字符级模型 125\n7.3.2　字符串序列和概率表示 126\n7.3.3　使用字符对音乐编码—\nABC音乐格式 126\n7.3.4　有用的库和方法 128\n7.3.5　数据集描述和加载 129\n7.3.6　网络训练 129\n7.3.7　数据集预处理 130\n7.3.8　损失函数描述 131\n7.3.9　停止条件 131\n7.3.10　结果描述 131\n7.3.11　完整源代码 132\n7.4　小结 137\n第8章　深度神经网络 138\n8.1　深度神经网络的定义 138\n8.2　深度网络结构的历史变迁 138\n8.2.1　LeNet 5 138\n8.2.2　Alexnet 139\n8.2.3　VGG模型 139\n8.2.4　第一代Inception模型 140\n8.2.5　第二代Inception模型 141\n8.2.6　第三代Inception模型 141\n8.2.7　残差网络（ResNet） 142\n8.2.8　其他的深度神经网络\n结构 143\n8.3　例子—VGG艺术风格转移 143\n8.3.1　有用的库和方法 143\n8.3.2　数据集描述和加载 143\n8.3.3　数据集预处理 144\n8.3.4　模型结构 144\n8.3.5　损失函数 144\n8.3.6　收敛性测试 145\n8.3.7　程序执行 145\n8.3.8　完整源代码 146\n8.4　小结 153\n第9章　规模化运行模型—GPU和\n服务 154\n9.1　TensorFlow中的GPU支持 154\n9.2　打印可用资源和设备参数 155\n9.2.1　计算能力查询 155\n9.2.2　选择CPU用于计算 156\n9.2.3　设备名称 156\n9.3　例1—将一个操作指派给\nGPU 156\n9.4　例2—并行计算Pi的数值 157\n9.4.1　实现方法 158\n9.4.2　源代码 158\n9.5　分布式TensorFlow 159\n9.5.1　分布式计算组件 159\n9.5.2　创建TensorFlow集群 160\n9.5.3　集群操作—发送计算方法\n到任务 161\n9.5.4　分布式编码结构示例 162\n9.6　例3—分布式Pi计算 163\n9.6.1　服务器端脚本 163\n9.6.2　客户端脚本 164\n9.7　例4—在集群上运行分布式\n模型 165\n9.8　小结 168\n第10章　库的安装和其他技巧 169\n10.1　Linux安装 169\n10.1.1　安装要求 170\n10.1.2　Ubuntu安装准备（安装操作的\n前期操作） 170\n10.1.3　Linux下通过pip安装\nTensorFlow 170\n10.1.4　Linux下从源码安装\nTensorFlow 175\n10.2　Windows安装 179\n10.2.1　经典的Docker工具箱\n方法 180\n10.2.2　安装步骤 180\n10.3　MacOS X安装 183\n10.4　小结 185\n","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29596594.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29596594.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29596594.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27187200\/","id":"27187200","publisher":"人民邮电出版社","isbn10":"711546362X","isbn13":"9787115463623","title":"TensorFlow机器学习项目实战","url":"https:\/\/api.douban.com\/v2\/book\/27187200","alt_title":"","author_intro":"Rodolfo Bonnin是一名系统工程师，同时也是阿根廷国立理工大学的博士生。他还在德国斯图加特大学进修过并行编程和图像理解的研究生课程。\n他从2005年开始研究高性能计算，并在2008年开始研究和实现卷积神经网络，编写过一个同时支持CPU和GPU的神经网络前馈部分。最近，他一直在进行使用神经网络进行欺诈模式检测的工作，目前正在使用ML技术进行信号分类。\n感谢我的妻子和孩子们，尤其感谢他们在我写这本书时表现出的耐心。感谢本书的审稿人，他们让这项工作更专业化。感谢Marcos Boaglio，他安装调试了设备，以使我能完成这本书。","summary":"TensorFlow是Google所主导的机器学习框架，也是机器学习领域研究和应用的热门对象。\n本书主要介绍如何使用TensorFlow库实现各种各样的模型，旨在降低学习门槛，并为读者解决问题提供详细的方法和指导。全书共10章，分别介绍了TensorFlow基础知识、聚类、线性回归、逻辑回归、不同的神经网络、规模化运行模型以及库的应用技巧。\n本书适合想要学习和了解 TensorFlow 和机器学习的读者阅读参考。如果读者具备一定的C++和Python的经验，将能够更加轻松地阅读和学习本书。","price":""},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["李沐","刘树杰","张冬冬","周明"],"pubdate":"2018-8-1","tags":[{"count":7,"name":"机器翻译","title":"机器翻译"},{"count":4,"name":"计算机","title":"计算机"},{"count":4,"name":"深度学习","title":"深度学习"},{"count":4,"name":"人工智能","title":"人工智能"},{"count":4,"name":"NLP","title":"NLP"},{"count":3,"name":"机器学习","title":"机器学习"},{"count":2,"name":"微软亚洲研究院","title":"微软亚洲研究院"},{"count":2,"name":"已购","title":"已购"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29987028.jpg","binding":"平装","translator":[],"catalog":"第一章 绪论\n1.1 机器翻译概述\n1.1.1 机器翻译定义\n1.1.2 机器翻译简史\n1.1.3 机器翻译方法\n1.1.4 机器翻译分析及展望\n1.2 机器翻译的应用\n1.2.1 文本翻译\n1.2.2 语音翻译\n1.2.3 应用扩展\n1.3 本书章节总览\n参考文献\n第二章 机器翻译语料和评测\n2.1 机器翻译语料\n2.1.1 单语语料\n2.1.2 双语语料\n2.1.3 语料获取\n2.1.4 语料处理\n2.2 机器翻译评测\n2.2.1 人工评测\n2.2.2 自动评测\n2.2.3 评测活动\n参考文献\n第三章 统计机器翻译基础\n3.1 统计机器翻译简介\n3.1.1 统计机器翻译系统框架\n3.1.2 统计机器翻译基本流程\n3.2 统计机器翻译建模\n3.2.1 噪声-信道模型\n3.2.2 对数-线性模型\n3.2.3 模型训练方法\n3.3 语言模型\n3.3.1 n元文法语言模型定义\n3.3.2 语言模型的平滑\n3.3.3 语言模型的评价指标\n3.4 翻译模型\n3.4.1 词汇翻译模型\n3.4.2 短语翻译模型\n3.5 调序模型\n3.5.1 基于跳转距离的调序模型\n3.5.2 词汇化调序模型\n3.5.3 基于句法的调序模型\n3.6 扩展阅读\n参考文献\n第四章 统计机器翻译系统模型\n4.1 基于短语的统计机器翻译模型\n4.1.1 噪声-信道模型短语翻译模型\n4.1.2 对数-线性模型短语翻译模型\n4.1.3 解码\n4.2 基于形式文法的统计机器翻译模型\n4.2.1 基于反向转录文法的统计机器翻译模型\n4.2.2 基于层次化短语的统计机器翻译模型\n4.3 基于句法的统计机器翻译系统模型\n4.3.1 树到串的翻译模型\n4.3.2 串到树的翻译模型\n4.4 多系统融合\n4.4.1 句子级系统融合\n4.4.2 短语级系统融合\n4.4.3 词级系统融合\n4.5 领域自适应\n4.5.1 基于数据选择的领域自适应\n4.5.2 基于自学习的领域自适应\n4.5.3 基于上下文信息的领域自适应\n4.6 统计机器翻译开源工具\n4.7 扩展阅读\n参考文献\n第五章 自然语言处理中的深度学习基础\n5.1 深度学习基础\n5.1.1 简介\n5.1.2 感知机\n5.1.3 多层感知机\n5.1.4 激活函数\n5.1.5 反向传播算法\n5.2 神经网络学习算法\n5.2.1 随机梯度下降算法\n5.2.2 基于动量的随机梯度下降算法\n5.2.3 AdaGrad算法\n5.2.4 RMSProp算法\n5.2.5 AdaDelta算法\n5.2.6 Adam算法\n5.2.7 不同参数更新方法的比较\n5.3 自然语言处理中常用的神经网络模型\n5.3.1 前馈神经网络\n5.3.2 循环神经网络\n5.3.3 长短时记忆网络\n5.3.4 深层循环神经网络\n5.3.5 卷积神经网络\n5.3.6 通用词嵌入\n5.4 扩展阅读\n5.5 词汇缩写详解\n参考文献\n第六章 神经机器翻译\n6.1 简单的神经网络机器翻译模型\n6.2 神经联合模型\n6.2.1 从语言模型到联合模型\n6.2.2 基于神经网络的联合模型\n6.2.3 基于神经网络的联合模型的训练\n6.2.4 联合模型解码速度的优化\n6.3 基于序列转换的神经机器翻译\n6.3.1 编码器-解码器框架\n6.3.2 编码器及其构造\n6.3.3 其他方式的编码器\n6.3.4 解码器及其构造\n6.4 注意力模型\n6.4.1 基本序列转换模型的困难\n6.4.2 注意力网络\n6.4.3 匹配函数\n6.4.4 局部匹配与全局匹配\n6.5 卷积串到串模型\n6.5.1 卷积编码器和解码器\n6.5.2 多步注意力机制\n6.6 完全基于注意力网络的神经翻译模型\n6.6.1 基于注意力网络的编码器和解码器\n6.6.2 分组（multi-head）注意力网络\n6.6.3 位置编码（positional encoding）\n6.6.4 自注意力网络性能分析\n6.7 参数正则化\n6.7.1 L1／L2正则化\n6.7.2 maxout和dropout正则化\n6.8 神经机器翻译解码\n6.8.1 贪心搜索（greedy search）\n6.8.2 束搜索（beam search）\n6.8.3 集合解码（ensemble decoding）\n6.9 神经机器翻译模型的训练\n6.10 扩展阅读\n6.11 本章小结\n参考文献\n第七章 前沿课题\n7.1 基于句法的神经机器翻译\n7.2 并行化训练\n7.2.1 数据并行化\n7.2.2 模型并行化\n7.3 神经机器翻译的快速解码技术\n7.3.1 网络预计算\n7.3.2 参数的量化\n7.3.3 受限词表优化\n7.4 注意力模型的改进\n7.4.1 覆盖度和能产度\n7.4.2 循环注意力网络\n7.5 神经机器翻译的可伸缩性\n7.5.1 近似softmax函数\n7.5.2 未登录词处理\n7.5.3 基于词根分解的开放词汇表\n7.6 单语数据在神经机器翻译中的应用\n7.6.1 独立的神经语言模型\n7.6.2 往返翻译（back translatinn）\n7.6.3 联合训练（joint training）\n7.6.4 强化学习在神经机器翻译中的应用\n7.6.5 生成对抗网络\n7.7 扩展阅读\n7.8 本章小结\n参考文献","pages":"222","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29987028.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29987028.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29987028.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30441528\/","id":"30441528","publisher":"高等教育出版社","isbn10":"7040502437","isbn13":"9787040502435","title":"机器翻译","url":"https:\/\/api.douban.com\/v2\/book\/30441528","alt_title":"","author_intro":"","summary":"机器翻译是人工智能，尤其是自然语言处理方向里的一个重要研究领域。本书旨在作为该领域的入门书籍，内容上尽可能覆盖机器翻译研究历史上各种主流的研究方法和相关资源。全书分为七章，三个主要部分。第一部分(第一、第二章) 主要介绍了机器翻译的历史、研究概况和基础知识，第二部分 (第三、第四章) 详细讨论了统计机器翻译方法的理论和实现，第三部分 (第五至七章) 则着重介绍了基于深度学习在机器翻译研究中应用的最新进展，内容包括深度学习的基础知识和在机器翻译中应用深度学习的不同方法。每章后均附有扩展阅读的内容供想深入研究的读者参考。\n本书可以作为高等院校计算机和信息技术等相关专业的研究生教材，也可供对机器翻译的研究和进展有兴趣的读者和工程技术人员参考。","series":{"id":"45465","title":"人工智能丛书"},"price":""},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"A Gentle Introduction For Data Science","author":["N.D Lewis"],"pubdate":"2016-1-10","tags":[{"count":1,"name":"深度学习","title":"深度学习"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28382579.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"254","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28382579.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28382579.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28382579.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26707910\/","id":"26707910","publisher":"CreateSpace Independent Publishing Platform","isbn10":"1519514212","isbn13":"9781519514219","title":"Deep Learning Made Easy with R","url":"https:\/\/api.douban.com\/v2\/book\/26707910","alt_title":"","author_intro":"","summary":"","price":"USD 17.77"},{"rating":{"max":10,"numRaters":13,"average":"8.2","min":0},"subtitle":"A Guide to Building Deep Learning Systems","author":["Tom Hope","Yehezkel S. Resheff","Itay Lieder"],"pubdate":"2017-8-27","tags":[{"count":8,"name":"深度学习","title":"深度学习"},{"count":4,"name":"计算机","title":"计算机"},{"count":4,"name":"TensorFlow","title":"TensorFlow"},{"count":4,"name":"DeepLearning","title":"DeepLearning"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":1,"name":"英文原版","title":"英文原版"},{"count":1,"name":"数据科学","title":"数据科学"},{"count":1,"name":"教材","title":"教材"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29562303.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"242","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29562303.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29562303.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29562303.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27072918\/","id":"27072918","publisher":"O'Reilly Media","isbn10":"1491978511","isbn13":"9781491978511","title":"Learning TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/27072918","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["Rodolfo Bonnin"],"pubdate":"2016-12-6","tags":[{"count":6,"name":"tensorflow","title":"tensorflow"},{"count":3,"name":"深度学习","title":"深度学习"},{"count":2,"name":"Python","title":"Python"},{"count":1,"name":"美国","title":"美国"},{"count":1,"name":"参考资料","title":"参考资料"},{"count":1,"name":"人工智能","title":"人工智能"},{"count":1,"name":"python","title":"python"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29195182.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"291","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29195182.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29195182.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29195182.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26927961\/","id":"26927961","publisher":"Packt Publishing","isbn10":"1786466589","isbn13":"9781786466587","title":"Building Machine Learning Projects with TensorFlow","url":"https:\/\/api.douban.com\/v2\/book\/26927961","alt_title":"","author_intro":"About the Author\nRodolfo Bonnin Rodolfo Bonnin is a systems engineer and PhD student at Universidad Tecnologica Nacional, Argentina. He also pursued parallel programming and image understanding postgraduate courses at Uni Stuttgart, Germany. He has done research on high performance computing since 2005 and began studying and implementing convolutional neural networks in 2008,writing a CPU and GPU - supporting neural network feed forward stage. More recently he's been working in the field of fraud pattern detection with Neural Networks, and is currently working on signal classification using ML techniques.\nRead more","summary":"Key Features Bored of too much theory on TensorFlow? This book is what you need! Thirteen solid projects and four examples teach you how to implement TensorFlow in production. This example-rich guide teaches you how to perform highly accurate and efficient numerical computing with TensorFlow It is a practical and methodically explained guide that allows you to apply Tensorflow’s features from the very beginning. Book Description This book of projects highlights how TensorFlow can be used in different scenarios - this includes projects for training models, machine learning, deep learning, and working with various neural networks. Each project provides exciting and insightful exercises that will teach you how to use TensorFlow and show you how layers of data can be explored by working with Tensors. Simply pick a project that is in line with your environment and get stacks of information on how to implement TensorFlow in production. What you will learn Load, interact, dissect, process, and save complex datasets Solve classification and regression problems using state of the art techniques Predict the outcome of a simple time series using Linear Regression modeling Use a Logistic Regression scheme to predict the future result of a time series Classify images using deep neural network schemes Tag a set of images and detect features using a deep neural network, including a Convolutional Neural Network (CNN) layer Resolve character recognition problems using the Recurrent Neural Network (RNN) model About the Author Rodolfo Bonnin is a systems engineer and PhD student at Universidad Tecnologica Nacional, Argentina. He also pursued parallel programming and image understanding postgraduate courses at Uni Stuttgart, Germany. He has done research on high performance computing since 2005 and began studying and implementing convolutional neural networks in 2008,writing a CPU and GPU - supporting neural network feed forward stage.","price":"USD 54.99"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"A Hands-on Introduction","author":["Nikhil Ketkar"],"pubdate":"2017-11-5","tags":[{"count":6,"name":"深度学习","title":"深度学习"},{"count":4,"name":"Python","title":"Python"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":1,"name":"AI","title":"AI"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29500248.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"160","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29500248.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29500248.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29500248.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27030685\/","id":"27030685","publisher":"Apress","isbn10":"1484227654","isbn13":"9781484227657","title":"Deep Learning with Python","url":"https:\/\/api.douban.com\/v2\/book\/27030685","alt_title":"","author_intro":"From the Back Cover\nDiscover the practical aspects of implementing deep-learning solutions using the rich Python ecosystem. This book bridges the gap between the academic state-of-the-art and the industry state-of-the-practice by introducing you to deep learning frameworks such as Keras, Theano, and Caffe. The practicalities of these frameworks is often acquired by practitioners by reading source code, manuals, and posting questions on community forums, which tends to be a slow and a painful process.Deep Learning with Pythonallows you to ramp up to such practical know-how in a short period of time and focus more on the domain, models, and algorithms.This book briefly covers the mathematical prerequisites and fundamentals of deep learning, making this book a good starting point for software developers who want to get started in deep learning. A brief survey of deep learning architectures is also included.Deep Learning with Pythonalso introduces you to key concepts of automatic differentiation and GPU computation which, while not central to deep learning, are critical when it comes to conducting large scale experiments.You will:Leverage deep learning frameworks in Python namely, Keras, Theano, and CaffeGain the fundamentals of deep learning with mathematical prerequisitesDiscover the practical considerations of large scale experimentsTake deep learning models to production\nRead more\nAbout the Author\nNikhil S. Ketkar currently leads the Machine Learning Platform team at Flipkart, India’s largest e-commerce company. He received his Ph.D. from Washington State University. Following that he conducted postdoctoral research at University of North Carolina at Charlotte, which was followed by a brief stint in high frequency trading at Transmaket in Chicago. More recently he led the data mining team in Guavus, a startup doing big data analytics in the telecom domain and Indix, a startup doing data science in the e-commerce domain. His research interests include machine learning and graph theory.\nRead more","summary":"Discover the practical aspects of implementing deep-learning solutions using the rich Python ecosystem. This book bridges the gap between the academic state-of-the-art and the industry state-of-the-practice by introducing you to deep learning frameworks such as Keras, Theano, and Caffe. The practicalities of these frameworks is often acquired by practitioners by reading source code, manuals, and posting questions on community forums, which tends to be a slow and a painful process. Deep Learning with Python allows you to ramp up to such practical know-how in a short period of time and focus more on the domain, models, and algorithms.\nThis book briefly covers the mathematical prerequisites and fundamentals of deep learning, making this book a good starting point for software developers who want to get started in deep learning. A brief survey of deep learning architectures is also included.\nDeep Learning with Python also introduces you to key concepts of automatic differentiation and GPU computation which, while not central to deep learning, are critical when it comes to conducting large scale experiments.\nWhat You Will Learn\nLeverage deep learning frameworks in Python namely, Keras, Theano, and CaffeGain the fundamentals of deep learning with mathematical prerequisitesDiscover the practical considerations of large scale experimentsTake deep learning models to production\nWho This Book Is ForSoftware developers who want to try out deep learning as a practical solution to a particular problem.Software developers in a data science team who want to take deep learning models developed by data scientists to production.","price":"USD 40.07"},{"rating":{"max":10,"numRaters":10,"average":"6.0","min":0},"subtitle":"","author":["校宝在线","孙琳","蒋阳波","汪建成","项斌"],"pubdate":"2018-11","tags":[{"count":6,"name":"人工智能","title":"人工智能"},{"count":6,"name":"AI","title":"AI"},{"count":4,"name":"深度学习","title":"深度学习"},{"count":3,"name":"神经网络","title":"神经网络"},{"count":3,"name":"机器学习","title":"机器学习"},{"count":3,"name":"PyTorch","title":"PyTorch"},{"count":2,"name":"编程","title":"编程"},{"count":2,"name":"好书，值得一读","title":"好书，值得一读"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29899276.jpg","binding":"","translator":[],"catalog":"前言\n第 1 章 深度学习介绍......................................................................................... 1\n1.1 人工智能、机器学习与深度学习 .................................................................. 2\n1.2 深度学习工具介绍 .......................................................................................... 5\n1.3 PyTorch 介绍.................................................................................................... 7\n1.4 你能从本书中学到什么 .................................................................................. 9\n第 2 章 PyTorch 安装和快速上手 ...................................................................... 11\n2.1 PyTorch 安装.................................................................................................. 12\n2.1.1 Anaconda 安装.................................................................................... 12\n2.1.2 PyTorch 安装....................................................................................... 19\n2.2 Jupyter Notebook 使用................................................................................... 19\n2.3 NumPy 基础知识........................................................................................... 22\n2.3.1 基本概念 ............................................................................................. 23\n2.3.2 创建数组 ............................................................................................. 24\n2.3.3 基本运算 ............................................................................................. 26\n2.3.4 索引、切片和迭代 ............................................................................. 27\n2.3.5 数组赋值 ............................................................................................. 32\n2.3.6 更改数组的形状 ................................................................................. 33\n2.3.7 组合、拆分数组 ................................................................................. 34\n2.3.8 广播 ..................................................................................................... 35\n2.4 PyTorch 基础知识.......................................................................................... 37\n2.4.1 Tensor 简介 ......................................................................................... 37\n2.4.2 Variable 简介....................................................................................... 37VIII\nPyTorch 机器学习从入门到实战\n2.4.3 CUDA 简介......................................................................................... 38\n2.4.4 模型的保存与加载 ............................................................................. 39\n2.4.5 第一个 PyTorch 程序.......................................................................... 39\n第 3 章 神经网络 .............................................................................................. 42\n3.1 神经元与神经网络 ........................................................................................ 43\n3.2 激活函数 ........................................................................................................ 45\n3.2.1 Sigmoid ................................................................................................ 46\n3.2.2 Tanh ..................................................................................................... 47\n3.2.3 Hard Tanh ............................................................................................ 48\n3.2.4 ReLU ................................................................................................... 49\n3.2.5 ReLU 的扩展 ...................................................................................... 50\n3.2.6 Softmax ................................................................................................ 53\n3.2.7 LogSoftmax ......................................................................................... 54\n3.3 前向算法 ........................................................................................................ 54\n3.4 损失函数 ........................................................................................................ 56\n3.4.1 损失函数的概念 ................................................................................. 56\n3.4.2 回归问题 ............................................................................................. 56\n3.4.3 分类问题 ............................................................................................. 57\n3.4.4 PyTorch 中常用的损失函数............................................................... 58\n3.5 后向算法 ........................................................................................................ 61\n3.6 数据的准备 .................................................................................................... 64\n3.7 实例：单层神经网络 .................................................................................... 65\n第 4 章 深层神经网络及训练............................................................................ 69\n4.1 深层神经网络 ................................................................................................ 71\n4.1.1 神经网络为何难以训练 ..................................................................... 71\n4.1.2 改进策略 ............................................................................................. 73\n4.2 梯度下降 ........................................................................................................ 73\n4.2.1 随机梯度下降 ..................................................................................... 73\n4.2.2 Mini-Batch 梯度下降.......................................................................... 74\n4.3 优化器 ............................................................................................................ 75\n4.3.1 SGD ..................................................................................................... 76\n4.3.2 Momentum .......................................................................................... 76\n4.3.3 AdaGrad .............................................................................................. 77\n4.3.4 RMSProp ............................................................................................. 78IX\n目 录\n4.3.5 Adam ................................................................................................... 79\n4.3.6 选择正确的优化算法 ......................................................................... 79\n4.3.7 优化器的使用实例 ............................................................................. 80\n4.4 正则化 ............................................................................................................ 83\n4.4.1 参数规范惩罚 ..................................................................................... 84\n4.4.2 Batch Normalization ............................................................................ 84\n4.4.3 Dropout ................................................................................................ 85\n4.5 实例：MNIST 深层神经网络....................................................................... 87\n第 5 章 卷积神经网络....................................................................................... 91\n5.1 计算机视觉 .................................................................................................... 93\n5.1.1 人类视觉和计算机视觉 ..................................................................... 93\n5.1.2 特征提取 ............................................................................................. 93\n5.1.3 数据集 ................................................................................................. 95\n5.2 卷积神经网络 ................................................................................................ 98\n5.2.1 卷积层 ............................................................................................... 100\n5.2.2 池化层 ............................................................................................... 102\n5.2.3 经典卷积神经网络 ........................................................................... 103\n5.3 MNIST 数据集上卷积神经网络的实现..................................................... 108\n第 6 章 嵌入与表征学习 .................................................................................. 112\n6.1 PCA .............................................................................................................. 113\n6.1.1 PCA 原理 .......................................................................................... 113\n6.1.2 PCA 的 PyTorch 实现....................................................................... 114\n6.2 自动编码器 .................................................................................................. 115\n6.2.1 自动编码器原理 ............................................................................... 116\n6.2.2 自动解码器的 PyTorch 实现............................................................ 116\n6.2.3 实例：图像去噪 ............................................................................... 120\n6.3 词嵌入 .......................................................................................................... 123\n6.3.1 词嵌入原理 ....................................................................................... 123\n6.3.2 实例：基于词向量的语言模型实现 ............................................... 126\n第 7 章 序列预测模型..................................................................................... 130\n7.1 序列数据处理 .............................................................................................. 131\n7.2 循环神经网络 .............................................................................................. 132\n7.3 LSTM 和 GRU ............................................................................................. 136X\nPyTorch 机器学习从入门到实战\n7.4 LSTM 在自然语言处理中的应用............................................................... 140\n7.4.1 词性标注 ........................................................................................... 140\n7.4.2 情感分析 ........................................................................................... 142\n7.5 串到串网络 .................................................................................................. 143\n7.5.1 串到串网络原理 ............................................................................... 143\n7.5.2 注意力机制 ....................................................................................... 144\n7.6 实例：基于 GRU 和 Attention 的机器翻译............................................... 145\n7.6.1 公共模块 ........................................................................................... 145\n7.6.2 数据处理 ........................................................................................... 145\n7.6.3 模型定义 ........................................................................................... 149\n7.6.4 训练模块定义 ................................................................................... 153\n7.6.5 训练和模型保存 ............................................................................... 159\n7.6.6 评估过程 ........................................................................................... 161\n第 8 章 PyTorch 项目实战 .............................................................................. 163\n8.1 图像识别和迁移学习——猫狗大战 .......................................................... 164\n8.1.1 迁移学习介绍 ................................................................................... 164\n8.1.2 计算机视觉工具包 ........................................................................... 164\n8.1.3 猫狗大战的 PyTorch 实现................................................................ 165\n8.2 文本分类 ...................................................................................................... 170\n8.2.1 文本分类的介绍 ............................................................................... 171\n8.2.2 计算机文本工具包 ........................................................................... 172\n8.2.3 基于 CNN 的文本分类的 PyTorch 实现 ......................................... 172\n8.3 语音识别系统介绍 ...................................................................................... 180\n8.3.1 语音识别介绍 ................................................................................... 181\n8.3.2 命令词识别的 PyTorch 实现............................................................ 181","ebook_url":"https:\/\/read.douban.com\/ebook\/59209320\/","pages":"181","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29899276.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29899276.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29899276.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30354653\/","id":"30354653","publisher":"机械工业出版社","isbn10":"7111610458","isbn13":"9787111610458","title":"PyTorch 机器学习从入门到实战","url":"https:\/\/api.douban.com\/v2\/book\/30354653","alt_title":"","author_intro":"","summary":"近年来，基于深度学习的人工智能掀起了一股学习的热潮。本书是使用 PyTorch 深度学习框架的入门图书，从深度学习原理入手，由浅入深地阐述深度学习中神经网络、深度神经网络、卷积神经网络、自编码器、循环神经网络等内容，同时穿插学习 PyTorch 框架的各个知识点和基于知识点的实例。最后，综合运用 PyTorch 和深度学习知识来解决实践中的具体问题，比如图像识别、文本分类和命令词识别等。可以说，本书是深度学习和 PyTorch的入门教程，同时也引领读者进入机遇和挑战共存的人工智能领域。\n本书针对的对象是机器学习和人工智能的爱好者和研究者，希望其能够有一定的机器学习和深度学习知识，有一定的 Python 编程基础。","ebook_price":"25.00","price":"59"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Patrick Harrison","Matthew Honnibal"],"pubdate":"2018-4-30","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"Python","title":"Python"},{"count":1,"name":"NLP","title":"NLP"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29583543.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"250","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29583543.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29583543.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29583543.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27175358\/","id":"27175358","publisher":"O′Reilly","isbn10":"1491984414","isbn13":"9781491984413","title":"Deep Learning with Text","url":"https:\/\/api.douban.com\/v2\/book\/27175358","alt_title":"","author_intro":"","summary":"","price":"GBP 34.29"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"A Learner's Guide to Coding and Computational Thinking","author":["Eric Freeman"],"pubdate":"2018-1-12","tags":[{"count":2,"name":"深度学习","title":"深度学习"},{"count":1,"name":"Deeplearning","title":"Deeplearning"},{"count":1,"name":"2017","title":"2017"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29702729.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"640","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29702729.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29702729.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29702729.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27055785\/","id":"27055785","publisher":"O’Reilly Media","isbn10":"1491958863","isbn13":"9781491958865","title":"Head First Learn to Code","url":"https:\/\/api.douban.com\/v2\/book\/27055785","alt_title":"","author_intro":"","summary":"","price":"5$"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"Pythonで学ぶディープラーニングの理論と実装","author":["斎藤 康毅"],"pubdate":"2016-9","tags":[{"count":3,"name":"深度学习","title":"深度学习"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"日版","title":"日版"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"动物书","title":"动物书"},{"count":1,"name":"python","title":"python"},{"count":1,"name":"deoplearning","title":"deoplearning"},{"count":1,"name":"Python","title":"Python"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29397553.jpg","binding":"平装","translator":[],"catalog":"目次\nまえがき\n1章　Python入門\n1.1　Pythonとは\n1.2　Pythonのインストール\n1.2.1　Pythonのバージョン\n1.2.2　使用する外部ライブラリ\n1.2.3　Anacondaディストリビューション\n1.3　Pythonインタプリタ\n1.3.1　算術計算\n1.3.2　データ型\n1.3.3　変数\n1.3.4　リスト\n1.3.5　ディクショナリ\n1.3.6　ブーリアン\n1.3.7　if文\n1.3.8　for文\n1.3.9　関数\n1.4　Pythonスクリプトファイル\n1.4.1　ファイルに保存\n1.4.2　クラス\n1.5　NumPy\n1.5.1　NumPyのインポート\n1.5.2　NumPy配列の生成\n1.5.3　NumPyの算術計算\n1.5.4　NumPyのN次元配列\n1.5.5　ブロードキャスト\n1.5.6　要素へのアクセス\n1.6　Matplotlib\n1.6.1　単純なグラフの描画\n1.6.2　pyplotの機能\n1.6.3　画像の表示\n1.7　まとめ\n2章　パーセプトロン\n2.1　パーセプトロンとは\n2.2　単純な論理回路\n2.2.1　ANDゲート\n2.2.2　NANDゲートとORゲート\n2.3　パーセプトロンの実装\n2.3.1　簡単な実装\n2.3.2　重みとバイアスの導入\n2.3.3　重みとバイアスによる実装\n2.4　パーセプトロンの限界\n2.4.1　XORゲート\n2.4.2　線形と非線形\n2.5　多層パーセプトロン\n2.5.1　既存ゲートの組み合わせ\n2.5.2　XORゲートの実装\n2.6　NANDからコンピュータへ\n2.7　まとめ\n3章　ニューラルネットワーク\n3.1　パーセプトロンからニューラルネットワークへ\n3.1.1　ニューラルネットワークの例\n3.1.2　パーセプトロンの復習\n3.1.3　活性化関数の登場\n3.2　活性化関数\n3.2.1　シグモイド関数\n3.2.2　ステップ関数の実装\n3.2.3　ステップ関数のグラフ\n3.2.4　シグモイド関数の実装\n3.2.5　シグモイド関数とステップ関数の比較\n3.2.6　非線形関数\n3.2.7　ReLU関数\n3.3　多次元配列の計算\n3.3.1　多次元配列\n3.3.2　行列の内積\n3.3.3　ニューラルネットワークの内積\n3.4　3層ニューラルネットワークの実装\n3.4.1　記号の確認\n3.4.2　各層における信号伝達の実装\n3.4.3　実装のまとめ\n3.5　出力層の設計\n3.5.1　恒等関数とソフトマックス関数\n3.5.2　ソフトマックス関数の実装上の注意\n3.5.3　ソフトマックス関数の特徴\n3.5.4　出力層のニューロンの数\n3.6　手書き数字認識\n3.6.1　MNISTデータセット\n3.6.2　ニューラルネットワークの推論処理\n3.6.3　バッチ処理\n3.7　まとめ\n4章　ニューラルネットワークの学習\n4.1　データから学習する\n4.1.1　データ駆動\n4.1.2　訓練データとテストデータ\n4.2　損失関数\n4.2.1　2乗和誤差\n4.2.2　交差エントロピー誤差\n4.2.3　ミニバッチ学習\n4.2.4　［バッチ対応版］交差エントロピー誤差の実装\n4.2.5　なぜ損失関数を設定するのか？\n4.3　数値微分\n4.3.1　微分\n4.3.2　数値微分の例\n4.3.3　偏微分\n4.4　勾配\n4.4.1　勾配法\n4.4.2　ニューラルネットワークに対する勾配\n4.5　学習アルゴリズムの実装\n4.5.1　2層ニューラルネットワークのクラス\n4.5.2　ミニバッチ学習の実装\n4.5.3　テストデータで評価\n4.6　まとめ\n5章　誤差逆伝播法\n5.1　計算グラフ\n5.1.1　計算グラフで解く\n5.1.2　局所的な計算\n5.1.3　なぜ計算グラフで解くのか？\n5.2　連鎖率\n5.2.1　計算グラフの逆伝播\n5.2.2　連鎖率とは\n5.2.3　連鎖率と計算グラフ\n5.3　逆伝播\n5.3.1　加算ノードの逆伝播\n5.3.2　乗算ノードの逆伝播\n5.3.3　リンゴの例\n5.4　単純なレイヤの実装\n5.4.1　乗算レイヤの実装\n5.4.2　加算レイヤの実装\n5.5　活性化関数レイヤの実装\n5.5.1　ReLUレイヤ\n5.5.2　Sigmoidレイヤ\n5.6　A.ne／Softmaxレイヤの実装\n5.6.1　A.neレイヤ\n5.6.2　バッチ版A.neレイヤ\n5.6.3　Softmax-with-Lossレイヤ\n5.7　誤差逆伝播法の実装\n5.7.1　ニューラルネットワークの学習の全体図\n5.7.2　誤差逆伝播法に対応したニューラルネットワークの実装\n5.7.3　誤差逆伝播法の勾配確認\n5.7.4　誤差逆伝播法を使った学習\n5.8　まとめ\n6章　学習に関するテクニック\n6.1　パラメータの更新\n6.1.1　冒険家の話\n6.1.2　SGD\n6.1.3　SGDの欠点\n6.1.4　Momentum\n6.1.5　AdaGrad\n6.1.6　Adam\n6.1.7　どの更新手法を用いるか？\n6.1.8　MNISTデータセットによる更新手法の比較\n6.2　重みの初期値\n6.2.1　重みの初期値を0にする？\n6.2.2　隠れ層のアクティベーション分布\n6.2.3　ReLUの場合の重みの初期値\n6.2.4　MNISTデータセットによる重み初期値の比較\n6.3　Batch Normalization\n6.3.1　Batch Normalizationのアルゴリズム\n6.3.2　Batch Normalizationの評価\n6.4　正則化\n6.4.1　過学習\n6.4.2　Weight decay\n6.4.3　Dropout\n6.5　ハイパーパラメータの検証\n6.5.1　検証データ\n6.5.2　ハイパーパラメータの最適化\n6.5.3　ハイパーパラメータ最適化の実装\n6.6　まとめ\n7章　畳み込みニューラルネットワーク\n7.1　全体の構造\n7.2　畳み込み層\n7.2.1　全結合層の問題点\n7.2.2　畳み込み演算\n7.2.3　パディング\n7.2.4　ストライド\n7.2.5　3次元データの畳み込み演算\n7.2.6　ブロックで考える\n7.2.7　バッチ処理\n7.3　プーリング層\n7.3.1　プーリング層の特徴\n7.4　Convolution／Poolingレイヤの実装\n7.4.1　4次元配列\n7.4.2　im2colによる展開\n7.4.3　Convolutionレイヤの実装\n7.4.4　Poolingレイヤの実装\n7.5　CNNの実装\n7.6　CNNの可視化\n7.6.1　1層目の重みの可視化\n7.6.2　階層構造による情報抽出\n7.7　代表的なCNN\n7.7.1　LeNet\n7.7.2　AlexNet\n7.8　まとめ\n8章　ディープラーニング\n8.1　ネットワークをより深く\n8.1.1　よりディープなネットワークへ\n8.1.2　さらに認識精度を高めるには\n8.1.3　層を深くすることのモチベーション\n8.2　ディープラーニングの小歴史\n8.2.1　ImageNet\n8.2.2　VGG\n8.2.3　GoogLeNet\n8.2.4　ResNet\n8.3　ディープラーニングの高速化\n8.3.1　取り組むべき問題\n8.3.2　GPUによる高速化\n8.3.3　分散学習\n8.3.4　演算精度のビット削減\n8.4　ディープラーニングの実用例\n8.4.1　物体検出\n8.4.2　セグメンテーション\n8.4.3　画像キャプション生成\n8.5　ディープラーニングの未来\n8.5.1　画像スタイル変換\n8.5.2　画像生成\n8.5.3　自動運転\n8.5.4　Deep Q-Network（強化学習）\n8.6　まとめ\n付録A　Softmax-with-Lossレイヤの計算グラフ\nA.1　順伝播\nA.2　逆伝播\nA.3　まとめ\n参考文献\nPython \/ NumPy\n計算グラフ（誤差逆伝播法）\nDeep Learningのオンライン授業（資料）\nパラメータの更新方法\n重みパラメータの初期値\nBatch Normalization \/ Dropout\nハイパーパラメータの最適化\nCNNの可視化\n代表的なネットワーク\nデータセット\n計算の高速化\nMNISTデータセットの精度ランキングおよび最高精度の手法\nディープラーニングのアプリケーション\n索引","pages":"320","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29397553.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29397553.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29397553.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26995614\/","id":"26995614","publisher":"O'Reilly Japan, Inc.","isbn10":"4873117585","isbn13":"9784873117584","title":"ゼロから作るDeep Learning","url":"https:\/\/api.douban.com\/v2\/book\/26995614","alt_title":"","author_intro":"","summary":"ディープラーニングの本格的な入門書。外部のライブラリに頼らずに、Python 3によってゼロからディープラーニングを作ることで、ディープラーニングの原理を楽しく学びます。ディープラーニングやニューラルネットワークの基礎だけでなく、誤差逆伝播法や畳み込みニューラルネットワークなども実装レベルで理解できます。ハイパーパラメータの決め方や重みの初期値といった実践的なテクニック、Batch NormalizationやDropout、Adamといった最近のトレンド、自動運転や画像生成、強化学習などの応用例、さらには、なぜディープラーニングは優れているのか？ なぜ層を深くすると認識精度がよくなるのか？ といった“Why”に関する問題も取り上げます。","price":"3,672円"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Theory, Architectures, and Applications","author":[],"pubdate":"1995-2-3","tags":[{"count":1,"name":"神经网络","title":"神经网络"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"反向传播算法","title":"反向传播算法"},{"count":1,"name":"人工智能","title":"人工智能"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s7033822.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"576","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s7033822.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s7033822.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s7033822.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4756354\/","id":"4756354","publisher":"Psychology Press","isbn10":"0805812598","isbn13":"9780805812596","title":"Backpropagation","url":"https:\/\/api.douban.com\/v2\/book\/4756354","alt_title":"","author_intro":"","summary":"Composed of three sections, this book presents the most popular training algorithm for neural networks: backpropagation. The first section presents the theory and principles behind backpropagation as seen from different perspectives such as statistics, machine learning, and dynamical systems. The second presents a number of network architectures that may be designed to match the general concepts of Parallel Distributed Processing with backpropagation learning. Finally, the third section shows how these principles can be applied to a number of different fields related to the cognitive sciences, including control, speech recognition, robotics, image processing, and cognitive psychology. The volume is designed to provide both a solid theoretical foundation and a set of examples that show the versatility of the concepts. Useful to experts in the field, it should also be most helpful to students seeking to understand the basic principles of connectionist learning and to engineers wanting to add neural networks in general -- and backpropagation in particular -- to their set of problem-solving methods.","price":"USD 90.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Use scikit-learn, TensorFlow, and Keras to create intelligent systems and machine learning solutions","author":["Alex Galea","Luis Capelo"],"pubdate":"2018-8-31","tags":[{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29919762.jpg","binding":"平装","translator":[],"catalog":"Table of Contents\n1. Jupyter Fundamentals\n2. Data Cleaning and Advanced Machine Learning\n3. Web Scraping and Interactive Visualizations\n4. Introduction to Neural Networks and Deep Learning\n5. Model Architecture\n6. Model Evaluation\n7. Productization","pages":"334","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29919762.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29919762.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29919762.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30375509\/","id":"30375509","publisher":"Packt Publishing","isbn10":"1789804744","isbn13":"9781789804744","title":"Applied Deep Learning with Python","url":"https:\/\/api.douban.com\/v2\/book\/30375509","alt_title":"","author_intro":"","summary":"A hands-on guide to deep learning that’s filled with intuitive explanations and engaging practical examples\nKey Features\n* Designed to iteratively develop the skills of Python users who don’t have a data science background\n* Covers the key foundational concepts you’ll need to know when building deep learning systems\n* Full of step-by-step exercises and activities to help build the skills that you need for the real-world\nBook Description\nTaking an approach that uses the latest developments in the Python ecosystem, you’ll first be guided through the Jupyter ecosystem, key visualization libraries and powerful data sanitization techniques before we train our first predictive model. We’ll explore a variety of approaches to classification like support vector networks, random decision forests and k-nearest neighbours to build out your understanding before we move into more complex territory. It’s okay if these terms seem overwhelming; we’ll show you how to put them to work.\nWe’ll build upon our classification coverage by taking a quick look at ethical web scraping and interactive visualizations to help you professionally gather and present your analysis. It’s after this that we start building out our keystone deep learning application, one that aims to predict the future price of Bitcoin based on historical public data.\nBy guiding you through a trained neural network, we’ll explore common deep learning network architectures (convolutional, recurrent, generative adversarial) and branch out into deep reinforcement learning before we dive into model optimization and evaluation. We’ll do all of this whilst working on a production-ready web application that combines Tensorflow and Keras to produce a meaningful user-friendly result, leaving you with all the skills you need to tackle and develop your own real-world deep learning projects confidently and effectively.\nWhat you will learn\n* Discover how you can assemble and clean your very own datasets\n* Develop a tailored machine learning classification strategy\n* Build, train and enhance your own models to solve unique problems\n* Work with production-ready frameworks like Tensorflow and Keras\n* Explain how neural networks operate in clear and simple terms\n* Understand how to deploy your predictions to the web\nWho this book is for\nIf you're a Python programmer stepping into the world of data science, this is the ideal way to get started.","price":"USD 44.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Building a Deep Learning Model with TensorFlow","author":["Hisham El-Amir","Mahmoud Hamdy"],"pubdate":"2020","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33507456.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"522","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s33507456.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s33507456.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s33507456.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34869504\/","id":"34869504","publisher":"Apress","isbn10":"1484253485","isbn13":"9781484253489","title":"Deep Learning Pipeline","url":"https:\/\/api.douban.com\/v2\/book\/34869504","alt_title":"","author_intro":"","summary":"","price":""}]}
